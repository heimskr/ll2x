.section .rodata
.align 8
.str:
.ascii "1\000"

.section .rodata
.align 8
.str.1:
.ascii "g_106 = %x, g_91 = %x, g_5 = %x, g_2 = %x, context = %x\012\000"

.section .rodata
.align 8
.str.10:
.ascii "g_119\000"

.section .rodata
.align 8
.str.100:
.ascii "g_1932\000"

.section .rodata
.align 8
.str.101:
.ascii "g_1933[i]\000"

.section .rodata
.align 8
.str.102:
.ascii "g_1934\000"

.section .rodata
.align 8
.str.103:
.ascii "g_1935\000"

.section .rodata
.align 8
.str.104:
.ascii "g_1936\000"

.section .rodata
.align 8
.str.105:
.ascii "g_1937\000"

.section .rodata
.align 8
.str.106:
.ascii "g_1938\000"

.section .rodata
.align 8
.str.107:
.ascii "g_1939\000"

.section .rodata
.align 8
.str.108:
.ascii "g_1940\000"

.section .rodata
.align 8
.str.109:
.ascii "g_1941\000"

.section .rodata
.align 8
.str.11:
.ascii "g_120\000"

.section .rodata
.align 8
.str.110:
.ascii "g_1942[i][j][k]\000"

.section .rodata
.align 8
.str.111:
.ascii "g_1943\000"

.section .rodata
.align 8
.str.112:
.ascii "g_1944[i]\000"

.section .rodata
.align 8
.str.113:
.ascii "g_1945[i]\000"

.section .rodata
.align 8
.str.114:
.ascii "g_1946\000"

.section .rodata
.align 8
.str.115:
.ascii "g_1947\000"

.section .rodata
.align 8
.str.116:
.ascii "g_1948\000"

.section .rodata
.align 8
.str.117:
.ascii "g_2024.f0\000"

.section .rodata
.align 8
.str.118:
.ascii "g_2072\000"

.section .rodata
.align 8
.str.119:
.ascii "g_2186\000"

.section .rodata
.align 8
.str.12:
.ascii "g_124\000"

.section .rodata
.align 8
.str.120:
.ascii "g_2199.f0\000"

.section .rodata
.align 8
.str.121:
.ascii "g_2324[i][j]\000"

.section .rodata
.align 8
.str.122:
.ascii "index = [%d][%d]\012\000"

.section .rodata
.align 8
.str.123:
.ascii "g_2354\000"

.section .rodata
.align 8
.str.124:
.ascii "g_2382\000"

.section .rodata
.align 8
.str.125:
.ascii "g_2427[i][j].f0\000"

.section .rodata
.align 8
.str.126:
.ascii "g_2519\000"

.section .rodata
.align 8
.str.127:
.ascii "g_2599\000"

.section .rodata
.align 8
.str.128:
.ascii "g_5<0> = 0x%x\012\000"

.section .rodata
.align 8
.str.129:
.ascii "g_5<1> = 0x%x\012\000"

.section .rodata
.align 8
.str.13:
.ascii "g_132.f0\000"

.section .rodata
.align 8
.str.134:
.ascii "...checksum after hashing %s : %lX\012\000"

.section .rodata
.align 8
.str.137:
.ascii "checksum = %X\012\000"

.section .rodata
.align 8
.str.14:
.ascii "g_137\000"

.section .rodata
.align 8
.str.15:
.ascii "g_203\000"

.section .rodata
.align 8
.str.16:
.ascii "g_232[i]\000"

.section .rodata
.align 8
.str.17:
.ascii "index = [%d]\012\000"

.section .rodata
.align 8
.str.18:
.ascii "g_245\000"

.section .rodata
.align 8
.str.19:
.ascii "g_246\000"

.section .rodata
.align 8
.str.2:
.ascii "func_1() = %d\012\000"

.section .rodata
.align 8
.str.20:
.ascii "g_247\000"

.section .rodata
.align 8
.str.21:
.ascii "g_259\000"

.section .rodata
.align 8
.str.22:
.ascii "g_265\000"

.section .rodata
.align 8
.str.23:
.ascii "g_294\000"

.section .rodata
.align 8
.str.24:
.ascii "g_338\000"

.section .rodata
.align 8
.str.25:
.ascii "g_367.f0\000"

.section .rodata
.align 8
.str.26:
.ascii "index = [%d], value = %x\012\000"

.section .rodata
.align 8
.str.27:
.ascii "g_422[i]\000"

.section .rodata
.align 8
.str.28:
.ascii "g_445.f0\000"

.section .rodata
.align 8
.str.29:
.ascii "g_449[i]\000"

.section .rodata
.align 8
.str.3:
.ascii "g_2\000"

.section .rodata
.align 8
.str.30:
.ascii "g_453.f0\000"

.section .rodata
.align 8
.str.31:
.ascii "g_455.f0\000"

.section .rodata
.align 8
.str.32:
.ascii "g_648\000"

.section .rodata
.align 8
.str.33:
.ascii "g_651\000"

.section .rodata
.align 8
.str.34:
.ascii "g_693.f0\000"

.section .rodata
.align 8
.str.35:
.ascii "g_695\000"

.section .rodata
.align 8
.str.36:
.ascii "g_862\000"

.section .rodata
.align 8
.str.37:
.ascii "g_1175\000"

.section .rodata
.align 8
.str.38:
.ascii "g_1221\000"

.section .rodata
.align 8
.str.39:
.ascii "g_1335\000"

.section .rodata
.align 8
.str.4:
.ascii "g_5\000"

.section .rodata
.align 8
.str.40:
.ascii "g_1357.f0\000"

.section .rodata
.align 8
.str.41:
.ascii "g_1391.f0\000"

.section .rodata
.align 8
.str.42:
.ascii "g_1487\000"

.section .rodata
.align 8
.str.43:
.ascii "g_1499\000"

.section .rodata
.align 8
.str.44:
.ascii "g_1554[i][j][k]\000"

.section .rodata
.align 8
.str.45:
.ascii "index = [%d][%d][%d]\012\000"

.section .rodata
.align 8
.str.46:
.ascii "g_1650.f0\000"

.section .rodata
.align 8
.str.47:
.ascii "g_1712\000"

.section .rodata
.align 8
.str.48:
.ascii "g_1717[i].f0\000"

.section .rodata
.align 8
.str.49:
.ascii "g_1877\000"

.section .rodata
.align 8
.str.5:
.ascii "g_91\000"

.section .rodata
.align 8
.str.50:
.ascii "g_1883\000"

.section .rodata
.align 8
.str.51:
.ascii "g_1884\000"

.section .rodata
.align 8
.str.52:
.ascii "g_1885\000"

.section .rodata
.align 8
.str.53:
.ascii "g_1886\000"

.section .rodata
.align 8
.str.54:
.ascii "g_1887\000"

.section .rodata
.align 8
.str.55:
.ascii "g_1888\000"

.section .rodata
.align 8
.str.56:
.ascii "g_1889[i]\000"

.section .rodata
.align 8
.str.57:
.ascii "g_1890\000"

.section .rodata
.align 8
.str.58:
.ascii "g_1891\000"

.section .rodata
.align 8
.str.59:
.ascii "g_1892[i]\000"

.section .rodata
.align 8
.str.6:
.ascii "g_106\000"

.section .rodata
.align 8
.str.60:
.ascii "g_1893[i]\000"

.section .rodata
.align 8
.str.61:
.ascii "g_1894[i]\000"

.section .rodata
.align 8
.str.62:
.ascii "g_1895\000"

.section .rodata
.align 8
.str.63:
.ascii "g_1896\000"

.section .rodata
.align 8
.str.64:
.ascii "g_1897\000"

.section .rodata
.align 8
.str.65:
.ascii "g_1898\000"

.section .rodata
.align 8
.str.66:
.ascii "g_1899\000"

.section .rodata
.align 8
.str.67:
.ascii "g_1900[i]\000"

.section .rodata
.align 8
.str.68:
.ascii "g_1901\000"

.section .rodata
.align 8
.str.69:
.ascii "g_1902\000"

.section .rodata
.align 8
.str.7:
.ascii "g_107\000"

.section .rodata
.align 8
.str.70:
.ascii "g_1903\000"

.section .rodata
.align 8
.str.71:
.ascii "g_1904\000"

.section .rodata
.align 8
.str.72:
.ascii "g_1905\000"

.section .rodata
.align 8
.str.73:
.ascii "g_1906\000"

.section .rodata
.align 8
.str.74:
.ascii "g_1907\000"

.section .rodata
.align 8
.str.75:
.ascii "g_1908\000"

.section .rodata
.align 8
.str.76:
.ascii "g_1909\000"

.section .rodata
.align 8
.str.77:
.ascii "g_1910\000"

.section .rodata
.align 8
.str.78:
.ascii "g_1911\000"

.section .rodata
.align 8
.str.79:
.ascii "g_1912\000"

.section .rodata
.align 8
.str.8:
.ascii "g_117\000"

.section .rodata
.align 8
.str.80:
.ascii "g_1913\000"

.section .rodata
.align 8
.str.81:
.ascii "g_1914\000"

.section .rodata
.align 8
.str.82:
.ascii "g_1915\000"

.section .rodata
.align 8
.str.83:
.ascii "g_1916[i]\000"

.section .rodata
.align 8
.str.84:
.ascii "g_1917\000"

.section .rodata
.align 8
.str.85:
.ascii "g_1918\000"

.section .rodata
.align 8
.str.86:
.ascii "g_1919\000"

.section .rodata
.align 8
.str.87:
.ascii "g_1920\000"

.section .rodata
.align 8
.str.88:
.ascii "g_1921\000"

.section .rodata
.align 8
.str.89:
.ascii "index = [%d][%d], value = %X\012\000"

.section .rodata
.align 8
.str.9:
.ascii "g_118\000"

.section .rodata
.align 8
.str.90:
.ascii "g_1922[i][j]\000"

.section .rodata
.align 8
.str.91:
.ascii "g_1923\000"

.section .rodata
.align 8
.str.92:
.ascii "g_1924\000"

.section .rodata
.align 8
.str.93:
.ascii "g_1925\000"

.section .rodata
.align 8
.str.94:
.ascii "g_1926\000"

.section .rodata
.align 8
.str.95:
.ascii "g_1927\000"

.section .rodata
.align 8
.str.96:
.ascii "g_1928\000"

.section .rodata
.align 8
.str.97:
.ascii "g_1929\000"

.section .rodata
.align 8
.str.98:
.ascii "g_1930\000"

.section .rodata
.align 8
.str.99:
.ascii "g_1931\000"

.section .data
.align 8
_ZL13crc32_context:
.int -1

.section .data
.align 8
_ZL3g_2:
.int 321396001

.section .data
.align 8
_ZL3g_5:
.int -440236594

.section .data
.align 8
_ZL4g_66:
.int 7

.section .data
.align 8
_ZL4g_91:
.byte -89

.section .data
.align 8
_ZL5g_106:
.word 4

.section .data
.align 8
_ZL5g_107:
.int 1420364725

.section .data
.align 8
_ZL5g_117:
.word 26209

.section .data
.align 8
_ZL5g_118:
.int -9

.section .data
.align 8
_ZL5g_119:
.int 960066178

.section .data
.align 8
_ZL5g_120:
.word -10

.section .data
.align 8
_ZL5g_124:
.word 17554

.section .data
.align 8
_ZL5g_132:
.word 1

.section .data
.align 8
_ZL5g_139:
.quad _ZL5g_140

.section .data
.align 8
_ZL5g_140:
.quad _ZL3g_5

.section .data
.align 8
_ZL5g_149:
.quad 5
.quad 5
.quad 5
.quad 5
.quad 5
.quad 5
.quad 5
.quad 5

.section .data
.align 8
_ZL5g_150:
.quad _ZL5g_149+8

.section .data
.align 8
_ZL5g_203:
.byte -5

.section .rodata
.align 8
_ZL5g_232:
.ascii "\321\321\321\321\321"

.section .data
.align 8
_ZL5g_245:
.quad 3

.section .data
.align 8
_ZL5g_246:
.int -439009062

.section .data
.align 8
_ZL5g_247:
.word 9

.section .data
.align 8
_ZL5g_259:
.byte 5

.section .data
.align 8
_ZL5g_265:
.word -1

.section .data
.align 8
_ZL5g_294:
.int -275451831

.section .data
.align 8
_ZL5g_313:
.word -29162

.section .data
.align 8
_ZL5g_337:
.quad _ZL5g_338

.section .data
.align 8
_ZL5g_338:
.quad 0

.section .data
.align 8
_ZL5g_365:
.quad _ZL5g_366

.section .data
.align 8
_ZL5g_366:
.quad _ZL5g_367

.section .data
.align 8
_ZL5g_367:
.word 12039

.section .data
.align 8
_ZL5g_422:
.int 582490830
.int 582490830
.int 582490830
.int 582490830
.int 582490830
.int 582490830

.section .data
.align 8
_ZL5g_445:
.byte -1
.fill 1, 1, 0

.section .data
.align 8
_ZL5g_448:
.quad _ZL5g_449+12

.section .data
.align 8
_ZL5g_449:
.int -1622083099
.int -1622083099
.int -2069577285
.int -1622083099
.int -1622083099
.int -2069577285
.int -1622083099
.int -1622083099
.int -2069577285
.int -1622083099

.section .data
.align 8
_ZL5g_452:
.quad _ZL5g_453

.section .data
.align 8
_ZL5g_453:
.word 19720

.section .data
.align 8
_ZL5g_455:
.word -14156

.section .data
.align 8
_ZL5g_648:
.byte 99

.section .data
.align 8
_ZL5g_651:
.word -1

.section .data
.align 8
_ZL5g_652:
.quad _ZL5g_653

.section .data
.align 8
_ZL5g_653:
.quad _ZL5g_654

.section .data
.align 8
_ZL5g_654:
.quad _ZL5g_655

.section .data
.align 8
_ZL5g_655:
.fill 8, 1, 0

.section .data
.align 8
_ZL5g_666:
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667

.section .data
.align 8
_ZL5g_667:
.quad _ZL5g_668

.section .data
.align 8
_ZL5g_668:
.quad _ZL5g_132

.section .data
.align 8
_ZL5g_693:
.int 9

.section .data
.align 8
_ZL5g_695:
.int 1853746151

.section .data
.align 8
_ZL5g_744:
.int -808993188

.section .data
.align 8
_ZL5g_837:
.byte -3
.fill 1, 1, 0

.section .data
.align 8
_ZL5g_862:
.quad 7

.section .data
.align 8
_ZL6g_1117:
.fill 8, 1, 0

.section .data
.align 8
_ZL6g_1175:
.word 2099

.section .data
.align 8
_ZL6g_1221:
.quad -1

.section .data
.align 8
_ZL6g_1335:
.byte -1

.section .data
.align 8
_ZL6g_1357:
.int -2133451005

.section .data
.align 8
_ZL6g_1391:
.byte -94
.fill 1, 1, 0

.section .data
.align 8
_ZL6g_1487:
.quad 0

.section .data
.align 8
_ZL6g_1499:
.int -1986020263

.section .data
.align 8
_ZL6g_1554:
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947

.section .data
.align 8
_ZL6g_1650:
.word 5215

.section .data
.align 8
_ZL6g_1680:
.quad _ZL6g_1681

.section .data
.align 8
_ZL6g_1681:
.quad _ZL6g_1682

.section .data
.align 8
_ZL6g_1682:
.quad _ZL5g_448

.section .data
.align 8
_ZL6g_1717:
.word -7
.word -7
.word -7
.word -7
.word -7
.word -7
.word -7
.word -7

.section .data
.align 8
_ZL6g_1877:
.int -497869374

.section .data
.align 8
_ZL6g_1883:
.int 1102553480

.section .data
.align 8
_ZL6g_1884:
.int 0

.section .data
.align 8
_ZL6g_1885:
.int 1

.section .data
.align 8
_ZL6g_1886:
.int 861366921

.section .data
.align 8
_ZL6g_1887:
.int -1

.section .data
.align 8
_ZL6g_1888:
.int 25839817

.section .data
.align 8
_ZL6g_1889:
.int 3
.int 3
.int 3
.int 3
.int 3
.int 3
.int 3
.int 3
.int 3
.int 3

.section .data
.align 8
_ZL6g_1890:
.int 7

.section .data
.align 8
_ZL6g_1891:
.int -1155024305

.section .data
.align 8
_ZL6g_1892:
.int 9
.int 9
.int 9
.int 9
.int 9

.section .data
.align 8
_ZL6g_1893:
.int 1
.int -1
.int -1
.int 1
.int -1
.int -1
.int 1

.section .data
.align 8
_ZL6g_1894:
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1

.section .data
.align 8
_ZL6g_1895:
.int -387690135

.section .data
.align 8
_ZL6g_1896:
.int 1

.section .data
.align 8
_ZL6g_1897:
.int -9

.section .data
.align 8
_ZL6g_1898:
.int -876145449

.section .data
.align 8
_ZL6g_1899:
.int -10

.section .data
.align 8
_ZL6g_1900:
.int -3
.int -3
.int -3

.section .data
.align 8
_ZL6g_1901:
.int -630089068

.section .data
.align 8
_ZL6g_1902:
.int -5

.section .data
.align 8
_ZL6g_1903:
.int -1359504650

.section .data
.align 8
_ZL6g_1904:
.int 1

.section .data
.align 8
_ZL6g_1905:
.int -5

.section .data
.align 8
_ZL6g_1906:
.int 0

.section .data
.align 8
_ZL6g_1907:
.int -1343935289

.section .data
.align 8
_ZL6g_1908:
.int -1278937823

.section .data
.align 8
_ZL6g_1909:
.int -8

.section .data
.align 8
_ZL6g_1910:
.int -10

.section .data
.align 8
_ZL6g_1911:
.int -1

.section .data
.align 8
_ZL6g_1912:
.int 7

.section .data
.align 8
_ZL6g_1913:
.int -4

.section .data
.align 8
_ZL6g_1914:
.int 955858442

.section .data
.align 8
_ZL6g_1915:
.int -6

.section .data
.align 8
_ZL6g_1916:
.int -11587196

.section .data
.align 8
_ZL6g_1917:
.int 7

.section .data
.align 8
_ZL6g_1918:
.int 116031467

.section .data
.align 8
_ZL6g_1919:
.int -1502158191

.section .data
.align 8
_ZL6g_1920:
.int 0

.section .data
.align 8
_ZL6g_1921:
.int -2000127066

.section .data
.align 8
_ZL6g_1922:
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1

.section .data
.align 8
_ZL6g_1923:
.int -1

.section .data
.align 8
_ZL6g_1924:
.int -1469769669

.section .data
.align 8
_ZL6g_1925:
.int -2

.section .data
.align 8
_ZL6g_1926:
.int -1

.section .data
.align 8
_ZL6g_1927:
.int 3

.section .data
.align 8
_ZL6g_1928:
.int 1948184196

.section .data
.align 8
_ZL6g_1929:
.int 2015585424

.section .data
.align 8
_ZL6g_1930:
.int 1431763380

.section .data
.align 8
_ZL6g_1931:
.int -199081461

.section .data
.align 8
_ZL6g_1932:
.int -1664503428

.section .data
.align 8
_ZL6g_1933:
.int 1836494699
.int 1836494699
.int 1836494699
.int 1836494699
.int 1836494699
.int 1836494699
.int 1836494699
.int 1836494699

.section .data
.align 8
_ZL6g_1934:
.int 1

.section .data
.align 8
_ZL6g_1935:
.int -1613090230

.section .data
.align 8
_ZL6g_1936:
.int 5

.section .data
.align 8
_ZL6g_1937:
.int -4

.section .data
.align 8
_ZL6g_1938:
.int -1753196125

.section .data
.align 8
_ZL6g_1939:
.int 1075735522

.section .data
.align 8
_ZL6g_1940:
.int 280916863

.section .data
.align 8
_ZL6g_1941:
.int 1669581321

.section .data
.align 8
_ZL6g_1942:
.int 1259935042
.int 1259935042
.int -1716021877
.int -6
.int 883023951
.int -6
.int 8
.int 4
.int 0
.int -6
.int 0
.int 8
.int -1
.int -6
.int 0
.int 4
.int -6
.int -6
.int 0
.int -1090100040
.int 1624602653
.int 8
.int 68931085
.int -1716021877
.int -905327648
.int -1817676719
.int -1317224659
.int 3
.int 0
.int -1259378644
.int 1259935042
.int -7
.int 1405156444
.int 446402858
.int 1
.int -6
.int -1471432512
.int 2
.int 1213796766
.int 8
.int -6
.int 883023951
.int -6
.int 446402858
.int 2
.int -1
.int 0
.int 365379932
.int 1387306853
.int 0
.int 1387306853
.int 2022890936
.int 446402858
.int -1817676719
.int 3
.int 0
.int -578629847
.int 887108380
.int -10
.int -1817676719
.int 1405156444
.int -905327648
.int -10
.int 652681088
.int -578629847
.int 1387306853
.int 3
.int 8
.int 446402858
.int 0
.int 1387306853
.int 1
.int 1387306853
.int 1
.int 0
.int 1405156444
.int 2
.int -578629847
.int -6
.int 1213796766
.int -6
.int -1817676719
.int 1213796766
.int 245270828
.int -1471432512
.int 0
.int 1
.int -9
.int 1405156444
.int 652681088
.int 1259935042
.int -1
.int 0
.int 1624602653
.int -1317224659
.int 8
.int -905327648
.int 68931085
.int 68931085
.int -905327648
.int 1624602653
.int 4
.int 0
.int 6
.int -6
.int -1471432512
.int 0
.int -1317224659
.int -1
.int -1817676719
.int 0
.int -1317224659
.int 0
.int -1471432512
.int 8
.int 6
.int 1405156444
.int 4
.int -1
.int -905327648
.int 8
.int 68931085
.int -1716021877
.int 8
.int 652681088
.int 1624602653
.int 883023951
.int -1

.section .data
.align 8
_ZL6g_1943:
.int -6

.section .data
.align 8
_ZL6g_1944:
.int 692300518
.int 1270180300
.int 4
.int 4
.int 1270180300
.int 692300518
.int 1270180300
.int 4
.int 4
.int 1270180300

.section .data
.align 8
_ZL6g_1945:
.int 53127161
.int -112896984
.int -112896984
.int 53127161
.int -112896984
.int -112896984
.int 53127161

.section .data
.align 8
_ZL6g_1946:
.int -707239258

.section .data
.align 8
_ZL6g_1947:
.int 1

.section .data
.align 8
_ZL6g_1948:
.int -2129396774

.section .data
.align 8
_ZL6g_2024:
.int 9

.section .data
.align 8
_ZL6g_2025:
.fill 8, 1, 0

.section .data
.align 8
_ZL6g_2072:
.int -5

.section .data
.align 8
_ZL6g_2175:
.fill 8, 1, 0

.section .data
.align 8
_ZL6g_2186:
.quad -7849629611674676947

.section .data
.align 8
_ZL6g_2199:
.word 15412

.section .data
.align 8
_ZL6g_2324:
.int 846055261
.int 846055261
.int 846055261
.int 846055261
.int 846055261

.section .data
.align 8
_ZL6g_2354:
.int 0

.section .data
.align 8
_ZL6g_2357:
.quad _ZL5g_149+56

.section .data
.align 8
_ZL6g_2364:
.quad _ZL6g_2365

.section .data
.align 8
_ZL6g_2365:
.fill 8, 1, 0

.section .data
.align 8
_ZL6g_2382:
.int -673340876

.section .data
.align 8
_ZL6g_2423:
.quad _ZL6g_2424

.section .data
.align 8
_ZL6g_2424:
.quad _ZL6g_2425

.section .data
.align 8
_ZL6g_2425:
.quad _ZL6g_2426

.section .data
.align 8
_ZL6g_2426:
.quad _ZL6g_2427+14

.section .data
.align 8
_ZL6g_2427:
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506

.section .data
.align 8
_ZL6g_2504:
.quad _ZL6g_2505

.section .data
.align 8
_ZL6g_2505:
.quad _ZL5g_124

.section .data
.align 8
_ZL6g_2519:
.word 1

.section .data
.align 8
_ZL6g_2599:
.word 1

.section .data
.align 8
_ZL9crc32_tab:
.fill 1024, 1, 0

.section .data
.align 8
__const._ZL6func_1v.l_1138:
.word 19532
.word 19532
.word 1
.word -18216
.word -3
.word -23628
.word -1
.word -21420
.word -10934
.fill 2, 1, 0
.word 19532
.word -1
.word 1
.word -18216
.word 1
.word -1
.word -1
.word -1
.word -8
.fill 2, 1, 0
.word -1
.word 19532
.word 1
.word -22925
.word -3
.word -1
.word -23628
.word -21420
.word -8
.word -21420
.word 19532
.word 19532
.word 1
.word -18216
.word -3
.word -23628
.word -1
.word -21420
.word -10934
.fill 2, 1, 0
.word 19532
.word -1
.word 1
.word -18216
.word 1
.word -1
.word -1
.word -1
.word -8
.fill 2, 1, 0
.word -1
.word 19532
.word 1
.word -22925
.word -3
.word -1
.word -23628
.word -21420
.word -8
.word -21420

.section .data
.align 8
__const._ZL6func_1v.l_2300:
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422

.section .data
.align 8
__const._ZL6func_1v.l_2323:
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245

.section .data
.align 8
__const._ZL6func_1v.l_2393:
.int -1
.int -1
.int -1
.int -1

.section .data
.align 8
__const._ZL6func_1v.l_2398:
.ascii "\370\200\370\377\370\200\370"
.ascii "p\374\374p\001\000\000"
.ascii "\377\200\366\200\377\200\366"
.ascii "\001p\374\374p\001\000"
.ascii "\370\377\370\200\370\377\370"

.section .data
.align 8
__const._ZL6func_1v.l_2419:
.word 24610
.fill 2, 1, 0
.word 24610
.fill 2, 1, 0

.section .data
.align 8
__const._ZL6func_1v.l_2420:
.word 1

.section .data
.align 8
__const._ZL6func_1v.l_2431:
.int -1
.int 1
.int -1
.int -9
.int -9
.int -1
.int 1
.int -1458929281
.int -2037217862
.int 1
.int 1
.int -2037217862
.int -1458929281
.int -2037217862
.int -1
.int -9
.int -9
.int -1
.int 1
.int -1
.int -9

.section .data
.align 8
__const._ZL6func_1v.l_2438:
.word -27195

.section .data
.align 8
__const._ZL6func_1v.l_2445:
.quad -3917657813870140125
.quad 3849861353668823529
.quad 0
.quad 6766247232868170495
.quad 8
.quad -3917657813870140125
.quad -728465569216903947
.quad -8166104977095878231
.quad -8166104977095878231
.quad -728465569216903947
.quad -3917657813870140125
.quad -728465569216903947
.quad -8166104977095878231
.quad -8166104977095878231
.quad -728465569216903947
.quad -3917657813870140125
.quad 8
.quad 6766247232868170495
.quad 0
.quad 3849861353668823529
.quad -3917657813870140125
.quad 8
.quad 6766247232868170495
.quad 0
.quad 3849861353668823529
.quad -3917657813870140125
.quad 4
.quad -8381085126885076989
.quad -8215331073916930251
.quad 3147099856984416980
.quad -3917657813870140125
.quad 4
.quad -8381085126885076989
.quad -8215331073916930251
.quad 3147099856984416980
.quad -3917657813870140125
.quad 3147099856984416980
.quad -8215331073916930251
.quad -8381085126885076989
.quad 4
.quad -3917657813870140125
.quad 3147099856984416980
.quad -8215331073916930251
.quad -8381085126885076989
.quad 4
.quad -3917657813870140125
.quad 3849861353668823529
.quad 0
.quad 6766247232868170495
.quad 8

.section .data
.align 8
__const._ZL6func_1v.l_2462:
.int -939128380
.int -1436823455
.int -939128380
.int -10
.int -10
.int -939128380
.int -1436823455
.int -939128380
.int -10
.int -10

.section .data
.align 8
__const._ZL6func_1v.l_2475:
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0

.section .data
.align 8
__const._ZL6func_1v.l_2541:
.int -1626403490
.int -1626403490
.int 268188372
.int -822529915
.int 268188372
.int -1626403490
.int -1626403490
.int 268188372
.int 100689136
.int 268188372
.int 268188372
.int 100689136
.int -1183618212
.int 100689136
.int 268188372
.int 268188372
.int 268188372
.int -1183618212
.int -822529915
.int -822529915
.int -1183618212
.int 268188372
.int -1183618212
.int -822529915
.int 100689136
.int -1183618212
.int 100689136
.int 268188372
.int 268188372
.int 100689136
.int -1183618212
.int 100689136
.int -1626403490
.int 268188372
.int -822529915
.int 268188372
.int -1626403490
.int -1626403490
.int 268188372
.int -822529915
.int -1626403490
.int -1626403490
.int 268188372
.int -822529915
.int 268188372
.int -1626403490
.int 268188372
.int 100689136
.int -822529915
.int 100689136
.int 100689136
.int -822529915
.int -1626403490
.int -822529915
.int 100689136
.int 100689136

.section .data
.align 8
__const._ZL6func_1v.l_2552:
.int 1
.int 1323863556
.int 1
.int 1
.int 1323863556
.int 1
.int 1
.int 1323863556

.section .data
.align 8
__const._ZL6func_1v.l_2564:
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_313
.fill 8, 1, 0
.quad _ZL5g_313
.quad _ZL5g_313
.fill 8, 1, 0
.quad _ZL5g_313
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_313
.fill 8, 1, 0
.quad _ZL5g_313
.quad _ZL5g_313
.fill 8, 1, 0
.quad _ZL5g_313
.quad _ZL5g_313

.section .data
.align 8
__const._ZL6func_1v.l_2573:
.word 24992

.section .data
.align 8
__const._ZL6func_1v.l_2605:
.word -25579

.section .data
.align 8
__const._ZL7func_39i2U0j.l_65:
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66

.section .data
.align 8
__const._ZL7func_39i2U0j.l_692:
.fill 2, 1, 0
.word -963
.word -963
.fill 2, 1, 0
.word -963
.word -963

.section .data
.align 8
__const._ZL7func_39i2U0j.l_694:
.quad _ZL3g_5
.quad _ZL3g_5
.quad _ZL5g_149+56
.quad _ZL3g_2
.quad _ZL5g_149+56
.quad _ZL3g_5
.quad _ZL3g_5
.quad _ZL5g_149+56
.quad _ZL3g_2
.quad _ZL5g_149+56

.section .data
.align 8
__const._ZL7func_532U1.l_659:
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_365
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_365
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_365

.section .data
.align 8
__const._ZL7func_532U1.l_665:
.quad -8650298959325932638
.quad -3
.quad -8650298959325932638
.quad -3
.quad -8650298959325932638
.quad -3
.quad -8650298959325932638
.quad -3
.quad -8650298959325932638
.quad -3

.section .data
.align 8
__const._ZL7func_532U1.l_672:
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667

.section .data
.align 8
__const._ZL7func_532U1.l_681:
.int 1646807761
.int 1646807761
.int 1646807761
.int 1646807761

.section .data
.align 8
__const._ZL7func_532U1.l_689:
.word -6
.word -24617
.word -24617
.word -6
.word -24617
.word -24617
.word -6

.section .data
.align 8
__const._ZL7func_57majs2U2.l_102:
.quad -7965347547192635289
.quad -1
.quad 8687842191135717611
.quad 8687842191135717611
.quad 6304065726303921533
.quad 6304065726303921533
.quad 8687842191135717611
.quad 0
.quad -7965347547192635289
.quad 1
.quad 6793063423703358781
.quad -1
.quad 6
.quad 6793063423703358781
.quad 0
.quad 6793063423703358781
.quad 0
.quad 6793063423703358781
.quad 6
.quad -1
.quad 6793063423703358781
.quad 1
.quad -7965347547192635289
.quad 0
.quad 8687842191135717611
.quad 6304065726303921533
.quad 6304065726303921533
.quad 8687842191135717611
.quad 8687842191135717611
.quad -1
.quad -7965347547192635289
.quad -2018131615923420070
.quad 6793063423703358781
.quad 8687842191135717611
.quad 6
.quad 4625240128305499996
.quad 0
.quad -6949724734613251999
.quad 0
.quad 4625240128305499996
.quad 6
.quad 8687842191135717611
.quad 6793063423703358781
.quad -2018131615923420070
.quad -7965347547192635289
.quad -1
.quad 8687842191135717611
.quad 8687842191135717611
.quad 6304065726303921533
.quad 6304065726303921533
.quad 8687842191135717611
.quad 0
.quad -7965347547192635289
.quad 1
.quad 6793063423703358781
.quad -1
.quad 6
.quad 6793063423703358781
.quad 0
.quad 6793063423703358781
.quad 0
.quad 6793063423703358781
.quad 6
.quad -1
.quad 6793063423703358781
.quad 1
.quad -7965347547192635289
.quad 0
.quad 8687842191135717611
.quad 6304065726303921533
.quad 6304065726303921533
.quad 8687842191135717611
.quad 8687842191135717611
.quad -1
.quad -7965347547192635289
.quad -2018131615923420070
.quad 6793063423703358781
.quad 8687842191135717611
.quad 6
.quad 4625240128305499996

.section .data
.align 8
__const._ZL7func_57majs2U2.l_104:
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91

.section .data
.align 8
__const._ZL7func_57majs2U2.l_116:
.int -846516339
.int -902765594
.int -846516339
.int 1
.int -5
.int 113742486
.int -4
.int 1031099311
.int 2136063165
.int -5
.int -164524034
.int -3
.int -10
.int 2136063165
.int -7
.int -5
.int -872931236
.int -2
.int -4
.int 980693711
.int 980693711
.int 1
.int -3
.int -1
.int -846516339
.int -10
.int 8
.int 0
.int -381729268
.int 780415476
.int 1
.int 1445354951
.int 1
.int 113742486
.int 1
.int 0
.int -10
.int 980693711
.int -846516339
.int -7
.int -7
.int 1
.int 1
.int 0
.int -4
.int 583556693
.int -2
.int -5
.int -4
.int 1
.int -10
.int -9
.int 583556693
.int -5
.int -7
.int 1445354951
.int -4
.int 1
.int 0
.int 1
.int -1
.int 2136063165
.int -846516339
.int -381729268
.int 427963075
.int 0
.int 2136063165
.int -10
.int 1
.int -1
.int 0
.int -3
.int 2136063165
.int 8
.int -6
.int -381729268
.int -3
.int -3
.int -1
.int 1
.int 0
.int 1
.int -1
.int -164524034
.int -7
.int 1
.int 6
.int -9
.int 1512356527
.int -7
.int -4
.int 1
.int 1
.int 583556693
.int -1
.int -381729268
.int 1
.int 1
.int 1
.int -7
.int -3
.int 113742486
.int -10
.int 8
.int -902765594
.int 113742486
.int 0
.int 583556693
.int 812717484
.int -10
.int -902765594
.int 780415476
.int 427963075
.int 113742486
.int 1
.int 2136063165
.int 1
.int -872931236
.int 0
.int -381729268
.int -846516339
.int 1445354951
.int 1
.int 0
.int 583556693
.int -7
.int 980693711
.int 1
.int 6
.int 0
.int -2
.int -164524034
.int -846516339
.int 0
.int 0
.int -872931236
.int -7
.int -3
.int 1
.int 980693711
.int -6
.int 780415476
.int 1
.int -3
.int 812717484
.int 1
.int 1
.int 113742486
.int 1
.int 0
.int -10
.int 980693711
.int -846516339
.int -7
.int -7
.int 1
.int 1
.int 0
.int -4
.int 583556693
.int -2
.int -5
.int -4
.int 1
.int -10
.int -9
.int 583556693
.int -5
.int -7
.int 1445354951
.int -4
.int 1
.int 0
.int 1
.int -1
.int 2136063165
.int -846516339
.int -381729268
.int 427963075
.int 0
.int 2136063165
.int -10
.int 1
.int -1
.int 0
.int -3
.int 2136063165
.int 8
.int -6
.int -381729268
.int -3
.int -3
.int -1
.int 1
.int 0
.int 1
.int -1
.int -164524034
.int -7
.int 1
.int 6
.int -9
.int 1512356527
.int -7
.int -4
.int 1
.int 1
.int 583556693
.int -1
.int -381729268
.int 1
.int 1
.int 1
.int -7
.int -3
.int 113742486

.section .data
.align 8
__const._ZL7func_57majs2U2.l_545:
.word 1

.section .data
.align 8
__const._ZL7func_57majs2U2.l_571:
.word 4

.section .data
.align 8
__const._ZL7func_57majs2U2.l_572:
.word 1

.section .data
.align 8
__const._ZL7func_57majs2U2.l_99:
.word -5

.section .data
.align 8
constinit:
.quad _ZL5g_259
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL5g_259
.quad _ZL4g_91

.section .data
.align 8
constinit.130:
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91

.section .data
.align 8
constinit.132:
.quad _ZL3g_2
.fill 8, 1, 0
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL3g_2

.section .data
.align 8
constinit.133:
.quad _ZL3g_2
.fill 8, 1, 0
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL3g_2

.section .text
.global _ZL10crc32_byteh
.p2align 4, 0x90
_ZL10crc32_byteh:
	.___ZL10crc32_byteh__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(6225:3): size = 1, type = i8*, var = ^2
	leaq -1(%rbp), %rax
	# LowerStore(6226:3).9: mov i8 %dil, (^2)
	movb %dil, (%rax)
	# LowerLoad(6228:3).4: _ZL13crc32_context into ^3
	movl _ZL13crc32_context(%rip), %ebx
	# LowerLshr(6229:3): ^3, 8 into i32 ^4
	shrl $8, %ebx
	# LowerLogic(6231:3): ^4, 16777215 into i32 ^5
	movl %ebx, %ecx
	andl $16777215, %ecx
	# LowerLoad(6231:3).4: _ZL13crc32_context into ^6
	movl _ZL13crc32_context(%rip), %ebx
	# LowerLoad(6232:3).2: (^2) into i8 ^7
	movb (%rax), %dl
	# LowerBasicConversion(6233:3): i8 ^7 -> i32 ^8
	# Truncate value to 8 bits
	andl $255, %edx
	# LowerLogic(6235:3): ^6, ^8 into i32 ^9
	movl %ebx, %eax
	xorl %edx, %eax
	# LowerLogic(6236:3): ^9, 255 into i32 ^10
	movl %eax, %ebx
	andl $255, %ebx
	# LowerBasicConversion(6236:3): i32 ^10 -> i64 ^11
	movq %rbx, %rdx
	leaq _ZL9crc32_tab(%rip), %rax
	# tt = Pointer, type = [256 x i32]
	# LowerGetelementptr(6237:3): array/pointer-type, dynamic index -> ^12
	# index ^11 -> temp ^16
	movq %rdx, %rbx
	# Multiply temp ^16 by 4 start
	shlq $2, %rbx
	# Multiply end
	# temp ^16 -> operand ^12
	movq %rbx, %rdx
	# Result ^12 += base pointer ^15
	addq %rax, %rdx
	# LowerLoad(6238:3).2: (^12) into i32 ^13
	movl (%rdx), %ebx
	# LowerLogic(6240:3): ^5, ^13 into i32 ^14
	movl %ecx, %eax
	xorl %ebx, %eax
	# LowerStore(6240:3).8a: leaq var, %temp
	leaq _ZL13crc32_context(%rip), %rbx
	# LowerStore(6240:3).8b: movq ^14, (%temp)
	movl %eax, (%rbx)
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_div_func_uint32_t_u_ujj
.p2align 4, 0x90
_ZL26safe_div_func_uint32_t_u_ujj:
	.___ZL26safe_div_func_uint32_t_u_ujj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(40 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4161:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rdx
	# LowerAlloca(4162:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4163:3).9: mov i32 %edi, (^3)
	movl %edi, (%rdx)
	# LowerStore(4165:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4167:3).2: (^4) into i32 ^5
	movl (%rax), %ebx
	# LowerIcmp(4168:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL26safe_div_func_uint32_t_u_ujj__M15
	jmp .___ZL26safe_div_func_uint32_t_u_ujj__M20
	.___ZL26safe_div_func_uint32_t_u_ujj__M15:
	# LowerLoad(4172:3).2: (^3) into i32 ^8
	movl (%rdx), %ecx
	# MovePhi: ^8 -> ^14
	jmp .___ZL26safe_div_func_uint32_t_u_ujj__M36
	.___ZL26safe_div_func_uint32_t_u_ujj__M20:
	# LowerLoad(4176:3).2: (^3) into i32 ^10
	movl (%rdx), %ebx
	# LowerLoad(4177:3).2: (^4) into i32 ^11
	movl (%rax), %esi
	# LowerUdiv(4178:3): ^10, ^11 into i32 ^12
	movl $0, %edx
	movl %ebx, %eax
	divl %esi
	movl %eax, %ebx
	# MovePhi: ^12 -> ^14
	movl %ebx, %ecx
	.___ZL26safe_div_func_uint32_t_u_ujj__M36:
	movl %ecx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL15transparent_crcmPci
.p2align 4, 0x90
_ZL15transparent_crcmPci:
	.___ZL15transparent_crcmPci__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(72 + 0, 16)
	subq $80, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -48(%rbp)
	movq %r12, -56(%rbp)
	# LowerAlloca(3426:3): size = 8, type = i64*, var = ^4
	leaq -8(%rbp), %rax
	# LowerAlloca(3427:3): size = 8, type = ptr*, var = ^5
	leaq -16(%rbp), %rbx
	# LowerAlloca(3428:3): size = 4, type = i32*, var = ^6
	leaq -20(%rbp), %r12
	# LowerStore(3429:3).9: mov i64 %rdi, (^4)
	movq %rdi, (%rax)
	# LowerStore(3431:3).9: mov ptr %rsi, (^5)
	movq %rsi, (%rbx)
	# LowerStore(3433:3).9: mov i32 %edx, (^6)
	movl %edx, (%r12)
	# LowerLoad(3435:3).2: (^4) into i64 ^7
	movq (%rax), %rcx
	# Clobber %rcx
	movq %rcx, -32(%rbp)
	# SetupCalls(3436:3): move argument i64 ^7
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	callq _ZL12crc32_8bytesm
	# Unclobber %rcx
	movq -32(%rbp), %rcx
	# LowerLoad(3437:3).2: (^6) into i32 ^8
	movl (%r12), %eax
	# LowerIcmp(3438:3): i32 ^8 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL15transparent_crcmPci__M42
	jmp .___ZL15transparent_crcmPci__M81
	.___ZL15transparent_crcmPci__M42:
	# LowerLoad(3442:3).2: (^5) into ptr ^11
	movq (%rbx), %rcx
	# LowerLoad(3443:3).4: _ZL13crc32_context into ^12
	movl _ZL13crc32_context(%rip), %ebx
	# LowerBasicConversion(3444:3): i32 ^12 -> i64 ^13
	# LowerLogic(3446:3): ^13, 4294967295 into i64 ^14
	movq %rbx, %rax
	movabsq $4294967295, %rbx
	xorq %rbx, %rax
	# Clobber %rcx
	movq %rcx, -32(%rbp)
	# Clobber %rax
	movq %rax, -40(%rbp)
	# SetupCalls(3446:3): move argument ptr @.str.134
	leaq .str.134(%rip), %rdi
	# SetupCalls(3446:3): move argument ptr ^11
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rsi
	# SetupCalls(3446:3): move argument i64 ^14
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(3446:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -40(%rbp), %rax
	# Unclobber %rcx
	movq -32(%rbp), %rcx
	.___ZL15transparent_crcmPci__M81:
	movq -56(%rbp), %r12
	movq -48(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_mod_func_int16_t_s_sss
.p2align 4, 0x90
_ZL25safe_mod_func_int16_t_s_sss:
	.___ZL25safe_mod_func_int16_t_s_sss__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(88 + 0, 16)
	subq $96, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4117:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rdx
	# LowerAlloca(4118:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(4119:3).9: mov i16 %di, (^3)
	movw %di, (%rdx)
	# LowerStore(4121:3).9: mov i16 %si, (^4)
	movw %si, (%rax)
	# LowerLoad(4123:3).2: (^4) into i16 ^5
	movw (%rax), %bx
	movswl %bx, %ecx
	# LowerIcmp(4125:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int16_t_s_sss__M32
	.___ZL25safe_mod_func_int16_t_s_sss__M16:
	# LowerLoad(4129:3).2: (^3) into i16 ^9
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerIcmp(4131:3): i32 ^10 vs. intlike -32768
	cmpl $-32768, %ecx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int16_t_s_sss__M24
	jmp .___ZL25safe_mod_func_int16_t_s_sss__M38
	.___ZL25safe_mod_func_int16_t_s_sss__M24:
	# LowerLoad(4135:3).2: (^4) into i16 ^13
	movw (%rax), %cx
	movswl %cx, %ebx
	# LowerIcmp(4137:3): i32 ^14 vs. intlike -1
	cmpl $-1, %ebx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int16_t_s_sss__M32
	jmp .___ZL25safe_mod_func_int16_t_s_sss__M38
	.___ZL25safe_mod_func_int16_t_s_sss__M32:
	# LowerLoad(4141:3).2: (^3) into i16 ^17
	movw (%rdx), %bx
	movswl %bx, %eax
	# MovePhi: ^18 -> ^26
	movl %eax, %r8d
	jmp .___ZL25safe_mod_func_int16_t_s_sss__M56
	.___ZL25safe_mod_func_int16_t_s_sss__M38:
	# LowerLoad(4146:3).2: (^3) into i16 ^20
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerLoad(4148:3).2: (^4) into i16 ^22
	movw (%rax), %bx
	movswl %bx, %esi
	# LowerSrem(4150:3): ^21, ^23 into i32 ^24
	movl $0, %edx
	movl %ecx, %eax
	idivl %esi
	movl %edx, %ebx
	# MovePhi: ^24 -> ^26
	movl %ebx, %r8d
	.___ZL25safe_mod_func_int16_t_s_sss__M56:
	# LowerTrunc(4155:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(4155:3): 32 to 16, apply mask
	andq $65535, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_add_func_int64_t_s_sll
.p2align 4, 0x90
_ZL25safe_add_func_int64_t_s_sll:
	.___ZL25safe_add_func_int64_t_s_sll__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(120 + 0, 16)
	subq $128, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4034:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(4035:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(4036:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(4038:3).9: mov i64 %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(4040:3).2: (^3) into i64 ^5
	movq (%rcx), %rbx
	# LowerIcmp(4041:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M15
	jmp .___ZL25safe_add_func_int64_t_s_sll__M35
	.___ZL25safe_add_func_int64_t_s_sll__M15:
	# LowerLoad(4045:3).2: (^4) into i64 ^8
	movq (%rax), %rbx
	# LowerIcmp(4046:3): i64 ^8 vs. intlike 0
	cmpq $0, %rbx
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M22
	jmp .___ZL25safe_add_func_int64_t_s_sll__M35
	.___ZL25safe_add_func_int64_t_s_sll__M22:
	# LowerLoad(4050:3).2: (^3) into i64 ^11
	movq (%rcx), %rsi
	# LowerLoad(4051:3).2: (^4) into i64 ^12
	movq (%rax), %rbx
	# LowerMath(4052:3): 9223372036854775807, ^12 into i64 ^13
	movabsq $9223372036854775807, %rdi
	movq %rdi, %rdx
	subq %rbx, %rdx
	# LowerIcmp(4053:3): i64 ^11 vs. operand i64 ^13
	cmpq %rdx, %rsi
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M62
	.___ZL25safe_add_func_int64_t_s_sll__M35:
	# LowerLoad(4057:3).2: (^3) into i64 ^16
	movq (%rcx), %rbx
	# LowerIcmp(4058:3): i64 ^16 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M42
	jmp .___ZL25safe_add_func_int64_t_s_sll__M67
	.___ZL25safe_add_func_int64_t_s_sll__M42:
	# LowerLoad(4062:3).2: (^4) into i64 ^19
	movq (%rax), %rbx
	# LowerIcmp(4063:3): i64 ^19 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M49
	jmp .___ZL25safe_add_func_int64_t_s_sll__M67
	.___ZL25safe_add_func_int64_t_s_sll__M49:
	# LowerLoad(4067:3).2: (^3) into i64 ^22
	movq (%rcx), %rbx
	# LowerLoad(4068:3).2: (^4) into i64 ^23
	movq (%rax), %rdx
	# LowerMath(4069:3): -9223372036854775808, ^23 into i64 ^24
	movabsq $-9223372036854775808, %rdi
	movq %rdi, %rsi
	subq %rdx, %rsi
	# LowerIcmp(4070:3): i64 ^22 vs. operand i64 ^24
	cmpq %rsi, %rbx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M62
	jmp .___ZL25safe_add_func_int64_t_s_sll__M67
	.___ZL25safe_add_func_int64_t_s_sll__M62:
	# LowerLoad(4074:3).2: (^3) into i64 ^27
	movq (%rcx), %r8
	# MovePhi: ^27 -> ^33
	jmp .___ZL25safe_add_func_int64_t_s_sll__M77
	.___ZL25safe_add_func_int64_t_s_sll__M67:
	# LowerLoad(4078:3).2: (^3) into i64 ^29
	movq (%rcx), %rdx
	# LowerLoad(4079:3).2: (^4) into i64 ^30
	movq (%rax), %rbx
	# LowerMath(4080:3): ^29, ^30 into i64 ^31
	movq %rdx, %rax
	addq %rbx, %rax
	# MovePhi: ^31 -> ^33
	movq %rax, %r8
	.___ZL25safe_add_func_int64_t_s_sll__M77:
	movq %r8, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_rshift_func_uint32_t_u_sji
.p2align 4, 0x90
_ZL29safe_rshift_func_uint32_t_u_sji:
	.___ZL29safe_rshift_func_uint32_t_u_sji__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3963:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(3964:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3965:3).9: mov i32 %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(3967:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3969:3).2: (^4) into i32 ^5
	movl (%rax), %ebx
	# LowerIcmp(3970:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL29safe_rshift_func_uint32_t_u_sji__M22
	.___ZL29safe_rshift_func_uint32_t_u_sji__M15:
	# LowerLoad(3974:3).2: (^4) into i32 ^8
	movl (%rax), %ebx
	# LowerIcmp(3975:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL29safe_rshift_func_uint32_t_u_sji__M22
	jmp .___ZL29safe_rshift_func_uint32_t_u_sji__M27
	.___ZL29safe_rshift_func_uint32_t_u_sji__M22:
	# LowerLoad(3979:3).2: (^3) into i32 ^11
	movl (%rcx), %edx
	# MovePhi: ^11 -> ^17
	jmp .___ZL29safe_rshift_func_uint32_t_u_sji__M39
	.___ZL29safe_rshift_func_uint32_t_u_sji__M27:
	# LowerLoad(3983:3).2: (^3) into i32 ^13
	movl (%rcx), %ebx
	# LowerLoad(3984:3).2: (^4) into i32 ^14
	movl (%rax), %ecx
	# LowerLshr(3985:3): ^13, ^14 into i32 ^15
	# LowerShift(3985:3): operand ^14 changed to %ecx
	movl %ebx, %eax
	shrl %cl, %eax
	# MovePhi: ^15 -> ^17
	movl %eax, %edx
	.___ZL29safe_rshift_func_uint32_t_u_sji__M39:
	movl %edx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL17platform_main_endji
.p2align 4, 0x90
_ZL17platform_main_endji:
	.___ZL17platform_main_endji__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(3455:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rbx
	# LowerAlloca(3456:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3457:3).9: mov i32 %edi, (^3)
	movl %edi, (%rbx)
	# LowerStore(3459:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3461:3).2: (^3) into i32 ^5
	movl (%rbx), %eax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(3462:3): move argument ptr @.str.137
	leaq .str.137(%rip), %rdi
	# SetupCalls(3462:3): move argument i32 ^5
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(3462:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -16(%rbp), %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_mul_func_uint16_t_u_utt
.p2align 4, 0x90
_ZL26safe_mul_func_uint16_t_u_utt:
	.___ZL26safe_mul_func_uint16_t_u_utt__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3744:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(3745:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(3746:3).9: mov i16 %di, (^3)
	movw %di, (%rcx)
	# LowerStore(3748:3).9: mov i16 %si, (^4)
	movw %si, (%rax)
	# LowerLoad(3750:3).2: (^3) into i16 ^5
	movw (%rcx), %bx
	# LowerBasicConversion(3751:3): i16 ^5 -> i32 ^6
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(3752:3).2: (^4) into i16 ^7
	movw (%rax), %cx
	# LowerBasicConversion(3753:3): i16 ^7 -> i32 ^8
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerMath(3754:3): ^6, ^8 into i32 ^9
	# Adjusting source operand from 32 bits to 64 bits and adjusting mov width from 64
	movq %rbx, %rax
	mull %ecx
	# Adjusting source operand from 32 bits to 64 bits and adjusting mov width from 32
	movq %rax, %rbx
	# LowerTrunc(3755:3): 32 to 16, move
	movw %bx, %ax
	# LowerTrunc(3755:3): 32 to 16, apply mask
	andq $65535, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_mul_func_int16_t_s_sss
.p2align 4, 0x90
_ZL25safe_mul_func_int16_t_s_sss:
	.___ZL25safe_mul_func_int16_t_s_sss__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4290:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(4291:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(4292:3).9: mov i16 %di, (^3)
	movw %di, (%rcx)
	# LowerStore(4294:3).9: mov i16 %si, (^4)
	movw %si, (%rax)
	# LowerLoad(4296:3).2: (^3) into i16 ^5
	movw (%rcx), %bx
	movswl %bx, %ecx
	# LowerLoad(4298:3).2: (^4) into i16 ^7
	movw (%rax), %dx
	movswl %dx, %ebx
	# LowerMath(4300:3): ^6, ^8 into i32 ^9
	# Adjusting source operand from 32 bits to 64 bits and adjusting mov width from 64
	movq %rcx, %rax
	mull %ebx
	# Adjusting source operand from 32 bits to 64 bits and adjusting mov width from 32
	movq %rax, %rbx
	# LowerTrunc(4301:3): 32 to 16, move
	movw %bx, %ax
	# LowerTrunc(4301:3): 32 to 16, apply mask
	andq $65535, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_mul_func_uint8_t_u_uhh
.p2align 4, 0x90
_ZL25safe_mul_func_uint8_t_u_uhh:
	.___ZL25safe_mul_func_uint8_t_u_uhh__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3692:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rcx
	# LowerAlloca(3693:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(3694:3).9: mov i8 %dil, (^3)
	movb %dil, (%rcx)
	# LowerStore(3696:3).9: mov i8 %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(3698:3).2: (^3) into i8 ^5
	movb (%rcx), %bl
	# LowerBasicConversion(3699:3): i8 ^5 -> i32 ^6
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(3700:3).2: (^4) into i8 ^7
	movb (%rax), %cl
	# LowerBasicConversion(3701:3): i8 ^7 -> i32 ^8
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerMath(3702:3): ^6, ^8 into i32 ^9
	# Adjusting source operand from 32 bits to 64 bits and adjusting mov width from 64
	movq %rbx, %rax
	mull %ecx
	# Adjusting source operand from 32 bits to 64 bits and adjusting mov width from 32
	movq %rax, %rbx
	# LowerTrunc(3703:3): 32 to 8, move
	movb %bl, %al
	# LowerTrunc(3703:3): 32 to 8, apply mask
	andq $255, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL12crc32_gentabv
.p2align 4, 0x90
_ZL12crc32_gentabv:
	.___ZL12crc32_gentabv__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	movq %r15, -32(%rbp)
	# LowerAlloca(1646:3): size = 4, type = i32*, var = ^1
	leaq -4(%rbp), %rbx
	# LowerAlloca(1647:3): size = 4, type = i32*, var = ^2
	leaq -8(%rbp), %rax
	# LowerAlloca(1648:3): size = 4, type = i32*, var = ^3
	leaq -12(%rbp), %rdx
	# LowerAlloca(1649:3): size = 4, type = i32*, var = ^4
	leaq -16(%rbp), %rcx
	# LowerStore(1652:3).3: mov $imm, (^2)
	movl $-306674912, (%rax)
	# LowerStore(1655:3).3: mov $imm, (^3)
	movl $0, (%rdx)
	.___ZL12crc32_gentabv__M13:
	# LowerLoad(1659:3).2: (^3) into i32 ^6
	movl (%rdx), %eax
	# LowerIcmp(1660:3): i32 ^6 vs. intlike 256
	cmpl $256, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL12crc32_gentabv__M20
	jmp .___ZL12crc32_gentabv__M100
	.___ZL12crc32_gentabv__M20:
	# LowerLoad(1664:3).2: (^3) into i32 ^9
	# Fixing source-to-dest movl (%rdx), (%rbx)
	movl (%rdx), %r15d
	movl %r15d, (%rbx)
	# LowerStore(1665:3).9: mov i32 ^9, (^1)
	# LowerStore(1666:3).3: mov $imm, (^4)
	movl $8, (%rcx)
	.___ZL12crc32_gentabv__M27:
	# LowerLoad(1670:3).2: (^4) into i32 ^11
	movl (%rcx), %eax
	# LowerIcmp(1671:3): i32 ^11 vs. intlike 0
	cmpl $0, %eax
	setg %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL12crc32_gentabv__M34
	jmp .___ZL12crc32_gentabv__M72
	.___ZL12crc32_gentabv__M34:
	# LowerLoad(1675:3).2: (^1) into i32 ^14
	movl (%rbx), %eax
	# LowerLogic(1677:3): ^14, 1 into i32 ^15
	andl $1, %eax
	# LowerIcmp(1677:3): i32 ^15 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL12crc32_gentabv__M44
	jmp .___ZL12crc32_gentabv__M55
	.___ZL12crc32_gentabv__M44:
	# LowerLoad(1681:3).2: (^1) into i32 ^18
	movl (%rbx), %eax
	# LowerLshr(1682:3): ^18, 1 into i32 ^19
	shrl $1, %eax
	# LowerLogic(1684:3): ^19, -306674912 into i32 ^20
	movl %eax, %esi
	xorl $-306674912, %esi
	# LowerStore(1684:3).9: mov i32 ^20, (^1)
	movl %esi, (%rbx)
	jmp .___ZL12crc32_gentabv__M63
	.___ZL12crc32_gentabv__M55:
	# LowerLoad(1688:3).2: (^1) into i32 ^22
	movl (%rbx), %eax
	# LowerLshr(1689:3): ^22, 1 into i32 ^23
	shrl $1, %eax
	# LowerStore(1690:3).9: mov i32 ^23, (^1)
	movl %eax, (%rbx)
	.___ZL12crc32_gentabv__M63:
	# LowerLoad(1697:3).2: (^4) into i32 ^26
	movl (%rcx), %eax
	# LowerMath(1698:3): ^26, -1 into i32 ^27
	addl $-1, %eax
	# LowerStore(1699:3).9: mov i32 ^27, (^4)
	movl %eax, (%rcx)
	jmp .___ZL12crc32_gentabv__M27
	.___ZL12crc32_gentabv__M72:
	# LowerLoad(1703:3).2: (^1) into i32 ^29
	movl (%rbx), %esi
	# LowerLoad(1704:3).2: (^3) into i32 ^30
	movl (%rdx), %eax
	movslq %eax, %rdi
	leaq _ZL9crc32_tab(%rip), %r8
	# tt = Pointer, type = [256 x i32]
	# LowerGetelementptr(1706:3): array/pointer-type, dynamic index -> ^32
	# index ^31 -> temp ^38
	movq %rdi, %r9
	# Multiply temp ^38 by 4 start
	shlq $2, %r9
	# Multiply end
	# temp ^38 -> operand ^32
	movq %r9, %rax
	# Result ^32 += base pointer ^37
	addq %r8, %rax
	# LowerStore(1707:3).9: mov i32 ^29, (^32)
	movl %esi, (%rax)
	# LowerLoad(1711:3).2: (^3) into i32 ^34
	movl (%rdx), %eax
	# LowerMath(1712:3): ^34, 1 into i32 ^35
	addl $1, %eax
	# LowerStore(1713:3).9: mov i32 ^35, (^3)
	movl %eax, (%rdx)
	jmp .___ZL12crc32_gentabv__M13
	.___ZL12crc32_gentabv__M100:
	movq -32(%rbp), %r15
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_div_func_uint16_t_u_utt
.p2align 4, 0x90
_ZL26safe_div_func_uint16_t_u_utt:
	.___ZL26safe_div_func_uint16_t_u_utt__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(40 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3660:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(3661:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(3662:3).9: mov i16 %di, (^3)
	movw %di, (%rcx)
	# LowerStore(3664:3).9: mov i16 %si, (^4)
	movw %si, (%rax)
	# LowerLoad(3666:3).2: (^4) into i16 ^5
	movw (%rax), %bx
	# LowerBasicConversion(3667:3): i16 ^5 -> i32 ^6
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerIcmp(3668:3): i32 ^6 vs. intlike 0
	cmpl $0, %ebx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL26safe_div_func_uint16_t_u_utt__M19
	jmp .___ZL26safe_div_func_uint16_t_u_utt__M28
	.___ZL26safe_div_func_uint16_t_u_utt__M19:
	# LowerLoad(3672:3).2: (^3) into i16 ^9
	movw (%rcx), %ax
	# LowerBasicConversion(3673:3): i16 ^9 -> i32 ^10
	# Truncate value to 16 bits
	andl $65535, %eax
	# MovePhi: ^10 -> ^18
	movl %eax, %r8d
	jmp .___ZL26safe_div_func_uint16_t_u_utt__M52
	.___ZL26safe_div_func_uint16_t_u_utt__M28:
	# LowerLoad(3677:3).2: (^3) into i16 ^12
	movw (%rcx), %si
	# LowerBasicConversion(3678:3): i16 ^12 -> i32 ^13
	# Truncate value to 16 bits
	andl $65535, %esi
	# LowerLoad(3679:3).2: (^4) into i16 ^14
	movw (%rax), %bx
	# LowerBasicConversion(3680:3): i16 ^14 -> i32 ^15
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerSdiv(3681:3): ^13, ^15 into i32 ^16
	movl $0, %edx
	movl %esi, %eax
	idivl %ebx
	movl %eax, %ebx
	# MovePhi: ^16 -> ^18
	movl %ebx, %r8d
	.___ZL26safe_div_func_uint16_t_u_utt__M52:
	# LowerTrunc(3686:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(3686:3): 32 to 16, apply mask
	andq $65535, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_div_func_uint64_t_u_umm
.p2align 4, 0x90
_ZL26safe_div_func_uint64_t_u_umm:
	.___ZL26safe_div_func_uint64_t_u_umm__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4217:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rdx
	# LowerAlloca(4218:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(4219:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rdx)
	# LowerStore(4221:3).9: mov i64 %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(4223:3).2: (^4) into i64 ^5
	movq (%rax), %rbx
	# LowerIcmp(4224:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL26safe_div_func_uint64_t_u_umm__M15
	jmp .___ZL26safe_div_func_uint64_t_u_umm__M20
	.___ZL26safe_div_func_uint64_t_u_umm__M15:
	# LowerLoad(4228:3).2: (^3) into i64 ^8
	movq (%rdx), %rcx
	# MovePhi: ^8 -> ^14
	jmp .___ZL26safe_div_func_uint64_t_u_umm__M36
	.___ZL26safe_div_func_uint64_t_u_umm__M20:
	# LowerLoad(4232:3).2: (^3) into i64 ^10
	movq (%rdx), %rbx
	# LowerLoad(4233:3).2: (^4) into i64 ^11
	movq (%rax), %rsi
	# LowerUdiv(4234:3): ^10, ^11 into i64 ^12
	movq $0, %rdx
	movq %rbx, %rax
	divq %rsi
	movq %rax, %rbx
	# MovePhi: ^12 -> ^14
	movq %rbx, %rcx
	.___ZL26safe_div_func_uint64_t_u_umm__M36:
	movq %rcx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_add_func_uint32_t_u_ujj
.p2align 4, 0x90
_ZL26safe_add_func_uint32_t_u_ujj:
	.___ZL26safe_add_func_uint32_t_u_ujj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(16 + 0, 16)
	subq $16, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3646:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(3647:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3648:3).9: mov i32 %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(3650:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3652:3).2: (^3) into i32 ^5
	movl (%rcx), %ebx
	# LowerLoad(3653:3).2: (^4) into i32 ^6
	movl (%rax), %ecx
	# LowerMath(3654:3): ^5, ^6 into i32 ^7
	movl %ebx, %eax
	addl %ecx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL24safe_add_func_int8_t_s_saa
.p2align 4, 0x90
_ZL24safe_add_func_int8_t_s_saa:
	.___ZL24safe_add_func_int8_t_s_saa__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4344:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rcx
	# LowerAlloca(4345:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(4346:3).9: mov i8 %dil, (^3)
	movb %dil, (%rcx)
	# LowerStore(4348:3).9: mov i8 %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(4350:3).2: (^3) into i8 ^5
	movb (%rcx), %bl
	movsbl %bl, %ecx
	# LowerLoad(4352:3).2: (^4) into i8 ^7
	movb (%rax), %dl
	movsbl %dl, %ebx
	# LowerMath(4354:3): ^6, ^8 into i32 ^9
	movl %ecx, %eax
	addl %ebx, %eax
	# LowerTrunc(4355:3): 32 to 8, move
	movb %al, %bl
	# LowerTrunc(4355:3): 32 to 8, apply mask
	andq $255, %rbx
	movb %bl, %al
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_add_func_int16_t_s_sss
.p2align 4, 0x90
_ZL25safe_add_func_int16_t_s_sss:
	.___ZL25safe_add_func_int16_t_s_sss__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4824:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(4825:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(4826:3).9: mov i16 %di, (^3)
	movw %di, (%rcx)
	# LowerStore(4828:3).9: mov i16 %si, (^4)
	movw %si, (%rax)
	# LowerLoad(4830:3).2: (^3) into i16 ^5
	movw (%rcx), %bx
	movswl %bx, %ecx
	# LowerLoad(4832:3).2: (^4) into i16 ^7
	movw (%rax), %dx
	movswl %dx, %ebx
	# LowerMath(4834:3): ^6, ^8 into i32 ^9
	movl %ecx, %eax
	addl %ebx, %eax
	# LowerTrunc(4835:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(4835:3): 32 to 16, apply mask
	andq $65535, %rbx
	movw %bx, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_sub_func_uint16_t_u_utt
.p2align 4, 0x90
_ZL26safe_sub_func_uint16_t_u_utt:
	.___ZL26safe_sub_func_uint16_t_u_utt__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3995:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(3996:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(3997:3).9: mov i16 %di, (^3)
	movw %di, (%rcx)
	# LowerStore(3999:3).9: mov i16 %si, (^4)
	movw %si, (%rax)
	# LowerLoad(4001:3).2: (^3) into i16 ^5
	movw (%rcx), %bx
	# LowerBasicConversion(4002:3): i16 ^5 -> i32 ^6
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(4003:3).2: (^4) into i16 ^7
	movw (%rax), %cx
	# LowerBasicConversion(4004:3): i16 ^7 -> i32 ^8
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerMath(4005:3): ^6, ^8 into i32 ^9
	movl %ebx, %eax
	subl %ecx, %eax
	# LowerTrunc(4006:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(4006:3): 32 to 16, apply mask
	andq $65535, %rbx
	movw %bx, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_sub_func_int64_t_s_sll
.p2align 4, 0x90
_ZL25safe_sub_func_int64_t_s_sll:
	.___ZL25safe_sub_func_int64_t_s_sll__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(72 + 0, 16)
	subq $80, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(3471:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rdx
	# LowerAlloca(3472:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(3473:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rdx)
	# LowerStore(3475:3).9: mov i64 %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(3477:3).2: (^3) into i64 ^5
	movq (%rdx), %rbx
	# LowerLoad(3478:3).2: (^4) into i64 ^6
	movq (%rax), %rcx
	# LowerLogic(3480:3): ^5, ^6 into i64 ^7
	movq %rbx, %rdi
	xorq %rcx, %rdi
	# LowerLoad(3480:3).2: (^3) into i64 ^8
	movq (%rdx), %rcx
	# LowerLoad(3481:3).2: (^3) into i64 ^9
	movq (%rdx), %rbx
	# LowerLoad(3482:3).2: (^4) into i64 ^10
	movq (%rax), %rsi
	# LowerLogic(3484:3): ^9, ^10 into i64 ^11
	movq %rbx, %r9
	xorq %rsi, %r9
	# LowerLogic(3485:3): ^11, -9223372036854775808 into i64 ^12
	movq %r9, %rbx
	movabsq $-9223372036854775808, %rsi
	andq %rsi, %rbx
	# LowerLogic(3486:3): ^8, ^12 into i64 ^13
	movq %rcx, %rsi
	xorq %rbx, %rsi
	# LowerLoad(3486:3).2: (^4) into i64 ^14
	movq (%rax), %rcx
	# LowerMath(3487:3): ^13, ^14 into i64 ^15
	movq %rsi, %rbx
	subq %rcx, %rbx
	# LowerLoad(3488:3).2: (^4) into i64 ^16
	movq (%rax), %rcx
	# LowerLogic(3490:3): ^15, ^16 into i64 ^17
	movq %rbx, %rsi
	xorq %rcx, %rsi
	# LowerLogic(3491:3): ^7, ^17 into i64 ^18
	movq %rdi, %rbx
	andq %rsi, %rbx
	# LowerIcmp(3491:3): i64 ^18 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_sub_func_int64_t_s_sll__M50
	jmp .___ZL25safe_sub_func_int64_t_s_sll__M55
	.___ZL25safe_sub_func_int64_t_s_sll__M50:
	# LowerLoad(3495:3).2: (^3) into i64 ^21
	movq (%rdx), %r8
	# MovePhi: ^21 -> ^27
	jmp .___ZL25safe_sub_func_int64_t_s_sll__M65
	.___ZL25safe_sub_func_int64_t_s_sll__M55:
	# LowerLoad(3499:3).2: (^3) into i64 ^23
	movq (%rdx), %rbx
	# LowerLoad(3500:3).2: (^4) into i64 ^24
	movq (%rax), %rcx
	# LowerMath(3501:3): ^23, ^24 into i64 ^25
	movq %rbx, %rax
	subq %rcx, %rax
	# MovePhi: ^25 -> ^27
	movq %rax, %r8
	.___ZL25safe_sub_func_int64_t_s_sll__M65:
	movq %r8, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_mod_func_uint64_t_u_umm
.p2align 4, 0x90
_ZL26safe_mod_func_uint64_t_u_umm:
	.___ZL26safe_mod_func_uint64_t_u_umm__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4090:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rdx
	# LowerAlloca(4091:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(4092:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rdx)
	# LowerStore(4094:3).9: mov i64 %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(4096:3).2: (^4) into i64 ^5
	movq (%rax), %rbx
	# LowerIcmp(4097:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL26safe_mod_func_uint64_t_u_umm__M15
	jmp .___ZL26safe_mod_func_uint64_t_u_umm__M20
	.___ZL26safe_mod_func_uint64_t_u_umm__M15:
	# LowerLoad(4101:3).2: (^3) into i64 ^8
	movq (%rdx), %rcx
	# MovePhi: ^8 -> ^14
	jmp .___ZL26safe_mod_func_uint64_t_u_umm__M36
	.___ZL26safe_mod_func_uint64_t_u_umm__M20:
	# LowerLoad(4105:3).2: (^3) into i64 ^10
	movq (%rdx), %rbx
	# LowerLoad(4106:3).2: (^4) into i64 ^11
	movq (%rax), %rsi
	# LowerUrem(4107:3): ^10, ^11 into i64 ^12
	movq $0, %rdx
	movq %rbx, %rax
	divq %rsi
	movq %rdx, %rbx
	# MovePhi: ^12 -> ^14
	movq %rbx, %rcx
	.___ZL26safe_mod_func_uint64_t_u_umm__M36:
	movq %rcx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL24safe_sub_func_int8_t_s_saa
.p2align 4, 0x90
_ZL24safe_sub_func_int8_t_s_saa:
	.___ZL24safe_sub_func_int8_t_s_saa__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3525:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rcx
	# LowerAlloca(3526:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(3527:3).9: mov i8 %dil, (^3)
	movb %dil, (%rcx)
	# LowerStore(3529:3).9: mov i8 %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(3531:3).2: (^3) into i8 ^5
	movb (%rcx), %bl
	movsbl %bl, %ecx
	# LowerLoad(3533:3).2: (^4) into i8 ^7
	movb (%rax), %dl
	movsbl %dl, %ebx
	# LowerMath(3535:3): ^6, ^8 into i32 ^9
	movl %ecx, %eax
	subl %ebx, %eax
	# LowerTrunc(3536:3): 32 to 8, move
	movb %al, %bl
	# LowerTrunc(3536:3): 32 to 8, apply mask
	andq $255, %rbx
	movb %bl, %al
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZN2U2aSERKS_
.p2align 4, 0x90
_ZN2U2aSERKS_:
	.___ZN2U2aSERKS___M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -48(%rbp)
	movq %r12, -56(%rbp)
	movq %r13, -40(%rbp)
	# LowerAlloca(4188:3): size = 8, type = ptr*, var = ^3
	leaq -8(%rbp), %r13
	# LowerAlloca(4189:3): size = 8, type = ptr*, var = ^4
	leaq -16(%rbp), %rax
	# LowerAlloca(4190:3): size = 8, type = ptr*, var = ^5
	leaq -24(%rbp), %rbx
	# LowerStore(4191:3).9: mov ptr %rdi, (^4)
	movq %rdi, (%rax)
	# LowerStore(4193:3).9: mov ptr %rsi, (^5)
	movq %rsi, (%rbx)
	# LowerLoad(4195:3).2: (^4) into ptr ^6
	movq (%rax), %r12
	# LowerLoad(4196:3).2: (^5) into ptr ^7
	movq (%rbx), %rax
	# LowerIcmp(4197:3): ptr ^6 vs. operand ptr ^7
	cmpq %rax, %r12
	sete %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZN2U2aSERKS___M19
	jmp .___ZN2U2aSERKS___M22
	.___ZN2U2aSERKS___M19:
	# LowerStore(4201:3).9: mov ptr ^6, (^3)
	movq %r12, (%r13)
	jmp .___ZN2U2aSERKS___M52
	.___ZN2U2aSERKS___M22:
	# LowerLoad(4205:3).2: (^5) into ptr ^11
	movq (%rbx), %rax
	# Clobber %rax
	movq %rax, -32(%rbp)
	# SetupCalls(4206:3): move argument ptr align 8 ^6
	# Fixed movzx with identical source and destination widths
	movq %r12, %rdi
	# SetupCalls(4206:3): move argument ptr align 8 ^11
	# Fixed movzx with identical source and destination widths
	movq %rax, %rsi
	# SetupCalls(4206:3): move argument i64 8
	movq $8, %rdx
	callq memcpy@PLT
	# Unclobber %rax
	movq -32(%rbp), %rax
	# LowerStore(4207:3).9: mov ptr ^6, (^3)
	movq %r12, (%r13)
	.___ZN2U2aSERKS___M52:
	# LowerLoad(4211:3).2: (^3) into ptr ^13
	movq (%r13), %rax
	movq -40(%rbp), %r13
	movq -56(%rbp), %r12
	movq -48(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL31safe_unary_minus_func_int16_t_ss
.p2align 4, 0x90
_ZL31safe_unary_minus_func_int16_t_ss:
	.___ZL31safe_unary_minus_func_int16_t_ss__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4012:3): size = 2, type = i16*, var = ^2
	leaq -2(%rbp), %rax
	# LowerStore(4013:3).9: mov i16 %di, (^2)
	movw %di, (%rax)
	# LowerLoad(4015:3).2: (^2) into i16 ^3
	movw (%rax), %bx
	movswl %bx, %eax
	# LowerMath(4017:3): 0, ^4 into i32 ^5
	movl $0, %ebx
	subl %eax, %ebx
	# LowerTrunc(4018:3): 32 to 16, move
	movw %bx, %ax
	# LowerTrunc(4018:3): 32 to 16, apply mask
	andq $65535, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_int64_t_s_ulj
.p2align 4, 0x90
_ZL28safe_lshift_func_int64_t_s_ulj:
	.___ZL28safe_lshift_func_int64_t_s_ulj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(80 + 0, 16)
	subq $80, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4638:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rdx
	# LowerAlloca(4639:3): size = 4, type = i32*, var = ^4
	leaq -12(%rbp), %rax
	# LowerStore(4640:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rdx)
	# LowerStore(4642:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4644:3).2: (^3) into i64 ^5
	movq (%rdx), %rbx
	# LowerIcmp(4645:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_ulj__M39
	.___ZL28safe_lshift_func_int64_t_s_ulj__M15:
	# LowerLoad(4649:3).2: (^4) into i32 ^8
	movl (%rax), %ebx
	# LowerIcmp(4650:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_ulj__M39
	.___ZL28safe_lshift_func_int64_t_s_ulj__M22:
	# LowerLoad(4654:3).2: (^3) into i64 ^11
	movq (%rdx), %rsi
	# LowerLoad(4655:3).2: (^4) into i32 ^12
	movl (%rax), %ebx
	# LowerBasicConversion(4656:3): i32 ^12 -> i64 ^13
	# LowerAshr(4657:3): 9223372036854775807, ^13 into i64 ^14
	# LowerShift(4657:3): operand ^13 changed to %rcx
	movq %rbx, %rcx
	movabsq $9223372036854775807, %rcx
	movq %rcx, %rbx
	sarq %cl, %rbx
	# LowerIcmp(4658:3): i64 ^11 vs. operand i64 ^14
	cmpq %rbx, %rsi
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_ulj__M39
	jmp .___ZL28safe_lshift_func_int64_t_s_ulj__M44
	.___ZL28safe_lshift_func_int64_t_s_ulj__M39:
	# LowerLoad(4662:3).2: (^3) into i64 ^17
	movq (%rdx), %r8
	# MovePhi: ^17 -> ^24
	jmp .___ZL28safe_lshift_func_int64_t_s_ulj__M58
	.___ZL28safe_lshift_func_int64_t_s_ulj__M44:
	# LowerLoad(4666:3).2: (^3) into i64 ^19
	movq (%rdx), %rbx
	# LowerLoad(4667:3).2: (^4) into i32 ^20
	movl (%rax), %edx
	# LowerBasicConversion(4668:3): i32 ^20 -> i64 ^21
	# LowerMath(4669:3): ^19, ^21 into i64 ^22
	# LowerShift(4669:3): operand ^21 changed to %rcx
	movq %rdx, %rcx
	movq %rbx, %rax
	shlq %cl, %rax
	# MovePhi: ^22 -> ^24
	movq %rax, %r8
	.___ZL28safe_lshift_func_int64_t_s_ulj__M58:
	movq %r8, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_lshift_func_uint64_t_u_smi
.p2align 4, 0x90
_ZL29safe_lshift_func_uint64_t_u_smi:
	.___ZL29safe_lshift_func_uint64_t_u_smi__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(80 + 0, 16)
	subq $80, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4707:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rdx
	# LowerAlloca(4708:3): size = 4, type = i32*, var = ^4
	leaq -12(%rbp), %rax
	# LowerStore(4709:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rdx)
	# LowerStore(4711:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4713:3).2: (^4) into i32 ^5
	movl (%rax), %ebx
	# LowerIcmp(4714:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint64_t_u_smi__M38
	.___ZL29safe_lshift_func_uint64_t_u_smi__M15:
	# LowerLoad(4718:3).2: (^4) into i32 ^8
	movl (%rax), %ebx
	# LowerIcmp(4719:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint64_t_u_smi__M38
	.___ZL29safe_lshift_func_uint64_t_u_smi__M22:
	# LowerLoad(4723:3).2: (^3) into i64 ^11
	movq (%rdx), %rsi
	# LowerLoad(4724:3).2: (^4) into i32 ^12
	movl (%rax), %ebx
	# LowerBasicConversion(4725:3): i32 ^12 -> i64 ^13
	# LowerLshr(4726:3): -1, ^13 into i64 ^14
	# LowerShift(4726:3): operand ^13 changed to %rcx
	movq %rbx, %rcx
	movq $-1, %rbx
	shrq %cl, %rbx
	# LowerIcmp(4727:3): i64 ^11 vs. operand i64 ^14
	cmpq %rbx, %rsi
	seta %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint64_t_u_smi__M38
	jmp .___ZL29safe_lshift_func_uint64_t_u_smi__M43
	.___ZL29safe_lshift_func_uint64_t_u_smi__M38:
	# LowerLoad(4731:3).2: (^3) into i64 ^17
	movq (%rdx), %r8
	# MovePhi: ^17 -> ^24
	jmp .___ZL29safe_lshift_func_uint64_t_u_smi__M57
	.___ZL29safe_lshift_func_uint64_t_u_smi__M43:
	# LowerLoad(4735:3).2: (^3) into i64 ^19
	movq (%rdx), %rbx
	# LowerLoad(4736:3).2: (^4) into i32 ^20
	movl (%rax), %edx
	# LowerBasicConversion(4737:3): i32 ^20 -> i64 ^21
	# LowerMath(4738:3): ^19, ^21 into i64 ^22
	# LowerShift(4738:3): operand ^21 changed to %rcx
	movq %rdx, %rcx
	movq %rbx, %rax
	shlq %cl, %rax
	# MovePhi: ^22 -> ^24
	movq %rax, %r8
	.___ZL29safe_lshift_func_uint64_t_u_smi__M57:
	movq %r8, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL7func_39i2U0j
.p2align 4, 0x90
_ZL7func_39i2U0j:
	.___ZL7func_39i2U0j__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(1192 + 0, 16)
	subq $1200, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -856(%rbp)
	movq %r12, -880(%rbp)
	movq %r13, -920(%rbp)
	movq %r14, -912(%rbp)
	movq %r15, -816(%rbp)
	# LowerAlloca(3761:3): size = 2, type = %union.U1*, var = ^4
	# Fixing source-to-dest leaq -2(%rbp), -648(%rbp)
	leaq -2(%rbp), %r15
	movq %r15, -648(%rbp)
	# LowerAlloca(3762:3): size = 4, type = %union.U0*, var = ^5
	# Fixing source-to-dest leaq -8(%rbp), -776(%rbp)
	leaq -8(%rbp), %r15
	movq %r15, -776(%rbp)
	# LowerAlloca(3763:3): size = 4, type = i32*, var = ^6
	# Fixing source-to-dest leaq -12(%rbp), -760(%rbp)
	leaq -12(%rbp), %r15
	movq %r15, -760(%rbp)
	# LowerAlloca(3764:3): size = 4, type = i32*, var = ^7
	# Fixing source-to-dest leaq -16(%rbp), -768(%rbp)
	leaq -16(%rbp), %r15
	movq %r15, -768(%rbp)
	# LowerAlloca(3765:3): size = 4, type = %union.U0*, var = ^8
	# Fixing source-to-dest leaq -20(%rbp), -784(%rbp)
	leaq -20(%rbp), %r15
	movq %r15, -784(%rbp)
	# LowerAlloca(3766:3): size = 8, type = ptr*, var = ^9
	leaq -32(%rbp), %rbx
	# LowerAlloca(3767:3): size = 192, type = [8 x [3 x ptr]]*, var = ^10
	leaq -224(%rbp), %rcx
	# LowerAlloca(3768:3): size = 4, type = i32*, var = ^11
	# Fixing source-to-dest leaq -228(%rbp), -672(%rbp)
	leaq -228(%rbp), %r15
	movq %r15, -672(%rbp)
	# LowerAlloca(3769:3): size = 8, type = i64*, var = ^12
	# Fixing source-to-dest leaq -240(%rbp), -720(%rbp)
	leaq -240(%rbp), %r15
	movq %r15, -720(%rbp)
	# LowerAlloca(3770:3): size = 256, type = [8 x [4 x ptr]]*, var = ^13
	leaq -496(%rbp), %r12
	# LowerAlloca(3771:3): size = 4, type = i32*, var = ^14
	# Fixing source-to-dest leaq -500(%rbp), -728(%rbp)
	leaq -500(%rbp), %r15
	movq %r15, -728(%rbp)
	# LowerAlloca(3772:3): size = 8, type = %union.U2*, var = ^15
	# Fixing source-to-dest leaq -512(%rbp), -704(%rbp)
	leaq -512(%rbp), %r15
	movq %r15, -704(%rbp)
	# LowerAlloca(3773:3): size = 12, type = [6 x [1 x %union.U4]]*, var = ^16
	# Fixing source-to-dest leaq -524(%rbp), -680(%rbp)
	leaq -524(%rbp), %r15
	movq %r15, -680(%rbp)
	# LowerAlloca(3774:3): size = 80, type = [10 x ptr]*, var = ^17
	leaq -608(%rbp), %r14
	# LowerAlloca(3775:3): size = 4, type = i32*, var = ^18
	leaq -612(%rbp), %r13
	# LowerAlloca(3776:3): size = 4, type = i32*, var = ^19
	leaq -616(%rbp), %r15
	# LowerAlloca(3777:3): size = 2, type = %union.U1*, var = ^20
	# Fixing source-to-dest leaq -618(%rbp), -688(%rbp)
	pushq %r15
	leaq -618(%rbp), %r15
	movq %r15, -688(%rbp)
	popq %r15
	# LowerAlloca(3778:3): size = 4, type = %union.U0*, var = ^21
	# Fixing source-to-dest leaq -624(%rbp), -696(%rbp)
	pushq %r15
	leaq -624(%rbp), %r15
	movq %r15, -696(%rbp)
	popq %r15
	# LowerAlloca(3779:3): size = 8, type = %union.U2*, var = ^22
	# Fixing source-to-dest leaq -632(%rbp), -712(%rbp)
	pushq %r15
	leaq -632(%rbp), %r15
	movq %r15, -712(%rbp)
	popq %r15
	# LowerAlloca(3780:3): size = 2, type = %union.U4*, var = ^23
	# Fixing source-to-dest leaq -634(%rbp), -664(%rbp)
	pushq %r15
	leaq -634(%rbp), %r15
	movq %r15, -664(%rbp)
	popq %r15
	# LowerAlloca(3781:3): size = 4, type = %union.U0*, var = ^24
	# Fixing source-to-dest leaq -640(%rbp), -656(%rbp)
	pushq %r15
	leaq -640(%rbp), %r15
	movq %r15, -656(%rbp)
	popq %r15
	# tt = Pointer, type = %union.U0
	# LowerGetelementptr(3782:3): struct-type: ptr ^5 -> ^25, indices=0,0
	movq -776(%rbp), %rax
	# LowerGetelementptr(3782:3): type of ^25 is i32*
	# LowerStore(3783:3).9: mov i32 %esi, (^25)
	movl %esi, (%rax)
	# LowerStore(3784:3).9: mov i32 %edi, (^6)
	movq -760(%rbp), %rax
	movl %edi, (%rax)
	# LowerStore(3787:3).9: mov i32 %edx, (^7)
	movq -768(%rbp), %rax
	movl %edx, (%rax)
	# LowerStore(3790:3).3: mov $imm, (^8)
	movq -784(%rbp), %rax
	movl $8, (%rax)
	# LowerStore(3792:3).9: mov %union.U0* ^8, (^9)
	# Fixing source-to-dest movq -784(%rbp), (%rbx)
	pushq %r15
	movq -784(%rbp), %r15
	movq %r15, (%rbx)
	popq %r15
	# Clobber %rcx
	movq %rcx, -792(%rbp)
	# SetupCalls(3794:3): move argument ptr align 16 ^10
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(3794:3): move argument ptr align 16 @__const._ZL7func_39i2U0j.l_65
	leaq __const._ZL7func_39i2U0j.l_65(%rip), %rsi
	# SetupCalls(3794:3): move argument i64 192
	movq $192, %rdx
	callq memcpy@PLT
	# Unclobber %rcx
	movq -792(%rbp), %rcx
	# LowerStore(3796:3).3: mov $imm, (^11)
	movq -672(%rbp), %rax
	movl $0, (%rax)
	# LowerStore(3798:3).3: mov $imm, (^12)
	movq -720(%rbp), %rax
	movq $-1, (%rax)
	# LowerStore(3800:3).3: mov $imm, (^4)
	movq -648(%rbp), %rax
	movb $0, (%rax)
	# LowerStore(3803:3).3: mov $imm, (^14)
	movq -728(%rbp), %rax
	movl $-1587066959, (%rax)
	# LowerStore(3805:3).3: mov $imm, (^15)
	movabsq $-3918988697788526482, %rcx
	movq -704(%rbp), %rax
	movq %rcx, (%rax)
	# SetupCalls(3807:3): move argument ptr align 2 ^16
	# Fixed movzx with identical source and destination widths
	movq -680(%rbp), %rdi
	# SetupCalls(3807:3): move argument ptr align 2 @__const._ZL7func_39i2U0j.l_692
	leaq __const._ZL7func_39i2U0j.l_692(%rip), %rsi
	# SetupCalls(3807:3): move argument i64 12
	movq $12, %rdx
	callq memcpy@PLT
	# SetupCalls(3809:3): move argument ptr align 16 ^17
	# Fixed movzx with identical source and destination widths
	movq %r14, %rdi
	# SetupCalls(3809:3): move argument ptr align 16 @__const._ZL7func_39i2U0j.l_694
	leaq __const._ZL7func_39i2U0j.l_694(%rip), %rsi
	# SetupCalls(3809:3): move argument i64 80
	movq $80, %rdx
	callq memcpy@PLT
	# LowerStore(3812:3).3: mov $imm, (^18)
	movl $0, (%r13)
	.___ZL7func_39i2U0j__M146:
	# LowerLoad(3816:3).2: (^18) into i32 ^27
	movl (%r13), %eax
	# LowerIcmp(3817:3): i32 ^27 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_39i2U0j__M153
	jmp .___ZL7func_39i2U0j__M213
	.___ZL7func_39i2U0j__M153:
	# LowerStore(3821:3).3: mov $imm, (^19)
	movl $0, (%r15)
	.___ZL7func_39i2U0j__M156:
	# LowerLoad(3825:3).2: (^19) into i32 ^31
	movl (%r15), %eax
	# LowerIcmp(3826:3): i32 ^31 vs. intlike 4
	cmpl $4, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_39i2U0j__M163
	jmp .___ZL7func_39i2U0j__M204
	.___ZL7func_39i2U0j__M163:
	# LowerLoad(3830:3).2: (^18) into i32 ^34
	movl (%r13), %eax
	movslq %eax, %rcx
	# tt = Pointer, type = [8 x [4 x ptr]]
	# LowerGetelementptr(3832:3): array/pointer-type, dynamic index -> ^36
	# index ^35 -> temp ^134
	movq %rcx, %rdx
	# Multiply temp ^134 by 32 start
	shlq $5, %rdx
	# Multiply end
	# temp ^134 -> operand ^36
	movq %rdx, %rax
	# Result ^36 += base pointer ^13
	addq %r12, %rax
	# LowerLoad(3833:3).2: (^19) into i32 ^37
	movl (%r15), %ecx
	movslq %ecx, %rdx
	# tt = Pointer, type = [4 x ptr]
	# LowerGetelementptr(3835:3): array/pointer-type, dynamic index -> ^39
	# index ^38 -> temp ^135
	movq %rdx, %rsi
	# Multiply temp ^135 by 8 start
	shlq $3, %rsi
	# Multiply end
	# temp ^135 -> operand ^39
	movq %rsi, %rcx
	# Result ^39 += base pointer ^36
	addq %rax, %rcx
	# LowerStore(3836:3).6: load global
	leaq _ZL4g_66(%rip), %rax
	# LowerStore(3836:3).9: mov ptr ^136, (^39)
	movq %rax, (%rcx)
	# LowerLoad(3840:3).2: (^19) into i32 ^41
	movl (%r15), %eax
	# LowerMath(3841:3): ^41, 1 into i32 ^42
	addl $1, %eax
	# LowerStore(3842:3).9: mov i32 ^42, (^19)
	movl %eax, (%r15)
	jmp .___ZL7func_39i2U0j__M156
	.___ZL7func_39i2U0j__M204:
	# LowerLoad(3849:3).2: (^18) into i32 ^45
	movl (%r13), %eax
	# LowerMath(3850:3): ^45, 1 into i32 ^46
	addl $1, %eax
	# LowerStore(3851:3).9: mov i32 ^46, (^18)
	movl %eax, (%r13)
	jmp .___ZL7func_39i2U0j__M146
	.___ZL7func_39i2U0j__M213:
	# LowerLoad(3855:3).2: (^9) into ptr ^48
	movq (%rbx), %rax
	# Clobber %rax
	movq %rax, -800(%rbp)
	# SetupCalls(3856:3): move argument ptr nonnull dereferenceable(4) align 4 ^48
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(3856:3): move argument ptr nonnull dereferenceable(4) align 4 ^8
	# Fixed movzx with identical source and destination widths
	movq -784(%rbp), %rsi
	callq _ZN2U0aSERKS_
	# SetupCalls(3856:3): move ptr result from %rax
	movq %rax, %rbx
	# Unclobber %rax
	movq -800(%rbp), %rax
	# SetupCalls(3857:3): move argument ptr nonnull dereferenceable(4) align 4 ^5
	# Fixed movzx with identical source and destination widths
	movq -776(%rbp), %rdi
	# SetupCalls(3857:3): move argument ptr nonnull dereferenceable(4) align 4 ^49
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rsi
	callq _ZN2U0aSERKS_
	# SetupCalls(3857:3): move ptr result from %rax
	movq %rax, %rax
	# LowerLoad(3858:3).4: _ZL3g_5 into ^51
	movl _ZL3g_5(%rip), %eax
	movslq %eax, %r12
	# LowerLoad(3860:3).4: _ZL3g_5 into ^53
	# Fixing source-to-dest movl _ZL3g_5(%rip), -752(%rbp)
	movl _ZL3g_5(%rip), %r15d
	movl %r15d, -752(%rbp)
	# LowerTrunc(3861:3): 32 to 8, move
	# LowerTrunc(3861:3): 32 to 8, apply mask
	andq $255, -752(%rbp)
	# LowerLoad(3862:3).2: (^11) into i32 ^55
	movq -672(%rbp), %rax
	movl (%rax), %ecx
	movslq %ecx, %rbx
	# LowerLoad(3864:3).2: (^12) into i64 ^57
	movq -720(%rbp), %rax
	movq (%rax), %r13
	# LowerTrunc(3865:3): 64 to 32, move and clear upper bits
	# LowerLoad(3866:3).2: (^6) into i32 ^59
	movq -760(%rbp), %rcx
	movl (%rcx), %eax
	# LowerLoad(3867:3).2: (^7) into i32 ^60
	movq -768(%rbp), %rdx
	movl (%rdx), %ecx
	# LowerIcmp(3868:3): i32 ^59 vs. operand i32 ^60
	cmpl %ecx, %eax
	seta %al
	andq $1, %rax
	# LowerBasicConversion(3869:3): i32 ^61 -> i16 ^62
	movw %ax, %cx
	# LowerLoad(3870:3).2: (^6) into i32 ^63
	movq -760(%rbp), %rdx
	movl (%rdx), %eax
	# Clobber %rcx
	movq %rcx, -792(%rbp)
	# Clobber %rax
	movq %rax, -800(%rbp)
	# SetupCalls(3871:3): move argument i16 signext ^62
	movzwq %cx, %rdi
	movswq %di, %rdi
	# SetupCalls(3871:3): move argument i32 ^63
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	callq _ZL28safe_lshift_func_int16_t_s_ssi
	# SetupCalls(3871:3): move i16 result from %rax
	movw %ax, %r14w
	# Unclobber %rax
	movq -800(%rbp), %rax
	# Unclobber %rcx
	movq -792(%rbp), %rcx
	# LowerIcmp(3872:3): i16 ^64 vs. intlike 0
	cmpw $0, %r14w
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_39i2U0j__M325
	jmp .___ZL7func_39i2U0j__M328
	.___ZL7func_39i2U0j__M325:
	# MovePhi: intlike -> ^68 (in new block 138 whose parent is 127)
	movb $1, -736(%rbp)
	jmp .___ZL7func_39i2U0j__M331
	.___ZL7func_39i2U0j__M328:
	# MovePhi: intlike -> ^68
	movb $1, -736(%rbp)
	.___ZL7func_39i2U0j__M331:
	# LowerBasicConversion(3880:3): i1 ^68 -> i32 ^69
	movl -736(%rbp), %eax
	# Truncate value to 8 bits
	andl $255, %eax
	# Clobber %rax
	movq %rax, -800(%rbp)
	# SetupCalls(3881:3): move argument i32 ^58
	# Fixed movzx with 32-bit source operand
	movl %r13d, %edi
	# SetupCalls(3881:3): move argument i32 ^69
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	callq _ZL26safe_mod_func_uint32_t_u_ujj
	# SetupCalls(3881:3): move i32 result from %rax
	movl %eax, %r13d
	# Unclobber %rax
	movq -800(%rbp), %rax
	# LowerBasicConversion(3882:3): i32 ^70 -> i64 ^71
	movq %r13, %rax
	# Clobber %rax
	movq %rax, -800(%rbp)
	# SetupCalls(3883:3): move argument i64 ^71
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(3883:3): move argument i64 1
	movq $1, %rsi
	callq _ZL26safe_div_func_uint64_t_u_umm
	# SetupCalls(3883:3): move i64 result from %rax
	movq %rax, %r13
	# Unclobber %rax
	movq -800(%rbp), %rax
	# LowerLoad(3884:3).4: _ZL3g_2 into ^73
	movl _ZL3g_2(%rip), %eax
	movslq %eax, %rcx
	# LowerIcmp(3886:3): i64 ^72 vs. operand i64 ^74
	cmpq %rcx, %r13
	setae %al
	andq $1, %rax
	# LowerLoad(3887:3).2: (^4) into i8 ^76
	movq -648(%rbp), %rax
	movb (%rax), %cl
	movsbw %cl, %ax
	# LowerLoad(3889:3).4: _ZL3g_5 into ^78
	movl _ZL3g_5(%rip), %ecx
	# LowerTrunc(3890:3): 32 to 16, move
	# LowerTrunc(3890:3): 32 to 16, apply mask
	andq $65535, %rcx
	# Clobber %rcx
	movq %rcx, -792(%rbp)
	# Clobber %rax
	movq %rax, -800(%rbp)
	# SetupCalls(3891:3): move argument i16 zeroext ^77
	movzwq %ax, %rdi
	andq $65535, %rdi
	# SetupCalls(3891:3): move argument i16 zeroext ^79
	movzwq %cx, %rsi
	andq $65535, %rsi
	callq _ZL26safe_add_func_uint16_t_u_utt
	# SetupCalls(3891:3): move i16 result from %rax
	movw %ax, %r13w
	# Unclobber %rax
	movq -800(%rbp), %rax
	# Unclobber %rcx
	movq -792(%rbp), %rcx
	# LowerBasicConversion(3892:3): i16 ^80 -> i32 ^81
	movl %r13d, %eax
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerStore(3893:3).9: mov i32 ^81, (^14)
	movq -728(%rbp), %rcx
	movl %eax, (%rcx)
	movslq %eax, %rcx
	movq $3, %rax
	# LowerIcmp(3895:3): i64 ^132 vs. operand i64 ^82
	cmpq %rcx, %rax
	setbe %al
	andq $1, %rax
	# LowerBasicConversion(3896:3): i64 ^83 -> i64 ^84
	movq %rax, %rcx
	# LowerLoad(3897:3).2: (^11) into i32 ^85
	movq -672(%rbp), %rax
	movl (%rax), %edx
	movslq %edx, %rax
	# Clobber %rcx
	movq %rcx, -792(%rbp)
	# Clobber %rax
	movq %rax, -800(%rbp)
	# SetupCalls(3899:3): move argument i64 ^84
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(3899:3): move argument i64 ^86
	# Fixed movzx with identical source and destination widths
	movq %rax, %rsi
	callq _ZL25safe_sub_func_int64_t_s_sll
	# SetupCalls(3899:3): move i64 result from %rax
	movq %rax, %r13
	# Unclobber %rax
	movq -800(%rbp), %rax
	# Unclobber %rcx
	movq -792(%rbp), %rcx
	# LowerIcmp(3900:3): i64 ^56 vs. operand i64 ^87
	cmpq %r13, %rbx
	setge %al
	andq $1, %rax
	# LowerBasicConversion(3901:3): i64 ^88 -> i64 ^89
	movq %rax, %rbx
	# LowerIcmp(3902:3): i64 ^89 vs. intlike 151
	cmpq $151, %rbx
	setg %al
	andq $1, %rax
	# LowerBasicConversion(3903:3): i64 ^90 -> i64 ^91
	movq %rax, %rbx
	movq $1, %rax
	# LowerIcmp(3904:3): i64 ^133 vs. operand i64 ^91
	cmpq %rbx, %rax
	setle %al
	andq $1, %rax
	# LowerBasicConversion(3905:3): i64 ^92 -> i8 ^93
	movb %al, %bl
	# LowerLoad(3906:3).2: (^12) into i64 ^94
	movq -720(%rbp), %rax
	movq (%rax), %rcx
	# LowerTrunc(3907:3): 64 to 8, move
	# LowerTrunc(3907:3): 64 to 8, apply mask
	andq $255, %rcx
	# Clobber %rcx
	movq %rcx, -792(%rbp)
	# SetupCalls(3908:3): move argument i8 zeroext ^93
	movzbq %bl, %rdi
	andq $255, %rdi
	# SetupCalls(3908:3): move argument i8 zeroext ^95
	movzbq %cl, %rsi
	andq $255, %rsi
	callq _ZL25safe_mod_func_uint8_t_u_uhh
	# SetupCalls(3908:3): move i8 result from %rax
	movb %al, %bl
	# Unclobber %rcx
	movq -792(%rbp), %rcx
	# LowerBasicConversion(3909:3): i8 ^96 -> i32 ^97
	movl %ebx, %r13d
	# Truncate value to 8 bits
	andl $255, %r13d
	# LowerLoad(3910:3).4: _ZL3g_5 into ^98
	movl _ZL3g_5(%rip), %ebx
	# LowerTrunc(3911:3): 32 to 16, move
	# LowerTrunc(3911:3): 32 to 16, apply mask
	andq $65535, %rbx
	# SetupCalls(3912:3): move argument ptr align 8 ^22
	# Fixed movzx with identical source and destination widths
	movq -712(%rbp), %rdi
	# SetupCalls(3912:3): move argument ptr align 8 ^15
	# Fixed movzx with identical source and destination widths
	movq -704(%rbp), %rsi
	# SetupCalls(3912:3): move argument i64 8
	movq $8, %rdx
	callq memcpy@PLT
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(3913:3): struct-type: ptr ^22 -> ^100, indices=0,0
	movq -712(%rbp), %rax
	# LowerGetelementptr(3913:3): type of ^100 is i64*
	# LowerLoad(3914:3).2: (^100) into i64 ^101
	movq (%rax), %r9
	# Clobber %r9
	movq %r9, -808(%rbp)
	# SetupCalls(3915:3): move argument i64 ^52
	# Fixed movzx with identical source and destination widths
	movq %r12, %rdi
	# SetupCalls(3915:3): move argument i8 signext ^54
	# Fixed movzx with identical source and destination widths
	movb -752(%rbp), %sil
	movsbq %sil, %rsi
	# SetupCalls(3915:3): move argument i32 ^97
	# Fixed movzx with 32-bit source operand
	movl %r13d, %edx
	# SetupCalls(3915:3): move argument i16 signext ^99
	movzwq %bx, %rcx
	movswq %cx, %rcx
	# SetupCalls(3915:3): move argument i64 ^101
	# Fixed movzx with identical source and destination widths
	movq %r9, %r8
	callq _ZL7func_57majs2U2
	# SetupCalls(3915:3): move i32 result from %rax
	movl %eax, %ebx
	# Unclobber %r9
	movq -808(%rbp), %r9
	# tt = Pointer, type = %union.U0
	# LowerGetelementptr(3916:3): struct-type: ptr ^21 -> ^103, indices=0,0
	movq -696(%rbp), %rax
	# LowerGetelementptr(3916:3): type of ^103 is i32*
	# LowerStore(3917:3).9: mov i32 ^102, (^103)
	movl %ebx, (%rax)
	# tt = Pointer, type = %union.U0
	# LowerGetelementptr(3918:3): struct-type: ptr ^21 -> ^104, indices=0,0
	movq -696(%rbp), %rax
	# LowerGetelementptr(3918:3): type of ^104 is i32*
	# LowerLoad(3919:3).2: (^104) into i32 ^105
	movl (%rax), %ebx
	# SetupCalls(3920:3): move argument i32 ^105
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edi
	callq _ZL7func_552U0
	# SetupCalls(3920:3): move i16 result from %rax
	movw %ax, %bx
	# tt = Pointer, type = %union.U1
	# LowerGetelementptr(3921:3): struct-type: ptr ^20 -> ^107, indices=0,0
	movq -688(%rbp), %rax
	# LowerGetelementptr(3921:3): type of ^107 is i16*
	# LowerStore(3922:3).9: mov i16 ^106, (^107)
	movw %bx, (%rax)
	# tt = Pointer, type = %union.U1
	# LowerGetelementptr(3923:3): struct-type: ptr ^20 -> ^108, indices=0,0
	movq -688(%rbp), %rax
	# LowerGetelementptr(3923:3): type of ^108 is i16*
	# LowerLoad(3924:3).2: (^108) into i16 ^109
	movw (%rax), %bx
	# SetupCalls(3925:3): move argument i16 ^109
	movzwq %bx, %rdi
	callq _ZL7func_532U1
	# SetupCalls(3925:3): move i32 result from %rax
	movl %eax, %ebx
	# LowerLoad(3926:3).4: _ZL3g_2 into ^111
	movl _ZL3g_2(%rip), %r12d
	# tt = Pointer, type = [6 x [1 x %union.U4]]
	# LowerGetelementptr(3927:3): struct-type: ptr ^16 -> ^112, indices=0,2
	movq -680(%rbp), %rax
	addq $4, %rax
	# LowerGetelementptr(3927:3): type of ^112 is [1 x %union.U4]*
	# tt = Pointer, type = [1 x %union.U4]
	# LowerGetelementptr(3928:3): struct-type: ptr ^112 -> ^113, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(3928:3): type of ^113 is %union.U4*
	# Clobber %rcx
	movq %rcx, -792(%rbp)
	# SetupCalls(3929:3): move argument ptr align 2 ^23
	# Fixed movzx with identical source and destination widths
	movq -664(%rbp), %rdi
	# SetupCalls(3929:3): move argument ptr align 2 ^113
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rsi
	# SetupCalls(3929:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	# Unclobber %rcx
	movq -792(%rbp), %rcx
	# LowerLoad(3930:3).2: (^11) into i32 ^114
	movq -672(%rbp), %rax
	movl (%rax), %r13d
	# LowerTrunc(3931:3): 32 to 16, move
	# LowerTrunc(3931:3): 32 to 16, apply mask
	andq $65535, %r13
	# SetupCalls(3932:3): move argument ptr align 4 ^24
	# Fixed movzx with identical source and destination widths
	movq -656(%rbp), %rdi
	# SetupCalls(3932:3): move argument ptr align 4 @_ZL5g_693
	leaq _ZL5g_693(%rip), %rsi
	# SetupCalls(3932:3): move argument i64 4
	movq $4, %rdx
	callq memcpy@PLT
	# tt = Pointer, type = %union.U4
	# LowerGetelementptr(3933:3): struct-type: ptr ^23 -> ^116, indices=0,0
	movq -664(%rbp), %rax
	# LowerGetelementptr(3933:3): type of ^116 is i16*
	# LowerLoad(3934:3).2: (^116) into i16 ^117
	movw (%rax), %cx
	# tt = Pointer, type = %union.U0
	# LowerGetelementptr(3935:3): struct-type: ptr ^24 -> ^118, indices=0,0
	movq -656(%rbp), %rax
	# LowerGetelementptr(3935:3): type of ^118 is i32*
	# LowerLoad(3936:3).2: (^118) into i32 ^119
	movl (%rax), %r9d
	# Clobber %rcx
	movq %rcx, -792(%rbp)
	# Clobber %r9
	movq %r9, -808(%rbp)
	# SetupCalls(3937:3): move argument i32 ^110
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edi
	# SetupCalls(3937:3): move argument i32 ^111
	# Fixed movzx with 32-bit source operand
	movl %r12d, %esi
	# SetupCalls(3937:3): move argument i16 ^117
	movzwq %cx, %rdx
	# SetupCalls(3937:3): move argument i16 zeroext ^115
	movzwq %r13w, %rcx
	andq $65535, %rcx
	# SetupCalls(3937:3): move argument i32 ^119
	# Fixed movzx with 32-bit source operand
	movl %r9d, %r8d
	callq _ZL7func_47ij2U4t2U0
	# SetupCalls(3937:3): move i32 result from %rax
	movl %eax, %ebx
	# Unclobber %r9
	movq -808(%rbp), %r9
	# Unclobber %rcx
	movq -792(%rbp), %rcx
	# SetupCalls(3938:3): move argument i32 ^120
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edi
	# SetupCalls(3938:3): move argument i32 -1748839321
	movq $-1748839321, %rsi
	callq _ZL25safe_add_func_int32_t_s_sii
	# SetupCalls(3938:3): move i32 result from %rax
	movl %eax, %ebx
	# LowerLoad(3939:3).4: _ZL5g_695 into ^122
	movl _ZL5g_695(%rip), %eax
	# LowerLogic(3941:3): ^122, ^121 into i32 ^123
	xorl %ebx, %eax
	# LowerStore(3941:3).8a: leaq var, %temp
	leaq _ZL5g_695(%rip), %rbx
	# LowerStore(3941:3).8b: movq ^123, (%temp)
	movl %eax, (%rbx)
	# tt = Pointer, type = %union.U1
	# LowerGetelementptr(3942:3): struct-type: ptr ^4 -> ^124, indices=0,0
	movq -648(%rbp), %rax
	# LowerGetelementptr(3942:3): type of ^124 is i16*
	# LowerLoad(3943:3).2: (^124) into i16 ^125
	movw (%rax), %bx
	movw %bx, %ax
	movq -816(%rbp), %r15
	movq -912(%rbp), %r14
	movq -920(%rbp), %r13
	movq -880(%rbp), %r12
	movq -856(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global main
.p2align 4, 0x90
main:
	.__main__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(1696 + 0, 16)
	subq $1696, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -104(%rbp)
	movq %r12, -112(%rbp)
	movq %r13, -128(%rbp)
	movq %r14, -144(%rbp)
	movq %r15, -120(%rbp)
	# LowerAlloca(342:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rdx
	# LowerAlloca(343:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rbx
	# LowerAlloca(344:3): size = 8, type = ptr*, var = ^5
	leaq -16(%rbp), %rcx
	# LowerAlloca(345:3): size = 4, type = i32*, var = ^6
	leaq -20(%rbp), %r12
	# LowerAlloca(346:3): size = 4, type = i32*, var = ^7
	leaq -24(%rbp), %r15
	# LowerAlloca(347:3): size = 4, type = i32*, var = ^8
	leaq -28(%rbp), %r13
	# LowerAlloca(348:3): size = 4, type = i32*, var = ^9
	# Fixing source-to-dest leaq -32(%rbp), -48(%rbp)
	pushq %r15
	leaq -32(%rbp), %r15
	movq %r15, -48(%rbp)
	popq %r15
	# LowerAlloca(349:3): size = 2, type = %union.U4*, var = ^10
	leaq -34(%rbp), %r14
	# LowerStore(350:3).3: mov $imm, (^3)
	movl $0, (%rdx)
	# LowerStore(351:3).9: mov i32 %edi, (^4)
	movl %edi, (%rbx)
	# LowerStore(353:3).9: mov ptr %rsi, (^5)
	movq %rsi, (%rcx)
	# LowerStore(359:3).3: mov $imm, (^9)
	movq -48(%rbp), %rax
	movl $0, (%rax)
	# LowerLoad(360:3).2: (^4) into i32 ^11
	movl (%rbx), %eax
	# LowerIcmp(361:3): i32 ^11 vs. intlike 2
	cmpl $2, %eax
	sete %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M31
	jmp .__main__M73
	.__main__M31:
	# LowerLoad(365:3).2: (^5) into ptr ^14
	movq (%rcx), %rax
	# tt = Pointer, type = ptr
	# LowerGetelementptr(366:3): struct-type: ptr ^14 -> ^15, indices=1
	addq $8, %rax
	# LowerGetelementptr(366:3): type of ^15 is ptr*
	# LowerLoad(367:3).2: (^15) into ptr ^16
	movq (%rax), %rbx
	# SetupCalls(368:3): move argument ptr ^16
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(368:3): move argument ptr @.str
	leaq .str(%rip), %rsi
	callq strcmp@PLT
	# SetupCalls(368:3): move i32 result from %rax
	movl %eax, %ebx
	# LowerIcmp(369:3): i32 ^17 vs. intlike 0
	cmpl $0, %ebx
	sete %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M70
	jmp .__main__M73
	.__main__M70:
	# LowerStore(373:3).3: mov $imm, (^9)
	movq -48(%rbp), %rax
	movl $1, (%rax)
	.__main__M73:
	# Discarded useless call to _ZL19platform_main_beginv
	callq _ZL12crc32_gentabv
	# LowerLoad(379:3).4: _ZL5g_106 into ^21
	movw _ZL5g_106(%rip), %bx
	# LowerBasicConversion(380:3): i16 ^21 -> i32 ^22
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(381:3).4: _ZL4g_91 into ^23
	movb _ZL4g_91(%rip), %cl
	# LowerBasicConversion(382:3): i8 ^23 -> i32 ^24
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerLoad(383:3).4: _ZL3g_5 into ^25
	movl _ZL3g_5(%rip), %r8d
	# LowerLoad(384:3).4: _ZL3g_2 into ^26
	movl _ZL3g_2(%rip), %eax
	# LowerLoad(385:3).4: _ZL13crc32_context into ^27
	movl _ZL13crc32_context(%rip), %r10d
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# Clobber %r8
	movq %r8, -64(%rbp)
	# Clobber %r10
	movq %r10, -72(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(386:3): move argument ptr @.str.1
	leaq .str.1(%rip), %rdi
	# SetupCalls(386:3): move argument i32 ^22
	# Fixed movzx with 32-bit source operand
	movl %ebx, %esi
	# SetupCalls(386:3): move argument i32 ^24
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	# SetupCalls(386:3): move argument i32 ^25
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	# SetupCalls(386:3): move argument i32 ^26
	# Fixed movzx with 32-bit source operand
	movl %eax, %r8d
	# SetupCalls(386:3): move argument i32 ^27
	# Fixed movzx with 32-bit source operand
	movl %r10d, %r9d
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(386:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %r10
	movq -72(%rbp), %r10
	# Unclobber %r8
	movq -64(%rbp), %r8
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	callq _ZL6func_1v
	# SetupCalls(388:3): move i16 result from %rax
	movw %ax, %bx
	# tt = Pointer, type = %union.U4
	# LowerGetelementptr(389:3): struct-type: ptr ^10 -> ^30, indices=0,0
	movq %r14, %rax
	# LowerGetelementptr(389:3): type of ^30 is i16*
	# LowerStore(390:3).9: mov i16 ^29, (^30)
	movw %bx, (%rax)
	# LowerLoad(391:3).4: _ZL5g_106 into ^31
	movw _ZL5g_106(%rip), %bx
	# LowerBasicConversion(392:3): i16 ^31 -> i32 ^32
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(393:3).4: _ZL4g_91 into ^33
	movb _ZL4g_91(%rip), %cl
	# LowerBasicConversion(394:3): i8 ^33 -> i32 ^34
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerLoad(395:3).4: _ZL3g_5 into ^35
	movl _ZL3g_5(%rip), %r8d
	# LowerLoad(396:3).4: _ZL3g_2 into ^36
	movl _ZL3g_2(%rip), %eax
	# LowerLoad(397:3).4: _ZL13crc32_context into ^37
	movl _ZL13crc32_context(%rip), %r10d
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# Clobber %r8
	movq %r8, -64(%rbp)
	# Clobber %r10
	movq %r10, -72(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(398:3): move argument ptr @.str.1
	leaq .str.1(%rip), %rdi
	# SetupCalls(398:3): move argument i32 ^32
	# Fixed movzx with 32-bit source operand
	movl %ebx, %esi
	# SetupCalls(398:3): move argument i32 ^34
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	# SetupCalls(398:3): move argument i32 ^35
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	# SetupCalls(398:3): move argument i32 ^36
	# Fixed movzx with 32-bit source operand
	movl %eax, %r8d
	# SetupCalls(398:3): move argument i32 ^37
	# Fixed movzx with 32-bit source operand
	movl %r10d, %r9d
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(398:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %r10
	movq -72(%rbp), %r10
	# Unclobber %r8
	movq -64(%rbp), %r8
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(399:3).2: (^10) into i16 ^39
	movw (%r14), %ax
	movswl %ax, %ebx
	# SetupCalls(401:3): move argument ptr @.str.2
	leaq .str.2(%rip), %rdi
	# SetupCalls(401:3): move argument i32 ^40
	# Fixed movzx with 32-bit source operand
	movl %ebx, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(401:3): move i32 result from %rax
	movl %eax, %eax
	# LowerLoad(402:3).4: _ZL5g_106 into ^42
	movw _ZL5g_106(%rip), %ax
	# LowerBasicConversion(403:3): i16 ^42 -> i32 ^43
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLoad(404:3).4: _ZL4g_91 into ^44
	movb _ZL4g_91(%rip), %bl
	# LowerBasicConversion(405:3): i8 ^44 -> i32 ^45
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(406:3).4: _ZL3g_5 into ^46
	movl _ZL3g_5(%rip), %r8d
	# LowerLoad(407:3).4: _ZL3g_2 into ^47
	movl _ZL3g_2(%rip), %r9d
	# LowerLoad(408:3).4: _ZL13crc32_context into ^48
	movl _ZL13crc32_context(%rip), %r10d
	# Clobber %r8
	movq %r8, -64(%rbp)
	# Clobber %r9
	movq %r9, -88(%rbp)
	# Clobber %r10
	movq %r10, -72(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(409:3): move argument ptr @.str.1
	leaq .str.1(%rip), %rdi
	# SetupCalls(409:3): move argument i32 ^43
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(409:3): move argument i32 ^45
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	# SetupCalls(409:3): move argument i32 ^46
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	# SetupCalls(409:3): move argument i32 ^47
	# Fixed movzx with 32-bit source operand
	movl %r9d, %r8d
	# SetupCalls(409:3): move argument i32 ^48
	# Fixed movzx with 32-bit source operand
	movl %r10d, %r9d
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(409:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %r10
	movq -72(%rbp), %r10
	# Unclobber %r9
	movq -88(%rbp), %r9
	# Unclobber %r8
	movq -64(%rbp), %r8
	# LowerLoad(410:3).4: _ZL3g_2 into ^50
	movl _ZL3g_2(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(412:3).2: (^9) into i32 ^52
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(413:3): move argument i64 ^51
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(413:3): move argument ptr @.str.3
	leaq .str.3(%rip), %rsi
	# SetupCalls(413:3): move argument i32 ^52
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(414:3).4: _ZL5g_106 into ^53
	movw _ZL5g_106(%rip), %cx
	# LowerBasicConversion(415:3): i16 ^53 -> i32 ^54
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(416:3).4: _ZL4g_91 into ^55
	movb _ZL4g_91(%rip), %bl
	# LowerBasicConversion(417:3): i8 ^55 -> i32 ^56
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(418:3).4: _ZL3g_5 into ^57
	movl _ZL3g_5(%rip), %eax
	# LowerLoad(419:3).4: _ZL3g_2 into ^58
	movl _ZL3g_2(%rip), %r9d
	# LowerLoad(420:3).4: _ZL13crc32_context into ^59
	movl _ZL13crc32_context(%rip), %r10d
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# Clobber %r9
	movq %r9, -88(%rbp)
	# Clobber %r10
	movq %r10, -72(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(421:3): move argument ptr @.str.1
	leaq .str.1(%rip), %rdi
	# SetupCalls(421:3): move argument i32 ^54
	# Fixed movzx with 32-bit source operand
	movl %ecx, %esi
	# SetupCalls(421:3): move argument i32 ^56
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	# SetupCalls(421:3): move argument i32 ^57
	# Fixed movzx with 32-bit source operand
	movl %eax, %ecx
	# SetupCalls(421:3): move argument i32 ^58
	# Fixed movzx with 32-bit source operand
	movl %r9d, %r8d
	# SetupCalls(421:3): move argument i32 ^59
	# Fixed movzx with 32-bit source operand
	movl %r10d, %r9d
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(421:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %r10
	movq -72(%rbp), %r10
	# Unclobber %r9
	movq -88(%rbp), %r9
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(422:3).4: _ZL3g_5 into ^61
	movl _ZL3g_5(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(424:3).2: (^9) into i32 ^63
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(425:3): move argument i64 ^62
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(425:3): move argument ptr @.str.4
	leaq .str.4(%rip), %rsi
	# SetupCalls(425:3): move argument i32 ^63
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(426:3).4: _ZL5g_106 into ^64
	movw _ZL5g_106(%rip), %ax
	# LowerBasicConversion(427:3): i16 ^64 -> i32 ^65
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLoad(428:3).4: _ZL4g_91 into ^66
	movb _ZL4g_91(%rip), %bl
	# LowerBasicConversion(429:3): i8 ^66 -> i32 ^67
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(430:3).4: _ZL3g_5 into ^68
	movl _ZL3g_5(%rip), %r8d
	# LowerLoad(431:3).4: _ZL3g_2 into ^69
	movl _ZL3g_2(%rip), %r9d
	# LowerLoad(432:3).4: _ZL13crc32_context into ^70
	movl _ZL13crc32_context(%rip), %r10d
	# Clobber %r8
	movq %r8, -64(%rbp)
	# Clobber %r9
	movq %r9, -88(%rbp)
	# Clobber %r10
	movq %r10, -72(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(433:3): move argument ptr @.str.1
	leaq .str.1(%rip), %rdi
	# SetupCalls(433:3): move argument i32 ^65
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(433:3): move argument i32 ^67
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	# SetupCalls(433:3): move argument i32 ^68
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	# SetupCalls(433:3): move argument i32 ^69
	# Fixed movzx with 32-bit source operand
	movl %r9d, %r8d
	# SetupCalls(433:3): move argument i32 ^70
	# Fixed movzx with 32-bit source operand
	movl %r10d, %r9d
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(433:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %r10
	movq -72(%rbp), %r10
	# Unclobber %r9
	movq -88(%rbp), %r9
	# Unclobber %r8
	movq -64(%rbp), %r8
	# LowerLoad(434:3).4: _ZL4g_91 into ^72
	movb _ZL4g_91(%rip), %al
	# LowerBasicConversion(435:3): i8 ^72 -> i64 ^73
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerLoad(436:3).2: (^9) into i32 ^74
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(437:3): move argument i64 ^73
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(437:3): move argument ptr @.str.5
	leaq .str.5(%rip), %rsi
	# SetupCalls(437:3): move argument i32 ^74
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(438:3).4: _ZL5g_106 into ^75
	movw _ZL5g_106(%rip), %ax
	# LowerBasicConversion(439:3): i16 ^75 -> i32 ^76
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLoad(440:3).4: _ZL4g_91 into ^77
	movb _ZL4g_91(%rip), %bl
	# LowerBasicConversion(441:3): i8 ^77 -> i32 ^78
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(442:3).4: _ZL3g_5 into ^79
	movl _ZL3g_5(%rip), %r8d
	# LowerLoad(443:3).4: _ZL3g_2 into ^80
	movl _ZL3g_2(%rip), %r9d
	# LowerLoad(444:3).4: _ZL13crc32_context into ^81
	movl _ZL13crc32_context(%rip), %r10d
	# Clobber %r8
	movq %r8, -64(%rbp)
	# Clobber %r9
	movq %r9, -88(%rbp)
	# Clobber %r10
	movq %r10, -72(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(445:3): move argument ptr @.str.1
	leaq .str.1(%rip), %rdi
	# SetupCalls(445:3): move argument i32 ^76
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(445:3): move argument i32 ^78
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	# SetupCalls(445:3): move argument i32 ^79
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	# SetupCalls(445:3): move argument i32 ^80
	# Fixed movzx with 32-bit source operand
	movl %r9d, %r8d
	# SetupCalls(445:3): move argument i32 ^81
	# Fixed movzx with 32-bit source operand
	movl %r10d, %r9d
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(445:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %r10
	movq -72(%rbp), %r10
	# Unclobber %r9
	movq -88(%rbp), %r9
	# Unclobber %r8
	movq -64(%rbp), %r8
	# LowerLoad(446:3).4: _ZL5g_106 into ^83
	movw _ZL5g_106(%rip), %ax
	# LowerBasicConversion(447:3): i16 ^83 -> i64 ^84
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLoad(448:3).2: (^9) into i32 ^85
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(449:3): move argument i64 ^84
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(449:3): move argument ptr @.str.6
	leaq .str.6(%rip), %rsi
	# SetupCalls(449:3): move argument i32 ^85
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(450:3).4: _ZL5g_106 into ^86
	movw _ZL5g_106(%rip), %ax
	# LowerBasicConversion(451:3): i16 ^86 -> i32 ^87
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLoad(452:3).4: _ZL4g_91 into ^88
	movb _ZL4g_91(%rip), %bl
	# LowerBasicConversion(453:3): i8 ^88 -> i32 ^89
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(454:3).4: _ZL3g_5 into ^90
	movl _ZL3g_5(%rip), %r8d
	# LowerLoad(455:3).4: _ZL3g_2 into ^91
	movl _ZL3g_2(%rip), %r9d
	# LowerLoad(456:3).4: _ZL13crc32_context into ^92
	movl _ZL13crc32_context(%rip), %r10d
	# Clobber %r8
	movq %r8, -64(%rbp)
	# Clobber %r9
	movq %r9, -88(%rbp)
	# Clobber %r10
	movq %r10, -72(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(457:3): move argument ptr @.str.1
	leaq .str.1(%rip), %rdi
	# SetupCalls(457:3): move argument i32 ^87
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(457:3): move argument i32 ^89
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	# SetupCalls(457:3): move argument i32 ^90
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	# SetupCalls(457:3): move argument i32 ^91
	# Fixed movzx with 32-bit source operand
	movl %r9d, %r8d
	# SetupCalls(457:3): move argument i32 ^92
	# Fixed movzx with 32-bit source operand
	movl %r10d, %r9d
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(457:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %r10
	movq -72(%rbp), %r10
	# Unclobber %r9
	movq -88(%rbp), %r9
	# Unclobber %r8
	movq -64(%rbp), %r8
	# LowerLoad(458:3).4: _ZL5g_107 into ^94
	movl _ZL5g_107(%rip), %eax
	# LowerBasicConversion(459:3): i32 ^94 -> i64 ^95
	# LowerLoad(460:3).2: (^9) into i32 ^96
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(461:3): move argument i64 ^95
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(461:3): move argument ptr @.str.7
	leaq .str.7(%rip), %rsi
	# SetupCalls(461:3): move argument i32 ^96
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(462:3).4: _ZL5g_117 into ^97
	movw _ZL5g_117(%rip), %ax
	movswq %ax, %rbx
	# LowerLoad(464:3).2: (^9) into i32 ^99
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(465:3): move argument i64 ^98
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(465:3): move argument ptr @.str.8
	leaq .str.8(%rip), %rsi
	# SetupCalls(465:3): move argument i32 ^99
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(466:3).4: _ZL5g_118 into ^100
	movl _ZL5g_118(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(468:3).2: (^9) into i32 ^102
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(469:3): move argument i64 ^101
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(469:3): move argument ptr @.str.9
	leaq .str.9(%rip), %rsi
	# SetupCalls(469:3): move argument i32 ^102
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(470:3).4: _ZL5g_119 into ^103
	movl _ZL5g_119(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(472:3).2: (^9) into i32 ^105
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(473:3): move argument i64 ^104
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(473:3): move argument ptr @.str.10
	leaq .str.10(%rip), %rsi
	# SetupCalls(473:3): move argument i32 ^105
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(474:3).4: _ZL5g_120 into ^106
	movw _ZL5g_120(%rip), %ax
	movswq %ax, %rbx
	# LowerLoad(476:3).2: (^9) into i32 ^108
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(477:3): move argument i64 ^107
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(477:3): move argument ptr @.str.11
	leaq .str.11(%rip), %rsi
	# SetupCalls(477:3): move argument i32 ^108
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(478:3).4: _ZL5g_124 into ^109
	movw _ZL5g_124(%rip), %bx
	# LowerBasicConversion(479:3): i16 ^109 -> i64 ^110
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(480:3).2: (^9) into i32 ^111
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(481:3): move argument i64 ^110
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(481:3): move argument ptr @.str.12
	leaq .str.12(%rip), %rsi
	# SetupCalls(481:3): move argument i32 ^111
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(482:3).4: _ZL5g_132 into ^112
	movw _ZL5g_132(%rip), %ax
	movswq %ax, %rbx
	# LowerLoad(484:3).2: (^9) into i32 ^114
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(485:3): move argument i64 ^113
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(485:3): move argument ptr @.str.13
	leaq .str.13(%rip), %rsi
	# SetupCalls(485:3): move argument i32 ^114
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(486:3).2: (^9) into i32 ^115
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(487:3): move argument i64 1
	movq $1, %rdi
	# SetupCalls(487:3): move argument ptr @.str.14
	leaq .str.14(%rip), %rsi
	# SetupCalls(487:3): move argument i32 ^115
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(488:3).4: _ZL5g_203 into ^116
	movb _ZL5g_203(%rip), %al
	movsbq %al, %rbx
	# LowerLoad(490:3).2: (^9) into i32 ^118
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(491:3): move argument i64 ^117
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(491:3): move argument ptr @.str.15
	leaq .str.15(%rip), %rsi
	# SetupCalls(491:3): move argument i32 ^118
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerStore(492:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M919:
	# LowerLoad(496:3).2: (^6) into i32 ^120
	movl (%r12), %eax
	# LowerIcmp(497:3): i32 ^120 vs. intlike 5
	cmpl $5, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M926
	jmp .__main__M1015
	.__main__M926:
	# LowerLoad(501:3).2: (^6) into i32 ^123
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL5g_232(%rip), %rcx
	# tt = Pointer, type = [5 x i8]
	# LowerGetelementptr(503:3): array/pointer-type, dynamic index -> ^125
	# index ^124 -> temp ^847
	movq %rbx, %rax
	# Multiply temp ^847 by 1 start
	# Multiply end
	# temp ^847 -> operand ^125
	# Result ^125 += base pointer ^846
	addq %rcx, %rax
	# LowerLoad(504:3).2: (^125) into i8 ^126
	movb (%rax), %bl
	movsbq %bl, %rax
	# LowerLoad(506:3).2: (^9) into i32 ^128
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(507:3): move argument i64 ^127
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(507:3): move argument ptr @.str.16
	leaq .str.16(%rip), %rsi
	# SetupCalls(507:3): move argument i32 ^128
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(508:3).2: (^9) into i32 ^129
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(509:3): i32 ^129 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M977
	jmp .__main__M1006
	.__main__M977:
	# LowerLoad(513:3).2: (^6) into i32 ^132
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(514:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(514:3): move argument i32 ^132
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(514:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M1006:
	# LowerLoad(521:3).2: (^6) into i32 ^136
	movl (%r12), %eax
	# LowerMath(522:3): ^136, 1 into i32 ^137
	addl $1, %eax
	# LowerStore(523:3).9: mov i32 ^137, (^6)
	movl %eax, (%r12)
	jmp .__main__M919
	.__main__M1015:
	# LowerLoad(527:3).4: _ZL5g_245 into ^139
	movq _ZL5g_245(%rip), %rbx
	# LowerLoad(528:3).2: (^9) into i32 ^140
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(529:3): move argument i64 ^139
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(529:3): move argument ptr @.str.18
	leaq .str.18(%rip), %rsi
	# SetupCalls(529:3): move argument i32 ^140
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(530:3).4: _ZL5g_246 into ^141
	movl _ZL5g_246(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(532:3).2: (^9) into i32 ^143
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(533:3): move argument i64 ^142
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(533:3): move argument ptr @.str.19
	leaq .str.19(%rip), %rsi
	# SetupCalls(533:3): move argument i32 ^143
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(534:3).4: _ZL5g_247 into ^144
	movw _ZL5g_247(%rip), %bx
	# LowerBasicConversion(535:3): i16 ^144 -> i64 ^145
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(536:3).2: (^9) into i32 ^146
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(537:3): move argument i64 ^145
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(537:3): move argument ptr @.str.20
	leaq .str.20(%rip), %rsi
	# SetupCalls(537:3): move argument i32 ^146
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(538:3).4: _ZL5g_259 into ^147
	movb _ZL5g_259(%rip), %al
	# LowerBasicConversion(539:3): i8 ^147 -> i64 ^148
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerLoad(540:3).2: (^9) into i32 ^149
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(541:3): move argument i64 ^148
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(541:3): move argument ptr @.str.21
	leaq .str.21(%rip), %rsi
	# SetupCalls(541:3): move argument i32 ^149
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(542:3).4: _ZL5g_265 into ^150
	movw _ZL5g_265(%rip), %bx
	# LowerBasicConversion(543:3): i16 ^150 -> i64 ^151
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(544:3).2: (^9) into i32 ^152
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(545:3): move argument i64 ^151
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(545:3): move argument ptr @.str.22
	leaq .str.22(%rip), %rsi
	# SetupCalls(545:3): move argument i32 ^152
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(546:3).2: (^9) into i32 ^153
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(547:3): move argument i64 -275451831
	movq $-275451831, %rdi
	# SetupCalls(547:3): move argument ptr @.str.23
	leaq .str.23(%rip), %rsi
	# SetupCalls(547:3): move argument i32 ^153
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(548:3).4: _ZL5g_338 into ^154
	movq _ZL5g_338(%rip), %rax
	# LowerLoad(549:3).2: (^9) into i32 ^155
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(550:3): move argument i64 ^154
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(550:3): move argument ptr @.str.24
	leaq .str.24(%rip), %rsi
	# SetupCalls(550:3): move argument i32 ^155
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(551:3).2: (^9) into i32 ^156
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(552:3): move argument i64 12039
	movq $12039, %rdi
	# SetupCalls(552:3): move argument ptr @.str.25
	leaq .str.25(%rip), %rsi
	# SetupCalls(552:3): move argument i32 ^156
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(553:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M1260:
	# LowerLoad(557:3).2: (^6) into i32 ^158
	movl (%r12), %eax
	# LowerIcmp(558:3): i32 ^158 vs. intlike 6
	cmpl $6, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1267
	jmp .__main__M1376
	.__main__M1267:
	# LowerLoad(562:3).2: (^9) into i32 ^161
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(563:3): i32 ^161 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1274
	jmp .__main__M1322
	.__main__M1274:
	# LowerLoad(567:3).2: (^6) into i32 ^164
	movl (%r12), %eax
	# LowerLoad(568:3).2: (^6) into i32 ^165
	movl (%r12), %ebx
	movslq %ebx, %rcx
	leaq _ZL5g_422(%rip), %rdx
	# tt = Pointer, type = [6 x i32]
	# LowerGetelementptr(570:3): array/pointer-type, dynamic index -> ^167
	# index ^166 -> temp ^849
	movq %rcx, %rsi
	# Multiply temp ^849 by 4 start
	shlq $2, %rsi
	# Multiply end
	# temp ^849 -> operand ^167
	movq %rsi, %rbx
	# Result ^167 += base pointer ^848
	addq %rdx, %rbx
	# LowerLoad(571:3).2: (^167) into i32 ^168
	movl (%rbx), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(572:3): move argument ptr @.str.26
	leaq .str.26(%rip), %rdi
	# SetupCalls(572:3): move argument i32 ^164
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(572:3): move argument i32 ^168
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(572:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	.__main__M1322:
	# LowerLoad(576:3).2: (^6) into i32 ^171
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL5g_422(%rip), %rcx
	# tt = Pointer, type = [6 x i32]
	# LowerGetelementptr(578:3): array/pointer-type, dynamic index -> ^173
	# index ^172 -> temp ^851
	movq %rbx, %rdx
	# Multiply temp ^851 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^851 -> operand ^173
	movq %rdx, %rax
	# Result ^173 += base pointer ^850
	addq %rcx, %rax
	# LowerLoad(579:3).2: (^173) into i32 ^174
	movl (%rax), %ebx
	movslq %ebx, %rax
	# LowerLoad(581:3).2: (^9) into i32 ^176
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(582:3): move argument i64 ^175
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(582:3): move argument ptr @.str.27
	leaq .str.27(%rip), %rsi
	# SetupCalls(582:3): move argument i32 ^176
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(586:3).2: (^6) into i32 ^178
	movl (%r12), %eax
	# LowerMath(587:3): ^178, 1 into i32 ^179
	addl $1, %eax
	# LowerStore(588:3).9: mov i32 ^179, (^6)
	movl %eax, (%r12)
	jmp .__main__M1260
	.__main__M1376:
	# LowerLoad(592:3).2: (^9) into i32 ^181
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(593:3): move argument i64 -1
	movq $-1, %rdi
	# SetupCalls(593:3): move argument ptr @.str.28
	leaq .str.28(%rip), %rsi
	# SetupCalls(593:3): move argument i32 ^181
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(594:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M1406:
	# LowerLoad(598:3).2: (^6) into i32 ^183
	movl (%r12), %eax
	# LowerIcmp(599:3): i32 ^183 vs. intlike 10
	cmpl $10, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1413
	jmp .__main__M1504
	.__main__M1413:
	# LowerLoad(603:3).2: (^6) into i32 ^186
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL5g_449(%rip), %rcx
	# tt = Pointer, type = [10 x i32]
	# LowerGetelementptr(605:3): array/pointer-type, dynamic index -> ^188
	# index ^187 -> temp ^853
	movq %rbx, %rdx
	# Multiply temp ^853 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^853 -> operand ^188
	movq %rdx, %rax
	# Result ^188 += base pointer ^852
	addq %rcx, %rax
	# LowerLoad(606:3).2: (^188) into i32 ^189
	movl (%rax), %ebx
	# LowerBasicConversion(607:3): i32 ^189 -> i64 ^190
	# LowerLoad(608:3).2: (^9) into i32 ^191
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(609:3): move argument i64 ^190
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(609:3): move argument ptr @.str.29
	leaq .str.29(%rip), %rsi
	# SetupCalls(609:3): move argument i32 ^191
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(610:3).2: (^9) into i32 ^192
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(611:3): i32 ^192 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1466
	jmp .__main__M1495
	.__main__M1466:
	# LowerLoad(615:3).2: (^6) into i32 ^195
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(616:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(616:3): move argument i32 ^195
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(616:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M1495:
	# LowerLoad(623:3).2: (^6) into i32 ^199
	movl (%r12), %eax
	# LowerMath(624:3): ^199, 1 into i32 ^200
	addl $1, %eax
	# LowerStore(625:3).9: mov i32 ^200, (^6)
	movl %eax, (%r12)
	jmp .__main__M1406
	.__main__M1504:
	# LowerLoad(629:3).4: _ZL5g_453 into ^202
	movw _ZL5g_453(%rip), %ax
	# LowerBasicConversion(630:3): i16 ^202 -> i64 ^203
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLoad(631:3).2: (^9) into i32 ^204
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(632:3): move argument i64 ^203
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(632:3): move argument ptr @.str.30
	leaq .str.30(%rip), %rsi
	# SetupCalls(632:3): move argument i32 ^204
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(633:3).4: _ZL5g_455 into ^205
	movw _ZL5g_455(%rip), %ax
	# LowerBasicConversion(634:3): i16 ^205 -> i64 ^206
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLoad(635:3).2: (^9) into i32 ^207
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(636:3): move argument i64 ^206
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(636:3): move argument ptr @.str.31
	leaq .str.31(%rip), %rsi
	# SetupCalls(636:3): move argument i32 ^207
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(637:3).4: _ZL5g_648 into ^208
	movb _ZL5g_648(%rip), %al
	movsbq %al, %rbx
	# LowerLoad(639:3).2: (^9) into i32 ^210
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(640:3): move argument i64 ^209
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(640:3): move argument ptr @.str.32
	leaq .str.32(%rip), %rsi
	# SetupCalls(640:3): move argument i32 ^210
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(641:3).4: _ZL5g_651 into ^211
	movw _ZL5g_651(%rip), %ax
	# LowerBasicConversion(642:3): i16 ^211 -> i64 ^212
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLoad(643:3).2: (^9) into i32 ^213
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(644:3): move argument i64 ^212
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(644:3): move argument ptr @.str.33
	leaq .str.33(%rip), %rsi
	# SetupCalls(644:3): move argument i32 ^213
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(645:3).4: _ZL5g_693 into ^214
	movl _ZL5g_693(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(647:3).2: (^9) into i32 ^216
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(648:3): move argument i64 ^215
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(648:3): move argument ptr @.str.34
	leaq .str.34(%rip), %rsi
	# SetupCalls(648:3): move argument i32 ^216
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(649:3).4: _ZL5g_695 into ^217
	movl _ZL5g_695(%rip), %eax
	# LowerBasicConversion(650:3): i32 ^217 -> i64 ^218
	# LowerLoad(651:3).2: (^9) into i32 ^219
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(652:3): move argument i64 ^218
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(652:3): move argument ptr @.str.35
	leaq .str.35(%rip), %rsi
	# SetupCalls(652:3): move argument i32 ^219
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(653:3).4: _ZL5g_862 into ^220
	movq _ZL5g_862(%rip), %rbx
	# LowerLoad(654:3).2: (^9) into i32 ^221
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(655:3): move argument i64 ^220
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(655:3): move argument ptr @.str.36
	leaq .str.36(%rip), %rsi
	# SetupCalls(655:3): move argument i32 ^221
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(656:3).4: _ZL6g_1175 into ^222
	movw _ZL6g_1175(%rip), %ax
	# LowerBasicConversion(657:3): i16 ^222 -> i64 ^223
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLoad(658:3).2: (^9) into i32 ^224
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(659:3): move argument i64 ^223
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(659:3): move argument ptr @.str.37
	leaq .str.37(%rip), %rsi
	# SetupCalls(659:3): move argument i32 ^224
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(660:3).4: _ZL6g_1221 into ^225
	movq _ZL6g_1221(%rip), %rax
	# LowerLoad(661:3).2: (^9) into i32 ^226
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(662:3): move argument i64 ^225
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(662:3): move argument ptr @.str.38
	leaq .str.38(%rip), %rsi
	# SetupCalls(662:3): move argument i32 ^226
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(663:3).4: _ZL6g_1335 into ^227
	movb _ZL6g_1335(%rip), %al
	movsbq %al, %rbx
	# LowerLoad(665:3).2: (^9) into i32 ^229
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(666:3): move argument i64 ^228
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(666:3): move argument ptr @.str.39
	leaq .str.39(%rip), %rsi
	# SetupCalls(666:3): move argument i32 ^229
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(667:3).4: _ZL6g_1357 into ^230
	movl _ZL6g_1357(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(669:3).2: (^9) into i32 ^232
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(670:3): move argument i64 ^231
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(670:3): move argument ptr @.str.40
	leaq .str.40(%rip), %rsi
	# SetupCalls(670:3): move argument i32 ^232
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(671:3).4: _ZL6g_1391 into ^233
	movb _ZL6g_1391(%rip), %al
	movsbq %al, %rbx
	# LowerLoad(673:3).2: (^9) into i32 ^235
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(674:3): move argument i64 ^234
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(674:3): move argument ptr @.str.41
	leaq .str.41(%rip), %rsi
	# SetupCalls(674:3): move argument i32 ^235
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(675:3).4: _ZL6g_1487 into ^236
	movq _ZL6g_1487(%rip), %rax
	# LowerLoad(676:3).2: (^9) into i32 ^237
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(677:3): move argument i64 ^236
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(677:3): move argument ptr @.str.42
	leaq .str.42(%rip), %rsi
	# SetupCalls(677:3): move argument i32 ^237
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(678:3).4: _ZL6g_1499 into ^238
	movl _ZL6g_1499(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(680:3).2: (^9) into i32 ^240
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(681:3): move argument i64 ^239
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(681:3): move argument ptr @.str.43
	leaq .str.43(%rip), %rsi
	# SetupCalls(681:3): move argument i32 ^240
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(682:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M1939:
	# LowerLoad(686:3).2: (^6) into i32 ^242
	movl (%r12), %eax
	# LowerIcmp(687:3): i32 ^242 vs. intlike 10
	cmpl $10, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1946
	jmp .__main__M2111
	.__main__M1946:
	# LowerStore(691:3).3: mov $imm, (^7)
	movl $0, (%r15)
	.__main__M1949:
	# LowerLoad(695:3).2: (^7) into i32 ^246
	movl (%r15), %eax
	# LowerIcmp(696:3): i32 ^246 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1956
	jmp .__main__M2102
	.__main__M1956:
	# LowerStore(700:3).3: mov $imm, (^8)
	movl $0, (%r13)
	.__main__M1959:
	# LowerLoad(704:3).2: (^8) into i32 ^250
	movl (%r13), %eax
	# LowerIcmp(705:3): i32 ^250 vs. intlike 2
	cmpl $2, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1966
	jmp .__main__M2093
	.__main__M1966:
	# LowerLoad(709:3).2: (^6) into i32 ^253
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1554(%rip), %rax
	# tt = Pointer, type = [10 x [8 x [2 x i32]]]
	# LowerGetelementptr(711:3): array/pointer-type, dynamic index -> ^255
	# index ^254 -> temp ^855
	movq %rbx, %rcx
	# Multiply temp ^855 by 64 start
	shlq $6, %rcx
	# Multiply end
	# temp ^855 -> operand ^255
	movq %rcx, %rbx
	# Result ^255 += base pointer ^854
	addq %rax, %rbx
	# LowerLoad(712:3).2: (^7) into i32 ^256
	movl (%r15), %eax
	movslq %eax, %rcx
	# tt = Pointer, type = [8 x [2 x i32]]
	# LowerGetelementptr(714:3): array/pointer-type, dynamic index -> ^258
	# index ^257 -> temp ^856
	movq %rcx, %rdx
	# Multiply temp ^856 by 8 start
	shlq $3, %rdx
	# Multiply end
	# temp ^856 -> operand ^258
	movq %rdx, %rax
	# Result ^258 += base pointer ^255
	addq %rbx, %rax
	# LowerLoad(715:3).2: (^8) into i32 ^259
	movl (%r13), %ebx
	movslq %ebx, %rcx
	# tt = Pointer, type = [2 x i32]
	# LowerGetelementptr(717:3): array/pointer-type, dynamic index -> ^261
	# index ^260 -> temp ^857
	movq %rcx, %rdx
	# Multiply temp ^857 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^857 -> operand ^261
	movq %rdx, %rbx
	# Result ^261 += base pointer ^258
	addq %rax, %rbx
	# LowerLoad(718:3).2: (^261) into i32 ^262
	movl (%rbx), %eax
	# LowerBasicConversion(719:3): i32 ^262 -> i64 ^263
	# LowerLoad(720:3).2: (^9) into i32 ^264
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(721:3): move argument i64 ^263
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(721:3): move argument ptr @.str.44
	leaq .str.44(%rip), %rsi
	# SetupCalls(721:3): move argument i32 ^264
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(722:3).2: (^9) into i32 ^265
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(723:3): i32 ^265 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2047
	jmp .__main__M2084
	.__main__M2047:
	# LowerLoad(727:3).2: (^6) into i32 ^268
	movl (%r12), %eax
	# LowerLoad(728:3).2: (^7) into i32 ^269
	movl (%r15), %ebx
	# LowerLoad(729:3).2: (^8) into i32 ^270
	movl (%r13), %r8d
	# Clobber %r8
	movq %r8, -64(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(730:3): move argument ptr @.str.45
	leaq .str.45(%rip), %rdi
	# SetupCalls(730:3): move argument i32 ^268
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(730:3): move argument i32 ^269
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	# SetupCalls(730:3): move argument i32 ^270
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(730:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %r8
	movq -64(%rbp), %r8
	.__main__M2084:
	# LowerLoad(737:3).2: (^8) into i32 ^274
	movl (%r13), %eax
	# LowerMath(738:3): ^274, 1 into i32 ^275
	addl $1, %eax
	# LowerStore(739:3).9: mov i32 ^275, (^8)
	movl %eax, (%r13)
	jmp .__main__M1959
	.__main__M2093:
	# LowerLoad(746:3).2: (^7) into i32 ^278
	movl (%r15), %eax
	# LowerMath(747:3): ^278, 1 into i32 ^279
	addl $1, %eax
	# LowerStore(748:3).9: mov i32 ^279, (^7)
	movl %eax, (%r15)
	jmp .__main__M1949
	.__main__M2102:
	# LowerLoad(755:3).2: (^6) into i32 ^282
	movl (%r12), %eax
	# LowerMath(756:3): ^282, 1 into i32 ^283
	addl $1, %eax
	# LowerStore(757:3).9: mov i32 ^283, (^6)
	movl %eax, (%r12)
	jmp .__main__M1939
	.__main__M2111:
	# LowerLoad(761:3).2: (^9) into i32 ^285
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(762:3): move argument i64 5215
	movq $5215, %rdi
	# SetupCalls(762:3): move argument ptr @.str.46
	leaq .str.46(%rip), %rsi
	# SetupCalls(762:3): move argument i32 ^285
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(763:3).2: (^9) into i32 ^286
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(764:3): move argument i64 2
	movq $2, %rdi
	# SetupCalls(764:3): move argument ptr @.str.47
	leaq .str.47(%rip), %rsi
	# SetupCalls(764:3): move argument i32 ^286
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(765:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M2168:
	# LowerLoad(769:3).2: (^6) into i32 ^288
	movl (%r12), %eax
	# LowerIcmp(770:3): i32 ^288 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2175
	jmp .__main__M2265
	.__main__M2175:
	# LowerLoad(774:3).2: (^6) into i32 ^291
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1717(%rip), %rcx
	# tt = Pointer, type = [8 x %union.U3]
	# LowerGetelementptr(776:3): array/pointer-type, dynamic index -> ^293
	# index ^292 -> temp ^859
	movq %rbx, %rdx
	# Multiply temp ^859 by 2 start
	shlq $1, %rdx
	# Multiply end
	# temp ^859 -> operand ^293
	movq %rdx, %rax
	# Result ^293 += base pointer ^858
	addq %rcx, %rax
	# LowerLoad(777:3).2: (^293) into i16 ^294
	movw (%rax), %bx
	movswq %bx, %rax
	# LowerLoad(779:3).2: (^9) into i32 ^296
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(780:3): move argument i64 ^295
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(780:3): move argument ptr @.str.48
	leaq .str.48(%rip), %rsi
	# SetupCalls(780:3): move argument i32 ^296
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(781:3).2: (^9) into i32 ^297
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(782:3): i32 ^297 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2227
	jmp .__main__M2256
	.__main__M2227:
	# LowerLoad(786:3).2: (^6) into i32 ^300
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(787:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(787:3): move argument i32 ^300
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(787:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M2256:
	# LowerLoad(794:3).2: (^6) into i32 ^304
	movl (%r12), %eax
	# LowerMath(795:3): ^304, 1 into i32 ^305
	addl $1, %eax
	# LowerStore(796:3).9: mov i32 ^305, (^6)
	movl %eax, (%r12)
	jmp .__main__M2168
	.__main__M2265:
	# LowerLoad(800:3).4: _ZL6g_1877 into ^307
	movl _ZL6g_1877(%rip), %eax
	# LowerBasicConversion(801:3): i32 ^307 -> i64 ^308
	# LowerLoad(802:3).2: (^9) into i32 ^309
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(803:3): move argument i64 ^308
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(803:3): move argument ptr @.str.49
	leaq .str.49(%rip), %rsi
	# SetupCalls(803:3): move argument i32 ^309
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(804:3).4: _ZL6g_1883 into ^310
	movl _ZL6g_1883(%rip), %eax
	# LowerBasicConversion(805:3): i32 ^310 -> i64 ^311
	# LowerLoad(806:3).2: (^9) into i32 ^312
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(807:3): move argument i64 ^311
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(807:3): move argument ptr @.str.50
	leaq .str.50(%rip), %rsi
	# SetupCalls(807:3): move argument i32 ^312
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(808:3).4: _ZL6g_1884 into ^313
	movl _ZL6g_1884(%rip), %eax
	# LowerBasicConversion(809:3): i32 ^313 -> i64 ^314
	# LowerLoad(810:3).2: (^9) into i32 ^315
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(811:3): move argument i64 ^314
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(811:3): move argument ptr @.str.51
	leaq .str.51(%rip), %rsi
	# SetupCalls(811:3): move argument i32 ^315
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(812:3).4: _ZL6g_1885 into ^316
	movl _ZL6g_1885(%rip), %eax
	# LowerBasicConversion(813:3): i32 ^316 -> i64 ^317
	# LowerLoad(814:3).2: (^9) into i32 ^318
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(815:3): move argument i64 ^317
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(815:3): move argument ptr @.str.52
	leaq .str.52(%rip), %rsi
	# SetupCalls(815:3): move argument i32 ^318
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(816:3).4: _ZL6g_1886 into ^319
	movl _ZL6g_1886(%rip), %eax
	# LowerBasicConversion(817:3): i32 ^319 -> i64 ^320
	# LowerLoad(818:3).2: (^9) into i32 ^321
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(819:3): move argument i64 ^320
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(819:3): move argument ptr @.str.53
	leaq .str.53(%rip), %rsi
	# SetupCalls(819:3): move argument i32 ^321
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(820:3).4: _ZL6g_1887 into ^322
	movl _ZL6g_1887(%rip), %eax
	# LowerBasicConversion(821:3): i32 ^322 -> i64 ^323
	# LowerLoad(822:3).2: (^9) into i32 ^324
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(823:3): move argument i64 ^323
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(823:3): move argument ptr @.str.54
	leaq .str.54(%rip), %rsi
	# SetupCalls(823:3): move argument i32 ^324
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(824:3).4: _ZL6g_1888 into ^325
	movl _ZL6g_1888(%rip), %eax
	# LowerBasicConversion(825:3): i32 ^325 -> i64 ^326
	# LowerLoad(826:3).2: (^9) into i32 ^327
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(827:3): move argument i64 ^326
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(827:3): move argument ptr @.str.55
	leaq .str.55(%rip), %rsi
	# SetupCalls(827:3): move argument i32 ^327
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(828:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M2486:
	# LowerLoad(832:3).2: (^6) into i32 ^329
	movl (%r12), %eax
	# LowerIcmp(833:3): i32 ^329 vs. intlike 10
	cmpl $10, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2493
	jmp .__main__M2584
	.__main__M2493:
	# LowerLoad(837:3).2: (^6) into i32 ^332
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1889(%rip), %rcx
	# tt = Pointer, type = [10 x i32]
	# LowerGetelementptr(839:3): array/pointer-type, dynamic index -> ^334
	# index ^333 -> temp ^861
	movq %rbx, %rdx
	# Multiply temp ^861 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^861 -> operand ^334
	movq %rdx, %rax
	# Result ^334 += base pointer ^860
	addq %rcx, %rax
	# LowerLoad(840:3).2: (^334) into i32 ^335
	movl (%rax), %ebx
	# LowerBasicConversion(841:3): i32 ^335 -> i64 ^336
	# LowerLoad(842:3).2: (^9) into i32 ^337
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(843:3): move argument i64 ^336
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(843:3): move argument ptr @.str.56
	leaq .str.56(%rip), %rsi
	# SetupCalls(843:3): move argument i32 ^337
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(844:3).2: (^9) into i32 ^338
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(845:3): i32 ^338 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2546
	jmp .__main__M2575
	.__main__M2546:
	# LowerLoad(849:3).2: (^6) into i32 ^341
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(850:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(850:3): move argument i32 ^341
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(850:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M2575:
	# LowerLoad(857:3).2: (^6) into i32 ^345
	movl (%r12), %eax
	# LowerMath(858:3): ^345, 1 into i32 ^346
	addl $1, %eax
	# LowerStore(859:3).9: mov i32 ^346, (^6)
	movl %eax, (%r12)
	jmp .__main__M2486
	.__main__M2584:
	# LowerLoad(863:3).4: _ZL6g_1890 into ^348
	movl _ZL6g_1890(%rip), %ebx
	# LowerBasicConversion(864:3): i32 ^348 -> i64 ^349
	# LowerLoad(865:3).2: (^9) into i32 ^350
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(866:3): move argument i64 ^349
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(866:3): move argument ptr @.str.57
	leaq .str.57(%rip), %rsi
	# SetupCalls(866:3): move argument i32 ^350
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(867:3).4: _ZL6g_1891 into ^351
	movl _ZL6g_1891(%rip), %eax
	# LowerBasicConversion(868:3): i32 ^351 -> i64 ^352
	# LowerLoad(869:3).2: (^9) into i32 ^353
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(870:3): move argument i64 ^352
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(870:3): move argument ptr @.str.58
	leaq .str.58(%rip), %rsi
	# SetupCalls(870:3): move argument i32 ^353
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(871:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M2649:
	# LowerLoad(875:3).2: (^6) into i32 ^355
	movl (%r12), %eax
	# LowerIcmp(876:3): i32 ^355 vs. intlike 5
	cmpl $5, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2656
	jmp .__main__M2747
	.__main__M2656:
	# LowerLoad(880:3).2: (^6) into i32 ^358
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1892(%rip), %rcx
	# tt = Pointer, type = [5 x i32]
	# LowerGetelementptr(882:3): array/pointer-type, dynamic index -> ^360
	# index ^359 -> temp ^863
	movq %rbx, %rdx
	# Multiply temp ^863 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^863 -> operand ^360
	movq %rdx, %rax
	# Result ^360 += base pointer ^862
	addq %rcx, %rax
	# LowerLoad(883:3).2: (^360) into i32 ^361
	movl (%rax), %ebx
	# LowerBasicConversion(884:3): i32 ^361 -> i64 ^362
	# LowerLoad(885:3).2: (^9) into i32 ^363
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(886:3): move argument i64 ^362
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(886:3): move argument ptr @.str.59
	leaq .str.59(%rip), %rsi
	# SetupCalls(886:3): move argument i32 ^363
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(887:3).2: (^9) into i32 ^364
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(888:3): i32 ^364 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2709
	jmp .__main__M2738
	.__main__M2709:
	# LowerLoad(892:3).2: (^6) into i32 ^367
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(893:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(893:3): move argument i32 ^367
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(893:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M2738:
	# LowerLoad(900:3).2: (^6) into i32 ^371
	movl (%r12), %eax
	# LowerMath(901:3): ^371, 1 into i32 ^372
	addl $1, %eax
	# LowerStore(902:3).9: mov i32 ^372, (^6)
	movl %eax, (%r12)
	jmp .__main__M2649
	.__main__M2747:
	# LowerStore(906:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M2750:
	# LowerLoad(910:3).2: (^6) into i32 ^375
	movl (%r12), %eax
	# LowerIcmp(911:3): i32 ^375 vs. intlike 7
	cmpl $7, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2757
	jmp .__main__M2848
	.__main__M2757:
	# LowerLoad(915:3).2: (^6) into i32 ^378
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1893(%rip), %rcx
	# tt = Pointer, type = [7 x i32]
	# LowerGetelementptr(917:3): array/pointer-type, dynamic index -> ^380
	# index ^379 -> temp ^865
	movq %rbx, %rdx
	# Multiply temp ^865 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^865 -> operand ^380
	movq %rdx, %rax
	# Result ^380 += base pointer ^864
	addq %rcx, %rax
	# LowerLoad(918:3).2: (^380) into i32 ^381
	movl (%rax), %ebx
	# LowerBasicConversion(919:3): i32 ^381 -> i64 ^382
	# LowerLoad(920:3).2: (^9) into i32 ^383
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(921:3): move argument i64 ^382
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(921:3): move argument ptr @.str.60
	leaq .str.60(%rip), %rsi
	# SetupCalls(921:3): move argument i32 ^383
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(922:3).2: (^9) into i32 ^384
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(923:3): i32 ^384 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2810
	jmp .__main__M2839
	.__main__M2810:
	# LowerLoad(927:3).2: (^6) into i32 ^387
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(928:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(928:3): move argument i32 ^387
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(928:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M2839:
	# LowerLoad(935:3).2: (^6) into i32 ^391
	movl (%r12), %eax
	# LowerMath(936:3): ^391, 1 into i32 ^392
	addl $1, %eax
	# LowerStore(937:3).9: mov i32 ^392, (^6)
	movl %eax, (%r12)
	jmp .__main__M2750
	.__main__M2848:
	# LowerStore(941:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M2851:
	# LowerLoad(945:3).2: (^6) into i32 ^395
	movl (%r12), %eax
	# LowerIcmp(946:3): i32 ^395 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2858
	jmp .__main__M2949
	.__main__M2858:
	# LowerLoad(950:3).2: (^6) into i32 ^398
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1894(%rip), %rcx
	# tt = Pointer, type = [8 x i32]
	# LowerGetelementptr(952:3): array/pointer-type, dynamic index -> ^400
	# index ^399 -> temp ^867
	movq %rbx, %rdx
	# Multiply temp ^867 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^867 -> operand ^400
	movq %rdx, %rax
	# Result ^400 += base pointer ^866
	addq %rcx, %rax
	# LowerLoad(953:3).2: (^400) into i32 ^401
	movl (%rax), %ebx
	# LowerBasicConversion(954:3): i32 ^401 -> i64 ^402
	# LowerLoad(955:3).2: (^9) into i32 ^403
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(956:3): move argument i64 ^402
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(956:3): move argument ptr @.str.61
	leaq .str.61(%rip), %rsi
	# SetupCalls(956:3): move argument i32 ^403
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(957:3).2: (^9) into i32 ^404
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(958:3): i32 ^404 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2911
	jmp .__main__M2940
	.__main__M2911:
	# LowerLoad(962:3).2: (^6) into i32 ^407
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(963:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(963:3): move argument i32 ^407
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(963:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M2940:
	# LowerLoad(970:3).2: (^6) into i32 ^411
	movl (%r12), %eax
	# LowerMath(971:3): ^411, 1 into i32 ^412
	addl $1, %eax
	# LowerStore(972:3).9: mov i32 ^412, (^6)
	movl %eax, (%r12)
	jmp .__main__M2851
	.__main__M2949:
	# LowerLoad(976:3).4: _ZL6g_1895 into ^414
	movl _ZL6g_1895(%rip), %eax
	# LowerBasicConversion(977:3): i32 ^414 -> i64 ^415
	# LowerLoad(978:3).2: (^9) into i32 ^416
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(979:3): move argument i64 ^415
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(979:3): move argument ptr @.str.62
	leaq .str.62(%rip), %rsi
	# SetupCalls(979:3): move argument i32 ^416
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(980:3).4: _ZL6g_1896 into ^417
	movl _ZL6g_1896(%rip), %eax
	# LowerBasicConversion(981:3): i32 ^417 -> i64 ^418
	# LowerLoad(982:3).2: (^9) into i32 ^419
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(983:3): move argument i64 ^418
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(983:3): move argument ptr @.str.63
	leaq .str.63(%rip), %rsi
	# SetupCalls(983:3): move argument i32 ^419
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(984:3).4: _ZL6g_1897 into ^420
	movl _ZL6g_1897(%rip), %eax
	# LowerBasicConversion(985:3): i32 ^420 -> i64 ^421
	# LowerLoad(986:3).2: (^9) into i32 ^422
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(987:3): move argument i64 ^421
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(987:3): move argument ptr @.str.64
	leaq .str.64(%rip), %rsi
	# SetupCalls(987:3): move argument i32 ^422
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(988:3).4: _ZL6g_1898 into ^423
	movl _ZL6g_1898(%rip), %eax
	# LowerBasicConversion(989:3): i32 ^423 -> i64 ^424
	# LowerLoad(990:3).2: (^9) into i32 ^425
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(991:3): move argument i64 ^424
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(991:3): move argument ptr @.str.65
	leaq .str.65(%rip), %rsi
	# SetupCalls(991:3): move argument i32 ^425
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(992:3).4: _ZL6g_1899 into ^426
	movl _ZL6g_1899(%rip), %eax
	# LowerBasicConversion(993:3): i32 ^426 -> i64 ^427
	# LowerLoad(994:3).2: (^9) into i32 ^428
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(995:3): move argument i64 ^427
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(995:3): move argument ptr @.str.66
	leaq .str.66(%rip), %rsi
	# SetupCalls(995:3): move argument i32 ^428
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(996:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M3108:
	# LowerLoad(1000:3).2: (^6) into i32 ^430
	movl (%r12), %eax
	# LowerIcmp(1001:3): i32 ^430 vs. intlike 3
	cmpl $3, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3115
	jmp .__main__M3206
	.__main__M3115:
	# LowerLoad(1005:3).2: (^6) into i32 ^433
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1900(%rip), %rcx
	# tt = Pointer, type = [3 x i32]
	# LowerGetelementptr(1007:3): array/pointer-type, dynamic index -> ^435
	# index ^434 -> temp ^869
	movq %rbx, %rdx
	# Multiply temp ^869 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^869 -> operand ^435
	movq %rdx, %rax
	# Result ^435 += base pointer ^868
	addq %rcx, %rax
	# LowerLoad(1008:3).2: (^435) into i32 ^436
	movl (%rax), %ebx
	# LowerBasicConversion(1009:3): i32 ^436 -> i64 ^437
	# LowerLoad(1010:3).2: (^9) into i32 ^438
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1011:3): move argument i64 ^437
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1011:3): move argument ptr @.str.67
	leaq .str.67(%rip), %rsi
	# SetupCalls(1011:3): move argument i32 ^438
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1012:3).2: (^9) into i32 ^439
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1013:3): i32 ^439 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3168
	jmp .__main__M3197
	.__main__M3168:
	# LowerLoad(1017:3).2: (^6) into i32 ^442
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1018:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(1018:3): move argument i32 ^442
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1018:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M3197:
	# LowerLoad(1025:3).2: (^6) into i32 ^446
	movl (%r12), %eax
	# LowerMath(1026:3): ^446, 1 into i32 ^447
	addl $1, %eax
	# LowerStore(1027:3).9: mov i32 ^447, (^6)
	movl %eax, (%r12)
	jmp .__main__M3108
	.__main__M3206:
	# LowerLoad(1031:3).4: _ZL6g_1901 into ^449
	movl _ZL6g_1901(%rip), %ebx
	# LowerBasicConversion(1032:3): i32 ^449 -> i64 ^450
	# LowerLoad(1033:3).2: (^9) into i32 ^451
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(1034:3): move argument i64 ^450
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1034:3): move argument ptr @.str.68
	leaq .str.68(%rip), %rsi
	# SetupCalls(1034:3): move argument i32 ^451
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(1035:3).4: _ZL6g_1902 into ^452
	movl _ZL6g_1902(%rip), %ebx
	# LowerBasicConversion(1036:3): i32 ^452 -> i64 ^453
	# LowerLoad(1037:3).2: (^9) into i32 ^454
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(1038:3): move argument i64 ^453
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1038:3): move argument ptr @.str.69
	leaq .str.69(%rip), %rsi
	# SetupCalls(1038:3): move argument i32 ^454
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(1039:3).4: _ZL6g_1903 into ^455
	movl _ZL6g_1903(%rip), %eax
	# LowerBasicConversion(1040:3): i32 ^455 -> i64 ^456
	# LowerLoad(1041:3).2: (^9) into i32 ^457
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1042:3): move argument i64 ^456
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1042:3): move argument ptr @.str.70
	leaq .str.70(%rip), %rsi
	# SetupCalls(1042:3): move argument i32 ^457
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1043:3).4: _ZL6g_1904 into ^458
	movl _ZL6g_1904(%rip), %ebx
	# LowerBasicConversion(1044:3): i32 ^458 -> i64 ^459
	# LowerLoad(1045:3).2: (^9) into i32 ^460
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(1046:3): move argument i64 ^459
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1046:3): move argument ptr @.str.71
	leaq .str.71(%rip), %rsi
	# SetupCalls(1046:3): move argument i32 ^460
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(1047:3).4: _ZL6g_1905 into ^461
	movl _ZL6g_1905(%rip), %eax
	# LowerBasicConversion(1048:3): i32 ^461 -> i64 ^462
	# LowerLoad(1049:3).2: (^9) into i32 ^463
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1050:3): move argument i64 ^462
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1050:3): move argument ptr @.str.72
	leaq .str.72(%rip), %rsi
	# SetupCalls(1050:3): move argument i32 ^463
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1051:3).4: _ZL6g_1906 into ^464
	movl _ZL6g_1906(%rip), %eax
	# LowerBasicConversion(1052:3): i32 ^464 -> i64 ^465
	# LowerLoad(1053:3).2: (^9) into i32 ^466
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1054:3): move argument i64 ^465
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1054:3): move argument ptr @.str.73
	leaq .str.73(%rip), %rsi
	# SetupCalls(1054:3): move argument i32 ^466
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1055:3).4: _ZL6g_1907 into ^467
	movl _ZL6g_1907(%rip), %eax
	# LowerBasicConversion(1056:3): i32 ^467 -> i64 ^468
	# LowerLoad(1057:3).2: (^9) into i32 ^469
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1058:3): move argument i64 ^468
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1058:3): move argument ptr @.str.74
	leaq .str.74(%rip), %rsi
	# SetupCalls(1058:3): move argument i32 ^469
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1059:3).4: _ZL6g_1908 into ^470
	movl _ZL6g_1908(%rip), %eax
	# LowerBasicConversion(1060:3): i32 ^470 -> i64 ^471
	# LowerLoad(1061:3).2: (^9) into i32 ^472
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1062:3): move argument i64 ^471
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1062:3): move argument ptr @.str.75
	leaq .str.75(%rip), %rsi
	# SetupCalls(1062:3): move argument i32 ^472
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1063:3).4: _ZL6g_1909 into ^473
	movl _ZL6g_1909(%rip), %eax
	# LowerBasicConversion(1064:3): i32 ^473 -> i64 ^474
	# LowerLoad(1065:3).2: (^9) into i32 ^475
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1066:3): move argument i64 ^474
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1066:3): move argument ptr @.str.76
	leaq .str.76(%rip), %rsi
	# SetupCalls(1066:3): move argument i32 ^475
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1067:3).4: _ZL6g_1910 into ^476
	movl _ZL6g_1910(%rip), %eax
	# LowerBasicConversion(1068:3): i32 ^476 -> i64 ^477
	movq %rax, %rbx
	# LowerLoad(1069:3).2: (^9) into i32 ^478
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1070:3): move argument i64 ^477
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1070:3): move argument ptr @.str.77
	leaq .str.77(%rip), %rsi
	# SetupCalls(1070:3): move argument i32 ^478
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1071:3).4: _ZL6g_1911 into ^479
	movl _ZL6g_1911(%rip), %eax
	# LowerBasicConversion(1072:3): i32 ^479 -> i64 ^480
	# LowerLoad(1073:3).2: (^9) into i32 ^481
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1074:3): move argument i64 ^480
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1074:3): move argument ptr @.str.78
	leaq .str.78(%rip), %rsi
	# SetupCalls(1074:3): move argument i32 ^481
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1075:3).4: _ZL6g_1912 into ^482
	movl _ZL6g_1912(%rip), %eax
	# LowerBasicConversion(1076:3): i32 ^482 -> i64 ^483
	# LowerLoad(1077:3).2: (^9) into i32 ^484
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1078:3): move argument i64 ^483
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1078:3): move argument ptr @.str.79
	leaq .str.79(%rip), %rsi
	# SetupCalls(1078:3): move argument i32 ^484
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1079:3).4: _ZL6g_1913 into ^485
	movl _ZL6g_1913(%rip), %eax
	# LowerBasicConversion(1080:3): i32 ^485 -> i64 ^486
	# LowerLoad(1081:3).2: (^9) into i32 ^487
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1082:3): move argument i64 ^486
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1082:3): move argument ptr @.str.80
	leaq .str.80(%rip), %rsi
	# SetupCalls(1082:3): move argument i32 ^487
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1083:3).4: _ZL6g_1914 into ^488
	movl _ZL6g_1914(%rip), %eax
	# LowerBasicConversion(1084:3): i32 ^488 -> i64 ^489
	# LowerLoad(1085:3).2: (^9) into i32 ^490
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1086:3): move argument i64 ^489
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1086:3): move argument ptr @.str.81
	leaq .str.81(%rip), %rsi
	# SetupCalls(1086:3): move argument i32 ^490
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1087:3).4: _ZL6g_1915 into ^491
	movl _ZL6g_1915(%rip), %eax
	# LowerBasicConversion(1088:3): i32 ^491 -> i64 ^492
	# LowerLoad(1089:3).2: (^9) into i32 ^493
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1090:3): move argument i64 ^492
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1090:3): move argument ptr @.str.82
	leaq .str.82(%rip), %rsi
	# SetupCalls(1090:3): move argument i32 ^493
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(1091:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M3677:
	# LowerLoad(1095:3).2: (^6) into i32 ^495
	movl (%r12), %eax
	# LowerIcmp(1096:3): i32 ^495 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3684
	jmp .__main__M3775
	.__main__M3684:
	# LowerLoad(1100:3).2: (^6) into i32 ^498
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1916(%rip), %rcx
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1102:3): array/pointer-type, dynamic index -> ^500
	# index ^499 -> temp ^871
	movq %rbx, %rdx
	# Multiply temp ^871 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^871 -> operand ^500
	movq %rdx, %rax
	# Result ^500 += base pointer ^870
	addq %rcx, %rax
	# LowerLoad(1103:3).2: (^500) into i32 ^501
	movl (%rax), %ebx
	# LowerBasicConversion(1104:3): i32 ^501 -> i64 ^502
	# LowerLoad(1105:3).2: (^9) into i32 ^503
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1106:3): move argument i64 ^502
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1106:3): move argument ptr @.str.83
	leaq .str.83(%rip), %rsi
	# SetupCalls(1106:3): move argument i32 ^503
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1107:3).2: (^9) into i32 ^504
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1108:3): i32 ^504 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3737
	jmp .__main__M3766
	.__main__M3737:
	# LowerLoad(1112:3).2: (^6) into i32 ^507
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1113:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(1113:3): move argument i32 ^507
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1113:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M3766:
	# LowerLoad(1120:3).2: (^6) into i32 ^511
	movl (%r12), %eax
	# LowerMath(1121:3): ^511, 1 into i32 ^512
	addl $1, %eax
	# LowerStore(1122:3).9: mov i32 ^512, (^6)
	movl %eax, (%r12)
	jmp .__main__M3677
	.__main__M3775:
	# LowerLoad(1126:3).4: _ZL6g_1917 into ^514
	movl _ZL6g_1917(%rip), %eax
	# LowerBasicConversion(1127:3): i32 ^514 -> i64 ^515
	# LowerLoad(1128:3).2: (^9) into i32 ^516
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1129:3): move argument i64 ^515
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1129:3): move argument ptr @.str.84
	leaq .str.84(%rip), %rsi
	# SetupCalls(1129:3): move argument i32 ^516
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1130:3).4: _ZL6g_1918 into ^517
	movl _ZL6g_1918(%rip), %eax
	# LowerBasicConversion(1131:3): i32 ^517 -> i64 ^518
	# LowerLoad(1132:3).2: (^9) into i32 ^519
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1133:3): move argument i64 ^518
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1133:3): move argument ptr @.str.85
	leaq .str.85(%rip), %rsi
	# SetupCalls(1133:3): move argument i32 ^519
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1134:3).4: _ZL6g_1919 into ^520
	movl _ZL6g_1919(%rip), %eax
	# LowerBasicConversion(1135:3): i32 ^520 -> i64 ^521
	# LowerLoad(1136:3).2: (^9) into i32 ^522
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1137:3): move argument i64 ^521
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1137:3): move argument ptr @.str.86
	leaq .str.86(%rip), %rsi
	# SetupCalls(1137:3): move argument i32 ^522
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1138:3).4: _ZL6g_1920 into ^523
	movl _ZL6g_1920(%rip), %eax
	# LowerBasicConversion(1139:3): i32 ^523 -> i64 ^524
	# LowerLoad(1140:3).2: (^9) into i32 ^525
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1141:3): move argument i64 ^524
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1141:3): move argument ptr @.str.87
	leaq .str.87(%rip), %rsi
	# SetupCalls(1141:3): move argument i32 ^525
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1142:3).4: _ZL6g_1921 into ^526
	movl _ZL6g_1921(%rip), %eax
	# LowerBasicConversion(1143:3): i32 ^526 -> i64 ^527
	# LowerLoad(1144:3).2: (^9) into i32 ^528
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1145:3): move argument i64 ^527
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1145:3): move argument ptr @.str.88
	leaq .str.88(%rip), %rsi
	# SetupCalls(1145:3): move argument i32 ^528
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(1146:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M3934:
	# LowerLoad(1150:3).2: (^6) into i32 ^530
	movl (%r12), %eax
	# LowerIcmp(1151:3): i32 ^530 vs. intlike 4
	cmpl $4, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3941
	jmp .__main__M4116
	.__main__M3941:
	# LowerStore(1155:3).3: mov $imm, (^7)
	movl $0, (%r15)
	.__main__M3944:
	# LowerLoad(1159:3).2: (^7) into i32 ^534
	movl (%r15), %eax
	# LowerIcmp(1160:3): i32 ^534 vs. intlike 9
	cmpl $9, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3951
	jmp .__main__M4107
	.__main__M3951:
	# LowerLoad(1164:3).2: (^9) into i32 ^537
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1165:3): i32 ^537 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3958
	jmp .__main__M4031
	.__main__M3958:
	# LowerLoad(1169:3).2: (^6) into i32 ^540
	movl (%r12), %ebx
	# LowerLoad(1170:3).2: (^7) into i32 ^541
	movl (%r15), %ecx
	# LowerLoad(1171:3).2: (^6) into i32 ^542
	movl (%r12), %eax
	movslq %eax, %rdx
	leaq _ZL6g_1922(%rip), %rsi
	# tt = Pointer, type = [4 x [9 x i32]]
	# LowerGetelementptr(1173:3): array/pointer-type, dynamic index -> ^544
	# index ^543 -> temp ^873
	movq %rdx, %rdi
	# Multiply temp ^873 by 36 start
	movq %rdi, %rax
	movq $36, %rdi
	mulq %rdi
	movq %rax, %rdi
	# Multiply end
	# temp ^873 -> operand ^544
	movq %rdi, %rax
	# Result ^544 += base pointer ^872
	addq %rsi, %rax
	# LowerLoad(1174:3).2: (^7) into i32 ^545
	movl (%r15), %edx
	movslq %edx, %rsi
	# tt = Pointer, type = [9 x i32]
	# LowerGetelementptr(1176:3): array/pointer-type, dynamic index -> ^547
	# index ^546 -> temp ^875
	movq %rsi, %rdi
	# Multiply temp ^875 by 4 start
	shlq $2, %rdi
	# Multiply end
	# temp ^875 -> operand ^547
	movq %rdi, %rdx
	# Result ^547 += base pointer ^544
	addq %rax, %rdx
	# LowerLoad(1177:3).2: (^547) into i32 ^548
	movl (%rdx), %eax
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1178:3): move argument ptr @.str.89
	leaq .str.89(%rip), %rdi
	# SetupCalls(1178:3): move argument i32 ^540
	# Fixed movzx with 32-bit source operand
	movl %ebx, %esi
	# SetupCalls(1178:3): move argument i32 ^541
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	# SetupCalls(1178:3): move argument i32 ^548
	# Fixed movzx with 32-bit source operand
	movl %eax, %ecx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1178:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	.__main__M4031:
	# LowerLoad(1182:3).2: (^6) into i32 ^551
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1922(%rip), %rcx
	# tt = Pointer, type = [4 x [9 x i32]]
	# LowerGetelementptr(1184:3): array/pointer-type, dynamic index -> ^553
	# index ^552 -> temp ^877
	movq %rbx, %rdx
	# Multiply temp ^877 by 36 start
	# Clobber %rdx
	movq %rdx, -96(%rbp)
	movq %rdx, %rax
	movq $36, %rbx
	mulq %rbx
	# Unclobber %rdx
	movq -96(%rbp), %rdx
	movq %rax, %rdx
	# Multiply end
	# temp ^877 -> operand ^553
	movq %rdx, %rax
	# Result ^553 += base pointer ^876
	addq %rcx, %rax
	# LowerLoad(1185:3).2: (^7) into i32 ^554
	movl (%r15), %ebx
	movslq %ebx, %rcx
	# tt = Pointer, type = [9 x i32]
	# LowerGetelementptr(1187:3): array/pointer-type, dynamic index -> ^556
	# index ^555 -> temp ^879
	movq %rcx, %rdx
	# Multiply temp ^879 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^879 -> operand ^556
	movq %rdx, %rbx
	# Result ^556 += base pointer ^553
	addq %rax, %rbx
	# LowerLoad(1188:3).2: (^556) into i32 ^557
	movl (%rbx), %eax
	# LowerBasicConversion(1189:3): i32 ^557 -> i64 ^558
	# LowerLoad(1190:3).2: (^9) into i32 ^559
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1191:3): move argument i64 ^558
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1191:3): move argument ptr @.str.90
	leaq .str.90(%rip), %rsi
	# SetupCalls(1191:3): move argument i32 ^559
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1195:3).2: (^7) into i32 ^561
	movl (%r15), %eax
	# LowerMath(1196:3): ^561, 1 into i32 ^562
	addl $1, %eax
	# LowerStore(1197:3).9: mov i32 ^562, (^7)
	movl %eax, (%r15)
	jmp .__main__M3944
	.__main__M4107:
	# LowerLoad(1204:3).2: (^6) into i32 ^565
	movl (%r12), %eax
	# LowerMath(1205:3): ^565, 1 into i32 ^566
	addl $1, %eax
	# LowerStore(1206:3).9: mov i32 ^566, (^6)
	movl %eax, (%r12)
	jmp .__main__M3934
	.__main__M4116:
	# LowerLoad(1210:3).4: _ZL6g_1923 into ^568
	movl _ZL6g_1923(%rip), %eax
	# LowerBasicConversion(1211:3): i32 ^568 -> i64 ^569
	# LowerLoad(1212:3).2: (^9) into i32 ^570
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1213:3): move argument i64 ^569
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1213:3): move argument ptr @.str.91
	leaq .str.91(%rip), %rsi
	# SetupCalls(1213:3): move argument i32 ^570
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1214:3).4: _ZL6g_1924 into ^571
	movl _ZL6g_1924(%rip), %eax
	# LowerBasicConversion(1215:3): i32 ^571 -> i64 ^572
	# LowerLoad(1216:3).2: (^9) into i32 ^573
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1217:3): move argument i64 ^572
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1217:3): move argument ptr @.str.92
	leaq .str.92(%rip), %rsi
	# SetupCalls(1217:3): move argument i32 ^573
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1218:3).4: _ZL6g_1925 into ^574
	movl _ZL6g_1925(%rip), %eax
	# LowerBasicConversion(1219:3): i32 ^574 -> i64 ^575
	# LowerLoad(1220:3).2: (^9) into i32 ^576
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1221:3): move argument i64 ^575
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1221:3): move argument ptr @.str.93
	leaq .str.93(%rip), %rsi
	# SetupCalls(1221:3): move argument i32 ^576
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1222:3).4: _ZL6g_1926 into ^577
	movl _ZL6g_1926(%rip), %eax
	# LowerBasicConversion(1223:3): i32 ^577 -> i64 ^578
	# LowerLoad(1224:3).2: (^9) into i32 ^579
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1225:3): move argument i64 ^578
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1225:3): move argument ptr @.str.94
	leaq .str.94(%rip), %rsi
	# SetupCalls(1225:3): move argument i32 ^579
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1226:3).4: _ZL6g_1927 into ^580
	movl _ZL6g_1927(%rip), %ebx
	# LowerBasicConversion(1227:3): i32 ^580 -> i64 ^581
	# LowerLoad(1228:3).2: (^9) into i32 ^582
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(1229:3): move argument i64 ^581
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1229:3): move argument ptr @.str.95
	leaq .str.95(%rip), %rsi
	# SetupCalls(1229:3): move argument i32 ^582
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(1230:3).4: _ZL6g_1928 into ^583
	movl _ZL6g_1928(%rip), %eax
	# LowerBasicConversion(1231:3): i32 ^583 -> i64 ^584
	# LowerLoad(1232:3).2: (^9) into i32 ^585
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1233:3): move argument i64 ^584
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1233:3): move argument ptr @.str.96
	leaq .str.96(%rip), %rsi
	# SetupCalls(1233:3): move argument i32 ^585
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1234:3).4: _ZL6g_1929 into ^586
	movl _ZL6g_1929(%rip), %eax
	# LowerBasicConversion(1235:3): i32 ^586 -> i64 ^587
	# LowerLoad(1236:3).2: (^9) into i32 ^588
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1237:3): move argument i64 ^587
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1237:3): move argument ptr @.str.97
	leaq .str.97(%rip), %rsi
	# SetupCalls(1237:3): move argument i32 ^588
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1238:3).4: _ZL6g_1930 into ^589
	movl _ZL6g_1930(%rip), %eax
	# LowerBasicConversion(1239:3): i32 ^589 -> i64 ^590
	# LowerLoad(1240:3).2: (^9) into i32 ^591
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1241:3): move argument i64 ^590
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1241:3): move argument ptr @.str.98
	leaq .str.98(%rip), %rsi
	# SetupCalls(1241:3): move argument i32 ^591
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1242:3).4: _ZL6g_1931 into ^592
	movl _ZL6g_1931(%rip), %eax
	# LowerBasicConversion(1243:3): i32 ^592 -> i64 ^593
	# LowerLoad(1244:3).2: (^9) into i32 ^594
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1245:3): move argument i64 ^593
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1245:3): move argument ptr @.str.99
	leaq .str.99(%rip), %rsi
	# SetupCalls(1245:3): move argument i32 ^594
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1246:3).4: _ZL6g_1932 into ^595
	movl _ZL6g_1932(%rip), %eax
	# LowerBasicConversion(1247:3): i32 ^595 -> i64 ^596
	movq %rax, %rbx
	# LowerLoad(1248:3).2: (^9) into i32 ^597
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1249:3): move argument i64 ^596
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1249:3): move argument ptr @.str.100
	leaq .str.100(%rip), %rsi
	# SetupCalls(1249:3): move argument i32 ^597
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(1250:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M4431:
	# LowerLoad(1254:3).2: (^6) into i32 ^599
	movl (%r12), %eax
	# LowerIcmp(1255:3): i32 ^599 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M4438
	jmp .__main__M4529
	.__main__M4438:
	# LowerLoad(1259:3).2: (^6) into i32 ^602
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1933(%rip), %rcx
	# tt = Pointer, type = [8 x i32]
	# LowerGetelementptr(1261:3): array/pointer-type, dynamic index -> ^604
	# index ^603 -> temp ^881
	movq %rbx, %rdx
	# Multiply temp ^881 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^881 -> operand ^604
	movq %rdx, %rax
	# Result ^604 += base pointer ^880
	addq %rcx, %rax
	# LowerLoad(1262:3).2: (^604) into i32 ^605
	movl (%rax), %ebx
	# LowerBasicConversion(1263:3): i32 ^605 -> i64 ^606
	# LowerLoad(1264:3).2: (^9) into i32 ^607
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1265:3): move argument i64 ^606
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1265:3): move argument ptr @.str.101
	leaq .str.101(%rip), %rsi
	# SetupCalls(1265:3): move argument i32 ^607
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1266:3).2: (^9) into i32 ^608
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1267:3): i32 ^608 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M4491
	jmp .__main__M4520
	.__main__M4491:
	# LowerLoad(1271:3).2: (^6) into i32 ^611
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1272:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(1272:3): move argument i32 ^611
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1272:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M4520:
	# LowerLoad(1279:3).2: (^6) into i32 ^615
	movl (%r12), %eax
	# LowerMath(1280:3): ^615, 1 into i32 ^616
	addl $1, %eax
	# LowerStore(1281:3).9: mov i32 ^616, (^6)
	movl %eax, (%r12)
	jmp .__main__M4431
	.__main__M4529:
	# LowerLoad(1285:3).4: _ZL6g_1934 into ^618
	movl _ZL6g_1934(%rip), %eax
	# LowerBasicConversion(1286:3): i32 ^618 -> i64 ^619
	# LowerLoad(1287:3).2: (^9) into i32 ^620
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1288:3): move argument i64 ^619
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1288:3): move argument ptr @.str.102
	leaq .str.102(%rip), %rsi
	# SetupCalls(1288:3): move argument i32 ^620
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1289:3).4: _ZL6g_1935 into ^621
	movl _ZL6g_1935(%rip), %eax
	# LowerBasicConversion(1290:3): i32 ^621 -> i64 ^622
	# LowerLoad(1291:3).2: (^9) into i32 ^623
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1292:3): move argument i64 ^622
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1292:3): move argument ptr @.str.103
	leaq .str.103(%rip), %rsi
	# SetupCalls(1292:3): move argument i32 ^623
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1293:3).4: _ZL6g_1936 into ^624
	movl _ZL6g_1936(%rip), %eax
	# LowerBasicConversion(1294:3): i32 ^624 -> i64 ^625
	# LowerLoad(1295:3).2: (^9) into i32 ^626
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1296:3): move argument i64 ^625
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1296:3): move argument ptr @.str.104
	leaq .str.104(%rip), %rsi
	# SetupCalls(1296:3): move argument i32 ^626
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1297:3).4: _ZL6g_1937 into ^627
	movl _ZL6g_1937(%rip), %eax
	# LowerBasicConversion(1298:3): i32 ^627 -> i64 ^628
	# LowerLoad(1299:3).2: (^9) into i32 ^629
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1300:3): move argument i64 ^628
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1300:3): move argument ptr @.str.105
	leaq .str.105(%rip), %rsi
	# SetupCalls(1300:3): move argument i32 ^629
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1301:3).4: _ZL6g_1938 into ^630
	movl _ZL6g_1938(%rip), %eax
	# LowerBasicConversion(1302:3): i32 ^630 -> i64 ^631
	# LowerLoad(1303:3).2: (^9) into i32 ^632
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1304:3): move argument i64 ^631
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1304:3): move argument ptr @.str.106
	leaq .str.106(%rip), %rsi
	# SetupCalls(1304:3): move argument i32 ^632
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1305:3).4: _ZL6g_1939 into ^633
	movl _ZL6g_1939(%rip), %eax
	# LowerBasicConversion(1306:3): i32 ^633 -> i64 ^634
	# LowerLoad(1307:3).2: (^9) into i32 ^635
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1308:3): move argument i64 ^634
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1308:3): move argument ptr @.str.107
	leaq .str.107(%rip), %rsi
	# SetupCalls(1308:3): move argument i32 ^635
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1309:3).4: _ZL6g_1940 into ^636
	movl _ZL6g_1940(%rip), %eax
	# LowerBasicConversion(1310:3): i32 ^636 -> i64 ^637
	# LowerLoad(1311:3).2: (^9) into i32 ^638
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1312:3): move argument i64 ^637
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1312:3): move argument ptr @.str.108
	leaq .str.108(%rip), %rsi
	# SetupCalls(1312:3): move argument i32 ^638
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1313:3).4: _ZL6g_1941 into ^639
	movl _ZL6g_1941(%rip), %eax
	# LowerBasicConversion(1314:3): i32 ^639 -> i64 ^640
	# LowerLoad(1315:3).2: (^9) into i32 ^641
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1316:3): move argument i64 ^640
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1316:3): move argument ptr @.str.109
	leaq .str.109(%rip), %rsi
	# SetupCalls(1316:3): move argument i32 ^641
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(1317:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M4781:
	# LowerLoad(1321:3).2: (^6) into i32 ^643
	movl (%r12), %eax
	# LowerIcmp(1322:3): i32 ^643 vs. intlike 4
	cmpl $4, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M4788
	jmp .__main__M4953
	.__main__M4788:
	# LowerStore(1326:3).3: mov $imm, (^7)
	movl $0, (%r15)
	.__main__M4791:
	# LowerLoad(1330:3).2: (^7) into i32 ^647
	movl (%r15), %eax
	# LowerIcmp(1331:3): i32 ^647 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M4798
	jmp .__main__M4944
	.__main__M4798:
	# LowerStore(1335:3).3: mov $imm, (^8)
	movl $0, (%r13)
	.__main__M4801:
	# LowerLoad(1339:3).2: (^8) into i32 ^651
	movl (%r13), %eax
	# LowerIcmp(1340:3): i32 ^651 vs. intlike 4
	cmpl $4, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M4808
	jmp .__main__M4935
	.__main__M4808:
	# LowerLoad(1344:3).2: (^6) into i32 ^654
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1942(%rip), %rcx
	# tt = Pointer, type = [4 x [8 x [4 x i32]]]
	# LowerGetelementptr(1346:3): array/pointer-type, dynamic index -> ^656
	# index ^655 -> temp ^883
	movq %rbx, %rdx
	# Multiply temp ^883 by 128 start
	shlq $7, %rdx
	# Multiply end
	# temp ^883 -> operand ^656
	movq %rdx, %rax
	# Result ^656 += base pointer ^882
	addq %rcx, %rax
	# LowerLoad(1347:3).2: (^7) into i32 ^657
	movl (%r15), %ebx
	movslq %ebx, %rcx
	# tt = Pointer, type = [8 x [4 x i32]]
	# LowerGetelementptr(1349:3): array/pointer-type, dynamic index -> ^659
	# index ^658 -> temp ^884
	movq %rcx, %rdx
	# Multiply temp ^884 by 16 start
	shlq $4, %rdx
	# Multiply end
	# temp ^884 -> operand ^659
	movq %rdx, %rbx
	# Result ^659 += base pointer ^656
	addq %rax, %rbx
	# LowerLoad(1350:3).2: (^8) into i32 ^660
	movl (%r13), %eax
	movslq %eax, %rcx
	# tt = Pointer, type = [4 x i32]
	# LowerGetelementptr(1352:3): array/pointer-type, dynamic index -> ^662
	# index ^661 -> temp ^885
	movq %rcx, %rdx
	# Multiply temp ^885 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^885 -> operand ^662
	movq %rdx, %rax
	# Result ^662 += base pointer ^659
	addq %rbx, %rax
	# LowerLoad(1353:3).2: (^662) into i32 ^663
	movl (%rax), %ebx
	# LowerBasicConversion(1354:3): i32 ^663 -> i64 ^664
	# LowerLoad(1355:3).2: (^9) into i32 ^665
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1356:3): move argument i64 ^664
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1356:3): move argument ptr @.str.110
	leaq .str.110(%rip), %rsi
	# SetupCalls(1356:3): move argument i32 ^665
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1357:3).2: (^9) into i32 ^666
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1358:3): i32 ^666 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M4889
	jmp .__main__M4926
	.__main__M4889:
	# LowerLoad(1362:3).2: (^6) into i32 ^669
	movl (%r12), %eax
	# LowerLoad(1363:3).2: (^7) into i32 ^670
	movl (%r15), %ebx
	# LowerLoad(1364:3).2: (^8) into i32 ^671
	movl (%r13), %r8d
	# Clobber %r8
	movq %r8, -64(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1365:3): move argument ptr @.str.45
	leaq .str.45(%rip), %rdi
	# SetupCalls(1365:3): move argument i32 ^669
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(1365:3): move argument i32 ^670
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	# SetupCalls(1365:3): move argument i32 ^671
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1365:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %r8
	movq -64(%rbp), %r8
	.__main__M4926:
	# LowerLoad(1372:3).2: (^8) into i32 ^675
	movl (%r13), %eax
	# LowerMath(1373:3): ^675, 1 into i32 ^676
	addl $1, %eax
	# LowerStore(1374:3).9: mov i32 ^676, (^8)
	movl %eax, (%r13)
	jmp .__main__M4801
	.__main__M4935:
	# LowerLoad(1381:3).2: (^7) into i32 ^679
	movl (%r15), %eax
	# LowerMath(1382:3): ^679, 1 into i32 ^680
	addl $1, %eax
	# LowerStore(1383:3).9: mov i32 ^680, (^7)
	movl %eax, (%r15)
	jmp .__main__M4791
	.__main__M4944:
	# LowerLoad(1390:3).2: (^6) into i32 ^683
	movl (%r12), %eax
	# LowerMath(1391:3): ^683, 1 into i32 ^684
	addl $1, %eax
	# LowerStore(1392:3).9: mov i32 ^684, (^6)
	movl %eax, (%r12)
	jmp .__main__M4781
	.__main__M4953:
	# LowerLoad(1396:3).4: _ZL6g_1943 into ^686
	movl _ZL6g_1943(%rip), %eax
	# LowerBasicConversion(1397:3): i32 ^686 -> i64 ^687
	# LowerLoad(1398:3).2: (^9) into i32 ^688
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1399:3): move argument i64 ^687
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1399:3): move argument ptr @.str.111
	leaq .str.111(%rip), %rsi
	# SetupCalls(1399:3): move argument i32 ^688
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(1400:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M4987:
	# LowerLoad(1404:3).2: (^6) into i32 ^690
	movl (%r12), %eax
	# LowerIcmp(1405:3): i32 ^690 vs. intlike 10
	cmpl $10, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M4994
	jmp .__main__M5085
	.__main__M4994:
	# LowerLoad(1409:3).2: (^6) into i32 ^693
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1944(%rip), %rcx
	# tt = Pointer, type = [10 x i32]
	# LowerGetelementptr(1411:3): array/pointer-type, dynamic index -> ^695
	# index ^694 -> temp ^887
	movq %rbx, %rdx
	# Multiply temp ^887 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^887 -> operand ^695
	movq %rdx, %rax
	# Result ^695 += base pointer ^886
	addq %rcx, %rax
	# LowerLoad(1412:3).2: (^695) into i32 ^696
	movl (%rax), %ebx
	# LowerBasicConversion(1413:3): i32 ^696 -> i64 ^697
	# LowerLoad(1414:3).2: (^9) into i32 ^698
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1415:3): move argument i64 ^697
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1415:3): move argument ptr @.str.112
	leaq .str.112(%rip), %rsi
	# SetupCalls(1415:3): move argument i32 ^698
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1416:3).2: (^9) into i32 ^699
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1417:3): i32 ^699 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M5047
	jmp .__main__M5076
	.__main__M5047:
	# LowerLoad(1421:3).2: (^6) into i32 ^702
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1422:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(1422:3): move argument i32 ^702
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1422:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M5076:
	# LowerLoad(1429:3).2: (^6) into i32 ^706
	movl (%r12), %eax
	# LowerMath(1430:3): ^706, 1 into i32 ^707
	addl $1, %eax
	# LowerStore(1431:3).9: mov i32 ^707, (^6)
	movl %eax, (%r12)
	jmp .__main__M4987
	.__main__M5085:
	# LowerStore(1435:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M5088:
	# LowerLoad(1439:3).2: (^6) into i32 ^710
	movl (%r12), %eax
	# LowerIcmp(1440:3): i32 ^710 vs. intlike 7
	cmpl $7, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M5095
	jmp .__main__M5186
	.__main__M5095:
	# LowerLoad(1444:3).2: (^6) into i32 ^713
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_1945(%rip), %rcx
	# tt = Pointer, type = [7 x i32]
	# LowerGetelementptr(1446:3): array/pointer-type, dynamic index -> ^715
	# index ^714 -> temp ^889
	movq %rbx, %rdx
	# Multiply temp ^889 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^889 -> operand ^715
	movq %rdx, %rax
	# Result ^715 += base pointer ^888
	addq %rcx, %rax
	# LowerLoad(1447:3).2: (^715) into i32 ^716
	movl (%rax), %ebx
	# LowerBasicConversion(1448:3): i32 ^716 -> i64 ^717
	# LowerLoad(1449:3).2: (^9) into i32 ^718
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1450:3): move argument i64 ^717
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1450:3): move argument ptr @.str.113
	leaq .str.113(%rip), %rsi
	# SetupCalls(1450:3): move argument i32 ^718
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1451:3).2: (^9) into i32 ^719
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1452:3): i32 ^719 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M5148
	jmp .__main__M5177
	.__main__M5148:
	# LowerLoad(1456:3).2: (^6) into i32 ^722
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1457:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rdi
	# SetupCalls(1457:3): move argument i32 ^722
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1457:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M5177:
	# LowerLoad(1464:3).2: (^6) into i32 ^726
	movl (%r12), %eax
	# LowerMath(1465:3): ^726, 1 into i32 ^727
	addl $1, %eax
	# LowerStore(1466:3).9: mov i32 ^727, (^6)
	movl %eax, (%r12)
	jmp .__main__M5088
	.__main__M5186:
	# LowerLoad(1470:3).4: _ZL6g_1946 into ^729
	movl _ZL6g_1946(%rip), %eax
	# LowerBasicConversion(1471:3): i32 ^729 -> i64 ^730
	# LowerLoad(1472:3).2: (^9) into i32 ^731
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1473:3): move argument i64 ^730
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1473:3): move argument ptr @.str.114
	leaq .str.114(%rip), %rsi
	# SetupCalls(1473:3): move argument i32 ^731
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1474:3).4: _ZL6g_1947 into ^732
	movl _ZL6g_1947(%rip), %eax
	# LowerBasicConversion(1475:3): i32 ^732 -> i64 ^733
	# LowerLoad(1476:3).2: (^9) into i32 ^734
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1477:3): move argument i64 ^733
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1477:3): move argument ptr @.str.115
	leaq .str.115(%rip), %rsi
	# SetupCalls(1477:3): move argument i32 ^734
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1478:3).4: _ZL6g_1948 into ^735
	movl _ZL6g_1948(%rip), %eax
	# LowerBasicConversion(1479:3): i32 ^735 -> i64 ^736
	# LowerLoad(1480:3).2: (^9) into i32 ^737
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1481:3): move argument i64 ^736
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1481:3): move argument ptr @.str.116
	leaq .str.116(%rip), %rsi
	# SetupCalls(1481:3): move argument i32 ^737
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1482:3).4: _ZL6g_2024 into ^738
	movl _ZL6g_2024(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(1484:3).2: (^9) into i32 ^740
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1485:3): move argument i64 ^739
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1485:3): move argument ptr @.str.117
	leaq .str.117(%rip), %rsi
	# SetupCalls(1485:3): move argument i32 ^740
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1486:3).4: _ZL6g_2072 into ^741
	movl _ZL6g_2072(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(1488:3).2: (^9) into i32 ^743
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1489:3): move argument i64 ^742
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1489:3): move argument ptr @.str.118
	leaq .str.118(%rip), %rsi
	# SetupCalls(1489:3): move argument i32 ^743
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1490:3).2: (^9) into i32 ^744
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1491:3): move argument i64 -7849629611674676947
	movabsq $-7849629611674676947, %rbx
	movq %rbx, %rdi
	# SetupCalls(1491:3): move argument ptr @.str.119
	leaq .str.119(%rip), %rsi
	# SetupCalls(1491:3): move argument i32 ^744
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1492:3).2: (^9) into i32 ^745
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1493:3): move argument i64 15412
	movq $15412, %rdi
	# SetupCalls(1493:3): move argument ptr @.str.120
	leaq .str.120(%rip), %rsi
	# SetupCalls(1493:3): move argument i32 ^745
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerStore(1494:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M5398:
	# LowerLoad(1498:3).2: (^6) into i32 ^747
	movl (%r12), %eax
	# LowerIcmp(1499:3): i32 ^747 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M5405
	jmp .__main__M5540
	.__main__M5405:
	# LowerStore(1503:3).3: mov $imm, (^7)
	movl $0, (%r15)
	.__main__M5408:
	# LowerLoad(1507:3).2: (^7) into i32 ^751
	movl (%r15), %eax
	# LowerIcmp(1508:3): i32 ^751 vs. intlike 5
	cmpl $5, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M5415
	jmp .__main__M5531
	.__main__M5415:
	# LowerLoad(1512:3).2: (^6) into i32 ^754
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_2324(%rip), %rcx
	# tt = Pointer, type = [1 x [5 x i32]]
	# LowerGetelementptr(1514:3): array/pointer-type, dynamic index -> ^756
	# index ^755 -> temp ^891
	movq %rbx, %rdx
	# Multiply temp ^891 by 20 start
	# Clobber %rdx
	movq %rdx, -96(%rbp)
	movq %rdx, %rax
	movq $20, %rbx
	mulq %rbx
	# Unclobber %rdx
	movq -96(%rbp), %rdx
	movq %rax, %rdx
	# Multiply end
	# temp ^891 -> operand ^756
	movq %rdx, %rax
	# Result ^756 += base pointer ^890
	addq %rcx, %rax
	# LowerLoad(1515:3).2: (^7) into i32 ^757
	movl (%r15), %ebx
	movslq %ebx, %rcx
	# tt = Pointer, type = [5 x i32]
	# LowerGetelementptr(1517:3): array/pointer-type, dynamic index -> ^759
	# index ^758 -> temp ^893
	movq %rcx, %rdx
	# Multiply temp ^893 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^893 -> operand ^759
	movq %rdx, %rbx
	# Result ^759 += base pointer ^756
	addq %rax, %rbx
	# LowerLoad(1518:3).2: (^759) into i32 ^760
	movl (%rbx), %ecx
	# LowerBasicConversion(1519:3): i32 ^760 -> i64 ^761
	# LowerLoad(1520:3).2: (^9) into i32 ^762
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1521:3): move argument i64 ^761
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1521:3): move argument ptr @.str.121
	leaq .str.121(%rip), %rsi
	# SetupCalls(1521:3): move argument i32 ^762
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(1522:3).2: (^9) into i32 ^763
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1523:3): i32 ^763 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M5489
	jmp .__main__M5522
	.__main__M5489:
	# LowerLoad(1527:3).2: (^6) into i32 ^766
	movl (%r12), %eax
	# LowerLoad(1528:3).2: (^7) into i32 ^767
	movl (%r15), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1529:3): move argument ptr @.str.122
	leaq .str.122(%rip), %rdi
	# SetupCalls(1529:3): move argument i32 ^766
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(1529:3): move argument i32 ^767
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1529:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M5522:
	# LowerLoad(1536:3).2: (^7) into i32 ^771
	movl (%r15), %eax
	# LowerMath(1537:3): ^771, 1 into i32 ^772
	addl $1, %eax
	# LowerStore(1538:3).9: mov i32 ^772, (^7)
	movl %eax, (%r15)
	jmp .__main__M5408
	.__main__M5531:
	# LowerLoad(1545:3).2: (^6) into i32 ^775
	movl (%r12), %eax
	# LowerMath(1546:3): ^775, 1 into i32 ^776
	addl $1, %eax
	# LowerStore(1547:3).9: mov i32 ^776, (^6)
	movl %eax, (%r12)
	jmp .__main__M5398
	.__main__M5540:
	# LowerLoad(1551:3).4: _ZL6g_2354 into ^778
	movl _ZL6g_2354(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(1553:3).2: (^9) into i32 ^780
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1554:3): move argument i64 ^779
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1554:3): move argument ptr @.str.123
	leaq .str.123(%rip), %rsi
	# SetupCalls(1554:3): move argument i32 ^780
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1555:3).4: _ZL6g_2382 into ^781
	movl _ZL6g_2382(%rip), %ebx
	# LowerBasicConversion(1556:3): i32 ^781 -> i64 ^782
	# LowerLoad(1557:3).2: (^9) into i32 ^783
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(1558:3): move argument i64 ^782
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1558:3): move argument ptr @.str.124
	leaq .str.124(%rip), %rsi
	# SetupCalls(1558:3): move argument i32 ^783
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerStore(1559:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M5604:
	# LowerLoad(1563:3).2: (^6) into i32 ^785
	movl (%r12), %eax
	# LowerIcmp(1564:3): i32 ^785 vs. intlike 4
	cmpl $4, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M5611
	jmp .__main__M5748
	.__main__M5611:
	# LowerStore(1568:3).3: mov $imm, (^7)
	movl $0, (%r15)
	.__main__M5614:
	# LowerLoad(1572:3).2: (^7) into i32 ^789
	movl (%r15), %eax
	# LowerIcmp(1573:3): i32 ^789 vs. intlike 6
	cmpl $6, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M5621
	jmp .__main__M5739
	.__main__M5621:
	# LowerLoad(1577:3).2: (^6) into i32 ^792
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq _ZL6g_2427(%rip), %rcx
	# tt = Pointer, type = [4 x [6 x %union.U4]]
	# LowerGetelementptr(1579:3): array/pointer-type, dynamic index -> ^794
	# index ^793 -> temp ^895
	movq %rbx, %rdx
	# Multiply temp ^895 by 12 start
	# Clobber %rdx
	movq %rdx, -96(%rbp)
	movq %rdx, %rax
	movq $12, %rbx
	mulq %rbx
	# Unclobber %rdx
	movq -96(%rbp), %rdx
	movq %rax, %rdx
	# Multiply end
	# temp ^895 -> operand ^794
	movq %rdx, %rax
	# Result ^794 += base pointer ^894
	addq %rcx, %rax
	# LowerLoad(1580:3).2: (^7) into i32 ^795
	movl (%r15), %ebx
	movslq %ebx, %rcx
	# tt = Pointer, type = [6 x %union.U4]
	# LowerGetelementptr(1582:3): array/pointer-type, dynamic index -> ^797
	# index ^796 -> temp ^897
	movq %rcx, %rdx
	# Multiply temp ^897 by 2 start
	shlq $1, %rdx
	# Multiply end
	# temp ^897 -> operand ^797
	movq %rdx, %rbx
	# Result ^797 += base pointer ^794
	addq %rax, %rbx
	# LowerLoad(1583:3).2: (^797) into i16 ^798
	movw (%rbx), %cx
	# LowerBasicConversion(1584:3): i16 ^798 -> i64 ^799
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(1585:3).2: (^9) into i32 ^800
	movq -48(%rbp), %rax
	movl (%rax), %ebx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(1586:3): move argument i64 ^799
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1586:3): move argument ptr @.str.125
	leaq .str.125(%rip), %rsi
	# SetupCalls(1586:3): move argument i32 ^800
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(1587:3).2: (^9) into i32 ^801
	movq -48(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(1588:3): i32 ^801 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M5697
	jmp .__main__M5730
	.__main__M5697:
	# LowerLoad(1592:3).2: (^6) into i32 ^804
	movl (%r12), %ebx
	# LowerLoad(1593:3).2: (^7) into i32 ^805
	movl (%r15), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1594:3): move argument ptr @.str.122
	leaq .str.122(%rip), %rdi
	# SetupCalls(1594:3): move argument i32 ^804
	# Fixed movzx with 32-bit source operand
	movl %ebx, %esi
	# SetupCalls(1594:3): move argument i32 ^805
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1594:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -80(%rbp), %rax
	.__main__M5730:
	# LowerLoad(1601:3).2: (^7) into i32 ^809
	movl (%r15), %eax
	# LowerMath(1602:3): ^809, 1 into i32 ^810
	addl $1, %eax
	# LowerStore(1603:3).9: mov i32 ^810, (^7)
	movl %eax, (%r15)
	jmp .__main__M5614
	.__main__M5739:
	# LowerLoad(1610:3).2: (^6) into i32 ^813
	movl (%r12), %eax
	# LowerMath(1611:3): ^813, 1 into i32 ^814
	addl $1, %eax
	# LowerStore(1612:3).9: mov i32 ^814, (^6)
	movl %eax, (%r12)
	jmp .__main__M5604
	.__main__M5748:
	# LowerLoad(1616:3).4: _ZL6g_2519 into ^816
	movw _ZL6g_2519(%rip), %ax
	movswq %ax, %rbx
	# LowerLoad(1618:3).2: (^9) into i32 ^818
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1619:3): move argument i64 ^817
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1619:3): move argument ptr @.str.126
	leaq .str.126(%rip), %rsi
	# SetupCalls(1619:3): move argument i32 ^818
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rax
	movq -80(%rbp), %rax
	# LowerLoad(1620:3).4: _ZL6g_2599 into ^819
	movw _ZL6g_2599(%rip), %bx
	# LowerBasicConversion(1621:3): i16 ^819 -> i64 ^820
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(1622:3).2: (^9) into i32 ^821
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(1623:3): move argument i64 ^820
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1623:3): move argument ptr @.str.127
	leaq .str.127(%rip), %rsi
	# SetupCalls(1623:3): move argument i32 ^821
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerLoad(1624:3).4: _ZL13crc32_context into ^822
	movl _ZL13crc32_context(%rip), %eax
	# LowerBasicConversion(1625:3): i32 ^822 -> i64 ^823
	# LowerLogic(1627:3): ^823, 4294967295 into i64 ^824
	movq %rax, %rbx
	movabsq $4294967295, %rax
	xorq %rax, %rbx
	# LowerTrunc(1627:3): 64 to 32, move and clear upper bits
	movl %ebx, %eax
	# LowerLoad(1628:3).2: (^9) into i32 ^826
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# Clobber %rax
	movq %rax, -80(%rbp)
	# SetupCalls(1629:3): move argument i32 ^825
	# Fixed movzx with 32-bit source operand
	movl %eax, %edi
	# SetupCalls(1629:3): move argument i32 ^826
	# Fixed movzx with 32-bit source operand
	movl %ebx, %esi
	callq _ZL17platform_main_endji
	# Unclobber %rax
	movq -80(%rbp), %rax
	movq $0, %rax
	movq -120(%rbp), %r15
	movq -144(%rbp), %r14
	movq -128(%rbp), %r13
	movq -112(%rbp), %r12
	movq -104(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL19platform_main_beginv
.p2align 4, 0x90
_ZL19platform_main_beginv:
	.___ZL19platform_main_beginv__M0:
	pushq %rbp
	movq %rsp, %rbp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_lshift_func_uint32_t_u_sji
.p2align 4, 0x90
_ZL29safe_lshift_func_uint32_t_u_sji:
	.___ZL29safe_lshift_func_uint32_t_u_sji__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(64 + 0, 16)
	subq $64, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4384:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rdx
	# LowerAlloca(4385:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4386:3).9: mov i32 %edi, (^3)
	movl %edi, (%rdx)
	# LowerStore(4388:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4390:3).2: (^4) into i32 ^5
	movl (%rax), %ebx
	# LowerIcmp(4391:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint32_t_u_sji__M36
	.___ZL29safe_lshift_func_uint32_t_u_sji__M15:
	# LowerLoad(4395:3).2: (^4) into i32 ^8
	movl (%rax), %ebx
	# LowerIcmp(4396:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint32_t_u_sji__M36
	.___ZL29safe_lshift_func_uint32_t_u_sji__M22:
	# LowerLoad(4400:3).2: (^3) into i32 ^11
	movl (%rdx), %esi
	# LowerLoad(4401:3).2: (^4) into i32 ^12
	movl (%rax), %ecx
	# LowerLshr(4402:3): -1, ^12 into i32 ^13
	# LowerShift(4402:3): operand ^12 changed to %ecx
	movl $-1, %ebx
	shrl %cl, %ebx
	# LowerIcmp(4403:3): i32 ^11 vs. operand i32 ^13
	cmpl %ebx, %esi
	seta %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint32_t_u_sji__M36
	jmp .___ZL29safe_lshift_func_uint32_t_u_sji__M41
	.___ZL29safe_lshift_func_uint32_t_u_sji__M36:
	# LowerLoad(4407:3).2: (^3) into i32 ^16
	movl (%rdx), %r8d
	# MovePhi: ^16 -> ^22
	jmp .___ZL29safe_lshift_func_uint32_t_u_sji__M53
	.___ZL29safe_lshift_func_uint32_t_u_sji__M41:
	# LowerLoad(4411:3).2: (^3) into i32 ^18
	movl (%rdx), %ebx
	# LowerLoad(4412:3).2: (^4) into i32 ^19
	movl (%rax), %ecx
	# LowerMath(4413:3): ^18, ^19 into i32 ^20
	# LowerShift(4413:3): operand ^19 changed to %ecx
	movl %ebx, %eax
	shll %cl, %eax
	# MovePhi: ^20 -> ^22
	movl %eax, %r8d
	.___ZL29safe_lshift_func_uint32_t_u_sji__M53:
	movl %r8d, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL12crc32_8bytesm
.p2align 4, 0x90
_ZL12crc32_8bytesm:
	.___ZL12crc32_8bytesm__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(40 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -32(%rbp)
	# LowerAlloca(6177:3): size = 8, type = i64*, var = ^2
	leaq -8(%rbp), %rbx
	# LowerStore(6178:3).9: mov i64 %rdi, (^2)
	movq %rdi, (%rbx)
	# LowerLoad(6180:3).2: (^2) into i64 ^3
	movq (%rbx), %rax
	# LowerLshr(6181:3): ^3, 0 into i64 ^4
	shrq $0, %rax
	# LowerLogic(6183:3): ^4, 255 into i64 ^5
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(6183:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(6183:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(6184:3): move argument i8 zeroext ^6
	movzbq %al, %rdi
	andq $255, %rdi
	callq _ZL10crc32_byteh
	# Unclobber %rax
	movq -16(%rbp), %rax
	# LowerLoad(6185:3).2: (^2) into i64 ^7
	movq (%rbx), %rcx
	# LowerLshr(6186:3): ^7, 8 into i64 ^8
	shrq $8, %rcx
	# LowerLogic(6188:3): ^8, 255 into i64 ^9
	movq %rcx, %rax
	andq $255, %rax
	# LowerTrunc(6188:3): 64 to 8, move
	movb %al, %cl
	# LowerTrunc(6188:3): 64 to 8, apply mask
	andq $255, %rcx
	# Clobber %rcx
	movq %rcx, -24(%rbp)
	# SetupCalls(6189:3): move argument i8 zeroext ^10
	movzbq %cl, %rdi
	andq $255, %rdi
	callq _ZL10crc32_byteh
	# Unclobber %rcx
	movq -24(%rbp), %rcx
	# LowerLoad(6190:3).2: (^2) into i64 ^11
	movq (%rbx), %rax
	# LowerLshr(6191:3): ^11, 16 into i64 ^12
	shrq $16, %rax
	# LowerLogic(6193:3): ^12, 255 into i64 ^13
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(6193:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(6193:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(6194:3): move argument i8 zeroext ^14
	movzbq %al, %rdi
	andq $255, %rdi
	callq _ZL10crc32_byteh
	# Unclobber %rax
	movq -16(%rbp), %rax
	# LowerLoad(6195:3).2: (^2) into i64 ^15
	movq (%rbx), %rax
	# LowerLshr(6196:3): ^15, 24 into i64 ^16
	movq %rax, %rcx
	shrq $24, %rcx
	# LowerLogic(6198:3): ^16, 255 into i64 ^17
	movq %rcx, %rdx
	andq $255, %rdx
	# LowerTrunc(6198:3): 64 to 8, move
	movb %dl, %al
	# LowerTrunc(6198:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(6199:3): move argument i8 zeroext ^18
	movzbq %al, %rdi
	andq $255, %rdi
	callq _ZL10crc32_byteh
	# Unclobber %rax
	movq -16(%rbp), %rax
	# LowerLoad(6200:3).2: (^2) into i64 ^19
	movq (%rbx), %rax
	# LowerLshr(6201:3): ^19, 32 into i64 ^20
	shrq $32, %rax
	# LowerLogic(6203:3): ^20, 255 into i64 ^21
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(6203:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(6203:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(6204:3): move argument i8 zeroext ^22
	movzbq %al, %rdi
	andq $255, %rdi
	callq _ZL10crc32_byteh
	# Unclobber %rax
	movq -16(%rbp), %rax
	# LowerLoad(6205:3).2: (^2) into i64 ^23
	movq (%rbx), %rax
	# LowerLshr(6206:3): ^23, 40 into i64 ^24
	shrq $40, %rax
	# LowerLogic(6208:3): ^24, 255 into i64 ^25
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(6208:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(6208:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(6209:3): move argument i8 zeroext ^26
	movzbq %al, %rdi
	andq $255, %rdi
	callq _ZL10crc32_byteh
	# Unclobber %rax
	movq -16(%rbp), %rax
	# LowerLoad(6210:3).2: (^2) into i64 ^27
	movq (%rbx), %rax
	# LowerLshr(6211:3): ^27, 48 into i64 ^28
	shrq $48, %rax
	# LowerLogic(6213:3): ^28, 255 into i64 ^29
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(6213:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(6213:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(6214:3): move argument i8 zeroext ^30
	movzbq %al, %rdi
	andq $255, %rdi
	callq _ZL10crc32_byteh
	# Unclobber %rax
	movq -16(%rbp), %rax
	# LowerLoad(6215:3).2: (^2) into i64 ^31
	movq (%rbx), %rax
	# LowerLshr(6216:3): ^31, 56 into i64 ^32
	shrq $56, %rax
	# LowerLogic(6218:3): ^32, 255 into i64 ^33
	movq %rax, %rbx
	andq $255, %rbx
	# LowerTrunc(6218:3): 64 to 8, move
	movb %bl, %al
	# LowerTrunc(6218:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(6219:3): move argument i8 zeroext ^34
	movzbq %al, %rdi
	andq $255, %rdi
	callq _ZL10crc32_byteh
	# Unclobber %rax
	movq -16(%rbp), %rax
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_add_func_uint64_t_u_umm
.p2align 4, 0x90
_ZL26safe_add_func_uint64_t_u_umm:
	.___ZL26safe_add_func_uint64_t_u_umm__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(3511:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(3512:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(3513:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(3515:3).9: mov i64 %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(3517:3).2: (^3) into i64 ^5
	movq (%rcx), %rbx
	# LowerLoad(3518:3).2: (^4) into i64 ^6
	movq (%rax), %rcx
	# LowerMath(3519:3): ^5, ^6 into i64 ^7
	movq %rbx, %rax
	addq %rcx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_int16_t_s_usj
.p2align 4, 0x90
_ZL28safe_lshift_func_int16_t_s_usj:
	.___ZL28safe_lshift_func_int16_t_s_usj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(80 + 0, 16)
	subq $80, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3602:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rdx
	# LowerAlloca(3603:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3604:3).9: mov i16 %di, (^3)
	movw %di, (%rdx)
	# LowerStore(3606:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3608:3).2: (^3) into i16 ^5
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerIcmp(3610:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_usj__M38
	.___ZL28safe_lshift_func_int16_t_s_usj__M16:
	# LowerLoad(3614:3).2: (^4) into i32 ^9
	movl (%rax), %ebx
	# LowerIcmp(3615:3): i32 ^9 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_usj__M38
	.___ZL28safe_lshift_func_int16_t_s_usj__M23:
	# LowerLoad(3619:3).2: (^3) into i16 ^12
	movw (%rdx), %bx
	movswl %bx, %esi
	# LowerLoad(3621:3).2: (^4) into i32 ^14
	movl (%rax), %ecx
	# LowerAshr(3622:3): 32767, ^14 into i32 ^15
	# LowerShift(3622:3): operand ^14 changed to %ecx
	movl $32767, %ebx
	sarl %cl, %ebx
	# LowerIcmp(3623:3): i32 ^13 vs. operand i32 ^15
	cmpl %ebx, %esi
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_usj__M38
	jmp .___ZL28safe_lshift_func_int16_t_s_usj__M44
	.___ZL28safe_lshift_func_int16_t_s_usj__M38:
	# LowerLoad(3627:3).2: (^3) into i16 ^18
	movw (%rdx), %ax
	movswl %ax, %ebx
	# MovePhi: ^19 -> ^26
	movl %ebx, %r8d
	jmp .___ZL28safe_lshift_func_int16_t_s_usj__M57
	.___ZL28safe_lshift_func_int16_t_s_usj__M44:
	# LowerLoad(3632:3).2: (^3) into i16 ^21
	movw (%rdx), %cx
	movswl %cx, %ebx
	# LowerLoad(3634:3).2: (^4) into i32 ^23
	movl (%rax), %ecx
	# LowerMath(3635:3): ^22, ^23 into i32 ^24
	# LowerShift(3635:3): operand ^23 changed to %ecx
	movl %ebx, %eax
	shll %cl, %eax
	# MovePhi: ^24 -> ^26
	movl %eax, %r8d
	.___ZL28safe_lshift_func_int16_t_s_usj__M57:
	# LowerTrunc(3640:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(3640:3): 32 to 16, apply mask
	andq $65535, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL32safe_unary_minus_func_uint64_t_um
.p2align 4, 0x90
_ZL32safe_unary_minus_func_uint64_t_um:
	.___ZL32safe_unary_minus_func_uint64_t_um__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(16 + 0, 16)
	subq $16, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4024:3): size = 8, type = i64*, var = ^2
	leaq -8(%rbp), %rax
	# LowerStore(4025:3).9: mov i64 %rdi, (^2)
	movq %rdi, (%rax)
	# LowerLoad(4027:3).2: (^2) into i64 ^3
	movq (%rax), %rbx
	# LowerMath(4028:3): 0, ^3 into i64 ^4
	movq $0, %rax
	subq %rbx, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_add_func_uint8_t_u_uhh
.p2align 4, 0x90
_ZL25safe_add_func_uint8_t_u_uhh:
	.___ZL25safe_add_func_uint8_t_u_uhh__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3585:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rcx
	# LowerAlloca(3586:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(3587:3).9: mov i8 %dil, (^3)
	movb %dil, (%rcx)
	# LowerStore(3589:3).9: mov i8 %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(3591:3).2: (^3) into i8 ^5
	movb (%rcx), %bl
	# LowerBasicConversion(3592:3): i8 ^5 -> i32 ^6
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(3593:3).2: (^4) into i8 ^7
	movb (%rax), %cl
	# LowerBasicConversion(3594:3): i8 ^7 -> i32 ^8
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerMath(3595:3): ^6, ^8 into i32 ^9
	movl %ebx, %eax
	addl %ecx, %eax
	# LowerTrunc(3596:3): 32 to 8, move
	movb %al, %bl
	# LowerTrunc(3596:3): 32 to 8, apply mask
	andq $255, %rbx
	movb %bl, %al
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_uint8_t_u_shi
.p2align 4, 0x90
_ZL28safe_lshift_func_uint8_t_u_shi:
	.___ZL28safe_lshift_func_uint8_t_u_shi__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(64 + 0, 16)
	subq $64, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3542:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rdx
	# LowerAlloca(3543:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3544:3).9: mov i8 %dil, (^3)
	movb %dil, (%rdx)
	# LowerStore(3546:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3548:3).2: (^4) into i32 ^5
	movl (%rax), %ebx
	# LowerIcmp(3549:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_uint8_t_u_shi__M40
	.___ZL28safe_lshift_func_uint8_t_u_shi__M15:
	# LowerLoad(3553:3).2: (^4) into i32 ^8
	movl (%rax), %ebx
	# LowerIcmp(3554:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_uint8_t_u_shi__M40
	.___ZL28safe_lshift_func_uint8_t_u_shi__M22:
	# LowerLoad(3558:3).2: (^3) into i8 ^11
	movb (%rdx), %sil
	# LowerBasicConversion(3559:3): i8 ^11 -> i32 ^12
	# Truncate value to 8 bits
	andl $255, %esi
	# LowerLoad(3560:3).2: (^4) into i32 ^13
	movl (%rax), %ecx
	# LowerAshr(3561:3): 255, ^13 into i32 ^14
	# LowerShift(3561:3): operand ^13 changed to %ecx
	movl $255, %ebx
	sarl %cl, %ebx
	# LowerIcmp(3562:3): i32 ^12 vs. operand i32 ^14
	cmpl %ebx, %esi
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_uint8_t_u_shi__M40
	jmp .___ZL28safe_lshift_func_uint8_t_u_shi__M49
	.___ZL28safe_lshift_func_uint8_t_u_shi__M40:
	# LowerLoad(3566:3).2: (^3) into i8 ^17
	movb (%rdx), %al
	# LowerBasicConversion(3567:3): i8 ^17 -> i32 ^18
	# Truncate value to 8 bits
	andl $255, %eax
	# MovePhi: ^18 -> ^25
	movl %eax, %r8d
	jmp .___ZL28safe_lshift_func_uint8_t_u_shi__M65
	.___ZL28safe_lshift_func_uint8_t_u_shi__M49:
	# LowerLoad(3571:3).2: (^3) into i8 ^20
	movb (%rdx), %bl
	# LowerBasicConversion(3572:3): i8 ^20 -> i32 ^21
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(3573:3).2: (^4) into i32 ^22
	movl (%rax), %ecx
	# LowerMath(3574:3): ^21, ^22 into i32 ^23
	# LowerShift(3574:3): operand ^22 changed to %ecx
	movl %ebx, %eax
	shll %cl, %eax
	# MovePhi: ^23 -> ^25
	movl %eax, %r8d
	.___ZL28safe_lshift_func_uint8_t_u_shi__M65:
	# LowerTrunc(3579:3): 32 to 8, move
	movb %r8b, %al
	# LowerTrunc(3579:3): 32 to 8, apply mask
	andq $255, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_rshift_func_uint32_t_u_ujj
.p2align 4, 0x90
_ZL29safe_rshift_func_uint32_t_u_ujj:
	.___ZL29safe_rshift_func_uint32_t_u_ujj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4579:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(4580:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4581:3).9: mov i32 %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(4583:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4585:3).2: (^4) into i32 ^5
	movl (%rax), %ebx
	# LowerIcmp(4586:3): i32 ^5 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL29safe_rshift_func_uint32_t_u_ujj__M15
	jmp .___ZL29safe_rshift_func_uint32_t_u_ujj__M20
	.___ZL29safe_rshift_func_uint32_t_u_ujj__M15:
	# LowerLoad(4590:3).2: (^3) into i32 ^8
	movl (%rcx), %edx
	# MovePhi: ^8 -> ^14
	jmp .___ZL29safe_rshift_func_uint32_t_u_ujj__M32
	.___ZL29safe_rshift_func_uint32_t_u_ujj__M20:
	# LowerLoad(4594:3).2: (^3) into i32 ^10
	movl (%rcx), %ebx
	# LowerLoad(4595:3).2: (^4) into i32 ^11
	movl (%rax), %ecx
	# LowerLshr(4596:3): ^10, ^11 into i32 ^12
	# LowerShift(4596:3): operand ^11 changed to %ecx
	movl %ebx, %eax
	shrl %cl, %eax
	# MovePhi: ^12 -> ^14
	movl %eax, %edx
	.___ZL29safe_rshift_func_uint32_t_u_ujj__M32:
	movl %edx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_int64_t_s_sli
.p2align 4, 0x90
_ZL28safe_lshift_func_int64_t_s_sli:
	.___ZL28safe_lshift_func_int64_t_s_sli__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(88 + 0, 16)
	subq $96, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4244:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rdx
	# LowerAlloca(4245:3): size = 4, type = i32*, var = ^4
	leaq -12(%rbp), %rax
	# LowerStore(4246:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rdx)
	# LowerStore(4248:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4250:3).2: (^3) into i64 ^5
	movq (%rdx), %rbx
	# LowerIcmp(4251:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_sli__M46
	.___ZL28safe_lshift_func_int64_t_s_sli__M15:
	# LowerLoad(4255:3).2: (^4) into i32 ^8
	movl (%rax), %ebx
	# LowerIcmp(4256:3): i32 ^8 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_sli__M46
	.___ZL28safe_lshift_func_int64_t_s_sli__M22:
	# LowerLoad(4260:3).2: (^4) into i32 ^11
	movl (%rax), %ebx
	# LowerIcmp(4261:3): i32 ^11 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_sli__M46
	.___ZL28safe_lshift_func_int64_t_s_sli__M29:
	# LowerLoad(4265:3).2: (^3) into i64 ^14
	movq (%rdx), %rbx
	# LowerLoad(4266:3).2: (^4) into i32 ^15
	movl (%rax), %esi
	# LowerBasicConversion(4267:3): i32 ^15 -> i64 ^16
	# LowerAshr(4268:3): 9223372036854775807, ^16 into i64 ^17
	# LowerShift(4268:3): operand ^16 changed to %rcx
	movq %rsi, %rcx
	movabsq $9223372036854775807, %rcx
	movq %rcx, %rsi
	sarq %cl, %rsi
	# LowerIcmp(4269:3): i64 ^14 vs. operand i64 ^17
	cmpq %rsi, %rbx
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_sli__M46
	jmp .___ZL28safe_lshift_func_int64_t_s_sli__M51
	.___ZL28safe_lshift_func_int64_t_s_sli__M46:
	# LowerLoad(4273:3).2: (^3) into i64 ^20
	movq (%rdx), %r8
	# MovePhi: ^20 -> ^27
	jmp .___ZL28safe_lshift_func_int64_t_s_sli__M65
	.___ZL28safe_lshift_func_int64_t_s_sli__M51:
	# LowerLoad(4277:3).2: (^3) into i64 ^22
	movq (%rdx), %rbx
	# LowerLoad(4278:3).2: (^4) into i32 ^23
	movl (%rax), %edx
	# LowerBasicConversion(4279:3): i32 ^23 -> i64 ^24
	# LowerMath(4280:3): ^22, ^24 into i64 ^25
	# LowerShift(4280:3): operand ^24 changed to %rcx
	movq %rdx, %rcx
	movq %rbx, %rax
	shlq %cl, %rax
	# MovePhi: ^25 -> ^27
	movq %rax, %r8
	.___ZL28safe_lshift_func_int64_t_s_sli__M65:
	movq %r8, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_uint8_t_u_uhj
.p2align 4, 0x90
_ZL28safe_lshift_func_uint8_t_u_uhj:
	.___ZL28safe_lshift_func_uint8_t_u_uhj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4504:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rdx
	# LowerAlloca(4505:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4506:3).9: mov i8 %dil, (^3)
	movb %dil, (%rdx)
	# LowerStore(4508:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4510:3).2: (^4) into i32 ^5
	movl (%rax), %ebx
	# LowerIcmp(4511:3): i32 ^5 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_uint8_t_u_uhj__M33
	.___ZL28safe_lshift_func_uint8_t_u_uhj__M15:
	# LowerLoad(4515:3).2: (^3) into i8 ^8
	movb (%rdx), %bl
	# LowerBasicConversion(4516:3): i8 ^8 -> i32 ^9
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(4517:3).2: (^4) into i32 ^10
	movl (%rax), %ecx
	# LowerAshr(4518:3): 255, ^10 into i32 ^11
	# LowerShift(4518:3): operand ^10 changed to %ecx
	movl $255, %esi
	sarl %cl, %esi
	# LowerIcmp(4519:3): i32 ^9 vs. operand i32 ^11
	cmpl %esi, %ebx
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_uint8_t_u_uhj__M33
	jmp .___ZL28safe_lshift_func_uint8_t_u_uhj__M42
	.___ZL28safe_lshift_func_uint8_t_u_uhj__M33:
	# LowerLoad(4523:3).2: (^3) into i8 ^14
	movb (%rdx), %al
	# LowerBasicConversion(4524:3): i8 ^14 -> i32 ^15
	# Truncate value to 8 bits
	andl $255, %eax
	# MovePhi: ^15 -> ^22
	movl %eax, %r8d
	jmp .___ZL28safe_lshift_func_uint8_t_u_uhj__M58
	.___ZL28safe_lshift_func_uint8_t_u_uhj__M42:
	# LowerLoad(4528:3).2: (^3) into i8 ^17
	movb (%rdx), %bl
	# LowerBasicConversion(4529:3): i8 ^17 -> i32 ^18
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(4530:3).2: (^4) into i32 ^19
	movl (%rax), %ecx
	# LowerMath(4531:3): ^18, ^19 into i32 ^20
	# LowerShift(4531:3): operand ^19 changed to %ecx
	movl %ebx, %eax
	shll %cl, %eax
	# MovePhi: ^20 -> ^22
	movl %eax, %r8d
	.___ZL28safe_lshift_func_uint8_t_u_uhj__M58:
	# LowerTrunc(4536:3): 32 to 8, move
	movb %r8b, %al
	# LowerTrunc(4536:3): 32 to 8, apply mask
	andq $255, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_mod_func_int64_t_s_sll
.p2align 4, 0x90
_ZL25safe_mod_func_int64_t_s_sll:
	.___ZL25safe_mod_func_int64_t_s_sll__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(80 + 0, 16)
	subq $80, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4307:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(4308:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(4309:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(4311:3).9: mov i64 %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(4313:3).2: (^4) into i64 ^5
	movq (%rax), %rbx
	# LowerIcmp(4314:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int64_t_s_sll__M30
	.___ZL25safe_mod_func_int64_t_s_sll__M15:
	# LowerLoad(4318:3).2: (^3) into i64 ^8
	movq (%rcx), %rbx
	# LowerIcmp(4319:3): i64 ^8 vs. intlike -9223372036854775808
	movabsq $-9223372036854775808, %rdx
	cmpq %rdx, %rbx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int64_t_s_sll__M23
	jmp .___ZL25safe_mod_func_int64_t_s_sll__M35
	.___ZL25safe_mod_func_int64_t_s_sll__M23:
	# LowerLoad(4323:3).2: (^4) into i64 ^11
	movq (%rax), %rbx
	# LowerIcmp(4324:3): i64 ^11 vs. intlike -1
	cmpq $-1, %rbx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int64_t_s_sll__M30
	jmp .___ZL25safe_mod_func_int64_t_s_sll__M35
	.___ZL25safe_mod_func_int64_t_s_sll__M30:
	# LowerLoad(4328:3).2: (^3) into i64 ^14
	movq (%rcx), %r8
	# MovePhi: ^14 -> ^20
	jmp .___ZL25safe_mod_func_int64_t_s_sll__M51
	.___ZL25safe_mod_func_int64_t_s_sll__M35:
	# LowerLoad(4332:3).2: (^3) into i64 ^16
	movq (%rcx), %rbx
	# LowerLoad(4333:3).2: (^4) into i64 ^17
	movq (%rax), %rcx
	# LowerSrem(4334:3): ^16, ^17 into i64 ^18
	movq $0, %rdx
	movq %rbx, %rax
	idivq %rcx
	movq %rdx, %rbx
	# MovePhi: ^18 -> ^20
	movq %rbx, %r8
	.___ZL25safe_mod_func_int64_t_s_sll__M51:
	movq %r8, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL31safe_unary_minus_func_int64_t_sl
.p2align 4, 0x90
_ZL31safe_unary_minus_func_int64_t_sl:
	.___ZL31safe_unary_minus_func_int64_t_sl__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4361:3): size = 8, type = i64*, var = ^2
	leaq -8(%rbp), %rax
	# LowerStore(4362:3).9: mov i64 %rdi, (^2)
	movq %rdi, (%rax)
	# LowerLoad(4364:3).2: (^2) into i64 ^3
	movq (%rax), %rbx
	# LowerIcmp(4365:3): i64 ^3 vs. intlike -9223372036854775808
	movabsq $-9223372036854775808, %rcx
	cmpq %rcx, %rbx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL31safe_unary_minus_func_int64_t_sl__M12
	jmp .___ZL31safe_unary_minus_func_int64_t_sl__M17
	.___ZL31safe_unary_minus_func_int64_t_sl__M12:
	# LowerLoad(4369:3).2: (^2) into i64 ^6
	movq (%rax), %rdx
	# MovePhi: ^6 -> ^11
	jmp .___ZL31safe_unary_minus_func_int64_t_sl__M25
	.___ZL31safe_unary_minus_func_int64_t_sl__M17:
	# LowerLoad(4373:3).2: (^2) into i64 ^8
	movq (%rax), %rbx
	# LowerMath(4374:3): 0, ^8 into i64 ^9
	movq $0, %rax
	subq %rbx, %rax
	# MovePhi: ^9 -> ^11
	movq %rax, %rdx
	.___ZL31safe_unary_minus_func_int64_t_sl__M25:
	movq %rdx, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_rshift_func_int16_t_s_ssi
.p2align 4, 0x90
_ZL28safe_rshift_func_int16_t_s_ssi:
	.___ZL28safe_rshift_func_int16_t_s_ssi__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(72 + 0, 16)
	subq $80, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4463:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rdx
	# LowerAlloca(4464:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4465:3).9: mov i16 %di, (^3)
	movw %di, (%rdx)
	# LowerStore(4467:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4469:3).2: (^3) into i16 ^5
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerIcmp(4471:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int16_t_s_ssi__M30
	.___ZL28safe_rshift_func_int16_t_s_ssi__M16:
	# LowerLoad(4475:3).2: (^4) into i32 ^9
	movl (%rax), %ebx
	# LowerIcmp(4476:3): i32 ^9 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int16_t_s_ssi__M30
	.___ZL28safe_rshift_func_int16_t_s_ssi__M23:
	# LowerLoad(4480:3).2: (^4) into i32 ^12
	movl (%rax), %ebx
	# LowerIcmp(4481:3): i32 ^12 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int16_t_s_ssi__M30
	jmp .___ZL28safe_rshift_func_int16_t_s_ssi__M36
	.___ZL28safe_rshift_func_int16_t_s_ssi__M30:
	# LowerLoad(4485:3).2: (^3) into i16 ^15
	movw (%rdx), %ax
	movswl %ax, %ebx
	# MovePhi: ^16 -> ^23
	movl %ebx, %r8d
	jmp .___ZL28safe_rshift_func_int16_t_s_ssi__M49
	.___ZL28safe_rshift_func_int16_t_s_ssi__M36:
	# LowerLoad(4490:3).2: (^3) into i16 ^18
	movw (%rdx), %bx
	movswl %bx, %edx
	# LowerLoad(4492:3).2: (^4) into i32 ^20
	movl (%rax), %ecx
	# LowerAshr(4493:3): ^19, ^20 into i32 ^21
	# LowerShift(4493:3): operand ^20 changed to %ecx
	movl %edx, %eax
	sarl %cl, %eax
	# MovePhi: ^21 -> ^23
	movl %eax, %r8d
	.___ZL28safe_rshift_func_int16_t_s_ssi__M49:
	# LowerTrunc(4498:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(4498:3): 32 to 16, apply mask
	andq $65535, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_rshift_func_int16_t_s_usj
.p2align 4, 0x90
_ZL28safe_rshift_func_int16_t_s_usj:
	.___ZL28safe_rshift_func_int16_t_s_usj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4748:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rdx
	# LowerAlloca(4749:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4750:3).9: mov i16 %di, (^3)
	movw %di, (%rdx)
	# LowerStore(4752:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4754:3).2: (^3) into i16 ^5
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerIcmp(4756:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int16_t_s_usj__M23
	.___ZL28safe_rshift_func_int16_t_s_usj__M16:
	# LowerLoad(4760:3).2: (^4) into i32 ^9
	movl (%rax), %ebx
	# LowerIcmp(4761:3): i32 ^9 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int16_t_s_usj__M23
	jmp .___ZL28safe_rshift_func_int16_t_s_usj__M29
	.___ZL28safe_rshift_func_int16_t_s_usj__M23:
	# LowerLoad(4765:3).2: (^3) into i16 ^12
	movw (%rdx), %ax
	movswl %ax, %ebx
	# MovePhi: ^13 -> ^20
	movl %ebx, %r8d
	jmp .___ZL28safe_rshift_func_int16_t_s_usj__M42
	.___ZL28safe_rshift_func_int16_t_s_usj__M29:
	# LowerLoad(4770:3).2: (^3) into i16 ^15
	movw (%rdx), %bx
	movswl %bx, %edx
	# LowerLoad(4772:3).2: (^4) into i32 ^17
	movl (%rax), %ecx
	# LowerAshr(4773:3): ^16, ^17 into i32 ^18
	# LowerShift(4773:3): operand ^17 changed to %ecx
	movl %edx, %eax
	sarl %cl, %eax
	# MovePhi: ^18 -> ^20
	movl %eax, %r8d
	.___ZL28safe_rshift_func_int16_t_s_usj__M42:
	# LowerTrunc(4778:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(4778:3): 32 to 16, apply mask
	andq $65535, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_rshift_func_int32_t_s_sii
.p2align 4, 0x90
_ZL28safe_rshift_func_int32_t_s_sii:
	.___ZL28safe_rshift_func_int32_t_s_sii__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(64 + 0, 16)
	subq $64, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4423:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(4424:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4425:3).9: mov i32 %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(4427:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4429:3).2: (^3) into i32 ^5
	movl (%rcx), %ebx
	# LowerIcmp(4430:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int32_t_s_sii__M29
	.___ZL28safe_rshift_func_int32_t_s_sii__M15:
	# LowerLoad(4434:3).2: (^4) into i32 ^8
	movl (%rax), %ebx
	# LowerIcmp(4435:3): i32 ^8 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int32_t_s_sii__M29
	.___ZL28safe_rshift_func_int32_t_s_sii__M22:
	# LowerLoad(4439:3).2: (^4) into i32 ^11
	movl (%rax), %ebx
	# LowerIcmp(4440:3): i32 ^11 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int32_t_s_sii__M29
	jmp .___ZL28safe_rshift_func_int32_t_s_sii__M34
	.___ZL28safe_rshift_func_int32_t_s_sii__M29:
	# LowerLoad(4444:3).2: (^3) into i32 ^14
	movl (%rcx), %edx
	# MovePhi: ^14 -> ^20
	jmp .___ZL28safe_rshift_func_int32_t_s_sii__M46
	.___ZL28safe_rshift_func_int32_t_s_sii__M34:
	# LowerLoad(4448:3).2: (^3) into i32 ^16
	movl (%rcx), %ebx
	# LowerLoad(4449:3).2: (^4) into i32 ^17
	movl (%rax), %ecx
	# LowerAshr(4450:3): ^16, ^17 into i32 ^18
	# LowerShift(4450:3): operand ^17 changed to %ecx
	movl %ebx, %eax
	sarl %cl, %eax
	# MovePhi: ^18 -> ^20
	movl %eax, %edx
	.___ZL28safe_rshift_func_int32_t_s_sii__M46:
	movl %edx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_div_func_int64_t_s_sll
.p2align 4, 0x90
_ZL25safe_div_func_int64_t_s_sll:
	.___ZL25safe_div_func_int64_t_s_sll__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(80 + 0, 16)
	subq $80, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4542:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(4543:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(4544:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(4546:3).9: mov i64 %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(4548:3).2: (^4) into i64 ^5
	movq (%rax), %rbx
	# LowerIcmp(4549:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_div_func_int64_t_s_sll__M30
	.___ZL25safe_div_func_int64_t_s_sll__M15:
	# LowerLoad(4553:3).2: (^3) into i64 ^8
	movq (%rcx), %rbx
	# LowerIcmp(4554:3): i64 ^8 vs. intlike -9223372036854775808
	movabsq $-9223372036854775808, %rdx
	cmpq %rdx, %rbx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_div_func_int64_t_s_sll__M23
	jmp .___ZL25safe_div_func_int64_t_s_sll__M35
	.___ZL25safe_div_func_int64_t_s_sll__M23:
	# LowerLoad(4558:3).2: (^4) into i64 ^11
	movq (%rax), %rbx
	# LowerIcmp(4559:3): i64 ^11 vs. intlike -1
	cmpq $-1, %rbx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_div_func_int64_t_s_sll__M30
	jmp .___ZL25safe_div_func_int64_t_s_sll__M35
	.___ZL25safe_div_func_int64_t_s_sll__M30:
	# LowerLoad(4563:3).2: (^3) into i64 ^14
	movq (%rcx), %r8
	# MovePhi: ^14 -> ^20
	jmp .___ZL25safe_div_func_int64_t_s_sll__M51
	.___ZL25safe_div_func_int64_t_s_sll__M35:
	# LowerLoad(4567:3).2: (^3) into i64 ^16
	movq (%rcx), %rbx
	# LowerLoad(4568:3).2: (^4) into i64 ^17
	movq (%rax), %rcx
	# LowerSdiv(4569:3): ^16, ^17 into i64 ^18
	movq $0, %rdx
	movq %rbx, %rax
	idivq %rcx
	movq %rax, %rbx
	# MovePhi: ^18 -> ^20
	movq %rbx, %r8
	.___ZL25safe_div_func_int64_t_s_sll__M51:
	movq %r8, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_div_func_uint8_t_u_uhh
.p2align 4, 0x90
_ZL25safe_div_func_uint8_t_u_uhh:
	.___ZL25safe_div_func_uint8_t_u_uhh__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(40 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4606:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rcx
	# LowerAlloca(4607:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(4608:3).9: mov i8 %dil, (^3)
	movb %dil, (%rcx)
	# LowerStore(4610:3).9: mov i8 %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(4612:3).2: (^4) into i8 ^5
	movb (%rax), %bl
	# LowerBasicConversion(4613:3): i8 ^5 -> i32 ^6
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerIcmp(4614:3): i32 ^6 vs. intlike 0
	cmpl $0, %ebx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_div_func_uint8_t_u_uhh__M19
	jmp .___ZL25safe_div_func_uint8_t_u_uhh__M28
	.___ZL25safe_div_func_uint8_t_u_uhh__M19:
	# LowerLoad(4618:3).2: (^3) into i8 ^9
	movb (%rcx), %al
	# LowerBasicConversion(4619:3): i8 ^9 -> i32 ^10
	# Truncate value to 8 bits
	andl $255, %eax
	# MovePhi: ^10 -> ^18
	movl %eax, %r8d
	jmp .___ZL25safe_div_func_uint8_t_u_uhh__M52
	.___ZL25safe_div_func_uint8_t_u_uhh__M28:
	# LowerLoad(4623:3).2: (^3) into i8 ^12
	movb (%rcx), %sil
	# LowerBasicConversion(4624:3): i8 ^12 -> i32 ^13
	# Truncate value to 8 bits
	andl $255, %esi
	# LowerLoad(4625:3).2: (^4) into i8 ^14
	movb (%rax), %bl
	# LowerBasicConversion(4626:3): i8 ^14 -> i32 ^15
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerSdiv(4627:3): ^13, ^15 into i32 ^16
	movl $0, %edx
	movl %esi, %eax
	idivl %ebx
	movl %eax, %ebx
	# MovePhi: ^16 -> ^18
	movl %ebx, %r8d
	.___ZL25safe_div_func_uint8_t_u_uhh__M52:
	# LowerTrunc(4632:3): 32 to 8, move
	movb %r8b, %al
	# LowerTrunc(4632:3): 32 to 8, apply mask
	andq $255, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_add_func_uint16_t_u_utt
.p2align 4, 0x90
_ZL26safe_add_func_uint16_t_u_utt:
	.___ZL26safe_add_func_uint16_t_u_utt__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(6051:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(6052:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(6053:3).9: mov i16 %di, (^3)
	movw %di, (%rcx)
	# LowerStore(6055:3).9: mov i16 %si, (^4)
	movw %si, (%rax)
	# LowerLoad(6057:3).2: (^3) into i16 ^5
	movw (%rcx), %bx
	# LowerBasicConversion(6058:3): i16 ^5 -> i32 ^6
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(6059:3).2: (^4) into i16 ^7
	movw (%rax), %cx
	# LowerBasicConversion(6060:3): i16 ^7 -> i32 ^8
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerMath(6061:3): ^6, ^8 into i32 ^9
	movl %ebx, %eax
	addl %ecx, %eax
	# LowerTrunc(6062:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(6062:3): 32 to 16, apply mask
	andq $65535, %rbx
	movw %bx, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_rshift_func_uint16_t_u_sti
.p2align 4, 0x90
_ZL29safe_rshift_func_uint16_t_u_sti:
	.___ZL29safe_rshift_func_uint16_t_u_sti__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3709:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(3710:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3711:3).9: mov i16 %di, (^3)
	movw %di, (%rcx)
	# LowerStore(3713:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3715:3).2: (^4) into i32 ^5
	movl (%rax), %ebx
	# LowerIcmp(3716:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL29safe_rshift_func_uint16_t_u_sti__M22
	.___ZL29safe_rshift_func_uint16_t_u_sti__M15:
	# LowerLoad(3720:3).2: (^4) into i32 ^8
	movl (%rax), %ebx
	# LowerIcmp(3721:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL29safe_rshift_func_uint16_t_u_sti__M22
	jmp .___ZL29safe_rshift_func_uint16_t_u_sti__M31
	.___ZL29safe_rshift_func_uint16_t_u_sti__M22:
	# LowerLoad(3725:3).2: (^3) into i16 ^11
	movw (%rcx), %ax
	# LowerBasicConversion(3726:3): i16 ^11 -> i32 ^12
	# Truncate value to 16 bits
	andl $65535, %eax
	# MovePhi: ^12 -> ^19
	movl %eax, %edx
	jmp .___ZL29safe_rshift_func_uint16_t_u_sti__M47
	.___ZL29safe_rshift_func_uint16_t_u_sti__M31:
	# LowerLoad(3730:3).2: (^3) into i16 ^14
	movw (%rcx), %bx
	# LowerBasicConversion(3731:3): i16 ^14 -> i32 ^15
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(3732:3).2: (^4) into i32 ^16
	movl (%rax), %ecx
	# LowerAshr(3733:3): ^15, ^16 into i32 ^17
	# LowerShift(3733:3): operand ^16 changed to %ecx
	movl %ebx, %eax
	sarl %cl, %eax
	# MovePhi: ^17 -> ^19
	movl %eax, %edx
	.___ZL29safe_rshift_func_uint16_t_u_sti__M47:
	# LowerTrunc(3738:3): 32 to 16, move
	movw %dx, %ax
	# LowerTrunc(3738:3): 32 to 16, apply mask
	andq $65535, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_mod_func_uint32_t_u_ujj
.p2align 4, 0x90
_ZL26safe_mod_func_uint32_t_u_ujj:
	.___ZL26safe_mod_func_uint32_t_u_ujj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(40 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(6068:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rdx
	# LowerAlloca(6069:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(6070:3).9: mov i32 %edi, (^3)
	movl %edi, (%rdx)
	# LowerStore(6072:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(6074:3).2: (^4) into i32 ^5
	movl (%rax), %ebx
	# LowerIcmp(6075:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL26safe_mod_func_uint32_t_u_ujj__M15
	jmp .___ZL26safe_mod_func_uint32_t_u_ujj__M20
	.___ZL26safe_mod_func_uint32_t_u_ujj__M15:
	# LowerLoad(6079:3).2: (^3) into i32 ^8
	movl (%rdx), %ecx
	# MovePhi: ^8 -> ^14
	jmp .___ZL26safe_mod_func_uint32_t_u_ujj__M36
	.___ZL26safe_mod_func_uint32_t_u_ujj__M20:
	# LowerLoad(6083:3).2: (^3) into i32 ^10
	movl (%rdx), %ebx
	# LowerLoad(6084:3).2: (^4) into i32 ^11
	movl (%rax), %esi
	# LowerUrem(6085:3): ^10, ^11 into i32 ^12
	movl $0, %edx
	movl %ebx, %eax
	divl %esi
	movl %edx, %ebx
	# MovePhi: ^12 -> ^14
	movl %ebx, %ecx
	.___ZL26safe_mod_func_uint32_t_u_ujj__M36:
	movl %ecx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_rshift_func_uint64_t_u_umj
.p2align 4, 0x90
_ZL29safe_rshift_func_uint64_t_u_umj:
	.___ZL29safe_rshift_func_uint64_t_u_umj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4679:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rdx
	# LowerAlloca(4680:3): size = 4, type = i32*, var = ^4
	leaq -12(%rbp), %rax
	# LowerStore(4681:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rdx)
	# LowerStore(4683:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4685:3).2: (^4) into i32 ^5
	movl (%rax), %ecx
	# LowerIcmp(4686:3): i32 ^5 vs. intlike 32
	cmpl $32, %ecx
	setae %cl
	andq $1, %rcx
	cmpb $0, %cl
	jne .___ZL29safe_rshift_func_uint64_t_u_umj__M15
	jmp .___ZL29safe_rshift_func_uint64_t_u_umj__M20
	.___ZL29safe_rshift_func_uint64_t_u_umj__M15:
	# LowerLoad(4690:3).2: (^3) into i64 ^8
	movq (%rdx), %rbx
	# MovePhi: ^8 -> ^15
	jmp .___ZL29safe_rshift_func_uint64_t_u_umj__M34
	.___ZL29safe_rshift_func_uint64_t_u_umj__M20:
	# LowerLoad(4694:3).2: (^3) into i64 ^10
	movq (%rdx), %rsi
	# LowerLoad(4695:3).2: (^4) into i32 ^11
	movl (%rax), %edx
	# LowerBasicConversion(4696:3): i32 ^11 -> i64 ^12
	# LowerLshr(4697:3): ^10, ^12 into i64 ^13
	# LowerShift(4697:3): operand ^12 changed to %rcx
	movq %rdx, %rcx
	movq %rsi, %rax
	shrq %cl, %rax
	# MovePhi: ^13 -> ^15
	movq %rax, %rbx
	.___ZL29safe_rshift_func_uint64_t_u_umj__M34:
	movq %rbx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_sub_func_int32_t_s_sii
.p2align 4, 0x90
_ZL25safe_sub_func_int32_t_s_sii:
	.___ZL25safe_sub_func_int32_t_s_sii__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(64 + 0, 16)
	subq $64, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4784:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rdx
	# LowerAlloca(4785:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4786:3).9: mov i32 %edi, (^3)
	movl %edi, (%rdx)
	# LowerStore(4788:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4790:3).2: (^3) into i32 ^5
	movl (%rdx), %ebx
	# LowerLoad(4791:3).2: (^4) into i32 ^6
	movl (%rax), %ecx
	# LowerLogic(4793:3): ^5, ^6 into i32 ^7
	movl %ebx, %edi
	xorl %ecx, %edi
	# LowerLoad(4793:3).2: (^3) into i32 ^8
	movl (%rdx), %ecx
	# LowerLoad(4794:3).2: (^3) into i32 ^9
	movl (%rdx), %ebx
	# LowerLoad(4795:3).2: (^4) into i32 ^10
	movl (%rax), %esi
	# LowerLogic(4797:3): ^9, ^10 into i32 ^11
	movl %ebx, %r9d
	xorl %esi, %r9d
	# LowerLogic(4798:3): ^11, -2147483648 into i32 ^12
	movl %r9d, %ebx
	andl $-2147483648, %ebx
	# LowerLogic(4799:3): ^8, ^12 into i32 ^13
	movl %ecx, %esi
	xorl %ebx, %esi
	# LowerLoad(4799:3).2: (^4) into i32 ^14
	movl (%rax), %ecx
	# LowerMath(4800:3): ^13, ^14 into i32 ^15
	movl %esi, %ebx
	subl %ecx, %ebx
	# LowerLoad(4801:3).2: (^4) into i32 ^16
	movl (%rax), %ecx
	# LowerLogic(4803:3): ^15, ^16 into i32 ^17
	movl %ebx, %esi
	xorl %ecx, %esi
	# LowerLogic(4804:3): ^7, ^17 into i32 ^18
	movl %edi, %ebx
	andl %esi, %ebx
	# LowerIcmp(4804:3): i32 ^18 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_sub_func_int32_t_s_sii__M49
	jmp .___ZL25safe_sub_func_int32_t_s_sii__M54
	.___ZL25safe_sub_func_int32_t_s_sii__M49:
	# LowerLoad(4808:3).2: (^3) into i32 ^21
	movl (%rdx), %r8d
	# MovePhi: ^21 -> ^27
	jmp .___ZL25safe_sub_func_int32_t_s_sii__M64
	.___ZL25safe_sub_func_int32_t_s_sii__M54:
	# LowerLoad(4812:3).2: (^3) into i32 ^23
	movl (%rdx), %ebx
	# LowerLoad(4813:3).2: (^4) into i32 ^24
	movl (%rax), %ecx
	# LowerMath(4814:3): ^23, ^24 into i32 ^25
	movl %ebx, %eax
	subl %ecx, %eax
	# MovePhi: ^25 -> ^27
	movl %eax, %r8d
	.___ZL25safe_sub_func_int32_t_s_sii__M64:
	movl %r8d, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL6func_1v
.p2align 4, 0x90
_ZL6func_1v:
	.___ZL6func_1v__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(9848 + 0, 16)
	subq $9856, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -6424(%rbp)
	movq %r12, -6432(%rbp)
	movq %r13, -6512(%rbp)
	movq %r14, -6528(%rbp)
	movq %r15, -6360(%rbp)
	# LowerAlloca(1724:3): size = 2, type = %union.U4*, var = ^1
	# Fixing source-to-dest leaq -2(%rbp), -5344(%rbp)
	leaq -2(%rbp), %r15
	movq %r15, -5344(%rbp)
	# LowerAlloca(1725:3): size = 4, type = %union.U0*, var = ^2
	# Fixing source-to-dest leaq -8(%rbp), -5368(%rbp)
	leaq -8(%rbp), %r15
	movq %r15, -5368(%rbp)
	# LowerAlloca(1726:3): size = 4, type = i32*, var = ^3
	# Fixing source-to-dest leaq -12(%rbp), -5784(%rbp)
	leaq -12(%rbp), %r15
	movq %r15, -5784(%rbp)
	# LowerAlloca(1727:3): size = 4, type = i32*, var = ^4
	# Fixing source-to-dest leaq -16(%rbp), -5440(%rbp)
	leaq -16(%rbp), %r15
	movq %r15, -5440(%rbp)
	# LowerAlloca(1728:3): size = 4, type = i32*, var = ^5
	# Fixing source-to-dest leaq -20(%rbp), -5472(%rbp)
	leaq -20(%rbp), %r15
	movq %r15, -5472(%rbp)
	# LowerAlloca(1729:3): size = 4, type = i32*, var = ^6
	# Fixing source-to-dest leaq -24(%rbp), -5576(%rbp)
	leaq -24(%rbp), %r15
	movq %r15, -5576(%rbp)
	# LowerAlloca(1730:3): size = 8, type = ptr*, var = ^7
	leaq -32(%rbp), %rcx
	# LowerAlloca(1731:3): size = 8, type = ptr*, var = ^8
	# Fixing source-to-dest leaq -40(%rbp), -6136(%rbp)
	leaq -40(%rbp), %r15
	movq %r15, -6136(%rbp)
	# LowerAlloca(1732:3): size = 8, type = i64*, var = ^9
	# Fixing source-to-dest leaq -48(%rbp), -5592(%rbp)
	leaq -48(%rbp), %r15
	movq %r15, -5592(%rbp)
	# LowerAlloca(1733:3): size = 2016, type = [7 x [9 x [4 x ptr]]]*, var = ^10
	leaq -2064(%rbp), %rbx
	# LowerAlloca(1734:3): size = 8, type = ptr*, var = ^11
	leaq -2072(%rbp), %r12
	# LowerAlloca(1735:3): size = 8, type = ptr*, var = ^12
	# Fixing source-to-dest leaq -2080(%rbp), -5760(%rbp)
	leaq -2080(%rbp), %r15
	movq %r15, -5760(%rbp)
	# LowerAlloca(1736:3): size = 8, type = ptr*, var = ^13
	# Fixing source-to-dest leaq -2088(%rbp), -5352(%rbp)
	leaq -2088(%rbp), %r15
	movq %r15, -5352(%rbp)
	# LowerAlloca(1737:3): size = 8, type = ptr*, var = ^14
	# Fixing source-to-dest leaq -2096(%rbp), -5696(%rbp)
	leaq -2096(%rbp), %r15
	movq %r15, -5696(%rbp)
	# LowerAlloca(1738:3): size = 8, type = [4 x [1 x i16]]*, var = ^15
	# Fixing source-to-dest leaq -2104(%rbp), -5360(%rbp)
	leaq -2104(%rbp), %r15
	movq %r15, -5360(%rbp)
	# LowerAlloca(1739:3): size = 8, type = ptr*, var = ^16
	# Fixing source-to-dest leaq -2112(%rbp), -6304(%rbp)
	leaq -2112(%rbp), %r15
	movq %r15, -6304(%rbp)
	# LowerAlloca(1740:3): size = 2, type = i16*, var = ^17
	# Fixing source-to-dest leaq -2114(%rbp), -5480(%rbp)
	leaq -2114(%rbp), %r15
	movq %r15, -5480(%rbp)
	# LowerAlloca(1741:3): size = 8, type = ptr*, var = ^18
	# Fixing source-to-dest leaq -2128(%rbp), -6312(%rbp)
	leaq -2128(%rbp), %r15
	movq %r15, -6312(%rbp)
	# LowerAlloca(1742:3): size = 4, type = i32*, var = ^19
	# Fixing source-to-dest leaq -2132(%rbp), -6320(%rbp)
	leaq -2132(%rbp), %r15
	movq %r15, -6320(%rbp)
	# LowerAlloca(1743:3): size = 4, type = i32*, var = ^20
	# Fixing source-to-dest leaq -2136(%rbp), -6328(%rbp)
	leaq -2136(%rbp), %r15
	movq %r15, -6328(%rbp)
	# LowerAlloca(1744:3): size = 4, type = i32*, var = ^21
	leaq -2140(%rbp), %r13
	# LowerAlloca(1745:3): size = 4, type = i32*, var = ^22
	# Fixing source-to-dest leaq -2144(%rbp), -5680(%rbp)
	leaq -2144(%rbp), %r15
	movq %r15, -5680(%rbp)
	# LowerAlloca(1746:3): size = 4, type = i32*, var = ^23
	leaq -2148(%rbp), %r14
	# LowerAlloca(1747:3): size = 8, type = ptr*, var = ^24
	leaq -2160(%rbp), %r15
	# LowerAlloca(1748:3): size = 80, type = [1 x [10 x i64]]*, var = ^25
	# Fixing source-to-dest leaq -2240(%rbp), -6280(%rbp)
	pushq %r15
	leaq -2240(%rbp), %r15
	movq %r15, -6280(%rbp)
	popq %r15
	# LowerAlloca(1749:3): size = 4, type = i32*, var = ^26
	# Fixing source-to-dest leaq -2244(%rbp), -5736(%rbp)
	pushq %r15
	leaq -2244(%rbp), %r15
	movq %r15, -5736(%rbp)
	popq %r15
	# LowerAlloca(1750:3): size = 8, type = i64*, var = ^27
	# Fixing source-to-dest leaq -2256(%rbp), -5744(%rbp)
	pushq %r15
	leaq -2256(%rbp), %r15
	movq %r15, -5744(%rbp)
	popq %r15
	# LowerAlloca(1751:3): size = 24, type = [6 x i32]*, var = ^28
	# Fixing source-to-dest leaq -2288(%rbp), -5728(%rbp)
	pushq %r15
	leaq -2288(%rbp), %r15
	movq %r15, -5728(%rbp)
	popq %r15
	# LowerAlloca(1752:3): size = 4, type = i32*, var = ^29
	# Fixing source-to-dest leaq -2292(%rbp), -6272(%rbp)
	pushq %r15
	leaq -2292(%rbp), %r15
	movq %r15, -6272(%rbp)
	popq %r15
	# LowerAlloca(1753:3): size = 4, type = i32*, var = ^30
	# Fixing source-to-dest leaq -2296(%rbp), -6296(%rbp)
	pushq %r15
	leaq -2296(%rbp), %r15
	movq %r15, -6296(%rbp)
	popq %r15
	# LowerAlloca(1754:3): size = 4, type = i32*, var = ^31
	leaq -2300(%rbp), %rax
	# LowerAlloca(1755:3): size = 2, type = i16*, var = ^32
	# Fixing source-to-dest leaq -2302(%rbp), -6144(%rbp)
	pushq %r15
	leaq -2302(%rbp), %r15
	movq %r15, -6144(%rbp)
	popq %r15
	# LowerAlloca(1756:3): size = 4, type = i32*, var = ^33
	# Fixing source-to-dest leaq -2308(%rbp), -6152(%rbp)
	pushq %r15
	leaq -2308(%rbp), %r15
	movq %r15, -6152(%rbp)
	popq %r15
	# LowerAlloca(1757:3): size = 4, type = i32*, var = ^34
	# Fixing source-to-dest leaq -2312(%rbp), -6160(%rbp)
	pushq %r15
	leaq -2312(%rbp), %r15
	movq %r15, -6160(%rbp)
	popq %r15
	# LowerAlloca(1758:3): size = 8, type = ptr*, var = ^35
	# Fixing source-to-dest leaq -2320(%rbp), -6168(%rbp)
	pushq %r15
	leaq -2320(%rbp), %r15
	movq %r15, -6168(%rbp)
	popq %r15
	# LowerAlloca(1759:3): size = 8, type = ptr*, var = ^36
	# Fixing source-to-dest leaq -2328(%rbp), -6176(%rbp)
	pushq %r15
	leaq -2328(%rbp), %r15
	movq %r15, -6176(%rbp)
	popq %r15
	# LowerAlloca(1760:3): size = 8, type = ptr*, var = ^37
	# Fixing source-to-dest leaq -2336(%rbp), -6184(%rbp)
	pushq %r15
	leaq -2336(%rbp), %r15
	movq %r15, -6184(%rbp)
	popq %r15
	# LowerAlloca(1761:3): size = 8, type = ptr*, var = ^38
	# Fixing source-to-dest leaq -2344(%rbp), -6192(%rbp)
	pushq %r15
	leaq -2344(%rbp), %r15
	movq %r15, -6192(%rbp)
	popq %r15
	# LowerAlloca(1762:3): size = 8, type = ptr*, var = ^39
	# Fixing source-to-dest leaq -2352(%rbp), -6200(%rbp)
	pushq %r15
	leaq -2352(%rbp), %r15
	movq %r15, -6200(%rbp)
	popq %r15
	# LowerAlloca(1763:3): size = 8, type = ptr*, var = ^40
	# Fixing source-to-dest leaq -2360(%rbp), -6208(%rbp)
	pushq %r15
	leaq -2360(%rbp), %r15
	movq %r15, -6208(%rbp)
	popq %r15
	# LowerAlloca(1764:3): size = 288, type = [4 x [9 x ptr]]*, var = ^41
	# Fixing source-to-dest leaq -2656(%rbp), -6216(%rbp)
	pushq %r15
	leaq -2656(%rbp), %r15
	movq %r15, -6216(%rbp)
	popq %r15
	# LowerAlloca(1765:3): size = 4, type = i32*, var = ^42
	leaq -2660(%rbp), %rax
	# LowerAlloca(1766:3): size = 4, type = i32*, var = ^43
	leaq -2664(%rbp), %rax
	# LowerAlloca(1767:3): size = 2, type = i16*, var = ^44
	# Fixing source-to-dest leaq -2666(%rbp), -6224(%rbp)
	pushq %r15
	leaq -2666(%rbp), %r15
	movq %r15, -6224(%rbp)
	popq %r15
	# LowerAlloca(1768:3): size = 120, type = [4 x [3 x [5 x %union.U4]]]*, var = ^45
	# Fixing source-to-dest leaq -2800(%rbp), -6232(%rbp)
	pushq %r15
	leaq -2800(%rbp), %r15
	movq %r15, -6232(%rbp)
	popq %r15
	# LowerAlloca(1769:3): size = 2, type = i16*, var = ^46
	# Fixing source-to-dest leaq -2802(%rbp), -6240(%rbp)
	pushq %r15
	leaq -2802(%rbp), %r15
	movq %r15, -6240(%rbp)
	popq %r15
	# LowerAlloca(1770:3): size = 8, type = i64*, var = ^47
	# Fixing source-to-dest leaq -2816(%rbp), -6248(%rbp)
	pushq %r15
	leaq -2816(%rbp), %r15
	movq %r15, -6248(%rbp)
	popq %r15
	# LowerAlloca(1771:3): size = 4, type = i32*, var = ^48
	leaq -2820(%rbp), %rax
	# LowerAlloca(1772:3): size = 4, type = i32*, var = ^49
	leaq -2824(%rbp), %rax
	# LowerAlloca(1773:3): size = 4, type = i32*, var = ^50
	leaq -2828(%rbp), %rax
	# LowerAlloca(1774:3): size = 2, type = i16*, var = ^51
	# Fixing source-to-dest leaq -2830(%rbp), -6032(%rbp)
	pushq %r15
	leaq -2830(%rbp), %r15
	movq %r15, -6032(%rbp)
	popq %r15
	# LowerAlloca(1775:3): size = 8, type = ptr*, var = ^52
	# Fixing source-to-dest leaq -2840(%rbp), -6024(%rbp)
	pushq %r15
	leaq -2840(%rbp), %r15
	movq %r15, -6024(%rbp)
	popq %r15
	# LowerAlloca(1776:3): size = 8, type = ptr*, var = ^53
	# Fixing source-to-dest leaq -2848(%rbp), -5376(%rbp)
	pushq %r15
	leaq -2848(%rbp), %r15
	movq %r15, -5376(%rbp)
	popq %r15
	# LowerAlloca(1777:3): size = 2, type = i16*, var = ^54
	# Fixing source-to-dest leaq -2850(%rbp), -5896(%rbp)
	pushq %r15
	leaq -2850(%rbp), %r15
	movq %r15, -5896(%rbp)
	popq %r15
	# LowerAlloca(1778:3): size = 8, type = ptr*, var = ^55
	# Fixing source-to-dest leaq -2864(%rbp), -5392(%rbp)
	pushq %r15
	leaq -2864(%rbp), %r15
	movq %r15, -5392(%rbp)
	popq %r15
	# LowerAlloca(1779:3): size = 4, type = %union.U0*, var = ^56
	# Fixing source-to-dest leaq -2868(%rbp), -5808(%rbp)
	pushq %r15
	leaq -2868(%rbp), %r15
	movq %r15, -5808(%rbp)
	popq %r15
	# LowerAlloca(1780:3): size = 8, type = ptr*, var = ^57
	# Fixing source-to-dest leaq -2880(%rbp), -5672(%rbp)
	pushq %r15
	leaq -2880(%rbp), %r15
	movq %r15, -5672(%rbp)
	popq %r15
	# LowerAlloca(1781:3): size = 8, type = ptr*, var = ^58
	# Fixing source-to-dest leaq -2888(%rbp), -5776(%rbp)
	pushq %r15
	leaq -2888(%rbp), %r15
	movq %r15, -5776(%rbp)
	popq %r15
	# LowerAlloca(1782:3): size = 8, type = ptr*, var = ^59
	# Fixing source-to-dest leaq -2896(%rbp), -6088(%rbp)
	pushq %r15
	leaq -2896(%rbp), %r15
	movq %r15, -6088(%rbp)
	popq %r15
	# LowerAlloca(1783:3): size = 48, type = [3 x [2 x ptr]]*, var = ^60
	# Fixing source-to-dest leaq -2944(%rbp), -5752(%rbp)
	pushq %r15
	leaq -2944(%rbp), %r15
	movq %r15, -5752(%rbp)
	popq %r15
	# LowerAlloca(1784:3): size = 48, type = [6 x ptr]*, var = ^61
	# Fixing source-to-dest leaq -2992(%rbp), -6096(%rbp)
	pushq %r15
	leaq -2992(%rbp), %r15
	movq %r15, -6096(%rbp)
	popq %r15
	# LowerAlloca(1785:3): size = 8, type = ptr*, var = ^62
	# Fixing source-to-dest leaq -3000(%rbp), -5584(%rbp)
	pushq %r15
	leaq -3000(%rbp), %r15
	movq %r15, -5584(%rbp)
	popq %r15
	# LowerAlloca(1786:3): size = 4, type = i32*, var = ^63
	# Fixing source-to-dest leaq -3004(%rbp), -6048(%rbp)
	pushq %r15
	leaq -3004(%rbp), %r15
	movq %r15, -6048(%rbp)
	popq %r15
	# LowerAlloca(1787:3): size = 4, type = i32*, var = ^64
	# Fixing source-to-dest leaq -3008(%rbp), -6056(%rbp)
	pushq %r15
	leaq -3008(%rbp), %r15
	movq %r15, -6056(%rbp)
	popq %r15
	# LowerAlloca(1788:3): size = 4, type = i32*, var = ^65
	# Fixing source-to-dest leaq -3012(%rbp), -6064(%rbp)
	pushq %r15
	leaq -3012(%rbp), %r15
	movq %r15, -6064(%rbp)
	popq %r15
	# LowerAlloca(1789:3): size = 4, type = i32*, var = ^66
	# Fixing source-to-dest leaq -3016(%rbp), -6072(%rbp)
	pushq %r15
	leaq -3016(%rbp), %r15
	movq %r15, -6072(%rbp)
	popq %r15
	# LowerAlloca(1790:3): size = 4, type = i32*, var = ^67
	# Fixing source-to-dest leaq -3020(%rbp), -6080(%rbp)
	pushq %r15
	leaq -3020(%rbp), %r15
	movq %r15, -6080(%rbp)
	popq %r15
	# LowerAlloca(1791:3): size = 4, type = i32*, var = ^68
	leaq -3024(%rbp), %rax
	# LowerAlloca(1792:3): size = 4, type = i32*, var = ^69
	leaq -3028(%rbp), %rax
	# LowerAlloca(1793:3): size = 4, type = %union.U0*, var = ^70
	# Fixing source-to-dest leaq -3032(%rbp), -5816(%rbp)
	pushq %r15
	leaq -3032(%rbp), %r15
	movq %r15, -5816(%rbp)
	popq %r15
	# LowerAlloca(1794:3): size = 2, type = %union.U1*, var = ^71
	# Fixing source-to-dest leaq -3034(%rbp), -5800(%rbp)
	pushq %r15
	leaq -3034(%rbp), %r15
	movq %r15, -5800(%rbp)
	popq %r15
	# LowerAlloca(1795:3): size = 4, type = %union.U0*, var = ^72
	# Fixing source-to-dest leaq -3040(%rbp), -5720(%rbp)
	pushq %r15
	leaq -3040(%rbp), %r15
	movq %r15, -5720(%rbp)
	popq %r15
	# LowerAlloca(1796:3): size = 2, type = %union.U1*, var = ^73
	# Fixing source-to-dest leaq -3042(%rbp), -5704(%rbp)
	pushq %r15
	leaq -3042(%rbp), %r15
	movq %r15, -5704(%rbp)
	popq %r15
	# LowerAlloca(1797:3): size = 16, type = [4 x i32]*, var = ^74
	# Fixing source-to-dest leaq -3072(%rbp), -5400(%rbp)
	pushq %r15
	leaq -3072(%rbp), %r15
	movq %r15, -5400(%rbp)
	popq %r15
	# LowerAlloca(1798:3): size = 32, type = [4 x ptr]*, var = ^75
	# Fixing source-to-dest leaq -3104(%rbp), -5616(%rbp)
	pushq %r15
	leaq -3104(%rbp), %r15
	movq %r15, -5616(%rbp)
	popq %r15
	# LowerAlloca(1799:3): size = 4, type = i32*, var = ^76
	# Fixing source-to-dest leaq -3108(%rbp), -5408(%rbp)
	pushq %r15
	leaq -3108(%rbp), %r15
	movq %r15, -5408(%rbp)
	popq %r15
	# LowerAlloca(1800:3): size = 4, type = i32*, var = ^77
	# Fixing source-to-dest leaq -3112(%rbp), -5624(%rbp)
	pushq %r15
	leaq -3112(%rbp), %r15
	movq %r15, -5624(%rbp)
	popq %r15
	# LowerAlloca(1801:3): size = 35, type = [5 x [7 x i8]]*, var = ^78
	# Fixing source-to-dest leaq -3152(%rbp), -5416(%rbp)
	pushq %r15
	leaq -3152(%rbp), %r15
	movq %r15, -5416(%rbp)
	popq %r15
	# LowerAlloca(1802:3): size = 4, type = i32*, var = ^79
	leaq -3156(%rbp), %rax
	# LowerAlloca(1803:3): size = 4, type = i32*, var = ^80
	leaq -3160(%rbp), %rax
	# LowerAlloca(1804:3): size = 4, type = i32*, var = ^81
	# Fixing source-to-dest leaq -3164(%rbp), -5424(%rbp)
	pushq %r15
	leaq -3164(%rbp), %r15
	movq %r15, -5424(%rbp)
	popq %r15
	# LowerAlloca(1805:3): size = 4, type = i32*, var = ^82
	leaq -3168(%rbp), %rax
	# LowerAlloca(1806:3): size = 4, type = i32*, var = ^83
	# Fixing source-to-dest leaq -3172(%rbp), -5464(%rbp)
	pushq %r15
	leaq -3172(%rbp), %r15
	movq %r15, -5464(%rbp)
	popq %r15
	# LowerAlloca(1807:3): size = 400, type = [5 x [10 x i64]]*, var = ^84
	# Fixing source-to-dest leaq -3584(%rbp), -5456(%rbp)
	pushq %r15
	leaq -3584(%rbp), %r15
	movq %r15, -5456(%rbp)
	popq %r15
	# LowerAlloca(1808:3): size = 4, type = i32*, var = ^85
	# Fixing source-to-dest leaq -3588(%rbp), -5448(%rbp)
	pushq %r15
	leaq -3588(%rbp), %r15
	movq %r15, -5448(%rbp)
	popq %r15
	# LowerAlloca(1809:3): size = 8, type = i64*, var = ^86
	# Fixing source-to-dest leaq -3600(%rbp), -5656(%rbp)
	pushq %r15
	leaq -3600(%rbp), %r15
	movq %r15, -5656(%rbp)
	popq %r15
	# LowerAlloca(1810:3): size = 8, type = [1 x ptr]*, var = ^87
	# Fixing source-to-dest leaq -3608(%rbp), -5600(%rbp)
	pushq %r15
	leaq -3608(%rbp), %r15
	movq %r15, -5600(%rbp)
	popq %r15
	# LowerAlloca(1811:3): size = 504, type = [7 x [9 x ptr]]*, var = ^88
	# Fixing source-to-dest leaq -4112(%rbp), -5648(%rbp)
	pushq %r15
	leaq -4112(%rbp), %r15
	movq %r15, -5648(%rbp)
	popq %r15
	# LowerAlloca(1812:3): size = 4, type = i32*, var = ^89
	# Fixing source-to-dest leaq -4116(%rbp), -5608(%rbp)
	pushq %r15
	leaq -4116(%rbp), %r15
	movq %r15, -5608(%rbp)
	popq %r15
	# LowerAlloca(1813:3): size = 4, type = i32*, var = ^90
	leaq -4120(%rbp), %rax
	# LowerAlloca(1814:3): size = 2, type = i16*, var = ^91
	# Fixing source-to-dest leaq -4122(%rbp), -5504(%rbp)
	pushq %r15
	leaq -4122(%rbp), %r15
	movq %r15, -5504(%rbp)
	popq %r15
	# LowerAlloca(1815:3): size = 2, type = %union.U4*, var = ^92
	# Fixing source-to-dest leaq -4124(%rbp), -5512(%rbp)
	pushq %r15
	leaq -4124(%rbp), %r15
	movq %r15, -5512(%rbp)
	popq %r15
	# LowerAlloca(1816:3): size = 4, type = i32*, var = ^93
	# Fixing source-to-dest leaq -4128(%rbp), -5520(%rbp)
	pushq %r15
	leaq -4128(%rbp), %r15
	movq %r15, -5520(%rbp)
	popq %r15
	# LowerAlloca(1817:3): size = 40, type = [10 x i32]*, var = ^94
	# Fixing source-to-dest leaq -4176(%rbp), -5528(%rbp)
	pushq %r15
	leaq -4176(%rbp), %r15
	movq %r15, -5528(%rbp)
	popq %r15
	# LowerAlloca(1818:3): size = 4, type = i32*, var = ^95
	# Fixing source-to-dest leaq -4180(%rbp), -5536(%rbp)
	pushq %r15
	leaq -4180(%rbp), %r15
	movq %r15, -5536(%rbp)
	popq %r15
	# LowerAlloca(1819:3): size = 4, type = i32*, var = ^96
	# Fixing source-to-dest leaq -4184(%rbp), -5544(%rbp)
	pushq %r15
	leaq -4184(%rbp), %r15
	movq %r15, -5544(%rbp)
	popq %r15
	# LowerAlloca(1820:3): size = 4, type = i32*, var = ^97
	leaq -4188(%rbp), %rax
	# LowerAlloca(1821:3): size = 84, type = [3 x [7 x i32]]*, var = ^98
	# Fixing source-to-dest leaq -4272(%rbp), -5552(%rbp)
	pushq %r15
	leaq -4272(%rbp), %r15
	movq %r15, -5552(%rbp)
	popq %r15
	# LowerAlloca(1822:3): size = 8, type = ptr*, var = ^99
	# Fixing source-to-dest leaq -4280(%rbp), -5560(%rbp)
	pushq %r15
	leaq -4280(%rbp), %r15
	movq %r15, -5560(%rbp)
	popq %r15
	# LowerAlloca(1823:3): size = 4, type = i32*, var = ^100
	leaq -4284(%rbp), %rax
	# LowerAlloca(1824:3): size = 4, type = i32*, var = ^101
	leaq -4288(%rbp), %rax
	# LowerAlloca(1825:3): size = 8, type = ptr*, var = ^102
	# Fixing source-to-dest leaq -4296(%rbp), -5568(%rbp)
	pushq %r15
	leaq -4296(%rbp), %r15
	movq %r15, -5568(%rbp)
	popq %r15
	# LowerAlloca(1826:3): size = 4, type = i32*, var = ^103
	leaq -4300(%rbp), %rax
	# LowerAlloca(1827:3): size = 8, type = ptr*, var = ^104
	# Fixing source-to-dest leaq -4312(%rbp), -6112(%rbp)
	pushq %r15
	leaq -4312(%rbp), %r15
	movq %r15, -6112(%rbp)
	popq %r15
	# LowerAlloca(1828:3): size = 4, type = %union.U0*, var = ^105
	# Fixing source-to-dest leaq -4316(%rbp), -6040(%rbp)
	pushq %r15
	leaq -4316(%rbp), %r15
	movq %r15, -6040(%rbp)
	popq %r15
	# LowerAlloca(1829:3): size = 8, type = ptr*, var = ^106
	# Fixing source-to-dest leaq -4328(%rbp), -5768(%rbp)
	pushq %r15
	leaq -4328(%rbp), %r15
	movq %r15, -5768(%rbp)
	popq %r15
	# LowerAlloca(1830:3): size = 4, type = i32*, var = ^107
	# Fixing source-to-dest leaq -4332(%rbp), -6120(%rbp)
	pushq %r15
	leaq -4332(%rbp), %r15
	movq %r15, -6120(%rbp)
	popq %r15
	# LowerAlloca(1831:3): size = 4, type = i32*, var = ^108
	# Fixing source-to-dest leaq -4336(%rbp), -6128(%rbp)
	pushq %r15
	leaq -4336(%rbp), %r15
	movq %r15, -6128(%rbp)
	popq %r15
	# LowerAlloca(1832:3): size = 224, type = [7 x [8 x i32]]*, var = ^109
	# Fixing source-to-dest leaq -4560(%rbp), -5664(%rbp)
	pushq %r15
	leaq -4560(%rbp), %r15
	movq %r15, -5664(%rbp)
	popq %r15
	# LowerAlloca(1833:3): size = 8, type = ptr*, var = ^110
	# Fixing source-to-dest leaq -4568(%rbp), -5640(%rbp)
	pushq %r15
	leaq -4568(%rbp), %r15
	movq %r15, -5640(%rbp)
	popq %r15
	# LowerAlloca(1834:3): size = 2, type = %union.U4*, var = ^111
	# Fixing source-to-dest leaq -4570(%rbp), -5952(%rbp)
	pushq %r15
	leaq -4570(%rbp), %r15
	movq %r15, -5952(%rbp)
	popq %r15
	# LowerAlloca(1835:3): size = 4, type = i32*, var = ^112
	leaq -4576(%rbp), %rax
	# LowerAlloca(1836:3): size = 4, type = i32*, var = ^113
	leaq -4580(%rbp), %rax
	# LowerAlloca(1837:3): size = 1, type = i8*, var = ^114
	# Fixing source-to-dest leaq -4581(%rbp), -5928(%rbp)
	pushq %r15
	leaq -4581(%rbp), %r15
	movq %r15, -5928(%rbp)
	popq %r15
	# LowerAlloca(1838:3): size = 4, type = i32*, var = ^115
	# Fixing source-to-dest leaq -4588(%rbp), -5992(%rbp)
	pushq %r15
	leaq -4588(%rbp), %r15
	movq %r15, -5992(%rbp)
	popq %r15
	# LowerAlloca(1839:3): size = 4, type = i32*, var = ^116
	# Fixing source-to-dest leaq -4592(%rbp), -6000(%rbp)
	pushq %r15
	leaq -4592(%rbp), %r15
	movq %r15, -6000(%rbp)
	popq %r15
	# LowerAlloca(1840:3): size = 4, type = i32*, var = ^117
	# Fixing source-to-dest leaq -4596(%rbp), -6008(%rbp)
	pushq %r15
	leaq -4596(%rbp), %r15
	movq %r15, -6008(%rbp)
	popq %r15
	# LowerAlloca(1841:3): size = 4, type = i32*, var = ^118
	# Fixing source-to-dest leaq -4600(%rbp), -6016(%rbp)
	pushq %r15
	leaq -4600(%rbp), %r15
	movq %r15, -6016(%rbp)
	popq %r15
	# LowerAlloca(1842:3): size = 32, type = [8 x i32]*, var = ^119
	# Fixing source-to-dest leaq -4640(%rbp), -5984(%rbp)
	pushq %r15
	leaq -4640(%rbp), %r15
	movq %r15, -5984(%rbp)
	popq %r15
	# LowerAlloca(1843:3): size = 2, type = %union.U1*, var = ^120
	# Fixing source-to-dest leaq -4642(%rbp), -5968(%rbp)
	pushq %r15
	leaq -4642(%rbp), %r15
	movq %r15, -5968(%rbp)
	popq %r15
	# LowerAlloca(1844:3): size = 4, type = i32*, var = ^121
	# Fixing source-to-dest leaq -4648(%rbp), -5976(%rbp)
	pushq %r15
	leaq -4648(%rbp), %r15
	movq %r15, -5976(%rbp)
	popq %r15
	# LowerAlloca(1845:3): size = 16, type = [8 x i16]*, var = ^122
	# Fixing source-to-dest leaq -4672(%rbp), -5904(%rbp)
	pushq %r15
	leaq -4672(%rbp), %r15
	movq %r15, -5904(%rbp)
	popq %r15
	# LowerAlloca(1846:3): size = 2, type = %union.U4*, var = ^123
	# Fixing source-to-dest leaq -4674(%rbp), -5920(%rbp)
	pushq %r15
	leaq -4674(%rbp), %r15
	movq %r15, -5920(%rbp)
	popq %r15
	# LowerAlloca(1847:3): size = 8, type = ptr*, var = ^124
	# Fixing source-to-dest leaq -4688(%rbp), -5944(%rbp)
	pushq %r15
	leaq -4688(%rbp), %r15
	movq %r15, -5944(%rbp)
	popq %r15
	# LowerAlloca(1848:3): size = 240, type = [6 x [5 x ptr]]*, var = ^125
	# Fixing source-to-dest leaq -4928(%rbp), -5936(%rbp)
	pushq %r15
	leaq -4928(%rbp), %r15
	movq %r15, -5936(%rbp)
	popq %r15
	# LowerAlloca(1849:3): size = 2, type = i16*, var = ^126
	# Fixing source-to-dest leaq -4930(%rbp), -5792(%rbp)
	pushq %r15
	leaq -4930(%rbp), %r15
	movq %r15, -5792(%rbp)
	popq %r15
	# LowerAlloca(1850:3): size = 8, type = ptr*, var = ^127
	# Fixing source-to-dest leaq -4944(%rbp), -5688(%rbp)
	pushq %r15
	leaq -4944(%rbp), %r15
	movq %r15, -5688(%rbp)
	popq %r15
	# LowerAlloca(1851:3): size = 4, type = i32*, var = ^128
	# Fixing source-to-dest leaq -4948(%rbp), -5912(%rbp)
	pushq %r15
	leaq -4948(%rbp), %r15
	movq %r15, -5912(%rbp)
	popq %r15
	# LowerAlloca(1852:3): size = 4, type = i32*, var = ^129
	leaq -4952(%rbp), %rax
	# LowerAlloca(1853:3): size = 4, type = i32*, var = ^130
	# Fixing source-to-dest leaq -4956(%rbp), -5824(%rbp)
	pushq %r15
	leaq -4956(%rbp), %r15
	movq %r15, -5824(%rbp)
	popq %r15
	# LowerAlloca(1854:3): size = 4, type = i32*, var = ^131
	# Fixing source-to-dest leaq -4960(%rbp), -5832(%rbp)
	pushq %r15
	leaq -4960(%rbp), %r15
	movq %r15, -5832(%rbp)
	popq %r15
	# LowerAlloca(1855:3): size = 4, type = i32*, var = ^132
	# Fixing source-to-dest leaq -4964(%rbp), -5840(%rbp)
	pushq %r15
	leaq -4964(%rbp), %r15
	movq %r15, -5840(%rbp)
	popq %r15
	# LowerAlloca(1856:3): size = 4, type = i32*, var = ^133
	# Fixing source-to-dest leaq -4968(%rbp), -5848(%rbp)
	pushq %r15
	leaq -4968(%rbp), %r15
	movq %r15, -5848(%rbp)
	popq %r15
	# LowerAlloca(1857:3): size = 4, type = i32*, var = ^134
	# Fixing source-to-dest leaq -4972(%rbp), -5856(%rbp)
	pushq %r15
	leaq -4972(%rbp), %r15
	movq %r15, -5856(%rbp)
	popq %r15
	# LowerAlloca(1858:3): size = 4, type = i32*, var = ^135
	# Fixing source-to-dest leaq -4976(%rbp), -5864(%rbp)
	pushq %r15
	leaq -4976(%rbp), %r15
	movq %r15, -5864(%rbp)
	popq %r15
	# LowerAlloca(1859:3): size = 32, type = [8 x i32]*, var = ^136
	# Fixing source-to-dest leaq -5008(%rbp), -5872(%rbp)
	pushq %r15
	leaq -5008(%rbp), %r15
	movq %r15, -5872(%rbp)
	popq %r15
	# LowerAlloca(1860:3): size = 320, type = [5 x [8 x ptr]]*, var = ^137
	# Fixing source-to-dest leaq -5328(%rbp), -5880(%rbp)
	pushq %r15
	leaq -5328(%rbp), %r15
	movq %r15, -5880(%rbp)
	popq %r15
	# LowerAlloca(1861:3): size = 4, type = i32*, var = ^138
	# Fixing source-to-dest leaq -5332(%rbp), -5888(%rbp)
	pushq %r15
	leaq -5332(%rbp), %r15
	movq %r15, -5888(%rbp)
	popq %r15
	# LowerAlloca(1862:3): size = 4, type = i32*, var = ^139
	leaq -5336(%rbp), %rax
	# LowerStore(1864:3).3: mov $imm, (^2)
	movq -5368(%rbp), %rax
	movl $-207668134, (%rax)
	# LowerStore(1866:3).3: mov $imm, (^3)
	movq -5784(%rbp), %rax
	movl $-1795190700, (%rax)
	# LowerStore(1868:3).3: mov $imm, (^4)
	movq -5440(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(1870:3).3: mov $imm, (^5)
	movq -5472(%rbp), %rax
	movl $-1689060711, (%rax)
	# LowerStore(1872:3).3: mov $imm, (^6)
	movq -5576(%rbp), %rax
	movl $1272617434, (%rax)
	# LowerStore(1874:3).6: load global
	leaq _ZL6g_2199(%rip), %rax
	# LowerStore(1874:3).9: mov ptr ^1184, (^7)
	movq %rax, (%rcx)
	# LowerStore(1876:3).9: mov ptr* ^7, (^8)
	movq -6136(%rbp), %rax
	movq %rcx, (%rax)
	# LowerStore(1878:3).3: mov $imm, (^9)
	movabsq $903025031038103379, %rcx
	movq -5592(%rbp), %rax
	movq %rcx, (%rax)
	# SetupCalls(1880:3): move argument ptr align 16 ^10
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1880:3): move argument ptr align 16 @__const._ZL6func_1v.l_2323
	leaq __const._ZL6func_1v.l_2323(%rip), %rsi
	# SetupCalls(1880:3): move argument i64 2016
	movq $2016, %rdx
	callq memcpy@PLT
	# LowerStore(1882:3).3: mov $imm, (^11)
	movq $0, (%r12)
	# LowerStore(1884:3).9: mov ptr* ^11, (^12)
	movq -5760(%rbp), %rax
	movq %r12, (%rax)
	# LowerStore(1886:3).6: load global
	leaq _ZL5g_313(%rip), %rbx
	# LowerStore(1886:3).9: mov ptr ^1185, (^13)
	movq -5352(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(1888:3).3: mov $imm, (^14)
	movq -5696(%rbp), %rax
	movq $0, (%rax)
	# SetupCalls(1890:3): move argument ptr align 2 ^15
	# Fixed movzx with identical source and destination widths
	movq -5360(%rbp), %rdi
	# SetupCalls(1890:3): move argument ptr align 2 @__const._ZL6func_1v.l_2419
	leaq __const._ZL6func_1v.l_2419(%rip), %rsi
	# SetupCalls(1890:3): move argument i64 8
	movq $8, %rdx
	callq memcpy@PLT
	# LowerStore(1892:3).3: mov $imm, (^16)
	movq -6304(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(1894:3).3: mov $imm, (^17)
	movq -5480(%rbp), %rax
	movw $1, (%rax)
	# LowerStore(1896:3).3: mov $imm, (^18)
	movq -6312(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(1898:3).3: mov $imm, (^19)
	movq -6320(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(1900:3).3: mov $imm, (^20)
	movq -6328(%rbp), %rax
	movl $594264973, (%rax)
	# LowerStore(1902:3).3: mov $imm, (^21)
	movl $0, (%r13)
	# LowerStore(1904:3).3: mov $imm, (^22)
	movq -5680(%rbp), %rax
	movl $-8, (%rax)
	# LowerStore(1906:3).3: mov $imm, (^23)
	movl $-1, (%r14)
	# LowerStore(1908:3).3: mov $imm, (^24)
	movq $0, (%r15)
	# LowerStore(1911:3).3: mov $imm, (^26)
	movq -5736(%rbp), %rax
	movl $-1576952829, (%rax)
	# LowerStore(1913:3).3: mov $imm, (^27)
	movabsq $5682451316754310983, %rbx
	movq -5744(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(1918:3).3: mov $imm, (^29)
	movq -6272(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M392:
	# LowerLoad(1922:3).2: (^29) into i32 ^141
	movq -6272(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1923:3): i32 ^141 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M399
	jmp .___ZL6func_1v__M465
	.___ZL6func_1v__M399:
	# LowerStore(1927:3).3: mov $imm, (^30)
	movq -6296(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M402:
	# LowerLoad(1931:3).2: (^30) into i32 ^145
	movq -6296(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1932:3): i32 ^145 vs. intlike 10
	cmpl $10, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M409
	jmp .___ZL6func_1v__M456
	.___ZL6func_1v__M409:
	# LowerLoad(1936:3).2: (^29) into i32 ^148
	movq -6272(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [1 x [10 x i64]]
	# LowerGetelementptr(1938:3): array/pointer-type, dynamic index -> ^150
	# index ^149 -> temp ^1166
	movq %rbx, %rdx
	# Multiply temp ^1166 by 80 start
	# Clobber %rdx
	movq %rdx, -6336(%rbp)
	movq %rdx, %rax
	movq $80, %rbx
	mulq %rbx
	# Unclobber %rdx
	movq -6336(%rbp), %rdx
	movq %rax, %rdx
	# Multiply end
	# temp ^1166 -> operand ^150
	movq %rdx, %rcx
	# Result ^150 += base pointer ^25
	addq -6280(%rbp), %rcx
	# LowerLoad(1939:3).2: (^30) into i32 ^151
	movq -6296(%rbp), %rax
	movl (%rax), %ebx
	movslq %ebx, %rax
	# tt = Pointer, type = [10 x i64]
	# LowerGetelementptr(1941:3): array/pointer-type, dynamic index -> ^153
	# index ^152 -> temp ^1168
	movq %rax, %rbx
	# Multiply temp ^1168 by 8 start
	shlq $3, %rbx
	# Multiply end
	# temp ^1168 -> operand ^153
	movq %rbx, %rax
	# Result ^153 += base pointer ^150
	addq %rcx, %rax
	# LowerStore(1942:3).3: mov $imm, (^153)
	movabsq $3399871360421987074, %rbx
	movq %rbx, (%rax)
	# LowerLoad(1946:3).2: (^30) into i32 ^155
	movq -6296(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(1947:3): ^155, 1 into i32 ^156
	addl $1, %eax
	# LowerStore(1948:3).9: mov i32 ^156, (^30)
	movq -6296(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M402
	.___ZL6func_1v__M456:
	# LowerLoad(1955:3).2: (^29) into i32 ^159
	movq -6272(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(1956:3): ^159, 1 into i32 ^160
	addl $1, %eax
	# LowerStore(1957:3).9: mov i32 ^160, (^29)
	movq -6272(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M392
	.___ZL6func_1v__M465:
	# LowerStore(1961:3).3: mov $imm, (^29)
	movq -6272(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M468:
	# LowerLoad(1965:3).2: (^29) into i32 ^163
	movq -6272(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1966:3): i32 ^163 vs. intlike 6
	cmpl $6, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M475
	jmp .___ZL6func_1v__M500
	.___ZL6func_1v__M475:
	# LowerLoad(1970:3).2: (^29) into i32 ^166
	movq -6272(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [6 x i32]
	# LowerGetelementptr(1972:3): array/pointer-type, dynamic index -> ^168
	# index ^167 -> temp ^1169
	movq %rbx, %rcx
	# Multiply temp ^1169 by 4 start
	shlq $2, %rcx
	# Multiply end
	# temp ^1169 -> operand ^168
	movq %rcx, %rax
	# Result ^168 += base pointer ^28
	addq -5728(%rbp), %rax
	# LowerStore(1973:3).3: mov $imm, (^168)
	movl $2087786319, (%rax)
	# LowerLoad(1977:3).2: (^29) into i32 ^170
	movq -6272(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(1978:3): ^170, 1 into i32 ^171
	addl $1, %eax
	# LowerStore(1979:3).9: mov i32 ^171, (^29)
	movq -6272(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M468
	.___ZL6func_1v__M500:
	# LowerStore(1983:3).2a: mov $imm, %temp
	movl $0, _ZL3g_2(%rip)
	# LowerStore(1983:3).2b: mov %temp, (global)
	.___ZL6func_1v__M505:
	# LowerLoad(1987:3).4: _ZL3g_2 into ^174
	movl _ZL3g_2(%rip), %eax
	# LowerIcmp(1988:3): i32 ^174 vs. intlike 7
	cmpl $7, %eax
	sete %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M512
	jmp .___ZL6func_1v__M682
	.___ZL6func_1v__M512:
	# LowerStore(1993:3).3: mov $imm, (^32)
	movq -6144(%rbp), %rax
	movw $-3, (%rax)
	# LowerStore(1995:3).3: mov $imm, (^33)
	movq -6152(%rbp), %rax
	movl $6, (%rax)
	# LowerStore(1997:3).3: mov $imm, (^34)
	movq -6160(%rbp), %rax
	movl $7, (%rax)
	leaq _ZL5g_149(%rip), %rax
	# tt = Pointer, type = [4 x [2 x %union.U2]]
	leaq _ZL5g_149(%rip), %rbx
	# LowerGetelementptr(1999:3): struct-type: [4 x [2 x %union.U2]] ^1083 -> ^1081, indices=0,3,1
	movq %rbx, %rax
	addq $48, %rax
	addq $8, %rax
	# LowerGetelementptr(1999:3): type of ^1081 is %union.U2*
	# LowerStore(1999:3).9: mov [4 x [2 x %union.U2]]* ^1081, (^35)
	movq -6168(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(2001:3).9: mov i32* ^34, (^36)
	movq -6176(%rbp), %rax
	# Fixing source-to-dest movq -6160(%rbp), (%rax)
	movq -6160(%rbp), %r15
	movq %r15, (%rax)
	leaq _ZL5g_422(%rip), %rax
	# tt = Pointer, type = [6 x i32]
	leaq _ZL5g_422(%rip), %rbx
	# LowerGetelementptr(2003:3): struct-type: [6 x i32] ^1086 -> ^1084, indices=0,1
	movq %rbx, %rax
	addq $4, %rax
	# LowerGetelementptr(2003:3): type of ^1084 is i32*
	# LowerStore(2003:3).9: mov [6 x i32]* ^1084, (^37)
	movq -6184(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(2005:3).9: mov i32* ^4, (^38)
	movq -6192(%rbp), %rax
	# Fixing source-to-dest movq -5440(%rbp), (%rax)
	movq -5440(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(2007:3).6: load global
	leaq _ZL5g_422(%rip), %rax
	# LowerStore(2007:3).9: mov ptr ^1187, (^39)
	movq -6200(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(2009:3).9: mov i32* ^34, (^40)
	movq -6208(%rbp), %rax
	# Fixing source-to-dest movq -6160(%rbp), (%rax)
	movq -6160(%rbp), %r15
	movq %r15, (%rax)
	# SetupCalls(2011:3): move argument ptr align 16 ^41
	# Fixed movzx with identical source and destination widths
	movq -6216(%rbp), %rdi
	# SetupCalls(2011:3): move argument ptr align 16 @__const._ZL6func_1v.l_2300
	leaq __const._ZL6func_1v.l_2300(%rip), %rsi
	# SetupCalls(2011:3): move argument i64 288
	movq $288, %rdx
	callq memcpy@PLT
	# LowerStore(2014:3).2a: mov $imm, %temp
	movl $12, _ZL3g_5(%rip)
	# LowerStore(2014:3).2b: mov %temp, (global)
	.___ZL6func_1v__M577:
	# LowerLoad(2018:3).4: _ZL3g_5 into ^178
	movl _ZL3g_5(%rip), %eax
	# LowerIcmp(2019:3): i32 ^178 vs. intlike -3
	cmpl $-3, %eax
	setge %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M584
	jmp .___ZL6func_1v__M652
	.___ZL6func_1v__M584:
	# LowerStore(2024:3).3: mov $imm, (^44)
	movq -6224(%rbp), %rax
	movw $30679, (%rax)
	# SetupCalls(2026:3): move argument ptr align 16 ^45
	# Fixed movzx with identical source and destination widths
	movq -6232(%rbp), %rdi
	# SetupCalls(2026:3): move argument ptr align 16 @__const._ZL6func_1v.l_1138
	leaq __const._ZL6func_1v.l_1138(%rip), %rsi
	# SetupCalls(2026:3): move argument i64 120
	movq $120, %rdx
	callq memcpy@PLT
	# LowerStore(2028:3).3: mov $imm, (^46)
	movq -6240(%rbp), %rax
	movw $-1, (%rax)
	# LowerStore(2030:3).3: mov $imm, (^47)
	movabsq $6970159599675675478, %rax
	movq -6248(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerLoad(2037:3).4: _ZL3g_5 into ^182
	movl _ZL3g_5(%rip), %eax
	movslq %eax, %rbx
	# SetupCalls(2039:3): move argument i64 ^183
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(2039:3): move argument i64 7
	movq $7, %rsi
	callq _ZL25safe_sub_func_int64_t_s_sll
	# SetupCalls(2039:3): move i64 result from %rax
	movq %rax, %rbx
	# LowerTrunc(2040:3): 64 to 32, move and clear upper bits
	movl %ebx, %eax
	# LowerStore(2041:3).8a: leaq var, %temp
	leaq _ZL3g_5(%rip), %rbx
	# LowerStore(2041:3).8b: movq ^185, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M577
	.___ZL6func_1v__M652:
	# LowerLoad(2045:3).4: _ZL5g_139 into ^187
	movq _ZL5g_139(%rip), %rax
	# LowerLoad(2046:3).2: (^187) into ptr ^188
	movq (%rax), %rbx
	# LowerLoad(2047:3).2: (^188) into i32 ^189
	movl (%rbx), %eax
	# LowerIcmp(2048:3): i32 ^189 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M663
	jmp .___ZL6func_1v__M664
	.___ZL6func_1v__M663:
	jmp .___ZL6func_1v__M682
	.___ZL6func_1v__M664:
	# LowerLoad(2055:3).2: (^6) into i32 ^193
	movq -5576(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(2056:3): ^193, 1 into i32 ^194
	addl $1, %eax
	# LowerStore(2057:3).9: mov i32 ^194, (^6)
	movq -5576(%rbp), %rbx
	movl %eax, (%rbx)
	# LowerLoad(2061:3).4: _ZL3g_2 into ^196
	movl _ZL3g_2(%rip), %eax
	# LowerMath(2062:3): ^196, 1 into i32 ^197
	addl $1, %eax
	# LowerStore(2063:3).8a: leaq var, %temp
	leaq _ZL3g_2(%rip), %rbx
	# LowerStore(2063:3).8b: movq ^197, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M505
	.___ZL6func_1v__M682:
	# LowerLoad(2067:3).2: (^5) into i32 ^199
	movq -5472(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %r12
	# LowerLoad(2069:3).2: (^2) into i32 ^201
	movq -5368(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(2070:3): i32 ^201 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M692
	jmp .___ZL6func_1v__M695
	.___ZL6func_1v__M692:
	# MovePhi: intlike -> ^234 (in new block 1246 whose parent is 198)
	movb $1, -6104(%rbp)
	jmp .___ZL6func_1v__M951
	.___ZL6func_1v__M695:
	# LowerLoad(2074:3).2: (^6) into i32 ^204
	movq -5576(%rbp), %rax
	movl (%rax), %r13d
	# LowerBasicConversion(2075:3): i32 ^204 -> i64 ^205
	# LowerLoad(2076:3).4: _ZL6g_1931 into ^206
	movl _ZL6g_1931(%rip), %r14d
	# LowerTrunc(2077:3): 32 to 8, move
	# LowerTrunc(2077:3): 32 to 8, apply mask
	andq $255, %r14
	# LowerLoad(2078:3).4: _ZL6g_2025 into ^208
	movq _ZL6g_2025(%rip), %rax
	# LowerLoad(2079:3).2: (^8) into ptr ^209
	movq -6136(%rbp), %rcx
	movq (%rcx), %rbx
	# LowerIcmp(2080:3): ptr ^208 vs. operand ptr ^209
	cmpq %rbx, %rax
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2081:3): ptr ^210 -> i8 ^211
	movb %al, %bl
	# LowerLoad(2082:3).2: (^5) into i32 ^212
	movq -5472(%rbp), %rcx
	movl (%rcx), %eax
	# LowerTrunc(2083:3): 32 to 8, move
	# LowerTrunc(2083:3): 32 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2084:3): move argument i8 zeroext ^211
	movzbq %bl, %rdi
	andq $255, %rdi
	# SetupCalls(2084:3): move argument i8 zeroext ^213
	movzbq %al, %rsi
	andq $255, %rsi
	callq _ZL25safe_mul_func_uint8_t_u_uhh
	# SetupCalls(2084:3): move i8 result from %rax
	movb %al, %bl
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerBasicConversion(2085:3): i8 ^214 -> i16 ^215
	movw %bx, %ax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerLoad(2086:3).2: (^9) into i64 ^216
	movq -5592(%rbp), %rcx
	movq (%rcx), %rbx
	# LowerTrunc(2087:3): 64 to 16, move
	# LowerTrunc(2087:3): 64 to 16, apply mask
	andq $65535, %rbx
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2088:3): move argument i16 zeroext ^215
	movzwq %ax, %rdi
	andq $65535, %rdi
	# SetupCalls(2088:3): move argument i16 zeroext ^217
	movzwq %bx, %rsi
	andq $65535, %rsi
	callq _ZL26safe_div_func_uint16_t_u_utt
	# SetupCalls(2088:3): move i16 result from %rax
	movw %ax, %bx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerBasicConversion(2089:3): i16 ^218 -> i32 ^219
	movl %ebx, %ecx
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(2090:3).2: (^2) into i32 ^220
	movq -5368(%rbp), %rbx
	movl (%rbx), %eax
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2091:3): move argument i32 ^219
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edi
	# SetupCalls(2091:3): move argument i32 ^220
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	callq _ZL26safe_add_func_uint32_t_u_ujj
	# SetupCalls(2091:3): move i32 result from %rax
	movl %eax, %ebx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerTrunc(2092:3): 32 to 16, move
	movw %bx, %ax
	# LowerTrunc(2092:3): 32 to 16, apply mask
	andq $65535, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2093:3): move argument i16 signext ^222
	movzwq %ax, %rdi
	movswq %di, %rdi
	# SetupCalls(2093:3): move argument i32 4
	movq $4, %rsi
	callq _ZL28safe_lshift_func_int16_t_s_usj
	# SetupCalls(2093:3): move i16 result from %rax
	movw %ax, %bx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerTrunc(2094:3): 16 to 8, move
	movb %bl, %al
	# LowerTrunc(2094:3): 16 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2095:3): move argument i8 zeroext ^207
	movzbq %r14b, %rdi
	andq $255, %rdi
	# SetupCalls(2095:3): move argument i8 zeroext ^224
	movzbq %al, %rsi
	andq $255, %rsi
	callq _ZL25safe_add_func_uint8_t_u_uhh
	# SetupCalls(2095:3): move i8 result from %rax
	movb %al, %al
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerIcmp(2096:3): i64 ^205 vs. intlike 7
	cmpq $7, %r13
	sete %al
	andq $1, %rax
	# LowerBasicConversion(2097:3): i64 ^226 -> i8 ^227
	movb %al, %bl
	# SetupCalls(2098:3): move argument i8 zeroext ^227
	movzbq %bl, %rdi
	andq $255, %rdi
	# SetupCalls(2098:3): move argument i32 1
	movq $1, %rsi
	callq _ZL28safe_lshift_func_uint8_t_u_shi
	# SetupCalls(2098:3): move i8 result from %rax
	movb %al, %bl
	# LowerLoad(2099:3).2: (^6) into i32 ^229
	movq -5576(%rbp), %rcx
	movl (%rcx), %eax
	# LowerTrunc(2100:3): 32 to 8, move
	# LowerTrunc(2100:3): 32 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2101:3): move argument i8 signext ^228
	movzbq %bl, %rdi
	movsbq %dil, %rdi
	# SetupCalls(2101:3): move argument i8 signext ^230
	movzbq %al, %rsi
	movsbq %sil, %rsi
	callq _ZL24safe_sub_func_int8_t_s_saa
	# SetupCalls(2101:3): move i8 result from %rax
	movb %al, %bl
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerIcmp(2102:3): i8 ^231 vs. intlike 0
	cmpb $0, %bl
	setne %al
	andq $1, %rax
	# MovePhi: ^232 -> ^234
	movb %al, -6104(%rbp)
	.___ZL6func_1v__M951:
	# LowerBasicConversion(2107:3): i1 ^234 -> i64 ^235
	movq -6104(%rbp), %rax
	# Truncate value to 8 bits
	andl $255, %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2108:3): move argument i64 7838281458710188276
	movabsq $7838281458710188276, %rbx
	movq %rbx, %rdi
	# SetupCalls(2108:3): move argument i64 ^235
	# Fixed movzx with identical source and destination widths
	movq %rax, %rsi
	callq _ZL26safe_add_func_uint64_t_u_umm
	# SetupCalls(2108:3): move i64 result from %rax
	movq %rax, %rbx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerIcmp(2109:3): i64 ^200 vs. operand i64 ^236
	cmpq %rbx, %r12
	setae %al
	andq $1, %rax
	# LowerBasicConversion(2110:3): i64 ^237 -> i32 ^238
	movl %eax, %ebx
	# LowerLoad(2111:3).2: (^3) into i32 ^239
	movq -5784(%rbp), %rcx
	movl (%rcx), %eax
	# LowerLogic(2113:3): ^239, ^238 into i32 ^240
	andl %ebx, %eax
	# LowerStore(2113:3).9: mov i32 ^240, (^3)
	movq -5784(%rbp), %rbx
	movl %eax, (%rbx)
	# LowerLoad(2114:3).4: _ZL6g_2324 into ^241
	movl _ZL6g_2324(%rip), %ebx
	# LowerLogic(2116:3): ^240, ^241 into i32 ^242
	movl %eax, %ecx
	orl %ebx, %ecx
	.___ZL6func_1v__M1000:
	# LowerStore(2120:3).3: mov $imm, (^51)
	movq -6032(%rbp), %rax
	movw $14316, (%rax)
	# LowerStore(2122:3).6: load global
	leaq _ZL5g_744(%rip), %rax
	# LowerStore(2122:3).9: mov ptr ^1191, (^52)
	movq -6024(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(2124:3).6: load global
	leaq _ZL5g_422(%rip), %rbx
	# LowerStore(2124:3).9: mov ptr ^1192, (^53)
	movq -5376(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2126:3).3: mov $imm, (^54)
	movq -5896(%rbp), %rax
	movw $-6, (%rax)
	# LowerStore(2128:3).6: load global
	leaq _ZL5g_837(%rip), %rbx
	# LowerStore(2128:3).9: mov ptr ^1193, (^55)
	movq -5392(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2130:3).3: mov $imm, (^56)
	movq -5808(%rbp), %rax
	movl $569081037, (%rax)
	# LowerStore(2132:3).6: load global
	leaq _ZL5g_338(%rip), %rbx
	# LowerStore(2132:3).9: mov ptr ^1194, (^57)
	movq -5672(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2134:3).6: load global
	leaq _ZL6g_1487(%rip), %rbx
	# LowerStore(2134:3).9: mov ptr ^1195, (^58)
	movq -5776(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2136:3).6: load global
	leaq _ZL6g_2175(%rip), %rbx
	# LowerStore(2136:3).9: mov ptr ^1196, (^59)
	movq -6088(%rbp), %rax
	movq %rbx, (%rax)
	# tt = Pointer, type = [3 x [2 x ptr]]
	# LowerGetelementptr(2138:3): struct-type: ptr ^60 -> ^244, indices=0,0
	movq -5752(%rbp), %rax
	# LowerGetelementptr(2138:3): type of ^244 is [2 x ptr]*
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2139:3): struct-type: ptr ^244 -> ^245, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(2139:3): type of ^245 is ptr*
	# LowerStore(2140:3).9: mov ptr* ^59, (^245)
	# Fixing source-to-dest movq -6088(%rbp), (%rbx)
	movq -6088(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(2141:3): struct-type: ptr ^245 -> ^246, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(2141:3): type of ^246 is ptr*
	# LowerStore(2142:3).9: mov ptr* ^59, (^246)
	# Fixing source-to-dest movq -6088(%rbp), (%rcx)
	movq -6088(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2143:3): struct-type: ptr ^244 -> ^247, indices=1
	movq %rax, %rbx
	addq $16, %rbx
	# LowerGetelementptr(2143:3): type of ^247 is [2 x ptr]*
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2144:3): struct-type: ptr ^247 -> ^248, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(2144:3): type of ^248 is ptr*
	# LowerStore(2145:3).9: mov ptr* ^59, (^248)
	# Fixing source-to-dest movq -6088(%rbp), (%rax)
	movq -6088(%rbp), %r15
	movq %r15, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(2146:3): struct-type: ptr ^248 -> ^249, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(2146:3): type of ^249 is ptr*
	# LowerStore(2147:3).9: mov ptr* ^59, (^249)
	# Fixing source-to-dest movq -6088(%rbp), (%rcx)
	movq -6088(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2148:3): struct-type: ptr ^247 -> ^250, indices=1
	movq %rbx, %rax
	addq $16, %rax
	# LowerGetelementptr(2148:3): type of ^250 is [2 x ptr]*
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2149:3): struct-type: ptr ^250 -> ^251, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(2149:3): type of ^251 is ptr*
	# LowerStore(2150:3).9: mov ptr* ^59, (^251)
	# Fixing source-to-dest movq -6088(%rbp), (%rbx)
	movq -6088(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(2151:3): struct-type: ptr ^251 -> ^252, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(2151:3): type of ^252 is ptr*
	# LowerStore(2152:3).9: mov ptr* ^59, (^252)
	# Fixing source-to-dest movq -6088(%rbp), (%rax)
	movq -6088(%rbp), %r15
	movq %r15, (%rax)
	# tt = Pointer, type = [6 x ptr]
	# LowerGetelementptr(2154:3): struct-type: ptr ^61 -> ^253, indices=0,0
	movq -6096(%rbp), %rbx
	# LowerGetelementptr(2154:3): type of ^253 is ptr*
	# tt = Pointer, type = [3 x [2 x ptr]]
	# LowerGetelementptr(2155:3): struct-type: ptr ^60 -> ^254, indices=0,1
	movq -5752(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(2155:3): type of ^254 is [2 x ptr]*
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2156:3): struct-type: ptr ^254 -> ^255, indices=0,0
	movq %rax, (%rbx)
	# LowerGetelementptr(2156:3): type of ^255 is ptr*
	# LowerStore(2157:3).9: mov [2 x ptr]* ^255, (^253)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(2158:3): struct-type: ptr ^253 -> ^256, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(2158:3): type of ^256 is ptr*
	# tt = Pointer, type = [3 x [2 x ptr]]
	# LowerGetelementptr(2159:3): struct-type: ptr ^60 -> ^257, indices=0,1
	movq -5752(%rbp), %rbx
	addq $16, %rbx
	# LowerGetelementptr(2159:3): type of ^257 is [2 x ptr]*
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2160:3): struct-type: ptr ^257 -> ^258, indices=0,0
	movq %rbx, (%rax)
	# LowerGetelementptr(2160:3): type of ^258 is ptr*
	# LowerStore(2161:3).9: mov [2 x ptr]* ^258, (^256)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(2162:3): struct-type: ptr ^256 -> ^259, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(2162:3): type of ^259 is ptr*
	# tt = Pointer, type = [3 x [2 x ptr]]
	# LowerGetelementptr(2163:3): struct-type: ptr ^60 -> ^260, indices=0,2
	movq -5752(%rbp), %rax
	addq $32, %rax
	# LowerGetelementptr(2163:3): type of ^260 is [2 x ptr]*
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2164:3): struct-type: ptr ^260 -> ^261, indices=0,0
	movq %rax, (%rbx)
	# LowerGetelementptr(2164:3): type of ^261 is ptr*
	# LowerStore(2165:3).9: mov [2 x ptr]* ^261, (^259)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(2166:3): struct-type: ptr ^259 -> ^262, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(2166:3): type of ^262 is ptr*
	# tt = Pointer, type = [3 x [2 x ptr]]
	# LowerGetelementptr(2167:3): struct-type: ptr ^60 -> ^263, indices=0,1
	movq -5752(%rbp), %rbx
	addq $16, %rbx
	# LowerGetelementptr(2167:3): type of ^263 is [2 x ptr]*
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2168:3): struct-type: ptr ^263 -> ^264, indices=0,0
	movq %rbx, (%rax)
	# LowerGetelementptr(2168:3): type of ^264 is ptr*
	# LowerStore(2169:3).9: mov [2 x ptr]* ^264, (^262)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(2170:3): struct-type: ptr ^262 -> ^265, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(2170:3): type of ^265 is ptr*
	# tt = Pointer, type = [3 x [2 x ptr]]
	# LowerGetelementptr(2171:3): struct-type: ptr ^60 -> ^266, indices=0,1
	movq -5752(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(2171:3): type of ^266 is [2 x ptr]*
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2172:3): struct-type: ptr ^266 -> ^267, indices=0,0
	movq %rax, (%rbx)
	# LowerGetelementptr(2172:3): type of ^267 is ptr*
	# LowerStore(2173:3).9: mov [2 x ptr]* ^267, (^265)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(2174:3): struct-type: ptr ^265 -> ^268, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(2174:3): type of ^268 is ptr*
	# tt = Pointer, type = [3 x [2 x ptr]]
	# LowerGetelementptr(2175:3): struct-type: ptr ^60 -> ^269, indices=0,2
	movq -5752(%rbp), %rbx
	addq $32, %rbx
	# LowerGetelementptr(2175:3): type of ^269 is [2 x ptr]*
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2176:3): struct-type: ptr ^269 -> ^270, indices=0,0
	movq %rbx, (%rax)
	# LowerGetelementptr(2176:3): type of ^270 is ptr*
	# LowerStore(2177:3).9: mov [2 x ptr]* ^270, (^268)
	# LowerStore(2179:3).6: load global
	leaq _ZL6g_1117(%rip), %rbx
	# LowerStore(2179:3).9: mov ptr ^1197, (^62)
	movq -5584(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2181:3).3: mov $imm, (^63)
	movq -6048(%rbp), %rax
	movl $252273539, (%rax)
	# LowerStore(2183:3).3: mov $imm, (^64)
	movq -6056(%rbp), %rax
	movl $-1732997855, (%rax)
	# LowerStore(2185:3).3: mov $imm, (^65)
	movq -6064(%rbp), %rax
	movl $-638229174, (%rax)
	# LowerStore(2187:3).3: mov $imm, (^66)
	movq -6072(%rbp), %rax
	movl $-1478310357, (%rax)
	# LowerStore(2189:3).3: mov $imm, (^67)
	movq -6080(%rbp), %rax
	movl $-1343789299, (%rax)
	# LowerLoad(2192:3).4: _ZL3g_5 into ^271
	movl _ZL3g_5(%rip), %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2193:3): move argument ptr @.str.128
	leaq .str.128(%rip), %rdi
	# SetupCalls(2193:3): move argument i32 ^271
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(2193:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerLoad(2194:3).4: _ZL6g_1946 into ^273
	movl _ZL6g_1946(%rip), %eax
	# LowerTrunc(2195:3): 32 to 16, move
	# LowerTrunc(2195:3): 32 to 16, apply mask
	andq $65535, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2196:3): move argument i16 zeroext ^274
	movzwq %ax, %rdi
	andq $65535, %rdi
	# SetupCalls(2196:3): move argument i32 7
	movq $7, %rsi
	callq _ZL29safe_rshift_func_uint16_t_u_sti
	# SetupCalls(2196:3): move i16 result from %rax
	movw %ax, %bx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerBasicConversion(2197:3): i16 ^275 -> i32 ^276
	movl %ebx, %ecx
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(2198:3).2: (^51) into i16 ^277
	movq -6032(%rbp), %rbx
	movw (%rbx), %ax
	movswl %ax, %ebx
	# LowerIcmp(2200:3): i32 ^276 vs. operand i32 ^278
	cmpl %ebx, %ecx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2201:3): i32 ^279 -> i32 ^280
	movl %eax, %ebx
	# LowerLoad(2202:3).4: _ZL6g_1680 into ^281
	movq _ZL6g_1680(%rip), %rax
	# LowerLoad(2203:3).2: (^281) into ptr ^282
	movq (%rax), %rcx
	# LowerLoad(2204:3).2: (^282) into ptr ^283
	movq (%rcx), %rax
	# LowerLoad(2205:3).2: (^283) into ptr ^284
	movq (%rax), %rcx
	# LowerLoad(2206:3).2: (^284) into i32 ^285
	movl (%rcx), %eax
	# LowerLoad(2207:3).2: (^4) into i32 ^286
	movq -5440(%rbp), %rdx
	movl (%rdx), %ecx
	# LowerLogic(2209:3): ^286, ^285 into i32 ^287
	andl %eax, %ecx
	# LowerStore(2209:3).9: mov i32 ^287, (^4)
	movq -5440(%rbp), %rax
	movl %ecx, (%rax)
	movslq %ecx, %rax
	# LowerLogic(2212:3): -2, ^288 into i64 ^289
	movq $-2, %rcx
	andq %rax, %rcx
	# LowerTrunc(2212:3): 64 to 16, move
	movw %cx, %ax
	# LowerTrunc(2212:3): 64 to 16, apply mask
	andq $65535, %rax
	# LowerLoad(2213:3).2: (^52) into ptr ^291
	movq -6024(%rbp), %rdx
	movq (%rdx), %rcx
	# LowerStore(2214:3).3: mov $imm, (^291)
	movw $24035, (%rcx)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2215:3): move argument i16 zeroext ^290
	movzwq %ax, %rdi
	andq $65535, %rdi
	# SetupCalls(2215:3): move argument i16 zeroext 24035
	movq $24035, %rsi
	andq $65535, %rsi
	callq _ZL26safe_mul_func_uint16_t_u_utt
	# SetupCalls(2215:3): move i16 result from %rax
	movw %ax, %r12w
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerBasicConversion(2216:3): i16 ^292 -> i64 ^293
	movq %r12, %rcx
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(2217:3).4: _ZL6g_1899 into ^294
	movl _ZL6g_1899(%rip), %edx
	# LowerBasicConversion(2218:3): i32 ^294 -> i64 ^295
	# LowerStore(2219:3).8a: leaq var, %temp
	leaq _ZL6g_1221(%rip), %rax
	# LowerStore(2219:3).8b: movq ^295, (%temp)
	movq %rdx, (%rax)
	# LowerLoad(2220:3).2: (^53) into ptr ^296
	movq -5376(%rbp), %rax
	movq (%rax), %rsi
	movq $0, %rax
	# LowerIcmp(2221:3): i64 ^1158 vs. operand ptr ^296
	cmpq %rsi, %rax
	sete %al
	andq $1, %rax
	# LowerBasicConversion(2222:3): ptr ^297 -> i64 ^298
	movq %rax, %rsi
	# LowerIcmp(2223:3): i64 ^295 vs. operand i64 ^298
	cmpq %rsi, %rdx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2224:3): i64 ^299 -> i64 ^300
	movq %rax, %rdx
	# LowerLogic(2226:3): ^300, 29 into i64 ^301
	orq $29, %rdx
	# LowerLogic(2227:3): ^293, ^301 into i64 ^302
	movq %rcx, %rax
	andq %rdx, %rax
	# LowerIcmp(2227:3): i64 ^302 vs. intlike 1
	cmpq $1, %rax
	sete %al
	andq $1, %rax
	# LowerBasicConversion(2228:3): i64 ^303 -> i32 ^304
	movl %eax, %ecx
	# LowerLogic(2230:3): ^280, ^304 into i32 ^305
	movl %ebx, %eax
	xorl %ecx, %eax
	# LowerLoad(2230:3).4: _ZL5g_139 into ^306
	movq _ZL5g_139(%rip), %rbx
	# LowerLoad(2231:3).2: (^306) into ptr ^307
	movq (%rbx), %rcx
	# LowerLoad(2232:3).2: (^307) into i32 ^308
	movl (%rcx), %ebx
	# LowerLogic(2234:3): ^308, ^305 into i32 ^309
	andl %eax, %ebx
	# LowerStore(2234:3).9: mov i32 ^309, (^307)
	movl %ebx, (%rcx)
	# LowerLoad(2235:3).4: _ZL3g_5 into ^310
	movl _ZL3g_5(%rip), %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2236:3): move argument ptr @.str.129
	leaq .str.129(%rip), %rdi
	# SetupCalls(2236:3): move argument i32 ^310
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(2236:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerLoad(2237:3).2: (^53) into ptr ^312
	movq -5376(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(2238:3).2: (^312) into i32 ^313
	movl (%rbx), %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2239:3): move argument i32 ^313
	# Fixed movzx with 32-bit source operand
	movl %eax, %edi
	# SetupCalls(2239:3): move argument i32 28
	movq $28, %rsi
	callq _ZL29safe_rshift_func_uint32_t_u_sji
	# SetupCalls(2239:3): move i32 result from %rax
	movl %eax, %ebx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# SetupCalls(2240:3): move argument i32 ^314
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edi
	# SetupCalls(2240:3): move argument i32 1
	movq $1, %rsi
	callq _ZL29safe_rshift_func_uint32_t_u_sji
	# SetupCalls(2240:3): move i32 result from %rax
	movl %eax, %ebx
	# LowerBasicConversion(2241:3): i32 ^315 -> i64 ^316
	movq %rbx, %rax
	leaq _ZL6g_1944(%rip), %rbx
	# tt = Pointer, type = [10 x i32]
	leaq _ZL6g_1944(%rip), %rbx
	# LowerGetelementptr(2242:3): struct-type: [10 x i32] ^1089 -> ^1087, indices=0,9
	movq %rbx, %rcx
	addq $36, %rcx
	# LowerGetelementptr(2242:3): type of ^1087 is i32*
	# LowerLoad(2242:3).2: (^1087) into i32 ^317
	movl (%rcx), %ebx
	# LowerBasicConversion(2243:3): i32 ^317 -> i64 ^318
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2244:3): move argument i64 ^316
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(2244:3): move argument i64 ^318
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rsi
	callq _ZL26safe_mul_func_uint64_t_u_umm
	# SetupCalls(2244:3): move i64 result from %rax
	movq %rax, %rax
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerLoad(2245:3).4: _ZL5g_422 into ^320
	movl _ZL5g_422(%rip), %ebx
	# LowerTrunc(2246:3): 32 to 16, move
	# LowerTrunc(2246:3): 32 to 16, apply mask
	andq $65535, %rbx
	# SetupCalls(2247:3): move argument i64 0
	movq $0, %rdi
	callq _ZL32safe_unary_minus_func_uint64_t_um
	# SetupCalls(2247:3): move i64 result from %rax
	movq %rax, %r12
	# LowerTrunc(2248:3): 64 to 16, move
	movw %r12w, %ax
	# LowerTrunc(2248:3): 64 to 16, apply mask
	andq $65535, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2249:3): move argument i16 signext ^323
	movzwq %ax, %rdi
	movswq %di, %rdi
	callq _ZL31safe_unary_minus_func_int16_t_ss
	# SetupCalls(2249:3): move i16 result from %rax
	movw %ax, %r12w
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerTrunc(2250:3): 16 to 8, move
	movb %r12b, %r13b
	# LowerTrunc(2250:3): 16 to 8, apply mask
	andq $255, %r13
	leaq _ZL6g_1922(%rip), %rax
	# tt = Pointer, type = [4 x [9 x i32]]
	leaq _ZL6g_1922(%rip), %rax
	# LowerGetelementptr(2251:3): struct-type: [4 x [9 x i32]] ^1092 -> ^1090, indices=0,1,5
	movq %rax, %rcx
	addq $36, %rcx
	addq $20, %rcx
	# LowerGetelementptr(2251:3): type of ^1090 is i32*
	# LowerLoad(2251:3).2: (^1090) into i32 ^326
	movl (%rcx), %eax
	# LowerBasicConversion(2252:3): i32 ^326 -> i64 ^327
	# LowerLogic(2254:3): -3, ^327 into i64 ^328
	movq $-3, %r12
	orq %rax, %r12
	# LowerLoad(2254:3).2: (^53) into ptr ^329
	movq -5376(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2255:3).2: (^329) into i32 ^330
	movl (%rcx), %eax
	# LowerTrunc(2256:3): 32 to 16, move
	# LowerTrunc(2256:3): 32 to 16, apply mask
	andq $65535, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2257:3): move argument i16 zeroext ^331
	movzwq %ax, %rdi
	andq $65535, %rdi
	# SetupCalls(2257:3): move argument i16 zeroext -12655
	movq $-12655, %rsi
	andq $65535, %rsi
	callq _ZL26safe_sub_func_uint16_t_u_utt
	# SetupCalls(2257:3): move i16 result from %rax
	movw %ax, %r14w
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerBasicConversion(2258:3): i16 ^332 -> i64 ^333
	movq %r14, %rax
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLogic(2260:3): ^328, ^333 into i64 ^334
	movq %r12, %rcx
	xorq %rax, %rcx
	# LowerTrunc(2260:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(2260:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2261:3): move argument i8 signext ^325
	movzbq %r13b, %rdi
	movsbq %dil, %rdi
	# SetupCalls(2261:3): move argument i8 signext ^335
	movzbq %al, %rsi
	movsbq %sil, %rsi
	callq _ZL24safe_sub_func_int8_t_s_saa
	# SetupCalls(2261:3): move i8 result from %rax
	movb %al, %al
	# Unclobber %rax
	movq -6344(%rbp), %rax
	leaq _ZL6g_1892(%rip), %rax
	# tt = Pointer, type = [5 x i32]
	leaq _ZL6g_1892(%rip), %rcx
	# LowerGetelementptr(2262:3): struct-type: [5 x i32] ^1095 -> ^1093, indices=0,3
	movq %rcx, %rax
	addq $12, %rax
	# LowerGetelementptr(2262:3): type of ^1093 is i32*
	# LowerLoad(2262:3).2: (^1093) into i32 ^337
	movl (%rax), %ecx
	# LowerLoad(2263:3).2: (^2) into i32 ^338
	movq -5368(%rbp), %rax
	movl (%rax), %edx
	# LowerIcmp(2264:3): i32 ^337 vs. operand i32 ^338
	cmpl %edx, %ecx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2265:3): i32 ^339 -> i64 ^340
	movq %rax, %rcx
	# LowerStore(2266:3).8a: leaq var, %temp
	leaq _ZL6g_1221(%rip), %rax
	# LowerStore(2266:3).8b: movq ^340, (%temp)
	movq %rcx, (%rax)
	# LowerLoad(2267:3).2: (^3) into i32 ^341
	movq -5784(%rbp), %rdx
	movl (%rdx), %eax
	movslq %eax, %rdx
	# Clobber %rdx
	movq %rdx, -6336(%rbp)
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(2269:3): move argument i64 ^340
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(2269:3): move argument i64 ^342
	# Fixed movzx with identical source and destination widths
	movq %rdx, %rsi
	callq _ZL25safe_sub_func_int64_t_s_sll
	# SetupCalls(2269:3): move i64 result from %rax
	movq %rax, %r12
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# Unclobber %rdx
	movq -6336(%rbp), %rdx
	# LowerIcmp(2270:3): i64 ^343 vs. intlike 0
	cmpq $0, %r12
	setne %al
	andq $1, %rax
	# LowerLogic(2272:3): ^344, true into i1 ^345
	movb %al, %cl
	xorb $1, %cl
	# LowerLoad(2272:3).4: _ZL5g_150 into ^346
	movq _ZL5g_150(%rip), %rax
	# LowerLoad(2273:3).2: (^53) into ptr ^347
	movq -5376(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2274:3).2: (^347) into i32 ^348
	movl (%rcx), %eax
	# LowerIcmp(2275:3): i32 ^348 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M1718
	jmp .___ZL6func_1v__M1721
	.___ZL6func_1v__M1718:
	# MovePhi: intlike -> ^354 (in new block 1247 whose parent is 1129)
	movb $1, %cl
	jmp .___ZL6func_1v__M1730
	.___ZL6func_1v__M1721:
	# LowerLoad(2279:3).2: (^54) into i16 ^351
	movq -5896(%rbp), %rcx
	movw (%rcx), %ax
	# LowerIcmp(2280:3): i16 ^351 vs. intlike 0
	cmpw $0, %ax
	setne %al
	andq $1, %rax
	# MovePhi: ^352 -> ^354
	movb %al, %cl
	.___ZL6func_1v__M1730:
	# LowerLoad(2285:3).2: (^6) into i32 ^355
	movq -5576(%rbp), %rax
	movl (%rax), %ecx
	# LowerLoad(2286:3).2: (^53) into ptr ^356
	movq -5376(%rbp), %rax
	movq (%rax), %rdx
	# LowerLoad(2287:3).2: (^356) into i32 ^357
	movl (%rdx), %eax
	# LowerIcmp(2288:3): i32 ^355 vs. operand i32 ^357
	cmpl %eax, %ecx
	setbe %al
	andq $1, %rax
	# LowerBasicConversion(2289:3): i32 ^358 -> i16 ^359
	movw %ax, %cx
	# LowerLoad(2290:3).2: (^55) into ptr ^360
	movq -5392(%rbp), %rdx
	movq (%rdx), %rax
	# LowerStore(2291:3).9: mov i16 ^359, (^360)
	movw %cx, (%rax)
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(2292:3): move argument i16 zeroext ^321
	movzwq %bx, %rdi
	andq $65535, %rdi
	# SetupCalls(2292:3): move argument i16 zeroext ^359
	movzwq %cx, %rsi
	andq $65535, %rsi
	callq _ZL26safe_sub_func_uint16_t_u_utt
	# SetupCalls(2292:3): move i16 result from %rax
	movw %ax, %bx
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerBasicConversion(2293:3): i16 ^361 -> i64 ^362
	movq %rbx, %rax
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerIcmp(2294:3): i64 ^362 vs. intlike 59803
	cmpq $59803, %rax
	setl %al
	andq $1, %rax
	# LowerBasicConversion(2295:3): i64 ^363 -> i32 ^364
	movl %eax, %ebx
	# SetupCalls(2296:3): move argument ptr align 4 ^70
	# Fixed movzx with identical source and destination widths
	movq -5816(%rbp), %rdi
	# SetupCalls(2296:3): move argument ptr align 4 ^56
	# Fixed movzx with identical source and destination widths
	movq -5808(%rbp), %rsi
	# SetupCalls(2296:3): move argument i64 4
	movq $4, %rdx
	callq memcpy@PLT
	leaq _ZL6g_1892(%rip), %rax
	# tt = Pointer, type = [5 x i32]
	leaq _ZL6g_1892(%rip), %rax
	# LowerGetelementptr(2297:3): struct-type: [5 x i32] ^1098 -> ^1096, indices=0,1
	movq %rax, %rcx
	addq $4, %rcx
	# LowerGetelementptr(2297:3): type of ^1096 is i32*
	# LowerLoad(2297:3).2: (^1096) into i32 ^365
	movl (%rcx), %eax
	# tt = Pointer, type = %union.U0
	# LowerGetelementptr(2298:3): struct-type: ptr ^70 -> ^366, indices=0,0
	movq -5816(%rbp), %rcx
	# LowerGetelementptr(2298:3): type of ^366 is i32*
	# LowerLoad(2299:3).2: (^366) into i32 ^367
	movl (%rcx), %edx
	# Clobber %rdx
	movq %rdx, -6336(%rbp)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2300:3): move argument i32 ^364
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edi
	# SetupCalls(2300:3): move argument i32 ^367
	# Fixed movzx with 32-bit source operand
	movl %edx, %esi
	# SetupCalls(2300:3): move argument i32 ^365
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL7func_39i2U0j
	# SetupCalls(2300:3): move i16 result from %rax
	movw %ax, %bx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# Unclobber %rdx
	movq -6336(%rbp), %rdx
	# tt = Pointer, type = %union.U1
	# LowerGetelementptr(2301:3): struct-type: ptr ^71 -> ^369, indices=0,0
	movq -5800(%rbp), %rax
	# LowerGetelementptr(2301:3): type of ^369 is i16*
	# LowerStore(2302:3).9: mov i16 ^368, (^369)
	movw %bx, (%rax)
	# LowerLoad(2303:3).4: _ZL6g_2354 into ^370
	movl _ZL6g_2354(%rip), %ebx
	# LowerLoad(2304:3).2: (^53) into ptr ^371
	movq -5376(%rbp), %rax
	movq (%rax), %rcx
	# LowerStore(2305:3).9: mov i32 ^370, (^371)
	movl %ebx, (%rcx)
	# LowerStore(2306:3).2a: mov $imm, %temp
	movw $0, _ZL5g_106(%rip)
	# LowerStore(2306:3).2b: mov %temp, (global)
	.___ZL6func_1v__M1868:
	# LowerLoad(2310:3).4: _ZL5g_106 into ^373
	movw _ZL5g_106(%rip), %ax
	# LowerBasicConversion(2311:3): i16 ^373 -> i32 ^374
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerIcmp(2312:3): i32 ^374 vs. intlike 31
	cmpl $31, %eax
	setg %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M1879
	jmp .___ZL6func_1v__M1896
	.___ZL6func_1v__M1879:
	# LowerLoad(2316:3).2: (^53) into ptr ^377
	movq -5376(%rbp), %rax
	movq (%rax), %rbx
	# LowerStore(2317:3).8a: leaq var, %temp
	leaq _ZL6g_2357(%rip), %rax
	# LowerStore(2317:3).8b: movq ^377, (%temp)
	movq %rbx, (%rax)
	# LowerLoad(2321:3).4: _ZL5g_106 into ^379
	movw _ZL5g_106(%rip), %ax
	# LowerMath(2322:3): ^379, 1 into i16 ^380
	addw $1, %ax
	# LowerStore(2323:3).8a: leaq var, %temp
	leaq _ZL5g_106(%rip), %rbx
	# LowerStore(2323:3).8b: movq ^380, (%temp)
	movw %ax, (%rbx)
	jmp .___ZL6func_1v__M1868
	.___ZL6func_1v__M1896:
	# LowerLoad(2327:3).2: (^3) into i32 ^382
	movq -5784(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerLoad(2329:3).4: _ZL6g_2364 into ^384
	movq _ZL6g_2364(%rip), %r12
	# LowerLoad(2330:3).4: _ZL6g_1910 into ^385
	movl _ZL6g_1910(%rip), %r13d
	# LowerLoad(2331:3).2: (^53) into ptr ^386
	movq -5376(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2332:3).2: (^386) into i32 ^387
	movl (%rcx), %eax
	movslq %eax, %rcx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(2334:3): move argument i64 5063416666836942707
	movabsq $5063416666836942707, %rax
	movq %rax, %rdi
	# SetupCalls(2334:3): move argument i64 ^388
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rsi
	callq _ZL26safe_mul_func_uint64_t_u_umm
	# SetupCalls(2334:3): move i64 result from %rax
	movq %rax, %r14
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerIcmp(2335:3): i64 ^389 vs. intlike 0
	cmpq $0, %r14
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M1939
	jmp .___ZL6func_1v__M1942
	.___ZL6func_1v__M1939:
	# MovePhi: intlike -> ^415 (in new block 1248 whose parent is 381)
	movb $1, %al
	jmp .___ZL6func_1v__M2042
	.___ZL6func_1v__M1942:
	leaq _ZL6g_1922(%rip), %rax
	# tt = Pointer, type = [4 x [9 x i32]]
	leaq _ZL6g_1922(%rip), %rax
	# LowerGetelementptr(2339:3): struct-type: [4 x [9 x i32]] ^1101 -> ^1099, indices=0,3,1
	movq %rax, %rcx
	addq $108, %rcx
	addq $4, %rcx
	# LowerGetelementptr(2339:3): type of ^1099 is i32*
	# LowerLoad(2339:3).2: (^1099) into i32 ^392
	movl (%rcx), %eax
	# LowerBasicConversion(2340:3): i32 ^392 -> i64 ^393
	# LowerLoad(2341:3).2: (^12) into ptr ^394
	movq -5760(%rbp), %rdx
	movq (%rdx), %rcx
	movq $0, %rdx
	# LowerIcmp(2342:3): i64 ^1159 vs. operand ptr ^394
	cmpq %rcx, %rdx
	setne %cl
	andq $1, %rcx
	# LowerBasicConversion(2343:3): ptr ^395 -> i64 ^396
	movq %rcx, %rdx
	# Clobber %rdx
	movq %rdx, -6336(%rbp)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2344:3): move argument i64 ^393
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(2344:3): move argument i64 ^396
	# Fixed movzx with identical source and destination widths
	movq %rdx, %rsi
	callq _ZL26safe_add_func_uint64_t_u_umm
	# SetupCalls(2344:3): move i64 result from %rax
	movq %rax, %r14
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# Unclobber %rdx
	movq -6336(%rbp), %rdx
	movq $-1, %rax
	# LowerIcmp(2345:3): i64 ^1160 vs. operand i64 ^397
	cmpq %r14, %rax
	setae %al
	andq $1, %rax
	# LowerBasicConversion(2346:3): i64 ^398 -> i32 ^399
	movl %eax, %ecx
	# LowerLoad(2347:3).4: _ZL6g_1907 into ^400
	movl _ZL6g_1907(%rip), %eax
	# LowerIcmp(2348:3): i32 ^399 vs. operand i32 ^400
	cmpl %eax, %ecx
	setb %al
	andq $1, %rax
	# LowerLogic(2350:3): ^401, true into i1 ^402
	movb %al, %cl
	xorb $1, %cl
	# LowerBasicConversion(2350:3): i1 ^402 -> i64 ^403
	movq %rcx, %rax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerIcmp(2351:3): i64 ^403 vs. intlike -1
	cmpq $-1, %rax
	sete %al
	andq $1, %rax
	# LowerBasicConversion(2352:3): i64 ^404 -> i64 ^405
	movq %rax, %rcx
	# LowerLogic(2354:3): ^405, 238 into i64 ^406
	orq $238, %rcx
	# LowerLoad(2354:3).2: (^57) into ptr ^407
	movq -5672(%rbp), %rdx
	movq (%rdx), %rax
	# LowerStore(2355:3).9: mov i64 ^406, (^407)
	movq %rcx, (%rax)
	# LowerLoad(2356:3).2: (^58) into ptr ^408
	movq -5776(%rbp), %rax
	movq (%rax), %rdx
	# LowerLoad(2357:3).2: (^408) into i64 ^409
	movq (%rdx), %rax
	# LowerLogic(2359:3): ^409, ^406 into i64 ^410
	xorq %rcx, %rax
	# LowerStore(2359:3).9: mov i64 ^410, (^408)
	movq %rax, (%rdx)
	# LowerLoad(2360:3).2: (^13) into ptr ^411
	movq -5352(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2361:3).2: (^13) into ptr ^412
	movq -5352(%rbp), %rax
	movq (%rax), %rdx
	# LowerIcmp(2362:3): ptr ^411 vs. operand ptr ^412
	cmpq %rdx, %rcx
	sete %al
	andq $1, %rax
	# MovePhi: intlike -> ^415
	movb $1, %al
	.___ZL6func_1v__M2042:
	# LowerLoad(2367:3).2: (^53) into ptr ^416
	movq -5376(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2368:3).2: (^416) into i32 ^417
	movl (%rcx), %eax
	# LowerLogic(2370:3): ^385, ^417 into i32 ^418
	movl %r13d, %ecx
	andl %eax, %ecx
	# LowerLoad(2370:3).4: _ZL4g_91 into ^419
	movb _ZL4g_91(%rip), %al
	# LowerBasicConversion(2371:3): i8 ^419 -> i64 ^420
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerLoad(2372:3).4: _ZL6g_1943 into ^421
	movl _ZL6g_1943(%rip), %ecx
	# LowerBasicConversion(2373:3): i32 ^421 -> i64 ^422
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2374:3): move argument i64 ^420
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(2374:3): move argument i64 ^422
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rsi
	callq _ZL26safe_mod_func_uint64_t_u_umm
	# SetupCalls(2374:3): move i64 result from %rax
	movq %rax, %r13
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerLoad(2375:3).2: (^53) into ptr ^424
	movq -5376(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2376:3).2: (^424) into i32 ^425
	movl (%rcx), %eax
	movslq %eax, %rcx
	# LowerIcmp(2378:3): i64 ^423 vs. operand i64 ^426
	cmpq %rcx, %r13
	setae %al
	andq $1, %rax
	# tt = Pointer, type = [3 x [2 x ptr]]
	# LowerGetelementptr(2379:3): struct-type: ptr ^60 -> ^428, indices=0,2
	movq -5752(%rbp), %rax
	addq $32, %rax
	# LowerGetelementptr(2379:3): type of ^428 is [2 x ptr]*
	# tt = Pointer, type = [2 x ptr]
	# LowerGetelementptr(2380:3): struct-type: ptr ^428 -> ^429, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(2380:3): type of ^429 is ptr*
	# LowerLoad(2381:3).2: (^429) into ptr ^430
	movq (%rcx), %rax
	# LowerStore(2382:3).9: mov ptr ^430, (^14)
	movq -5696(%rbp), %rcx
	movq %rax, (%rcx)
	# LowerIcmp(2383:3): ptr ^384 vs. operand ptr ^430
	cmpq %rax, %r12
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2384:3): ptr ^431 -> i32 ^432
	movl %eax, %r12d
	# LowerLogic(2386:3): ^432, -275451831 into i32 ^433
	xorl $-275451831, %r12d
	# SetupCalls(2386:3): move argument ptr align 4 ^72
	# Fixed movzx with identical source and destination widths
	movq -5720(%rbp), %rdi
	# SetupCalls(2386:3): move argument ptr align 4 ^2
	# Fixed movzx with identical source and destination widths
	movq -5368(%rbp), %rsi
	# SetupCalls(2386:3): move argument i64 4
	movq $4, %rdx
	callq memcpy@PLT
	# LowerLoad(2387:3).2: (^4) into i32 ^434
	movq -5440(%rbp), %rcx
	movl (%rcx), %eax
	# tt = Pointer, type = %union.U0
	# LowerGetelementptr(2388:3): struct-type: ptr ^72 -> ^435, indices=0,0
	movq -5720(%rbp), %rcx
	# LowerGetelementptr(2388:3): type of ^435 is i32*
	# LowerLoad(2389:3).2: (^435) into i32 ^436
	movl (%rcx), %edx
	# Clobber %rdx
	movq %rdx, -6336(%rbp)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2390:3): move argument i32 ^433
	# Fixed movzx with 32-bit source operand
	movl %r12d, %edi
	# SetupCalls(2390:3): move argument i32 ^436
	# Fixed movzx with 32-bit source operand
	movl %edx, %esi
	# SetupCalls(2390:3): move argument i32 ^434
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq _ZL7func_39i2U0j
	# SetupCalls(2390:3): move i16 result from %rax
	movw %ax, %r12w
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# Unclobber %rdx
	movq -6336(%rbp), %rdx
	# tt = Pointer, type = %union.U1
	# LowerGetelementptr(2391:3): struct-type: ptr ^73 -> ^438, indices=0,0
	movq -5704(%rbp), %rax
	# LowerGetelementptr(2391:3): type of ^438 is i16*
	# LowerStore(2392:3).9: mov i16 ^437, (^438)
	movw %r12w, (%rax)
	# LowerLoad(2393:3).2: (^4) into i32 ^439
	movq -5440(%rbp), %rcx
	movl (%rcx), %eax
	# LowerIcmp(2394:3): i32 ^439 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M2192
	.___ZL6func_1v__M2189:
	# MovePhi: intlike -> ^443 (in new block 1249 whose parent is 1132)
	movb $0, -5632(%rbp)
	jmp .___ZL6func_1v__M2195
	.___ZL6func_1v__M2192:
	# MovePhi: intlike -> ^443
	movb $1, -5632(%rbp)
	.___ZL6func_1v__M2195:
	# LowerLogic(2403:3): ^443, true into i1 ^444
	movb -5632(%rbp), %cl
	xorb $1, %cl
	# LowerBasicConversion(2403:3): i1 ^444 -> i64 ^445
	movq %rcx, %rax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerIcmp(2404:3): i64 ^445 vs. intlike 0
	cmpq $0, %rax
	seta %al
	andq $1, %rax
	# LowerBasicConversion(2405:3): i64 ^446 -> i32 ^447
	movl %eax, %ecx
	# LowerLogic(2407:3): ^447, -1 into i32 ^448
	xorl $-1, %ecx
	# LowerLoad(2407:3).4: _ZL6g_1937 into ^449
	movl _ZL6g_1937(%rip), %eax
	# LowerIcmp(2408:3): i32 ^448 vs. operand i32 ^449
	cmpl %eax, %ecx
	sete %al
	andq $1, %rax
	# SetupCalls(2409:3): move argument i64 ^383
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(2409:3): move argument i64 -5067512586769809598
	movabsq $-5067512586769809598, %rax
	movq %rax, %rsi
	callq _ZL25safe_add_func_int64_t_s_sll
	# SetupCalls(2409:3): move i64 result from %rax
	movq %rax, %rax
	# LowerLoad(2410:3).2: (^57) into ptr ^452
	movq -5672(%rbp), %rbx
	movq (%rbx), %rax
	# LowerIcmp(2411:3): i64* ^9 vs. operand ptr ^452
	cmpq %rax, -5592(%rbp)
	sete %al
	andq $1, %rax
	# LowerBasicConversion(2412:3): ptr ^453 -> i32 ^454
	movl %eax, %ebx
	# LowerLoad(2413:3).4: _ZL6g_1899 into ^455
	movl _ZL6g_1899(%rip), %eax
	# LowerIcmp(2414:3): i32 ^454 vs. operand i32 ^455
	cmpl %eax, %ebx
	sete %al
	andq $1, %rax
	# LowerLoad(2415:3).4: _ZL6g_2382 into ^457
	movl _ZL6g_2382(%rip), %eax
	# LowerLoad(2416:3).4: _ZL6g_1905 into ^458
	movl _ZL6g_1905(%rip), %ebx
	# LowerIcmp(2417:3): i32 ^457 vs. operand i32 ^458
	cmpl %ebx, %eax
	setb %al
	andq $1, %rax
	# LowerBasicConversion(2418:3): i32 ^459 -> i16 ^460
	movw %ax, %bx
	# SetupCalls(2419:3): move argument i16 zeroext ^460
	movzwq %bx, %rdi
	andq $65535, %rdi
	# SetupCalls(2419:3): move argument i16 zeroext -12113
	movq $-12113, %rsi
	andq $65535, %rsi
	callq _ZL26safe_div_func_uint16_t_u_utt
	# SetupCalls(2419:3): move i16 result from %rax
	movw %ax, %bx
	# LowerIcmp(2420:3): i16 ^461 vs. intlike 0
	cmpw $0, %bx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M2300
	jmp .___ZL6func_1v__M3405
	.___ZL6func_1v__M2300:
	# SetupCalls(2425:3): move argument ptr align 16 ^74
	# Fixed movzx with identical source and destination widths
	movq -5400(%rbp), %rdi
	# SetupCalls(2425:3): move argument ptr align 16 @__const._ZL6func_1v.l_2393
	leaq __const._ZL6func_1v.l_2393(%rip), %rsi
	# SetupCalls(2425:3): move argument i64 16
	movq $16, %rdx
	callq memcpy@PLT
	# LowerStore(2428:3).3: mov $imm, (^76)
	movq -5408(%rbp), %rax
	movl $6, (%rax)
	# LowerStore(2430:3).3: mov $imm, (^77)
	movq -5624(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M2330:
	# LowerLoad(2434:3).2: (^77) into i32 ^465
	movq -5624(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(2435:3): i32 ^465 vs. intlike 4
	cmpl $4, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M2337
	jmp .___ZL6func_1v__M2364
	.___ZL6func_1v__M2337:
	# LowerLoad(2439:3).2: (^77) into i32 ^468
	movq -5624(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [4 x ptr]
	# LowerGetelementptr(2441:3): array/pointer-type, dynamic index -> ^470
	# index ^469 -> temp ^1170
	movq %rbx, %rcx
	# Multiply temp ^1170 by 8 start
	shlq $3, %rcx
	# Multiply end
	# temp ^1170 -> operand ^470
	movq %rcx, %rax
	# Result ^470 += base pointer ^75
	addq -5616(%rbp), %rax
	# LowerStore(2442:3).6: load global
	leaq _ZL5g_648(%rip), %rbx
	# LowerStore(2442:3).9: mov ptr ^1203, (^470)
	movq %rbx, (%rax)
	# LowerLoad(2446:3).2: (^77) into i32 ^472
	movq -5624(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(2447:3): ^472, 1 into i32 ^473
	addl $1, %eax
	# LowerStore(2448:3).9: mov i32 ^473, (^77)
	movq -5624(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M2330
	.___ZL6func_1v__M2364:
	# LowerLoad(2452:3).4: _ZL5g_337 into ^475
	movq _ZL5g_337(%rip), %rax
	# LowerLoad(2453:3).2: (^62) into ptr ^476
	movq -5584(%rbp), %rbx
	movq (%rbx), %rax
	movq $0, %rbx
	# LowerIcmp(2454:3): i64 ^1161 vs. operand ptr ^476
	cmpq %rax, %rbx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2455:3): ptr ^477 -> i32 ^478
	movl %eax, %ebx
	# LowerStore(2456:3).2a: mov $imm, %temp
	movb $61, _ZL5g_259(%rip)
	# LowerStore(2456:3).2b: mov %temp, (global)
	# LowerIcmp(2457:3): i32 ^478 vs. intlike 61
	cmpl $61, %ebx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2458:3): i32 ^479 -> i8 ^480
	movb %al, %bl
	# SetupCalls(2459:3): move argument i8 zeroext ^480
	movzbq %bl, %rdi
	andq $255, %rdi
	# SetupCalls(2459:3): move argument i32 3
	movq $3, %rsi
	callq _ZL28safe_lshift_func_uint8_t_u_shi
	# SetupCalls(2459:3): move i8 result from %rax
	movb %al, %al
	# LowerLoad(2460:3).4: _ZL5g_150 into ^482
	movq _ZL5g_150(%rip), %rax
	# LowerLoad(2461:3).4: _ZL5g_150 into ^483
	movq _ZL5g_150(%rip), %rbx
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2462:3): move argument ptr nonnull dereferenceable(8) align 8 ^483
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(2462:3): move argument ptr nonnull dereferenceable(8) align 8 ^482
	# Fixed movzx with identical source and destination widths
	movq %rax, %rsi
	callq _ZN2U2aSERKS_
	# SetupCalls(2462:3): move ptr result from %rax
	movq %rax, %rax
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerIcmp(2463:3): ptr* ^53 vs. operand ptr* ^53
	# Fixing always false comparison
	movq $0, %rax
	andq $1, %rax
	# LowerBasicConversion(2464:3): ptr ^485 -> i64 ^486
	movq %rax, %rbx
	# SetupCalls(2465:3): move argument i64 ^486
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	callq _ZL32safe_unary_minus_func_uint64_t_um
	# SetupCalls(2465:3): move i64 result from %rax
	movq %rax, %rbx
	# LowerLoad(2466:3).2: (^13) into ptr ^488
	movq -5352(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2467:3).2: (^62) into ptr ^489
	movq -5584(%rbp), %rdx
	movq (%rdx), %rax
	# LowerLoad(2468:3).2: (^489) into ptr ^490
	movq (%rax), %rdx
	# LowerIcmp(2469:3): ptr ^488 vs. operand ptr ^490
	cmpq %rdx, %rcx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2470:3): ptr ^491 -> i64 ^492
	movq %rax, %rcx
	# LowerLogic(2472:3): ^492, 2 into i64 ^493
	orq $2, %rcx
	# LowerLoad(2472:3).2: (^6) into i32 ^494
	movq -5576(%rbp), %rdx
	movl (%rdx), %eax
	# LowerBasicConversion(2473:3): i32 ^494 -> i64 ^495
	# LowerIcmp(2474:3): i64 ^493 vs. operand i64 ^495
	cmpq %rax, %rcx
	setb %al
	andq $1, %rax
	# LowerBasicConversion(2475:3): i64 ^496 -> i32 ^497
	movl %eax, %ecx
	# LowerLoad(2476:3).2: (^53) into ptr ^498
	movq -5376(%rbp), %rax
	movq (%rax), %rdx
	# LowerLoad(2477:3).2: (^498) into i32 ^499
	movl (%rdx), %eax
	# LowerIcmp(2478:3): i32 ^497 vs. operand i32 ^499
	cmpl %eax, %ecx
	setge %al
	andq $1, %rax
	# LowerBasicConversion(2479:3): i32 ^500 -> i32 ^501
	movl %eax, %ecx
	leaq _ZL6g_1894(%rip), %rax
	# tt = Pointer, type = [8 x i32]
	leaq _ZL6g_1894(%rip), %rax
	# LowerGetelementptr(2480:3): struct-type: [8 x i32] ^1104 -> ^1102, indices=0,4
	movq %rax, %rdx
	addq $16, %rdx
	# LowerGetelementptr(2480:3): type of ^1102 is i32*
	# LowerLoad(2480:3).2: (^1102) into i32 ^502
	movl (%rdx), %eax
	# LowerIcmp(2481:3): i32 ^501 vs. operand i32 ^502
	cmpl %eax, %ecx
	seta %al
	andq $1, %rax
	# LowerBasicConversion(2482:3): i32 ^503 -> i64 ^504
	movq %rax, %rcx
	# LowerIcmp(2483:3): i64 ^487 vs. operand i64 ^504
	cmpq %rcx, %rbx
	setb %al
	andq $1, %rax
	# LowerBasicConversion(2484:3): i64 ^505 -> i32 ^506
	movl %eax, %ecx
	# LowerLoad(2485:3).2: (^53) into ptr ^507
	movq -5376(%rbp), %rbx
	movq (%rbx), %rax
	# LowerLoad(2486:3).2: (^507) into i32 ^508
	movl (%rax), %ebx
	# LowerLogic(2488:3): ^506, ^508 into i32 ^509
	movl %ecx, %eax
	xorl %ebx, %eax
	# tt = Pointer, type = [4 x i32]
	# LowerGetelementptr(2488:3): struct-type: ptr ^74 -> ^510, indices=0,0
	movq -5400(%rbp), %rcx
	# LowerGetelementptr(2488:3): type of ^510 is i32*
	# LowerLoad(2489:3).2: (^510) into i32 ^511
	movl (%rcx), %ebx
	# LowerLogic(2491:3): ^511, ^509 into i32 ^512
	orl %eax, %ebx
	# LowerStore(2491:3).9: mov i32 ^512, (^510)
	movl %ebx, (%rcx)
	# LowerIcmp(2492:3): i32 ^512 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M2554
	.___ZL6func_1v__M2551:
	# MovePhi: intlike -> ^519 (in new block 1250 whose parent is 1136)
	movb $0, -5496(%rbp)
	jmp .___ZL6func_1v__M2568
	.___ZL6func_1v__M2554:
	# tt = Pointer, type = [4 x i32]
	# LowerGetelementptr(2496:3): struct-type: ptr ^74 -> ^515, indices=0,2
	movq -5400(%rbp), %rax
	addq $8, %rax
	# LowerGetelementptr(2496:3): type of ^515 is i32*
	# LowerLoad(2497:3).2: (^515) into i32 ^516
	movl (%rax), %ebx
	# LowerIcmp(2498:3): i32 ^516 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	andq $1, %rax
	# MovePhi: ^517 -> ^519
	movb %al, -5496(%rbp)
	.___ZL6func_1v__M2568:
	# LowerBasicConversion(2503:3): i1 ^519 -> i64 ^520
	movq -5496(%rbp), %rax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerIcmp(2504:3): i64 ^520 vs. intlike 1709356644
	cmpq $1709356644, %rax
	setg %al
	andq $1, %rax
	# LowerBasicConversion(2505:3): i64 ^521 -> i16 ^522
	movw %ax, %bx
	# SetupCalls(2506:3): move argument i16 zeroext ^522
	movzwq %bx, %rdi
	andq $65535, %rdi
	# SetupCalls(2506:3): move argument i32 7
	movq $7, %rsi
	callq _ZL29safe_rshift_func_uint16_t_u_sti
	# SetupCalls(2506:3): move i16 result from %rax
	movw %ax, %bx
	# LowerBasicConversion(2507:3): i16 ^523 -> i32 ^524
	movl %ebx, %eax
	# Truncate value to 16 bits
	andl $65535, %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2508:3): move argument i32 ^524
	# Fixed movzx with 32-bit source operand
	movl %eax, %edi
	# SetupCalls(2508:3): move argument i32 1
	movq $1, %rsi
	callq _ZL26safe_div_func_uint32_t_u_ujj
	# SetupCalls(2508:3): move i32 result from %rax
	movl %eax, %ebx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerLoad(2509:3).2: (^76) into i32 ^526
	movq -5408(%rbp), %rax
	movl (%rax), %ecx
	# LowerLogic(2511:3): ^526, ^525 into i32 ^527
	andl %ebx, %ecx
	# LowerStore(2511:3).9: mov i32 ^527, (^76)
	movq -5408(%rbp), %rax
	movl %ecx, (%rax)
	# LowerLoad(2512:3).2: (^5) into i32 ^528
	movq -5472(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(2513:3): i32 ^527 vs. operand i32 ^528
	cmpl %eax, %ecx
	sete %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M2647
	jmp .___ZL6func_1v__M2650
	.___ZL6func_1v__M2647:
	# MovePhi: intlike -> ^532 (in new block 1251 whose parent is 518)
	movb $1, -5488(%rbp)
	jmp .___ZL6func_1v__M2653
	.___ZL6func_1v__M2650:
	# MovePhi: intlike -> ^532
	movb $1, -5488(%rbp)
	.___ZL6func_1v__M2653:
	# LowerBasicConversion(2521:3): i1 ^532 -> i16 ^533
	movw -5488(%rbp), %ax
	# Truncate value to 8 bits
	andl $255, %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2522:3): move argument i16 signext ^533
	movzwq %ax, %rdi
	movswq %di, %rdi
	# SetupCalls(2522:3): move argument i16 signext 6553
	movq $6553, %rsi
	movswq %si, %rsi
	callq _ZL25safe_mod_func_int16_t_s_sss
	# SetupCalls(2522:3): move i16 result from %rax
	movw %ax, %bx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	movswl %bx, %eax
	# LowerLogic(2525:3): ^535, 15412 into i32 ^536
	movl %eax, %ebx
	xorl $15412, %ebx
	# LowerLoad(2525:3).4: _ZL5g_139 into ^537
	movq _ZL5g_139(%rip), %rax
	# LowerLoad(2526:3).2: (^537) into ptr ^538
	movq (%rax), %rcx
	# LowerLoad(2527:3).2: (^538) into i32 ^539
	movl (%rcx), %eax
	# LowerLogic(2529:3): ^539, ^536 into i32 ^540
	xorl %ebx, %eax
	# LowerStore(2529:3).9: mov i32 ^540, (^538)
	movl %eax, (%rcx)
	# LowerStore(2530:3).2a: mov $imm, %temp
	movl $0, _ZL6g_1904(%rip)
	# LowerStore(2530:3).2b: mov %temp, (global)
	.___ZL6func_1v__M2704:
	# LowerLoad(2534:3).4: _ZL6g_1904 into ^542
	movl _ZL6g_1904(%rip), %eax
	# LowerIcmp(2535:3): i32 ^542 vs. intlike 7
	cmpl $7, %eax
	setbe %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M2711
	jmp .___ZL6func_1v__M3404
	.___ZL6func_1v__M2711:
	# LowerStore(2539:3).2a: mov $imm, %temp
	movl $0, _ZL6g_1921(%rip)
	# LowerStore(2539:3).2b: mov %temp, (global)
	.___ZL6func_1v__M2716:
	# LowerLoad(2543:3).4: _ZL6g_1921 into ^546
	movl _ZL6g_1921(%rip), %eax
	# LowerIcmp(2544:3): i32 ^546 vs. intlike 7
	cmpl $7, %eax
	setbe %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M2723
	jmp .___ZL6func_1v__M3393
	.___ZL6func_1v__M2723:
	# SetupCalls(2549:3): move argument ptr align 16 ^78
	# Fixed movzx with identical source and destination widths
	movq -5416(%rbp), %rdi
	# SetupCalls(2549:3): move argument ptr align 16 @__const._ZL6func_1v.l_2398
	leaq __const._ZL6func_1v.l_2398(%rip), %rsi
	# SetupCalls(2549:3): move argument i64 35
	movq $35, %rdx
	callq memcpy@PLT
	# LowerStore(2552:3).2a: mov $imm, %temp
	movl $0, _ZL6g_1898(%rip)
	# LowerStore(2552:3).2b: mov %temp, (global)
	.___ZL6func_1v__M2753:
	# LowerLoad(2556:3).4: _ZL6g_1898 into ^550
	movl _ZL6g_1898(%rip), %eax
	# LowerIcmp(2557:3): i32 ^550 vs. intlike 7
	cmpl $7, %eax
	setbe %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M2760
	jmp .___ZL6func_1v__M3382
	.___ZL6func_1v__M2760:
	# LowerStore(2562:3).3: mov $imm, (^81)
	movq -5424(%rbp), %rax
	movl $-290470832, (%rax)
	# LowerLoad(2564:3).4: _ZL6g_1921 into ^553
	movl _ZL6g_1921(%rip), %eax
	# LowerMath(2565:3): ^553, 1 into i32 ^554
	addl $1, %eax
	# LowerBasicConversion(2566:3): i32 ^554 -> i64 ^555
	movq %rax, %rbx
	leaq _ZL6g_1944(%rip), %rdx
	# tt = Pointer, type = [10 x i32]
	# LowerGetelementptr(2567:3): array/pointer-type, dynamic index -> ^556
	# index ^555 -> temp ^1172
	movq %rbx, %rcx
	# Multiply temp ^1172 by 4 start
	shlq $2, %rcx
	# Multiply end
	# temp ^1172 -> operand ^556
	movq %rcx, %rax
	# Result ^556 += base pointer ^1171
	addq %rdx, %rax
	# LowerLoad(2568:3).2: (^556) into i32 ^557
	movl (%rax), %ebx
	# LowerIcmp(2569:3): i32 ^557 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M2788
	jmp .___ZL6func_1v__M2789
	.___ZL6func_1v__M2788:
	jmp .___ZL6func_1v__M3382
	.___ZL6func_1v__M2789:
	# tt = Pointer, type = [4 x i32]
	# LowerGetelementptr(2576:3): struct-type: ptr ^74 -> ^561, indices=0,2
	movq -5400(%rbp), %rax
	addq $8, %rax
	# LowerGetelementptr(2576:3): type of ^561 is i32*
	# LowerLoad(2577:3).2: (^561) into i32 ^562
	movl (%rax), %ebx
	movslq %ebx, %rax
	# LowerIcmp(2579:3): i64 ^563 vs. intlike 4098852423
	movabsq $4098852423, %rbx
	cmpq %rbx, %rax
	setle %al
	andq $1, %rax
	# LowerBasicConversion(2580:3): i64 ^564 -> i32 ^565
	movl %eax, -6256(%rbp)
	# tt = Pointer, type = [5 x [7 x i8]]
	# LowerGetelementptr(2581:3): struct-type: ptr ^78 -> ^566, indices=0,4
	movq -5416(%rbp), %rax
	addq $28, %rax
	# LowerGetelementptr(2581:3): type of ^566 is [7 x i8]*
	# tt = Pointer, type = [7 x i8]
	# LowerGetelementptr(2582:3): struct-type: ptr ^566 -> ^567, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(2582:3): type of ^567 is i8*
	# LowerLoad(2583:3).2: (^567) into i8 ^568
	# Fixing source-to-dest movb (%rbx), -6264(%rbp)
	movb (%rbx), %r15b
	movb %r15b, -6264(%rbp)
	# LowerBasicConversion(2584:3): i8 ^568 -> i64 ^569
	# Truncate value to 8 bits
	andl $255, -6264(%rbp)
	# SetupCalls(2585:3): move argument i64 0
	movq $0, %rdi
	callq _ZL31safe_unary_minus_func_int64_t_sl
	# SetupCalls(2585:3): move i64 result from %rax
	movq %rax, %rbx
	# LowerLoad(2586:3).2: (^55) into ptr ^571
	movq -5392(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2587:3).2: (^571) into i16 ^572
	movw (%rcx), %ax
	# LowerBasicConversion(2588:3): i16 ^572 -> i64 ^573
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLogic(2590:3): ^573, ^570 into i64 ^574
	movq %rax, %rdx
	andq %rbx, %rdx
	# LowerTrunc(2590:3): 64 to 16, move
	movw %dx, %ax
	# LowerTrunc(2590:3): 64 to 16, apply mask
	andq $65535, %rax
	# LowerStore(2591:3).9: mov i16 ^575, (^571)
	movw %ax, (%rcx)
	# LowerBasicConversion(2592:3): i16 ^575 -> i64 ^576
	movq %rax, %rbx
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(2593:3).4: _ZL5g_448 into ^577
	movq _ZL5g_448(%rip), %rax
	# LowerLoad(2594:3).2: (^577) into i32 ^578
	movl (%rax), %r12d
	# LowerLoad(2595:3).4: _ZL6g_1898 into ^579
	movl _ZL6g_1898(%rip), %eax
	# LowerMath(2596:3): ^579, 2 into i32 ^580
	addl $2, %eax
	# LowerBasicConversion(2597:3): i32 ^580 -> i64 ^581
	movq %rax, %rcx
	leaq _ZL6g_1944(%rip), %rsi
	# tt = Pointer, type = [10 x i32]
	# LowerGetelementptr(2598:3): array/pointer-type, dynamic index -> ^582
	# index ^581 -> temp ^1174
	movq %rcx, %rdx
	# Multiply temp ^1174 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^1174 -> operand ^582
	movq %rdx, %rax
	# Result ^582 += base pointer ^1173
	addq %rsi, %rax
	# LowerStore(2599:3).9: mov i32 ^578, (^582)
	movl %r12d, (%rax)
	# LowerLoad(2600:3).2: (^76) into i32 ^583
	movq -5408(%rbp), %rax
	movl (%rax), %ecx
	movslq %ecx, %rax
	movabsq $-383318305269343207, %rcx
	movq %rcx, %rdx
	# LowerIcmp(2602:3): i64 ^1162 vs. operand i64 ^584
	cmpq %rax, %rdx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2603:3): i64 ^585 -> i32 ^586
	movl %eax, %ecx
	# LowerLoad(2604:3).4: _ZL5g_246 into ^587
	movl _ZL5g_246(%rip), %eax
	# LowerIcmp(2605:3): i32 ^586 vs. operand i32 ^587
	cmpl %eax, %ecx
	setg %al
	andq $1, %rax
	# LowerBasicConversion(2606:3): i32 ^588 -> i64 ^589
	movq %rax, %rcx
	# LowerIcmp(2607:3): i64 ^589 vs. intlike 1
	cmpq $1, %rcx
	seta %al
	andq $1, %rax
	# LowerBasicConversion(2608:3): i64 ^590 -> i32 ^591
	movl %eax, %ecx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(2609:3): move argument i32 ^591
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edi
	# SetupCalls(2609:3): move argument i32 7
	movq $7, %rsi
	callq _ZL28safe_rshift_func_int32_t_s_sii
	# SetupCalls(2609:3): move i32 result from %rax
	movl %eax, %r13d
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerTrunc(2610:3): 32 to 16, move
	movw %r13w, %ax
	# LowerTrunc(2610:3): 32 to 16, apply mask
	andq $65535, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2611:3): move argument i16 signext ^593
	movzwq %ax, %rdi
	movswq %di, %rdi
	# SetupCalls(2611:3): move argument i32 2
	movq $2, %rsi
	callq _ZL28safe_lshift_func_int16_t_s_usj
	# SetupCalls(2611:3): move i16 result from %rax
	movw %ax, %r13w
	# Unclobber %rax
	movq -6344(%rbp), %rax
	movswl %r13w, %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2613:3): move argument i32 ^578
	# Fixed movzx with 32-bit source operand
	movl %r12d, %edi
	# SetupCalls(2613:3): move argument i32 ^595
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	callq _ZL29safe_lshift_func_uint32_t_u_sji
	# SetupCalls(2613:3): move i32 result from %rax
	movl %eax, %r12d
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerBasicConversion(2614:3): i32 ^596 -> i64 ^597
	movq %r12, %rax
	# LowerLoad(2615:3).4: _ZL6g_1885 into ^598
	movl _ZL6g_1885(%rip), %ecx
	# LowerBasicConversion(2616:3): i32 ^598 -> i64 ^599
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2617:3): move argument i64 ^597
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(2617:3): move argument i64 ^599
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rsi
	callq _ZL25safe_mod_func_int64_t_s_sll
	# SetupCalls(2617:3): move i64 result from %rax
	movq %rax, %r12
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerLogic(2619:3): ^576, ^600 into i64 ^601
	movq %rbx, %rcx
	orq %r12, %rcx
	# LowerLoad(2619:3).2: (^81) into i32 ^602
	movq -5424(%rbp), %rax
	movl (%rax), %ebx
	movslq %ebx, %rax
	# LowerIcmp(2621:3): i64 ^601 vs. operand i64 ^603
	cmpq %rax, %rcx
	setg %al
	andq $1, %rax
	# LowerBasicConversion(2622:3): i64 ^604 -> i8 ^605
	movb %al, %bl
	# LowerLoad(2623:3).4: _ZL6g_2354 into ^606
	movl _ZL6g_2354(%rip), %eax
	# LowerTrunc(2624:3): 32 to 8, move
	# LowerTrunc(2624:3): 32 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2625:3): move argument i8 signext ^605
	movzbq %bl, %rdi
	movsbq %dil, %rdi
	# SetupCalls(2625:3): move argument i8 signext ^607
	movzbq %al, %rsi
	movsbq %sil, %rsi
	callq _ZL24safe_add_func_int8_t_s_saa
	# SetupCalls(2625:3): move i8 result from %rax
	movb %al, %bl
	# Unclobber %rax
	movq -6344(%rbp), %rax
	movsbq %bl, %rax
	# LowerLoad(2627:3).4: _ZL5g_338 into ^610
	movq _ZL5g_338(%rip), %rbx
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2628:3): move argument i64 ^609
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(2628:3): move argument i64 ^610
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rsi
	callq _ZL25safe_mod_func_int64_t_s_sll
	# SetupCalls(2628:3): move i64 result from %rax
	movq %rax, %rbx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerTrunc(2629:3): 64 to 16, move
	movw %bx, %ax
	# LowerTrunc(2629:3): 64 to 16, apply mask
	andq $65535, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2630:3): move argument i16 signext 7
	movq $7, %rdi
	movswq %di, %rdi
	# SetupCalls(2630:3): move argument i16 signext ^612
	movzwq %ax, %rsi
	movswq %si, %rsi
	callq _ZL25safe_mul_func_int16_t_s_sss
	# SetupCalls(2630:3): move i16 result from %rax
	movw %ax, %bx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	movswq %bx, %rax
	# LowerIcmp(2632:3): i64 ^614 vs. intlike 4022093807
	movabsq $4022093807, %rbx
	cmpq %rbx, %rax
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2633:3): i64 ^615 -> i64 ^616
	movq %rax, %rbx
	# LowerIcmp(2634:3): i64 ^616 vs. intlike 1
	cmpq $1, %rbx
	setl %al
	andq $1, %rax
	# LowerBasicConversion(2635:3): i64 ^617 -> i32 ^618
	movl %eax, %ebx
	# tt = Pointer, type = [4 x [1 x i16]]
	# LowerGetelementptr(2636:3): struct-type: ptr ^15 -> ^619, indices=0,2
	movq -5360(%rbp), %rax
	addq $4, %rax
	# LowerGetelementptr(2636:3): type of ^619 is [1 x i16]*
	# tt = Pointer, type = [1 x i16]
	# LowerGetelementptr(2637:3): struct-type: ptr ^619 -> ^620, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(2637:3): type of ^620 is i16*
	# LowerLoad(2638:3).2: (^620) into i16 ^621
	movw (%rcx), %ax
	# LowerBasicConversion(2639:3): i16 ^621 -> i32 ^622
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerIcmp(2640:3): i32 ^618 vs. operand i32 ^622
	cmpl %eax, %ebx
	sete %al
	andq $1, %rax
	# LowerBasicConversion(2641:3): i32 ^623 -> i32 ^624
	movl %eax, %ebx
	# tt = Pointer, type = [5 x [7 x i8]]
	# LowerGetelementptr(2642:3): struct-type: ptr ^78 -> ^625, indices=0,2
	movq -5416(%rbp), %rax
	addq $14, %rax
	# LowerGetelementptr(2642:3): type of ^625 is [7 x i8]*
	# tt = Pointer, type = [7 x i8]
	# LowerGetelementptr(2643:3): struct-type: ptr ^625 -> ^626, indices=0,4
	movq %rax, %rcx
	addq $4, %rcx
	# LowerGetelementptr(2643:3): type of ^626 is i8*
	# LowerLoad(2644:3).2: (^626) into i8 ^627
	movb (%rcx), %al
	# LowerBasicConversion(2645:3): i8 ^627 -> i32 ^628
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerIcmp(2646:3): i32 ^624 vs. operand i32 ^628
	cmpl %eax, %ebx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2647:3): i32 ^629 -> i32 ^630
	movl %eax, %ebx
	# LowerLoad(2648:3).4: _ZL6g_1680 into ^631
	movq _ZL6g_1680(%rip), %rax
	# LowerLoad(2649:3).2: (^631) into ptr ^632
	movq (%rax), %rcx
	# LowerLoad(2650:3).2: (^632) into ptr ^633
	movq (%rcx), %rax
	# LowerLoad(2651:3).2: (^633) into ptr ^634
	movq (%rax), %rcx
	# LowerLoad(2652:3).2: (^634) into i32 ^635
	movl (%rcx), %eax
	# LowerIcmp(2653:3): i32 ^630 vs. operand i32 ^635
	cmpl %eax, %ebx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2654:3): i32 ^636 -> i64 ^637
	movq %rax, %rbx
	# LowerIcmp(2655:3): i64 ^637 vs. intlike 5244673685766057056
	movabsq $5244673685766057056, %rax
	cmpq %rax, %rbx
	setl %al
	andq $1, %rax
	# LowerBasicConversion(2656:3): i64 ^638 -> i32 ^639
	movl %eax, %ebx
	# LowerLoad(2657:3).4: _ZL6g_1681 into ^640
	movq _ZL6g_1681(%rip), %rax
	# LowerLoad(2658:3).2: (^640) into ptr ^641
	movq (%rax), %rcx
	# LowerLoad(2659:3).2: (^641) into ptr ^642
	movq (%rcx), %rax
	# LowerLoad(2660:3).2: (^642) into i32 ^643
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(2661:3): move argument i32 ^639
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edi
	# SetupCalls(2661:3): move argument i32 ^643
	# Fixed movzx with 32-bit source operand
	movl %ecx, %esi
	callq _ZL26safe_div_func_uint32_t_u_ujj
	# SetupCalls(2661:3): move i32 result from %rax
	movl %eax, %ebx
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerBasicConversion(2662:3): i32 ^644 -> i64 ^645
	movq %rbx, %rcx
	# LowerLoad(2663:3).2: (^81) into i32 ^646
	movq -5424(%rbp), %rax
	movl (%rax), %ebx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(2664:3): move argument i64 ^645
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(2664:3): move argument i32 ^646
	# Fixed movzx with 32-bit source operand
	movl %ebx, %esi
	callq _ZL28safe_lshift_func_int64_t_s_sli
	# SetupCalls(2664:3): move i64 result from %rax
	movq %rax, %rbx
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# tt = Pointer, type = [4 x [1 x i16]]
	# LowerGetelementptr(2665:3): struct-type: ptr ^15 -> ^648, indices=0,1
	movq -5360(%rbp), %rax
	addq $2, %rax
	# LowerGetelementptr(2665:3): type of ^648 is [1 x i16]*
	# tt = Pointer, type = [1 x i16]
	# LowerGetelementptr(2666:3): struct-type: ptr ^648 -> ^649, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(2666:3): type of ^649 is i16*
	# LowerLoad(2667:3).2: (^649) into i16 ^650
	movw (%rcx), %ax
	# LowerBasicConversion(2668:3): i16 ^650 -> i64 ^651
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerIcmp(2669:3): i64 ^647 vs. operand i64 ^651
	cmpq %rax, %rbx
	setl %al
	andq $1, %rax
	# LowerLoad(2670:3).2: (^53) into ptr ^653
	movq -5376(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(2671:3).2: (^653) into i32 ^654
	movl (%rbx), %eax
	movslq %eax, %rbx
	# SetupCalls(2673:3): move argument i64 ^569
	# Fixed movzx with identical source and destination widths
	movq -6264(%rbp), %rdi
	# SetupCalls(2673:3): move argument i64 ^655
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rsi
	callq _ZL26safe_div_func_uint64_t_u_umm
	# SetupCalls(2673:3): move i64 result from %rax
	movq %rax, %rbx
	# LowerLoad(2674:3).4: _ZL6g_2324 into ^657
	movl _ZL6g_2324(%rip), %eax
	# LowerBasicConversion(2675:3): i32 ^657 -> i64 ^658
	# LowerLogic(2677:3): ^656, ^658 into i64 ^659
	movq %rbx, %rcx
	xorq %rax, %rcx
	# LowerIcmp(2677:3): i64 ^659 vs. intlike 0
	cmpq $0, %rcx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M3342
	.___ZL6func_1v__M3339:
	# MovePhi: intlike -> ^665 (in new block 1252 whose parent is 1143)
	movb $0, -5384(%rbp)
	jmp .___ZL6func_1v__M3351
	.___ZL6func_1v__M3342:
	# LowerLoad(2681:3).4: _ZL6g_1948 into ^662
	movl _ZL6g_1948(%rip), %eax
	# LowerIcmp(2682:3): i32 ^662 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	# MovePhi: ^663 -> ^665
	movb %al, -5384(%rbp)
	.___ZL6func_1v__M3351:
	# LowerBasicConversion(2687:3): i1 ^665 -> i32 ^666
	movl -5384(%rbp), %eax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerIcmp(2688:3): i32 ^565 vs. operand i32 ^666
	cmpl %eax, -6256(%rbp)
	setge %al
	andq $1, %rax
	# LowerBasicConversion(2689:3): i32 ^667 -> i64 ^668
	movq %rax, %rbx
	# LowerIcmp(2690:3): i64 ^668 vs. intlike 0
	cmpq $0, %rbx
	setle %al
	andq $1, %rax
	# LowerBasicConversion(2691:3): i64 ^669 -> i32 ^670
	movl %eax, %ebx
	# LowerLoad(2692:3).4: _ZL6g_2357 into ^671
	movq _ZL6g_2357(%rip), %rax
	# LowerStore(2693:3).9: mov i32 ^670, (^671)
	movl %ebx, (%rax)
	# LowerLoad(2697:3).4: _ZL6g_1898 into ^673
	movl _ZL6g_1898(%rip), %eax
	# LowerMath(2698:3): ^673, 1 into i32 ^674
	addl $1, %eax
	# LowerStore(2699:3).8a: leaq var, %temp
	leaq _ZL6g_1898(%rip), %rbx
	# LowerStore(2699:3).8b: movq ^674, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M2753
	.___ZL6func_1v__M3382:
	# LowerLoad(2706:3).4: _ZL6g_1921 into ^677
	movl _ZL6g_1921(%rip), %eax
	# LowerMath(2707:3): ^677, 1 into i32 ^678
	addl $1, %eax
	# LowerStore(2708:3).8a: leaq var, %temp
	leaq _ZL6g_1921(%rip), %rbx
	# LowerStore(2708:3).8b: movq ^678, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M2716
	.___ZL6func_1v__M3393:
	# LowerLoad(2715:3).4: _ZL6g_1904 into ^681
	movl _ZL6g_1904(%rip), %eax
	# LowerMath(2716:3): ^681, 1 into i32 ^682
	addl $1, %eax
	# LowerStore(2717:3).8a: leaq var, %temp
	leaq _ZL6g_1904(%rip), %rbx
	# LowerStore(2717:3).8b: movq ^682, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M2704
	.___ZL6func_1v__M3404:
	jmp .___ZL6func_1v__M4338
	.___ZL6func_1v__M3405:
	# LowerStore(2725:3).3: mov $imm, (^83)
	movq -5464(%rbp), %rax
	movl $-1902289856, (%rax)
	# SetupCalls(2727:3): move argument ptr align 16 ^84
	# Fixed movzx with identical source and destination widths
	movq -5456(%rbp), %rdi
	# SetupCalls(2727:3): move argument ptr align 16 @__const._ZL6func_1v.l_2445
	leaq __const._ZL6func_1v.l_2445(%rip), %rsi
	# SetupCalls(2727:3): move argument i64 400
	movq $400, %rdx
	callq memcpy@PLT
	# LowerStore(2729:3).3: mov $imm, (^85)
	movq -5448(%rbp), %rax
	movl $757060412, (%rax)
	# LowerStore(2731:3).3: mov $imm, (^86)
	movabsq $-6161547311127722695, %rbx
	movq -5656(%rbp), %rax
	movq %rbx, (%rax)
	# SetupCalls(2734:3): move argument ptr align 16 ^88
	# Fixed movzx with identical source and destination widths
	movq -5648(%rbp), %rdi
	# SetupCalls(2734:3): move argument ptr align 16 @__const._ZL6func_1v.l_2475
	leaq __const._ZL6func_1v.l_2475(%rip), %rsi
	# SetupCalls(2734:3): move argument i64 504
	movq $504, %rdx
	callq memcpy@PLT
	# LowerStore(2737:3).3: mov $imm, (^89)
	movq -5608(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M3465:
	# LowerLoad(2741:3).2: (^89) into i32 ^686
	movq -5608(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(2742:3): i32 ^686 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M3472
	jmp .___ZL6func_1v__M3499
	.___ZL6func_1v__M3472:
	# LowerLoad(2746:3).2: (^89) into i32 ^689
	movq -5608(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [1 x ptr]
	# LowerGetelementptr(2748:3): array/pointer-type, dynamic index -> ^691
	# index ^690 -> temp ^1175
	movq %rbx, %rcx
	# Multiply temp ^1175 by 8 start
	shlq $3, %rcx
	# Multiply end
	# temp ^1175 -> operand ^691
	movq %rcx, %rax
	# Result ^691 += base pointer ^87
	addq -5600(%rbp), %rax
	# LowerStore(2749:3).6: load global
	leaq _ZL5g_338(%rip), %rbx
	# LowerStore(2749:3).9: mov ptr ^1211, (^691)
	movq %rbx, (%rax)
	# LowerLoad(2753:3).2: (^89) into i32 ^693
	movq -5608(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(2754:3): ^693, 1 into i32 ^694
	addl $1, %eax
	# LowerStore(2755:3).9: mov i32 ^694, (^89)
	movq -5608(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M3465
	.___ZL6func_1v__M3499:
	# LowerStore(2759:3).2a: mov $imm, %temp
	movl $0, _ZL6g_1934(%rip)
	# LowerStore(2759:3).2b: mov %temp, (global)
	.___ZL6func_1v__M3504:
	# LowerLoad(2763:3).4: _ZL6g_1934 into ^697
	movl _ZL6g_1934(%rip), %eax
	# LowerIcmp(2764:3): i32 ^697 vs. intlike 6
	cmpl $6, %eax
	setbe %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M3511
	jmp .___ZL6func_1v__M3871
	.___ZL6func_1v__M3511:
	# LowerStore(2769:3).3: mov $imm, (^91)
	movq -5504(%rbp), %rax
	movw $-1834, (%rax)
	# SetupCalls(2771:3): move argument ptr align 2 ^92
	# Fixed movzx with identical source and destination widths
	movq -5512(%rbp), %rdi
	# SetupCalls(2771:3): move argument i32 0
	movq $0, %rsi
	# SetupCalls(2771:3): move argument i64 2
	movq $2, %rdx
	callq memset@PLT
	# LowerStore(2773:3).3: mov $imm, (^93)
	movq -5520(%rbp), %rax
	movl $-1, (%rax)
	# SetupCalls(2775:3): move argument ptr align 16 ^94
	# Fixed movzx with identical source and destination widths
	movq -5528(%rbp), %rdi
	# SetupCalls(2775:3): move argument ptr align 16 @__const._ZL6func_1v.l_2462
	leaq __const._ZL6func_1v.l_2462(%rip), %rsi
	# SetupCalls(2775:3): move argument i64 40
	movq $40, %rdx
	callq memcpy@PLT
	# LowerStore(2777:3).3: mov $imm, (^95)
	movq -5536(%rbp), %rax
	movl $-849278951, (%rax)
	# LowerStore(2779:3).3: mov $imm, (^96)
	movq -5544(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(2781:3).2a: mov $imm, %temp
	movl $0, _ZL5g_693(%rip)
	# LowerStore(2781:3).2b: mov %temp, (global)
	# LowerLoad(2785:3).4: _ZL5g_693 into ^701
	movl _ZL5g_693(%rip), %eax
	# LowerIcmp(2786:3): i32 ^701 vs. intlike 6
	cmpl $6, %eax
	setle %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M3581
	jmp .___ZL6func_1v__M3607
	.___ZL6func_1v__M3581:
	# SetupCalls(2791:3): move argument ptr align 2 ^1
	# Fixed movzx with identical source and destination widths
	movq -5344(%rbp), %rdi
	# SetupCalls(2791:3): move argument ptr align 2 @__const._ZL6func_1v.l_2420
	leaq __const._ZL6func_1v.l_2420(%rip), %rsi
	# SetupCalls(2791:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	jmp .___ZL6func_1v__M5863
	.___ZL6func_1v__M3607:
	# LowerStore(2801:3).2a: mov $imm, %temp
	movl $1, _ZL5g_744(%rip)
	# LowerStore(2801:3).2b: mov %temp, (global)
	.___ZL6func_1v__M3612:
	# LowerLoad(2805:3).4: _ZL5g_744 into ^709
	movl _ZL5g_744(%rip), %eax
	# LowerIcmp(2806:3): i32 ^709 vs. intlike 6
	cmpl $6, %eax
	setbe %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M3619
	jmp .___ZL6func_1v__M3860
	.___ZL6func_1v__M3619:
	# SetupCalls(2811:3): move argument ptr align 16 ^98
	# Fixed movzx with identical source and destination widths
	movq -5552(%rbp), %rdi
	# SetupCalls(2811:3): move argument ptr align 16 @__const._ZL6func_1v.l_2431
	leaq __const._ZL6func_1v.l_2431(%rip), %rsi
	# SetupCalls(2811:3): move argument i64 84
	movq $84, %rdx
	callq memcpy@PLT
	# LowerStore(2813:3).3: mov $imm, (^99)
	movq -5560(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(2816:3).2a: mov $imm, %temp
	movl $0, _ZL6g_1928(%rip)
	# LowerStore(2816:3).2b: mov %temp, (global)
	.___ZL6func_1v__M3651:
	# LowerLoad(2820:3).4: _ZL6g_1928 into ^713
	movl _ZL6g_1928(%rip), %eax
	# LowerIcmp(2821:3): i32 ^713 vs. intlike 6
	cmpl $6, %eax
	setbe %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M3658
	jmp .___ZL6func_1v__M3803
	.___ZL6func_1v__M3658:
	# LowerStore(2826:3).6: load global
	leaq _ZL6g_2423(%rip), %rbx
	# LowerStore(2826:3).9: mov ptr ^1216, (^102)
	movq -5568(%rbp), %rax
	movq %rbx, (%rax)
	# LowerLoad(2828:3).4: _ZL6g_2423 into ^716
	movq _ZL6g_2423(%rip), %rbx
	# LowerLoad(2829:3).2: (^102) into ptr ^717
	movq -5568(%rbp), %rax
	movq (%rax), %rcx
	# LowerStore(2830:3).9: mov ptr ^716, (^717)
	movq %rbx, (%rcx)
	# LowerIcmp(2831:3): ptr ^716 vs. intlike 0
	cmpq $0, %rbx
	sete %al
	andq $1, %rax
	# LowerBasicConversion(2832:3): ptr ^718 -> i16 ^719
	movw %ax, %r12w
	# LowerLoad(2833:3).4: _ZL6g_1928 into ^720
	movl _ZL6g_1928(%rip), %eax
	# LowerBasicConversion(2834:3): i32 ^720 -> i64 ^721
	leaq _ZL6g_1945(%rip), %rbx
	# tt = Pointer, type = [7 x i32]
	# LowerGetelementptr(2835:3): array/pointer-type, dynamic index -> ^722
	# index ^721 -> temp ^1177
	movq %rax, %rcx
	# Multiply temp ^1177 by 4 start
	shlq $2, %rcx
	# Multiply end
	# temp ^1177 -> operand ^722
	movq %rcx, %rax
	# Result ^722 += base pointer ^1176
	addq %rbx, %rax
	# LowerLoad(2836:3).2: (^722) into i32 ^723
	movl (%rax), %ebx
	# LowerTrunc(2837:3): 32 to 8, move
	# LowerTrunc(2837:3): 32 to 8, apply mask
	andq $255, %rbx
	# SetupCalls(2838:3): move argument i8 zeroext ^724
	movzbq %bl, %rdi
	andq $255, %rdi
	# SetupCalls(2838:3): move argument i32 1
	movq $1, %rsi
	callq _ZL28safe_lshift_func_uint8_t_u_uhj
	# SetupCalls(2838:3): move i8 result from %rax
	movb %al, %bl
	# LowerBasicConversion(2839:3): i8 ^725 -> i32 ^726
	movl %ebx, %eax
	# Truncate value to 8 bits
	andl $255, %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2840:3): move argument i16 signext ^719
	movzwq %r12w, %rdi
	movswq %di, %rdi
	# SetupCalls(2840:3): move argument i32 ^726
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	callq _ZL28safe_rshift_func_int16_t_s_ssi
	# SetupCalls(2840:3): move i16 result from %rax
	movw %ax, %bx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	movswl %bx, %eax
	# tt = Pointer, type = [3 x [7 x i32]]
	# LowerGetelementptr(2842:3): struct-type: ptr ^98 -> ^729, indices=0,1
	movq -5552(%rbp), %rbx
	addq $28, %rbx
	# LowerGetelementptr(2842:3): type of ^729 is [7 x i32]*
	# tt = Pointer, type = [7 x i32]
	# LowerGetelementptr(2843:3): struct-type: ptr ^729 -> ^730, indices=0,4
	movq %rbx, %rcx
	addq $16, %rcx
	# LowerGetelementptr(2843:3): type of ^730 is i32*
	# LowerLoad(2844:3).2: (^730) into i32 ^731
	movl (%rcx), %ebx
	# LowerLogic(2846:3): ^731, ^728 into i32 ^732
	orl %eax, %ebx
	# LowerStore(2846:3).9: mov i32 ^732, (^730)
	movl %ebx, (%rcx)
	# LowerStore(2847:3).3: mov $imm, (^91)
	movq -5504(%rbp), %rax
	movw $-1, (%rax)
	# LowerLoad(2848:3).4: _ZL5g_653 into ^733
	movq _ZL5g_653(%rip), %rax
	# LowerLoad(2849:3).2: (^733) into ptr ^734
	movq (%rax), %rbx
	# LowerLoad(2850:3).2: (^734) into ptr ^735
	movq (%rbx), %rax
	# LowerLoad(2851:3).4: _ZL5g_653 into ^736
	movq _ZL5g_653(%rip), %rbx
	# LowerLoad(2852:3).2: (^736) into ptr ^737
	movq (%rbx), %rcx
	# LowerStore(2853:3).9: mov ptr ^735, (^737)
	movq %rax, (%rcx)
	# LowerLoad(2854:3).2: (^83) into i32 ^738
	movq -5464(%rbp), %rax
	movl (%rax), %ebx
	# LowerMath(2855:3): ^738, -1 into i32 ^739
	addl $-1, %ebx
	# LowerStore(2856:3).9: mov i32 ^739, (^83)
	movq -5464(%rbp), %rax
	movl %ebx, (%rax)
	# LowerLoad(2860:3).4: _ZL6g_1928 into ^741
	movl _ZL6g_1928(%rip), %eax
	# LowerMath(2861:3): ^741, 1 into i32 ^742
	addl $1, %eax
	# LowerStore(2862:3).8a: leaq var, %temp
	leaq _ZL6g_1928(%rip), %rbx
	# LowerStore(2862:3).8b: movq ^742, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M3651
	.___ZL6func_1v__M3803:
	# LowerStore(2866:3).2a: mov $imm, %temp
	movl $-1, _ZL6g_1939(%rip)
	# LowerStore(2866:3).2b: mov %temp, (global)
	# LowerLoad(2870:3).4: _ZL6g_1939 into ^745
	movl _ZL6g_1939(%rip), %eax
	# LowerIcmp(2871:3): i32 ^745 vs. intlike 55
	cmpl $55, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M3815
	jmp .___ZL6func_1v__M3849
	.___ZL6func_1v__M3815:
	# SetupCalls(2876:3): move argument ptr align 2 ^1
	# Fixed movzx with identical source and destination widths
	movq -5344(%rbp), %rdi
	# SetupCalls(2876:3): move argument ptr align 2 @__const._ZL6func_1v.l_2438
	leaq __const._ZL6func_1v.l_2438(%rip), %rsi
	# SetupCalls(2876:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	# LowerLoad(2877:3).2: (^83) into i32 ^748
	movq -5464(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(2878:3): i32 ^748 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M3847
	jmp .___ZL6func_1v__M3848
	.___ZL6func_1v__M3847:
	jmp .___ZL6func_1v__M3849
	.___ZL6func_1v__M3848:
	jmp .___ZL6func_1v__M5863
	.___ZL6func_1v__M3849:
	# LowerLoad(2897:3).4: _ZL5g_744 into ^757
	movl _ZL5g_744(%rip), %eax
	# LowerMath(2898:3): ^757, 1 into i32 ^758
	addl $1, %eax
	# LowerStore(2899:3).8a: leaq var, %temp
	leaq _ZL5g_744(%rip), %rbx
	# LowerStore(2899:3).8b: movq ^758, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M3612
	.___ZL6func_1v__M3860:
	# LowerLoad(2906:3).4: _ZL6g_1934 into ^761
	movl _ZL6g_1934(%rip), %eax
	# LowerMath(2907:3): ^761, 1 into i32 ^762
	addl $1, %eax
	# LowerStore(2908:3).8a: leaq var, %temp
	leaq _ZL6g_1934(%rip), %rbx
	# LowerStore(2908:3).8b: movq ^762, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M3504
	.___ZL6func_1v__M3871:
	# LowerLoad(2912:3).2: (^85) into i32 ^764
	movq -5448(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(2913:3): i32 ^764 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M3881
	.___ZL6func_1v__M3878:
	# MovePhi: intlike -> ^836 (in new block 1254 whose parent is 763)
	movb $0, -5432(%rbp)
	jmp .___ZL6func_1v__M4327
	.___ZL6func_1v__M3881:
	# LowerLoad(2917:3).2: (^53) into ptr ^767
	movq -5376(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(2918:3).2: (^767) into i32 ^768
	movl (%rbx), %r12d
	# LowerTrunc(2919:3): 32 to 16, move
	# LowerTrunc(2919:3): 32 to 16, apply mask
	andq $65535, %r12
	# LowerLoad(2920:3).4: _ZL6g_2423 into ^770
	movq _ZL6g_2423(%rip), %rax
	# LowerLoad(2921:3).2: (^770) into ptr ^771
	movq (%rax), %rbx
	# LowerLoad(2922:3).2: (^771) into ptr ^772
	movq (%rbx), %rax
	# LowerLoad(2923:3).2: (^772) into ptr ^773
	movq (%rax), %rbx
	# LowerLoad(2924:3).2: (^53) into ptr ^774
	movq -5376(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(2925:3).2: (^774) into i32 ^775
	movl (%rbx), %eax
	# LowerTrunc(2926:3): 32 to 16, move
	# LowerTrunc(2926:3): 32 to 16, apply mask
	andq $65535, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2927:3): move argument i16 signext ^776
	movzwq %ax, %rdi
	movswq %di, %rdi
	# SetupCalls(2927:3): move argument i32 7
	movq $7, %rsi
	callq _ZL28safe_rshift_func_int16_t_s_ssi
	# SetupCalls(2927:3): move i16 result from %rax
	movw %ax, %bx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	movswq %bx, %r13
	# LowerLoad(2929:3).4: _ZL5g_150 into ^779
	movq _ZL5g_150(%rip), %rax
	# LowerLoad(2930:3).4: _ZL5g_150 into ^780
	movq _ZL5g_150(%rip), %rbx
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2931:3): move argument ptr nonnull dereferenceable(8) align 8 ^780
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(2931:3): move argument ptr nonnull dereferenceable(8) align 8 ^779
	# Fixed movzx with identical source and destination widths
	movq %rax, %rsi
	callq _ZN2U2aSERKS_
	# SetupCalls(2931:3): move ptr result from %rax
	movq %rax, %rax
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerLoad(2932:3).2: (^2) into i32 ^782
	movq -5368(%rbp), %rax
	movl (%rax), %ebx
	movslq %ebx, %rax
	# LowerLogic(2935:3): 23858, ^783 into i64 ^784
	movq $23858, %rbx
	xorq %rax, %rbx
	# LowerLoad(2935:3).4: _ZL6g_2024 into ^785
	movl _ZL6g_2024(%rip), %eax
	# LowerIcmp(2936:3): i32 ^785 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M3975
	jmp .___ZL6func_1v__M3978
	.___ZL6func_1v__M3975:
	# MovePhi: intlike -> ^789 (in new block 1253 whose parent is 1145)
	movb $1, %al
	jmp .___ZL6func_1v__M3981
	.___ZL6func_1v__M3978:
	# MovePhi: intlike -> ^789
	movb $1, %al
	.___ZL6func_1v__M3981:
	# LowerLoad(2944:3).2: (^17) into i16 ^790
	movq -5480(%rbp), %rax
	movw (%rax), %cx
	# LowerTrunc(2945:3): 16 to 8, move
	# LowerTrunc(2945:3): 16 to 8, apply mask
	andq $255, %rcx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(2946:3): move argument i8 zeroext 1
	movq $1, %rdi
	andq $255, %rdi
	# SetupCalls(2946:3): move argument i8 zeroext ^791
	movzbq %cl, %rsi
	andq $255, %rsi
	callq _ZL25safe_div_func_uint8_t_u_uhh
	# SetupCalls(2946:3): move i8 result from %rax
	movb %al, %r14b
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerBasicConversion(2947:3): i8 ^792 -> i64 ^793
	movq %r14, %rax
	# Truncate value to 8 bits
	andl $255, %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2948:3): move argument i64 ^784
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(2948:3): move argument i64 ^793
	# Fixed movzx with identical source and destination widths
	movq %rax, %rsi
	callq _ZL26safe_mul_func_uint64_t_u_umm
	# SetupCalls(2948:3): move i64 result from %rax
	movq %rax, %rbx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# SetupCalls(2949:3): move argument i64 ^778
	# Fixed movzx with identical source and destination widths
	movq %r13, %rdi
	# SetupCalls(2949:3): move argument i64 ^794
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rsi
	callq _ZL25safe_div_func_int64_t_s_sll
	# SetupCalls(2949:3): move i64 result from %rax
	movq %rax, %rbx
	# LowerTrunc(2950:3): 64 to 16, move
	movw %bx, %ax
	# LowerTrunc(2950:3): 64 to 16, apply mask
	andq $65535, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2951:3): move argument i16 zeroext ^769
	movzwq %r12w, %rdi
	andq $65535, %rdi
	# SetupCalls(2951:3): move argument i16 zeroext ^796
	movzwq %ax, %rsi
	andq $65535, %rsi
	callq _ZL26safe_div_func_uint16_t_u_utt
	# SetupCalls(2951:3): move i16 result from %rax
	movw %ax, %bx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerBasicConversion(2952:3): i16 ^797 -> i32 ^798
	movl %ebx, %ecx
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(2953:3).2: (^2) into i32 ^799
	movq -5368(%rbp), %rax
	movl (%rax), %ebx
	# LowerLogic(2955:3): ^798, ^799 into i32 ^800
	movl %ecx, %edx
	orl %ebx, %edx
	# tt = Pointer, type = [4 x [1 x i16]]
	# LowerGetelementptr(2955:3): struct-type: ptr ^15 -> ^801, indices=0,3
	movq -5360(%rbp), %rax
	addq $6, %rax
	# LowerGetelementptr(2955:3): type of ^801 is [1 x i16]*
	# tt = Pointer, type = [1 x i16]
	# LowerGetelementptr(2956:3): struct-type: ptr ^801 -> ^802, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(2956:3): type of ^802 is i16*
	# LowerLoad(2957:3).2: (^802) into i16 ^803
	movw (%rbx), %cx
	# LowerBasicConversion(2958:3): i16 ^803 -> i32 ^804
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLogic(2960:3): ^800, ^804 into i32 ^805
	movl %edx, %eax
	orl %ecx, %eax
	# tt = Pointer, type = [4 x [1 x i16]]
	# LowerGetelementptr(2960:3): struct-type: ptr ^15 -> ^806, indices=0,2
	movq -5360(%rbp), %rbx
	addq $4, %rbx
	# LowerGetelementptr(2960:3): type of ^806 is [1 x i16]*
	# tt = Pointer, type = [1 x i16]
	# LowerGetelementptr(2961:3): struct-type: ptr ^806 -> ^807, indices=0,0
	movq %rbx, %rcx
	# LowerGetelementptr(2961:3): type of ^807 is i16*
	# LowerLoad(2962:3).2: (^807) into i16 ^808
	movw (%rcx), %bx
	# LowerBasicConversion(2963:3): i16 ^808 -> i32 ^809
	# Truncate value to 16 bits
	andl $65535, %ebx
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2964:3): move argument i32 ^805
	# Fixed movzx with 32-bit source operand
	movl %eax, %edi
	# SetupCalls(2964:3): move argument i32 ^809
	# Fixed movzx with 32-bit source operand
	movl %ebx, %esi
	callq _ZL29safe_rshift_func_uint32_t_u_ujj
	# SetupCalls(2964:3): move i32 result from %rax
	movl %eax, %ebx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerBasicConversion(2965:3): i32 ^810 -> i64 ^811
	movq %rbx, %rax
	# LowerLoad(2966:3).2: (^53) into ptr ^812
	movq -5376(%rbp), %rbx
	movq (%rbx), %rcx
	# LowerLoad(2967:3).2: (^812) into i32 ^813
	movl (%rcx), %ebx
	movslq %ebx, %rcx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2969:3): move argument i64 ^811
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(2969:3): move argument i64 ^814
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rsi
	callq _ZL25safe_div_func_int64_t_s_sll
	# SetupCalls(2969:3): move i64 result from %rax
	movq %rax, %rbx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerLoad(2970:3).2: (^83) into i32 ^816
	movq -5464(%rbp), %rcx
	movl (%rcx), %eax
	# LowerBasicConversion(2971:3): i32 ^816 -> i64 ^817
	movq %rax, %rcx
	# LowerIcmp(2972:3): i64 ^815 vs. operand i64 ^817
	cmpq %rcx, %rbx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(2973:3): i64 ^818 -> i32 ^819
	movl %eax, %ebx
	# LowerLoad(2974:3).2: (^53) into ptr ^820
	movq -5376(%rbp), %rcx
	movq (%rcx), %rax
	# LowerLoad(2975:3).2: (^820) into i32 ^821
	movl (%rax), %ecx
	# LowerIcmp(2976:3): i32 ^819 vs. operand i32 ^821
	cmpl %ecx, %ebx
	setge %al
	andq $1, %rax
	# LowerBasicConversion(2977:3): i32 ^822 -> i8 ^823
	movb %al, %bl
	# LowerLoad(2978:3).4: _ZL6g_1932 into ^824
	movl _ZL6g_1932(%rip), %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2979:3): move argument i8 zeroext ^823
	movzbq %bl, %rdi
	andq $255, %rdi
	# SetupCalls(2979:3): move argument i32 ^824
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	callq _ZL28safe_lshift_func_uint8_t_u_shi
	# SetupCalls(2979:3): move i8 result from %rax
	movb %al, %bl
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# SetupCalls(2980:3): move argument i8 signext ^825
	movzbq %bl, %rdi
	movsbq %dil, %rdi
	# SetupCalls(2980:3): move argument i8 signext 82
	movq $82, %rsi
	movsbq %sil, %rsi
	callq _ZL24safe_add_func_int8_t_s_saa
	# SetupCalls(2980:3): move i8 result from %rax
	movb %al, %bl
	movsbq %bl, %rax
	# tt = Pointer, type = [5 x [10 x i64]]
	# LowerGetelementptr(2982:3): struct-type: ptr ^84 -> ^828, indices=0,3
	movq -5456(%rbp), %rbx
	addq $240, %rbx
	# LowerGetelementptr(2982:3): type of ^828 is [10 x i64]*
	# tt = Pointer, type = [10 x i64]
	# LowerGetelementptr(2983:3): struct-type: ptr ^828 -> ^829, indices=0,2
	movq %rbx, %rcx
	addq $16, %rcx
	# LowerGetelementptr(2983:3): type of ^829 is i64*
	# LowerLoad(2984:3).2: (^829) into i64 ^830
	movq (%rcx), %rbx
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(2985:3): move argument i64 ^827
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(2985:3): move argument i64 ^830
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rsi
	callq _ZL26safe_mul_func_uint64_t_u_umm
	# SetupCalls(2985:3): move i64 result from %rax
	movq %rax, %rax
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerLoad(2986:3).2: (^85) into i32 ^832
	movq -5448(%rbp), %rax
	movl (%rax), %ebx
	# LowerLoad(2987:3).2: (^53) into ptr ^833
	movq -5376(%rbp), %rax
	movq (%rax), %rcx
	# LowerStore(2988:3).9: mov i32 ^832, (^833)
	movl %ebx, (%rcx)
	# LowerIcmp(2989:3): i32 ^832 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	andq $1, %rax
	# MovePhi: ^834 -> ^836
	movb %al, -5432(%rbp)
	.___ZL6func_1v__M4327:
	# LowerBasicConversion(2994:3): i1 ^836 -> i32 ^837
	movl -5432(%rbp), %eax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerLoad(2995:3).4: _ZL5g_139 into ^838
	movq _ZL5g_139(%rip), %rbx
	# LowerLoad(2996:3).2: (^838) into ptr ^839
	movq (%rbx), %rcx
	# LowerStore(2997:3).9: mov i32 ^837, (^839)
	movl %eax, (%rcx)
	.___ZL6func_1v__M4338:
	jmp .___ZL6func_1v__M5835
	.___ZL6func_1v__M4339:
	# LowerStore(3005:3).6: load global
	leaq _ZL6g_2504(%rip), %rbx
	# LowerStore(3005:3).9: mov ptr ^1221, (^104)
	movq -6112(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(3007:3).3: mov $imm, (^105)
	movq -6040(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(3009:3).6: load global
	leaq _ZL5g_313(%rip), %rbx
	# LowerStore(3009:3).9: mov ptr ^1222, (^106)
	movq -5768(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(3011:3).3: mov $imm, (^107)
	movq -6120(%rbp), %rax
	movl $197268864, (%rax)
	# LowerStore(3013:3).3: mov $imm, (^108)
	movq -6128(%rbp), %rax
	movl $-199073996, (%rax)
	# SetupCalls(3015:3): move argument ptr align 16 ^109
	# Fixed movzx with identical source and destination widths
	movq -5664(%rbp), %rdi
	# SetupCalls(3015:3): move argument ptr align 16 @__const._ZL6func_1v.l_2541
	leaq __const._ZL6func_1v.l_2541(%rip), %rsi
	# SetupCalls(3015:3): move argument i64 224
	movq $224, %rdx
	callq memcpy@PLT
	# LowerStore(3017:3).9: mov i64* ^27, (^110)
	movq -5640(%rbp), %rax
	# Fixing source-to-dest movq -5744(%rbp), (%rax)
	movq -5744(%rbp), %r15
	movq %r15, (%rax)
	# SetupCalls(3019:3): move argument ptr align 2 ^111
	# Fixed movzx with identical source and destination widths
	movq -5952(%rbp), %rdi
	# SetupCalls(3019:3): move argument ptr align 2 @__const._ZL6func_1v.l_2605
	leaq __const._ZL6func_1v.l_2605(%rip), %rsi
	# SetupCalls(3019:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	leaq _ZL5g_149(%rip), %rax
	# tt = Pointer, type = [4 x [2 x %union.U2]]
	leaq _ZL5g_149(%rip), %rbx
	# LowerGetelementptr(3022:3): struct-type: [4 x [2 x %union.U2]] ^1107 -> ^1105, indices=0,3,1
	movq %rbx, %rax
	addq $48, %rax
	addq $8, %rax
	# LowerGetelementptr(3022:3): type of ^1105 is %union.U2*
	# LowerLoad(3022:3).2: (^1105) into i64 ^842
	movq (%rax), %rbx
	# SetupCalls(3023:3): move argument i64 ^842
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	callq _ZL31safe_unary_minus_func_int64_t_sl
	# SetupCalls(3023:3): move i64 result from %rax
	movq %rax, %rbx
	# LowerLoad(3024:3).4: _ZL5g_150 into ^844
	movq _ZL5g_150(%rip), %rax
	# LowerLoad(3025:3).4: _ZL6g_2504 into ^845
	movq _ZL6g_2504(%rip), %rax
	# LowerLoad(3026:3).2: (^104) into ptr ^846
	movq -6112(%rbp), %rdx
	movq (%rdx), %rcx
	# LowerStore(3027:3).9: mov ptr ^845, (^846)
	movq %rax, (%rcx)
	# LowerIcmp(3028:3): ptr ^845 vs. global _ZL6g_2505
	leaq _ZL6g_2505(%rip), %rcx
	cmpq %rcx, %rax
	setne %al
	andq $1, %rax
	# LowerLoad(3029:3).4: _ZL5g_448 into ^848
	movq _ZL5g_448(%rip), %rax
	# LowerLoad(3030:3).2: (^848) into i32 ^849
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(3031:3): move argument i32 2093652833
	movq $2093652833, %rdi
	# SetupCalls(3031:3): move argument i32 ^849
	# Fixed movzx with 32-bit source operand
	movl %ecx, %esi
	callq _ZL25safe_sub_func_int32_t_s_sii
	# SetupCalls(3031:3): move i32 result from %rax
	movl %eax, %r12d
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerLoad(3032:3).2: (^2) into i32 ^851
	movq -5368(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(3033:3): i32 ^850 vs. operand i32 ^851
	cmpl %ecx, %r12d
	sete %al
	andq $1, %rax
	# LowerBasicConversion(3034:3): i32 ^852 -> i16 ^853
	movw %ax, %cx
	# LowerLoad(3035:3).2: (^106) into ptr ^854
	movq -5768(%rbp), %rdx
	movq (%rdx), %rax
	# LowerStore(3036:3).9: mov i16 ^853, (^854)
	movw %cx, (%rax)
	# LowerLoad(3037:3).2: (^105) into i32 ^855
	movq -6040(%rbp), %rdx
	movl (%rdx), %eax
	# LowerTrunc(3038:3): 32 to 16, move
	# LowerTrunc(3038:3): 32 to 16, apply mask
	andq $65535, %rax
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(3039:3): move argument i16 signext ^853
	movzwq %cx, %rdi
	movswq %di, %rdi
	# SetupCalls(3039:3): move argument i16 signext ^856
	movzwq %ax, %rsi
	movswq %si, %rsi
	callq _ZL25safe_mod_func_int16_t_s_sss
	# SetupCalls(3039:3): move i16 result from %rax
	movw %ax, %r12w
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	movswl %r12w, %ecx
	leaq _ZL6g_1922(%rip), %rax
	# tt = Pointer, type = [4 x [9 x i32]]
	leaq _ZL6g_1922(%rip), %rdx
	# LowerGetelementptr(3041:3): struct-type: [4 x [9 x i32]] ^1110 -> ^1108, indices=0,2,1
	movq %rdx, %rax
	addq $72, %rax
	addq $4, %rax
	# LowerGetelementptr(3041:3): type of ^1108 is i32*
	# LowerLoad(3041:3).2: (^1108) into i32 ^859
	movl (%rax), %edx
	# LowerIcmp(3042:3): i32 ^858 vs. operand i32 ^859
	cmpl %edx, %ecx
	setbe %al
	andq $1, %rax
	# LowerBasicConversion(3043:3): i32 ^860 -> i32 ^861
	movl %eax, %ecx
	# LowerLoad(3044:3).2: (^5) into i32 ^862
	movq -5472(%rbp), %rax
	movl (%rax), %edx
	# LowerIcmp(3045:3): i32 ^861 vs. operand i32 ^862
	cmpl %edx, %ecx
	setle %al
	andq $1, %rax
	# LowerBasicConversion(3046:3): i32 ^863 -> i32 ^864
	movl %eax, %ecx
	# LowerLoad(3047:3).2: (^105) into i32 ^865
	movq -6040(%rbp), %rdx
	movl (%rdx), %eax
	# LowerIcmp(3048:3): i32 ^864 vs. operand i32 ^865
	cmpl %eax, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M4559
	jmp .___ZL6func_1v__M4562
	.___ZL6func_1v__M4559:
	# MovePhi: intlike -> ^872 (in new block 1255 whose parent is 1150)
	movb $1, -5960(%rbp)
	jmp .___ZL6func_1v__M4573
	.___ZL6func_1v__M4562:
	# LowerLoad(3052:3).4: _ZL5g_337 into ^868
	movq _ZL5g_337(%rip), %rax
	# LowerLoad(3053:3).2: (^868) into i64 ^869
	movq (%rax), %rcx
	# LowerIcmp(3054:3): i64 ^869 vs. intlike 0
	cmpq $0, %rcx
	setne %al
	andq $1, %rax
	# MovePhi: ^870 -> ^872
	movb %al, -5960(%rbp)
	.___ZL6func_1v__M4573:
	# LowerBasicConversion(3059:3): i1 ^872 -> i16 ^873
	movw -5960(%rbp), %ax
	# Truncate value to 8 bits
	andl $255, %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(3060:3): move argument i16 signext ^873
	movzwq %ax, %rdi
	movswq %di, %rdi
	# SetupCalls(3060:3): move argument i32 14
	movq $14, %rsi
	callq _ZL28safe_rshift_func_int16_t_s_usj
	# SetupCalls(3060:3): move i16 result from %rax
	movw %ax, %r12w
	# Unclobber %rax
	movq -6344(%rbp), %rax
	movswq %r12w, %rax
	# LowerLoad(3062:3).4: _ZL6g_1930 into ^876
	movl _ZL6g_1930(%rip), %ecx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(3063:3): move argument i64 ^875
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(3063:3): move argument i32 ^876
	# Fixed movzx with 32-bit source operand
	movl %ecx, %esi
	callq _ZL29safe_lshift_func_uint64_t_u_smi
	# SetupCalls(3063:3): move i64 result from %rax
	movq %rax, %r12
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	movq $1746, %rax
	# LowerIcmp(3064:3): i64 ^1164 vs. operand i64 ^877
	cmpq %r12, %rax
	setb %al
	andq $1, %rax
	# LowerBasicConversion(3065:3): i64 ^878 -> i32 ^879
	movl %eax, %ecx
	# LowerLoad(3066:3).2: (^105) into i32 ^880
	movq -6040(%rbp), %rdx
	movl (%rdx), %eax
	# LowerIcmp(3067:3): i32 ^879 vs. operand i32 ^880
	cmpl %eax, %ecx
	sete %al
	andq $1, %rax
	# LowerBasicConversion(3068:3): i32 ^881 -> i16 ^882
	movw %ax, %cx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(3069:3): move argument i16 signext ^882
	movzwq %cx, %rdi
	movswq %di, %rdi
	# SetupCalls(3069:3): move argument i16 signext 4663
	movq $4663, %rsi
	movswq %si, %rsi
	callq _ZL25safe_mod_func_int16_t_s_sss
	# SetupCalls(3069:3): move i16 result from %rax
	movw %ax, %r12w
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	movswq %r12w, %rax
	# LowerIcmp(3071:3): i64 ^884 vs. intlike 2978496419
	movabsq $2978496419, %rcx
	cmpq %rcx, %rax
	setl %al
	andq $1, %rax
	# LowerBasicConversion(3072:3): i64 ^885 -> i32 ^886
	movl %eax, %ecx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(3073:3): move argument i64 ^843
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(3073:3): move argument i32 ^886
	# Fixed movzx with 32-bit source operand
	movl %ecx, %esi
	callq _ZL29safe_rshift_func_uint64_t_u_umj
	# SetupCalls(3073:3): move i64 result from %rax
	movq %rax, %rbx
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerTrunc(3074:3): 64 to 32, move and clear upper bits
	movl %ebx, %eax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(3075:3): move argument i64 -8285731994164951014
	movabsq $-8285731994164951014, %rbx
	movq %rbx, %rdi
	# SetupCalls(3075:3): move argument i32 ^888
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	callq _ZL28safe_lshift_func_int64_t_s_ulj
	# SetupCalls(3075:3): move i64 result from %rax
	movq %rax, %rbx
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerLogic(3077:3): ^889, 63187 into i64 ^890
	movq %rbx, %rax
	orq $63187, %rax
	# LowerTrunc(3077:3): 64 to 8, move
	movb %al, %bl
	# LowerTrunc(3077:3): 64 to 8, apply mask
	andq $255, %rbx
	# LowerLoad(3078:3).4: _ZL6g_2519 into ^892
	movw _ZL6g_2519(%rip), %ax
	# LowerTrunc(3079:3): 16 to 8, move
	# LowerTrunc(3079:3): 16 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(3080:3): move argument i8 zeroext ^891
	movzbq %bl, %rdi
	andq $255, %rdi
	# SetupCalls(3080:3): move argument i8 zeroext ^893
	movzbq %al, %rsi
	andq $255, %rsi
	callq _ZL25safe_add_func_uint8_t_u_uhh
	# SetupCalls(3080:3): move i8 result from %rax
	movb %al, %bl
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerIcmp(3081:3): i8 ^894 vs. intlike 0
	cmpb $0, %bl
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M4780
	jmp .___ZL6func_1v__M5768
	.___ZL6func_1v__M4780:
	# LowerStore(3086:3).3: mov $imm, (^114)
	movq -5928(%rbp), %rax
	movb $1, (%rax)
	# LowerStore(3088:3).3: mov $imm, (^115)
	movq -5992(%rbp), %rax
	movl $2118415308, (%rax)
	# LowerStore(3090:3).3: mov $imm, (^116)
	movq -6000(%rbp), %rax
	movl $1, (%rax)
	# LowerStore(3092:3).3: mov $imm, (^117)
	movq -6008(%rbp), %rax
	movl $1564788400, (%rax)
	# LowerStore(3094:3).3: mov $imm, (^118)
	movq -6016(%rbp), %rax
	movl $-72581471, (%rax)
	# SetupCalls(3096:3): move argument ptr align 16 ^119
	# Fixed movzx with identical source and destination widths
	movq -5984(%rbp), %rdi
	# SetupCalls(3096:3): move argument ptr align 16 @__const._ZL6func_1v.l_2552
	leaq __const._ZL6func_1v.l_2552(%rip), %rsi
	# SetupCalls(3096:3): move argument i64 32
	movq $32, %rdx
	callq memcpy@PLT
	# LowerStore(3098:3).3: mov $imm, (^120)
	movq -5968(%rbp), %rax
	movb $0, (%rax)
	# LowerStore(3100:3).3: mov $imm, (^121)
	movq -5976(%rbp), %rax
	movl $1200670702, (%rax)
	# SetupCalls(3103:3): move argument ptr align 2 ^123
	# Fixed movzx with identical source and destination widths
	movq -5920(%rbp), %rdi
	# SetupCalls(3103:3): move argument ptr align 2 @__const._ZL6func_1v.l_2573
	leaq __const._ZL6func_1v.l_2573(%rip), %rsi
	# SetupCalls(3103:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	# LowerStore(3105:3).6: load global
	leaq _ZL5g_837(%rip), %rax
	# LowerStore(3105:3).9: mov ptr ^1223, (^124)
	movq -5944(%rbp), %rbx
	movq %rax, (%rbx)
	# tt = Pointer, type = [6 x [5 x ptr]]
	# LowerGetelementptr(3107:3): struct-type: ptr ^125 -> ^897, indices=0,0
	movq -5936(%rbp), %rax
	# LowerGetelementptr(3107:3): type of ^897 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(3108:3): struct-type: ptr ^897 -> ^898, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(3108:3): type of ^898 is ptr*
	# LowerStore(3109:3).9: mov i8* ^114, (^898)
	# Fixing source-to-dest movq -5928(%rbp), (%rbx)
	movq -5928(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3110:3): struct-type: ptr ^898 -> ^899, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3110:3): type of ^899 is ptr*
	# LowerStore(3111:3).6: load global
	leaq _ZL4g_91(%rip), %rbx
	# LowerStore(3111:3).9: mov ptr ^1224, (^899)
	movq %rbx, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3112:3): struct-type: ptr ^899 -> ^900, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3112:3): type of ^900 is ptr*
	# LowerStore(3113:3).6: load global
	leaq _ZL4g_91(%rip), %rcx
	# LowerStore(3113:3).9: mov ptr ^1225, (^900)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3114:3): struct-type: ptr ^900 -> ^901, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3114:3): type of ^901 is ptr*
	# LowerStore(3115:3).6: load global
	leaq _ZL4g_91(%rip), %rbx
	# LowerStore(3115:3).9: mov ptr ^1226, (^901)
	movq %rbx, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3116:3): struct-type: ptr ^901 -> ^902, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3116:3): type of ^902 is ptr*
	# LowerStore(3117:3).6: load global
	leaq _ZL4g_91(%rip), %rcx
	# LowerStore(3117:3).9: mov ptr ^1227, (^902)
	movq %rcx, (%rbx)
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(3118:3): struct-type: ptr ^897 -> ^903, indices=1
	movq %rax, %rbx
	addq $40, %rbx
	# LowerGetelementptr(3118:3): type of ^903 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(3119:3): struct-type: ptr ^903 -> ^904, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(3119:3): type of ^904 is ptr*
	# LowerStore(3120:3).6: load global
	leaq _ZL4g_91(%rip), %rcx
	# LowerStore(3120:3).9: mov ptr ^1228, (^904)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3121:3): struct-type: ptr ^904 -> ^905, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3121:3): type of ^905 is ptr*
	# LowerStore(3122:3).9: mov i8* ^114, (^905)
	# Fixing source-to-dest movq -5928(%rbp), (%rcx)
	movq -5928(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3123:3): struct-type: ptr ^905 -> ^906, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(3123:3): type of ^906 is ptr*
	# LowerStore(3124:3).6: load global
	leaq _ZL4g_91(%rip), %rcx
	# LowerStore(3124:3).9: mov ptr ^1229, (^906)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3125:3): struct-type: ptr ^906 -> ^907, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3125:3): type of ^907 is ptr*
	# LowerStore(3126:3).6: load global
	leaq _ZL5g_259(%rip), %rax
	# LowerStore(3126:3).9: mov ptr ^1230, (^907)
	movq %rax, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3127:3): struct-type: ptr ^907 -> ^908, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(3127:3): type of ^908 is ptr*
	# LowerStore(3128:3).6: load global
	leaq _ZL4g_91(%rip), %rcx
	# LowerStore(3128:3).9: mov ptr ^1231, (^908)
	movq %rcx, (%rax)
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(3129:3): struct-type: ptr ^903 -> ^909, indices=1
	movq %rbx, %r12
	addq $40, %r12
	# LowerGetelementptr(3129:3): type of ^909 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(3130:3): struct-type: ptr ^909 -> ^910, indices=0,0
	movq %r12, %rax
	# LowerGetelementptr(3130:3): type of ^910 is ptr*
	# SetupCalls(3131:3): move argument ptr align 8 ^909
	# Fixed movzx with identical source and destination widths
	movq %r12, %rdi
	# SetupCalls(3131:3): move argument ptr align 8 @constinit
	leaq constinit(%rip), %rsi
	# SetupCalls(3131:3): move argument i64 40
	movq $40, %rdx
	callq memcpy@PLT
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(3132:3): struct-type: ptr ^909 -> ^911, indices=1
	movq %r12, %rbx
	addq $40, %rbx
	# LowerGetelementptr(3132:3): type of ^911 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(3133:3): struct-type: ptr ^911 -> ^912, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(3133:3): type of ^912 is ptr*
	# SetupCalls(3134:3): move argument ptr align 8 ^911
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(3134:3): move argument ptr align 8 @constinit.130
	leaq constinit.130(%rip), %rsi
	# SetupCalls(3134:3): move argument i64 40
	movq $40, %rdx
	callq memcpy@PLT
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(3135:3): struct-type: ptr ^911 -> ^913, indices=1
	movq %rbx, %rax
	addq $40, %rax
	# LowerGetelementptr(3135:3): type of ^913 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(3136:3): struct-type: ptr ^913 -> ^914, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(3136:3): type of ^914 is ptr*
	# LowerStore(3137:3).6: load global
	leaq _ZL4g_91(%rip), %rcx
	# LowerStore(3137:3).9: mov ptr ^1232, (^914)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3138:3): struct-type: ptr ^914 -> ^915, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3138:3): type of ^915 is ptr*
	# LowerStore(3139:3).6: load global
	leaq _ZL5g_259(%rip), %rbx
	# LowerStore(3139:3).9: mov ptr ^1233, (^915)
	movq %rbx, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3140:3): struct-type: ptr ^915 -> ^916, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3140:3): type of ^916 is ptr*
	# LowerStore(3141:3).6: load global
	leaq _ZL4g_91(%rip), %rcx
	# LowerStore(3141:3).9: mov ptr ^1234, (^916)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3142:3): struct-type: ptr ^916 -> ^917, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3142:3): type of ^917 is ptr*
	# LowerStore(3143:3).6: load global
	leaq _ZL4g_91(%rip), %rbx
	# LowerStore(3143:3).9: mov ptr ^1235, (^917)
	movq %rbx, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3144:3): struct-type: ptr ^917 -> ^918, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3144:3): type of ^918 is ptr*
	# LowerStore(3145:3).9: mov i8* ^114, (^918)
	# Fixing source-to-dest movq -5928(%rbp), (%rbx)
	movq -5928(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(3146:3): struct-type: ptr ^913 -> ^919, indices=1
	movq %rax, %rbx
	addq $40, %rbx
	# LowerGetelementptr(3146:3): type of ^919 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(3147:3): struct-type: ptr ^919 -> ^920, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(3147:3): type of ^920 is ptr*
	# LowerStore(3148:3).9: mov i8* ^114, (^920)
	# Fixing source-to-dest movq -5928(%rbp), (%rax)
	movq -5928(%rbp), %r15
	movq %r15, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3149:3): struct-type: ptr ^920 -> ^921, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3149:3): type of ^921 is ptr*
	# LowerStore(3150:3).6: load global
	leaq _ZL5g_259(%rip), %rax
	# LowerStore(3150:3).9: mov ptr ^1236, (^921)
	movq %rax, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3151:3): struct-type: ptr ^921 -> ^922, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(3151:3): type of ^922 is ptr*
	# LowerStore(3152:3).6: load global
	leaq _ZL4g_91(%rip), %rbx
	# LowerStore(3152:3).9: mov ptr ^1237, (^922)
	movq %rbx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3153:3): struct-type: ptr ^922 -> ^923, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3153:3): type of ^923 is ptr*
	# LowerStore(3154:3).6: load global
	leaq _ZL5g_259(%rip), %rax
	# LowerStore(3154:3).9: mov ptr ^1238, (^923)
	movq %rax, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(3155:3): struct-type: ptr ^923 -> ^924, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(3155:3): type of ^924 is ptr*
	# LowerStore(3156:3).6: load global
	leaq _ZL4g_91(%rip), %rbx
	# LowerStore(3156:3).9: mov ptr ^1239, (^924)
	movq %rbx, (%rax)
	# LowerStore(3158:3).3: mov $imm, (^126)
	movq -5792(%rbp), %rax
	movw $7524, (%rax)
	# LowerStore(3160:3).9: mov %union.U4* ^123, (^127)
	movq -5688(%rbp), %rax
	# Fixing source-to-dest movq -5920(%rbp), (%rax)
	movq -5920(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(3163:3).3: mov $imm, (^128)
	movq -5912(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M5111:
	# LowerLoad(3167:3).2: (^128) into i32 ^926
	movq -5912(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(3168:3): i32 ^926 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M5118
	jmp .___ZL6func_1v__M5143
	.___ZL6func_1v__M5118:
	# LowerLoad(3172:3).2: (^128) into i32 ^929
	movq -5912(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [8 x i16]
	# LowerGetelementptr(3174:3): array/pointer-type, dynamic index -> ^931
	# index ^930 -> temp ^1178
	movq %rbx, %rcx
	# Multiply temp ^1178 by 2 start
	shlq $1, %rcx
	# Multiply end
	# temp ^1178 -> operand ^931
	movq %rcx, %rax
	# Result ^931 += base pointer ^122
	addq -5904(%rbp), %rax
	# LowerStore(3175:3).3: mov $imm, (^931)
	movw $1, (%rax)
	# LowerLoad(3179:3).2: (^128) into i32 ^933
	movq -5912(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(3180:3): ^933, 1 into i32 ^934
	addl $1, %eax
	# LowerStore(3181:3).9: mov i32 ^934, (^128)
	movq -5912(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M5111
	.___ZL6func_1v__M5143:
	# LowerStore(3185:3).3: mov $imm, (^4)
	movq -5440(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M5146:
	# LowerLoad(3189:3).2: (^4) into i32 ^937
	movq -5440(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(3190:3): i32 ^937 vs. intlike -27
	cmpl $-27, %ebx
	setle %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M5153
	jmp .___ZL6func_1v__M5234
	.___ZL6func_1v__M5153:
	# LowerStore(3195:3).3: mov $imm, (^130)
	movq -5824(%rbp), %rax
	movl $-6, (%rax)
	# LowerStore(3197:3).3: mov $imm, (^131)
	movq -5832(%rbp), %rax
	movl $-1202443627, (%rax)
	# LowerStore(3199:3).3: mov $imm, (^132)
	movq -5840(%rbp), %rax
	movl $9, (%rax)
	# LowerStore(3201:3).3: mov $imm, (^133)
	movq -5848(%rbp), %rax
	movl $1326141411, (%rax)
	# LowerStore(3203:3).3: mov $imm, (^134)
	movq -5856(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(3205:3).3: mov $imm, (^135)
	movq -5864(%rbp), %rax
	movl $-1, (%rax)
	# SetupCalls(3208:3): move argument ptr align 16 ^137
	# Fixed movzx with identical source and destination widths
	movq -5880(%rbp), %rdi
	# SetupCalls(3208:3): move argument ptr align 16 @__const._ZL6func_1v.l_2564
	leaq __const._ZL6func_1v.l_2564(%rip), %rsi
	# SetupCalls(3208:3): move argument i64 320
	movq $320, %rdx
	callq memcpy@PLT
	# LowerStore(3211:3).3: mov $imm, (^138)
	movq -5888(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M5193:
	# LowerLoad(3215:3).2: (^138) into i32 ^941
	movq -5888(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(3216:3): i32 ^941 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M5200
	jmp .___ZL6func_1v__M5225
	.___ZL6func_1v__M5200:
	# LowerLoad(3220:3).2: (^138) into i32 ^944
	movq -5888(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [8 x i32]
	# LowerGetelementptr(3222:3): array/pointer-type, dynamic index -> ^946
	# index ^945 -> temp ^1179
	movq %rbx, %rcx
	# Multiply temp ^1179 by 4 start
	shlq $2, %rcx
	# Multiply end
	# temp ^1179 -> operand ^946
	movq %rcx, %rax
	# Result ^946 += base pointer ^136
	addq -5872(%rbp), %rax
	# LowerStore(3223:3).3: mov $imm, (^946)
	movl $-476256381, (%rax)
	# LowerLoad(3227:3).2: (^138) into i32 ^948
	movq -5888(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(3228:3): ^948, 1 into i32 ^949
	addl $1, %eax
	# LowerStore(3229:3).9: mov i32 ^949, (^138)
	movq -5888(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M5193
	.___ZL6func_1v__M5225:
	# LowerLoad(3236:3).2: (^4) into i32 ^952
	movq -5440(%rbp), %rax
	movl (%rax), %ebx
	# LowerMath(3237:3): ^952, -1 into i32 ^953
	addl $-1, %ebx
	# LowerStore(3238:3).9: mov i32 ^953, (^4)
	movq -5440(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M5146
	.___ZL6func_1v__M5234:
	# LowerStore(3242:3).2a: mov $imm, %temp
	movw $0, _ZL5g_837(%rip)
	# LowerStore(3242:3).2b: mov %temp, (global)
	.___ZL6func_1v__M5239:
	# LowerLoad(3246:3).4: _ZL5g_837 into ^956
	movw _ZL5g_837(%rip), %ax
	movswl %ax, %ebx
	# LowerIcmp(3248:3): i32 ^957 vs. intlike 1
	cmpl $1, %ebx
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M5247
	jmp .___ZL6func_1v__M5325
	.___ZL6func_1v__M5247:
	# LowerStore(3252:3).2a: mov $imm, %temp
	movl $0, _ZL6g_1939(%rip)
	# LowerStore(3252:3).2b: mov %temp, (global)
	.___ZL6func_1v__M5252:
	# LowerLoad(3256:3).4: _ZL6g_1939 into ^961
	movl _ZL6g_1939(%rip), %eax
	# LowerIcmp(3257:3): i32 ^961 vs. intlike 5
	cmpl $5, %eax
	setb %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M5259
	jmp .___ZL6func_1v__M5309
	.___ZL6func_1v__M5259:
	# LowerLoad(3261:3).4: _ZL5g_837 into ^964
	movw _ZL5g_837(%rip), %ax
	movswq %ax, %rbx
	leaq _ZL6g_2324(%rip), %rcx
	# tt = Pointer, type = [1 x [5 x i32]]
	# LowerGetelementptr(3263:3): array/pointer-type, dynamic index -> ^966
	# index ^965 -> temp ^1181
	movq %rbx, %rdx
	# Multiply temp ^1181 by 20 start
	# Clobber %rdx
	movq %rdx, -6336(%rbp)
	movq %rdx, %rax
	movq $20, %rbx
	mulq %rbx
	# Unclobber %rdx
	movq -6336(%rbp), %rdx
	movq %rax, %rdx
	# Multiply end
	# temp ^1181 -> operand ^966
	movq %rdx, %rax
	# Result ^966 += base pointer ^1180
	addq %rcx, %rax
	# LowerLoad(3264:3).4: _ZL6g_1939 into ^967
	movl _ZL6g_1939(%rip), %ebx
	# LowerBasicConversion(3265:3): i32 ^967 -> i64 ^968
	# tt = Pointer, type = [5 x i32]
	# LowerGetelementptr(3266:3): array/pointer-type, dynamic index -> ^969
	# index ^968 -> temp ^1183
	movq %rbx, %rcx
	# Multiply temp ^1183 by 4 start
	shlq $2, %rcx
	# Multiply end
	# temp ^1183 -> operand ^969
	movq %rcx, %rbx
	# Result ^969 += base pointer ^966
	addq %rax, %rbx
	# LowerStore(3267:3).3: mov $imm, (^969)
	movl $1769521508, (%rbx)
	# LowerLoad(3271:3).4: _ZL6g_1939 into ^971
	movl _ZL6g_1939(%rip), %eax
	# LowerMath(3272:3): ^971, 1 into i32 ^972
	addl $1, %eax
	# LowerStore(3273:3).8a: leaq var, %temp
	leaq _ZL6g_1939(%rip), %rbx
	# LowerStore(3273:3).8b: movq ^972, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M5252
	.___ZL6func_1v__M5309:
	# LowerLoad(3280:3).4: _ZL5g_837 into ^975
	movw _ZL5g_837(%rip), %ax
	movswl %ax, %ebx
	# LowerMath(3282:3): ^976, 1 into i32 ^977
	movl %ebx, %eax
	addl $1, %eax
	# LowerTrunc(3283:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(3283:3): 32 to 16, apply mask
	andq $65535, %rbx
	# LowerStore(3284:3).8a: leaq var, %temp
	leaq _ZL5g_837(%rip), %rax
	# LowerStore(3284:3).8b: movq ^978, (%temp)
	movw %bx, (%rax)
	jmp .___ZL6func_1v__M5239
	.___ZL6func_1v__M5325:
	# LowerLoad(3288:3).4: _ZL6g_2504 into ^980
	movq _ZL6g_2504(%rip), %rax
	# LowerLoad(3289:3).2: (^980) into ptr ^981
	movq (%rax), %rbx
	# LowerLoad(3290:3).2: (^981) into i16 ^982
	movw (%rbx), %ax
	# LowerIcmp(3291:3): i16 ^982 vs. intlike 0
	cmpw $0, %ax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M5339
	.___ZL6func_1v__M5336:
	# MovePhi: intlike -> ^988 (in new block 1256 whose parent is 979)
	movb $0, -5712(%rbp)
	jmp .___ZL6func_1v__M5348
	.___ZL6func_1v__M5339:
	# LowerLoad(3295:3).4: _ZL6g_1946 into ^985
	movl _ZL6g_1946(%rip), %eax
	# LowerIcmp(3296:3): i32 ^985 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	# MovePhi: ^986 -> ^988
	movb %al, -5712(%rbp)
	.___ZL6func_1v__M5348:
	# LowerBasicConversion(3301:3): i1 ^988 -> i64 ^989
	# Fixing source-to-dest movq -5712(%rbp), -6288(%rbp)
	movq -5712(%rbp), %r15
	movq %r15, -6288(%rbp)
	# Truncate value to 8 bits
	andl $255, -6288(%rbp)
	# tt = Pointer, type = [7 x [8 x i32]]
	# LowerGetelementptr(3302:3): struct-type: ptr ^109 -> ^990, indices=0,4
	movq -5664(%rbp), %rax
	addq $128, %rax
	# LowerGetelementptr(3302:3): type of ^990 is [8 x i32]*
	# tt = Pointer, type = [8 x i32]
	# LowerGetelementptr(3303:3): struct-type: ptr ^990 -> ^991, indices=0,5
	movq %rax, %rbx
	addq $20, %rbx
	# LowerGetelementptr(3303:3): type of ^991 is i32*
	# LowerLoad(3304:3).2: (^991) into i32 ^992
	movl (%rbx), %r12d
	# LowerLoad(3305:3).2: (^26) into i32 ^993
	movq -5736(%rbp), %rax
	movl (%rax), %ebx
	# LowerLoad(3306:3).2: (^27) into i64 ^994
	movq -5744(%rbp), %rax
	movq (%rax), %rcx
	# LowerIcmp(3307:3): i64 ^994 vs. intlike 0
	cmpq $0, %rcx
	setne %al
	andq $1, %rax
	# LowerLogic(3309:3): ^995, true into i1 ^996
	movb %al, %cl
	xorb $1, %cl
	# LowerBasicConversion(3309:3): i1 ^996 -> i32 ^997
	movl %ecx, %r13d
	# Truncate value to 8 bits
	andl $255, %r13d
	# tt = Pointer, type = [6 x i32]
	# LowerGetelementptr(3310:3): struct-type: ptr ^28 -> ^998, indices=0,3
	movq -5728(%rbp), %rax
	addq $12, %rax
	# LowerGetelementptr(3310:3): type of ^998 is i32*
	# LowerLoad(3311:3).2: (^998) into i32 ^999
	movl (%rax), %ecx
	# LowerMath(3312:3): ^999, 1 into i32 ^1000
	movl %ecx, %edx
	addl $1, %edx
	# LowerStore(3313:3).9: mov i32 ^1000, (^998)
	movl %edx, (%rax)
	# LowerLoad(3314:3).4: _ZL5g_259 into ^1001
	movb _ZL5g_259(%rip), %al
	# LowerBasicConversion(3315:3): i8 ^1001 -> i32 ^1002
	movl %eax, %edx
	# Truncate value to 8 bits
	andl $255, %edx
	# LowerLogic(3317:3): ^1002, ^999 into i32 ^1003
	movl %edx, %eax
	xorl %ecx, %eax
	# LowerTrunc(3317:3): 32 to 8, move
	movb %al, %cl
	# LowerTrunc(3317:3): 32 to 8, apply mask
	andq $255, %rcx
	# LowerStore(3318:3).8a: leaq var, %temp
	leaq _ZL5g_259(%rip), %rax
	# LowerStore(3318:3).8b: movq ^1004, (%temp)
	movb %cl, (%rax)
	# LowerBasicConversion(3319:3): i8 ^1004 -> i32 ^1005
	movl %ecx, %eax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerTrunc(3320:3): 32 to 8, move
	movb %al, %cl
	# LowerTrunc(3320:3): 32 to 8, apply mask
	andq $255, %rcx
	# LowerLoad(3321:3).4: _ZL6g_2599 into ^1007
	movw _ZL6g_2599(%rip), %ax
	# LowerLoad(3322:3).2: (^110) into ptr ^1008
	movq -5640(%rbp), %rax
	movq (%rax), %rdx
	leaq _ZL6g_2186(%rip), %rax
	# LowerIcmp(3323:3): @_ZL6g_2186 ^1165 vs. operand ptr ^1008
	cmpq %rdx, %rax
	setne %al
	andq $1, %rax
	# LowerBasicConversion(3324:3): ptr ^1009 -> i8 ^1010
	movb %al, %dl
	# Clobber %rdx
	movq %rdx, -6336(%rbp)
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(3325:3): move argument i8 zeroext ^1006
	movzbq %cl, %rdi
	andq $255, %rdi
	# SetupCalls(3325:3): move argument i8 zeroext ^1010
	movzbq %dl, %rsi
	andq $255, %rsi
	callq _ZL25safe_add_func_uint8_t_u_uhh
	# SetupCalls(3325:3): move i8 result from %rax
	movb %al, %r14b
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# Unclobber %rdx
	movq -6336(%rbp), %rdx
	# LowerBasicConversion(3326:3): i8 ^1011 -> i64 ^1012
	movq %r14, %rax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerLogic(3328:3): ^1012, 0 into i64 ^1013
	movq %rax, %rcx
	orq $0, %rcx
	# LowerLogic(3329:3): 0, ^1013 into i64 ^1014
	movq $0, %rax
	xorq %rcx, %rax
	# LowerTrunc(3329:3): 64 to 16, move
	movw %ax, %cx
	# LowerTrunc(3329:3): 64 to 16, apply mask
	andq $65535, %rcx
	# LowerLoad(3330:3).2: (^106) into ptr ^1016
	movq -5768(%rbp), %rax
	movq (%rax), %rdx
	# LowerStore(3331:3).9: mov i16 ^1015, (^1016)
	movw %cx, (%rdx)
	# LowerLoad(3332:3).2: (^126) into i16 ^1017
	movq -5792(%rbp), %rdx
	movw (%rdx), %ax
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(3333:3): move argument i16 signext ^1015
	movzwq %cx, %rdi
	movswq %di, %rdi
	# SetupCalls(3333:3): move argument i16 signext ^1017
	movzwq %ax, %rsi
	movswq %si, %rsi
	callq _ZL25safe_add_func_int16_t_s_sss
	# SetupCalls(3333:3): move i16 result from %rax
	movw %ax, %r14w
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	movswl %r14w, %ecx
	# LowerStore(3335:3).9: mov i32 ^1019, (^22)
	movq -5680(%rbp), %rax
	movl %ecx, (%rax)
	# LowerIcmp(3336:3): i32 ^997 vs. operand i32 ^1019
	cmpl %ecx, %r13d
	setge %al
	andq $1, %rax
	# tt = Pointer, type = [4 x [1 x i16]]
	# LowerGetelementptr(3337:3): struct-type: ptr ^15 -> ^1021, indices=0,2
	movq -5360(%rbp), %rax
	addq $4, %rax
	# LowerGetelementptr(3337:3): type of ^1021 is [1 x i16]*
	# tt = Pointer, type = [1 x i16]
	# LowerGetelementptr(3338:3): struct-type: ptr ^1021 -> ^1022, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(3338:3): type of ^1022 is i16*
	# LowerLoad(3339:3).2: (^1022) into i16 ^1023
	movw (%rcx), %ax
	# LowerBasicConversion(3340:3): i16 ^1023 -> i32 ^1024
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLoad(3341:3).4: _ZL5g_453 into ^1025
	movw _ZL5g_453(%rip), %cx
	# LowerBasicConversion(3342:3): i16 ^1025 -> i32 ^1026
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLogic(3344:3): ^1024, ^1026 into i32 ^1027
	movl %eax, %edx
	andl %ecx, %edx
	# LowerTrunc(3344:3): 32 to 16, move
	movw %dx, %ax
	# LowerTrunc(3344:3): 32 to 16, apply mask
	andq $65535, %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(3345:3): move argument i16 zeroext ^1028
	movzwq %ax, %rdi
	andq $65535, %rdi
	# SetupCalls(3345:3): move argument i16 zeroext 0
	movq $0, %rsi
	andq $65535, %rsi
	callq _ZL26safe_mul_func_uint16_t_u_utt
	# SetupCalls(3345:3): move i16 result from %rax
	movw %ax, %r13w
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# LowerBasicConversion(3346:3): i16 ^1029 -> i64 ^1030
	movq %r13, %rax
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerIcmp(3347:3): i64 ^1030 vs. intlike 8678000381446302913
	movabsq $8678000381446302913, %rcx
	cmpq %rcx, %rax
	setge %al
	andq $1, %rax
	# LowerBasicConversion(3348:3): i64 ^1031 -> i16 ^1032
	movw %ax, %cx
	# LowerLoad(3349:3).4: _ZL6g_2504 into ^1033
	movq _ZL6g_2504(%rip), %rax
	# LowerLoad(3350:3).2: (^1033) into ptr ^1034
	movq (%rax), %rdx
	# LowerLoad(3351:3).2: (^1034) into i16 ^1035
	movw (%rdx), %ax
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(3352:3): move argument i16 zeroext ^1032
	movzwq %cx, %rdi
	andq $65535, %rdi
	# SetupCalls(3352:3): move argument i16 zeroext ^1035
	movzwq %ax, %rsi
	andq $65535, %rsi
	callq _ZL26safe_mul_func_uint16_t_u_utt
	# SetupCalls(3352:3): move i16 result from %rax
	movw %ax, %r13w
	# Unclobber %rax
	movq -6344(%rbp), %rax
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerBasicConversion(3353:3): i16 ^1036 -> i32 ^1037
	movl %r13d, %eax
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerIcmp(3354:3): i32 ^993 vs. operand i32 ^1037
	cmpl %eax, %ebx
	setge %al
	andq $1, %rax
	# LowerBasicConversion(3355:3): i32 ^1038 -> i32 ^1039
	movl %eax, %ebx
	# tt = Pointer, type = [7 x [8 x i32]]
	# LowerGetelementptr(3356:3): struct-type: ptr ^109 -> ^1040, indices=0,5
	movq -5664(%rbp), %rax
	addq $160, %rax
	# LowerGetelementptr(3356:3): type of ^1040 is [8 x i32]*
	# tt = Pointer, type = [8 x i32]
	# LowerGetelementptr(3357:3): struct-type: ptr ^1040 -> ^1041, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(3357:3): type of ^1041 is i32*
	# LowerLoad(3358:3).2: (^1041) into i32 ^1042
	movl (%rcx), %eax
	# LowerLogic(3360:3): ^1039, ^1042 into i32 ^1043
	movl %ebx, %ecx
	orl %eax, %ecx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(3360:3): move argument i32 ^992
	# Fixed movzx with 32-bit source operand
	movl %r12d, %edi
	# SetupCalls(3360:3): move argument i32 ^1043
	# Fixed movzx with 32-bit source operand
	movl %ecx, %esi
	callq _ZL25safe_sub_func_int32_t_s_sii
	# SetupCalls(3360:3): move i32 result from %rax
	movl %eax, %ebx
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerLoad(3361:3).2: (^2) into i32 ^1045
	movq -5368(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -6352(%rbp)
	# SetupCalls(3362:3): move argument i32 ^1044
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edi
	# SetupCalls(3362:3): move argument i32 ^1045
	# Fixed movzx with 32-bit source operand
	movl %ecx, %esi
	callq _ZL25safe_sub_func_int32_t_s_sii
	# SetupCalls(3362:3): move i32 result from %rax
	movl %eax, %ebx
	# Unclobber %rcx
	movq -6352(%rbp), %rcx
	# LowerLoad(3363:3).4: _ZL6g_2504 into ^1047
	movq _ZL6g_2504(%rip), %rax
	# LowerLoad(3364:3).2: (^1047) into ptr ^1048
	movq (%rax), %rcx
	# LowerLoad(3365:3).2: (^1048) into i16 ^1049
	movw (%rcx), %ax
	# LowerBasicConversion(3366:3): i16 ^1049 -> i32 ^1050
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLogic(3368:3): ^1046, ^1050 into i32 ^1051
	movl %ebx, %ecx
	xorl %eax, %ecx
	# LowerTrunc(3368:3): 32 to 16, move
	movw %cx, %bx
	# LowerTrunc(3368:3): 32 to 16, apply mask
	andq $65535, %rbx
	# LowerLoad(3369:3).2: (^127) into ptr ^1053
	movq -5688(%rbp), %rax
	movq (%rax), %rcx
	# LowerStore(3370:3).9: mov i16 ^1052, (^1053)
	movw %bx, (%rcx)
	# LowerBasicConversion(3371:3): i16 ^1052 -> i32 ^1054
	movl %ebx, %eax
	# Truncate value to 16 bits
	andl $65535, %eax
	# tt = Pointer, type = [7 x [8 x i32]]
	# LowerGetelementptr(3372:3): struct-type: ptr ^109 -> ^1055, indices=0,5
	movq -5664(%rbp), %rbx
	addq $160, %rbx
	# LowerGetelementptr(3372:3): type of ^1055 is [8 x i32]*
	# tt = Pointer, type = [8 x i32]
	# LowerGetelementptr(3373:3): struct-type: ptr ^1055 -> ^1056, indices=0,0
	movq %rbx, %rcx
	# LowerGetelementptr(3373:3): type of ^1056 is i32*
	# LowerLoad(3374:3).2: (^1056) into i32 ^1057
	movl (%rcx), %ebx
	# LowerLogic(3376:3): ^1054, ^1057 into i32 ^1058
	movl %eax, %ecx
	orl %ebx, %ecx
	movslq %ecx, %rbx
	# LowerLoad(3377:3).2: (^110) into ptr ^1060
	movq -5640(%rbp), %rax
	movq (%rax), %rcx
	# LowerStore(3378:3).9: mov i64 ^1059, (^1060)
	movq %rbx, (%rcx)
	# SetupCalls(3379:3): move argument i64 ^1059
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(3379:3): move argument i32 36
	movq $36, %rsi
	callq _ZL29safe_rshift_func_uint64_t_u_umj
	# SetupCalls(3379:3): move i64 result from %rax
	movq %rax, %rbx
	# LowerIcmp(3380:3): i64 ^989 vs. operand i64 ^1061
	cmpq %rbx, -6288(%rbp)
	seta %al
	andq $1, %rax
	# LowerBasicConversion(3381:3): i64 ^1062 -> i32 ^1063
	movl %eax, %ebx
	# LowerLoad(3382:3).4: _ZL5g_140 into ^1064
	movq _ZL5g_140(%rip), %rax
	# LowerStore(3383:3).9: mov i32 ^1063, (^1064)
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M5834
	.___ZL6func_1v__M5768:
	# LowerStore(3387:3).2a: mov $imm, %temp
	movl $0, _ZL6g_1904(%rip)
	# LowerStore(3387:3).2b: mov %temp, (global)
	# LowerLoad(3391:3).4: _ZL6g_1904 into ^1067
	movl _ZL6g_1904(%rip), %eax
	# LowerIcmp(3392:3): i32 ^1067 vs. intlike 20
	cmpl $20, %eax
	setbe %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL6func_1v__M5780
	jmp .___ZL6func_1v__M5808
	.___ZL6func_1v__M5780:
	# LowerLoad(3396:3).4: _ZL5g_452 into ^1070
	movq _ZL5g_452(%rip), %rax
	# Clobber %rax
	movq %rax, -6344(%rbp)
	# SetupCalls(3397:3): move argument ptr align 2 ^1
	# Fixed movzx with identical source and destination widths
	movq -5344(%rbp), %rdi
	# SetupCalls(3397:3): move argument ptr align 2 ^1070
	# Fixed movzx with identical source and destination widths
	movq %rax, %rsi
	# SetupCalls(3397:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	# Unclobber %rax
	movq -6344(%rbp), %rax
	jmp .___ZL6func_1v__M5863
	.___ZL6func_1v__M5808:
	# SetupCalls(3407:3): move argument ptr align 2 ^1
	# Fixed movzx with identical source and destination widths
	movq -5344(%rbp), %rdi
	# SetupCalls(3407:3): move argument ptr align 2 ^111
	# Fixed movzx with identical source and destination widths
	movq -5952(%rbp), %rsi
	# SetupCalls(3407:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	jmp .___ZL6func_1v__M5863
	.___ZL6func_1v__M5834:
	.___ZL6func_1v__M5835:
	# LowerLoad(3414:3).2: (^13) into ptr ^1077
	movq -5352(%rbp), %rax
	movq (%rax), %rbx
	# SetupCalls(3415:3): move argument ptr align 2 ^1
	# Fixed movzx with identical source and destination widths
	movq -5344(%rbp), %rdi
	# SetupCalls(3415:3): move argument ptr align 2 ^1077
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rsi
	# SetupCalls(3415:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	.___ZL6func_1v__M5863:
	# tt = Pointer, type = %union.U4
	# LowerGetelementptr(3419:3): struct-type: ptr ^1 -> ^1079, indices=0,0
	movq -5344(%rbp), %rax
	# LowerGetelementptr(3419:3): type of ^1079 is i16*
	# LowerLoad(3420:3).2: (^1079) into i16 ^1080
	movw (%rax), %bx
	movw %bx, %ax
	movq -6360(%rbp), %r15
	movq -6528(%rbp), %r14
	movq -6512(%rbp), %r13
	movq -6432(%rbp), %r12
	movq -6424(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_rshift_func_int64_t_s_ulj
.p2align 4, 0x90
_ZL28safe_rshift_func_int64_t_s_ulj:
	.___ZL28safe_rshift_func_int64_t_s_ulj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(6144:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(6145:3): size = 4, type = i32*, var = ^4
	leaq -12(%rbp), %rax
	# LowerStore(6146:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(6148:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(6150:3).2: (^3) into i64 ^5
	movq (%rcx), %rbx
	# LowerIcmp(6151:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int64_t_s_ulj__M22
	.___ZL28safe_rshift_func_int64_t_s_ulj__M15:
	# LowerLoad(6155:3).2: (^4) into i32 ^8
	movl (%rax), %ebx
	# LowerIcmp(6156:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int64_t_s_ulj__M22
	jmp .___ZL28safe_rshift_func_int64_t_s_ulj__M27
	.___ZL28safe_rshift_func_int64_t_s_ulj__M22:
	# LowerLoad(6160:3).2: (^3) into i64 ^11
	movq (%rcx), %r8
	# MovePhi: ^11 -> ^18
	jmp .___ZL28safe_rshift_func_int64_t_s_ulj__M41
	.___ZL28safe_rshift_func_int64_t_s_ulj__M27:
	# LowerLoad(6164:3).2: (^3) into i64 ^13
	movq (%rcx), %rdx
	# LowerLoad(6165:3).2: (^4) into i32 ^14
	movl (%rax), %ebx
	# LowerBasicConversion(6166:3): i32 ^14 -> i64 ^15
	# LowerAshr(6167:3): ^13, ^15 into i64 ^16
	# LowerShift(6167:3): operand ^15 changed to %rcx
	movq %rbx, %rcx
	movq %rdx, %rax
	sarq %cl, %rax
	# MovePhi: ^16 -> ^18
	movq %rax, %r8
	.___ZL28safe_rshift_func_int64_t_s_ulj__M41:
	movq %r8, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_add_func_int32_t_s_sii
.p2align 4, 0x90
_ZL25safe_add_func_int32_t_s_sii:
	.___ZL25safe_add_func_int32_t_s_sii__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(112 + 0, 16)
	subq $112, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4841:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(4842:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4843:3).9: mov i32 %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(4845:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4847:3).2: (^3) into i32 ^5
	movl (%rcx), %ebx
	# LowerIcmp(4848:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M15
	jmp .___ZL25safe_add_func_int32_t_s_sii__M34
	.___ZL25safe_add_func_int32_t_s_sii__M15:
	# LowerLoad(4852:3).2: (^4) into i32 ^8
	movl (%rax), %ebx
	# LowerIcmp(4853:3): i32 ^8 vs. intlike 0
	cmpl $0, %ebx
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M22
	jmp .___ZL25safe_add_func_int32_t_s_sii__M34
	.___ZL25safe_add_func_int32_t_s_sii__M22:
	# LowerLoad(4857:3).2: (^3) into i32 ^11
	movl (%rcx), %esi
	# LowerLoad(4858:3).2: (^4) into i32 ^12
	movl (%rax), %ebx
	# LowerMath(4859:3): 2147483647, ^12 into i32 ^13
	movl $2147483647, %edx
	subl %ebx, %edx
	# LowerIcmp(4860:3): i32 ^11 vs. operand i32 ^13
	cmpl %edx, %esi
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M60
	.___ZL25safe_add_func_int32_t_s_sii__M34:
	# LowerLoad(4864:3).2: (^3) into i32 ^16
	movl (%rcx), %ebx
	# LowerIcmp(4865:3): i32 ^16 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M41
	jmp .___ZL25safe_add_func_int32_t_s_sii__M65
	.___ZL25safe_add_func_int32_t_s_sii__M41:
	# LowerLoad(4869:3).2: (^4) into i32 ^19
	movl (%rax), %ebx
	# LowerIcmp(4870:3): i32 ^19 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M48
	jmp .___ZL25safe_add_func_int32_t_s_sii__M65
	.___ZL25safe_add_func_int32_t_s_sii__M48:
	# LowerLoad(4874:3).2: (^3) into i32 ^22
	movl (%rcx), %ebx
	# LowerLoad(4875:3).2: (^4) into i32 ^23
	movl (%rax), %edx
	# LowerMath(4876:3): -2147483648, ^23 into i32 ^24
	movl $-2147483648, %esi
	subl %edx, %esi
	# LowerIcmp(4877:3): i32 ^22 vs. operand i32 ^24
	cmpl %esi, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M60
	jmp .___ZL25safe_add_func_int32_t_s_sii__M65
	.___ZL25safe_add_func_int32_t_s_sii__M60:
	# LowerLoad(4881:3).2: (^3) into i32 ^27
	movl (%rcx), %r8d
	# MovePhi: ^27 -> ^33
	jmp .___ZL25safe_add_func_int32_t_s_sii__M75
	.___ZL25safe_add_func_int32_t_s_sii__M65:
	# LowerLoad(4885:3).2: (^3) into i32 ^29
	movl (%rcx), %edx
	# LowerLoad(4886:3).2: (^4) into i32 ^30
	movl (%rax), %ebx
	# LowerMath(4887:3): ^29, ^30 into i32 ^31
	movl %edx, %eax
	addl %ebx, %eax
	# MovePhi: ^31 -> ^33
	movl %eax, %r8d
	.___ZL25safe_add_func_int32_t_s_sii__M75:
	movl %r8d, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL7func_47ij2U4t2U0
.p2align 4, 0x90
_ZL7func_47ij2U4t2U0:
	.___ZL7func_47ij2U4t2U0__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -32(%rbp)
	movq %r12, -40(%rbp)
	# LowerAlloca(4897:3): size = 2, type = %union.U4*, var = ^6
	leaq -2(%rbp), %rax
	# LowerAlloca(4898:3): size = 4, type = %union.U0*, var = ^7
	leaq -8(%rbp), %r11
	# LowerAlloca(4899:3): size = 4, type = i32*, var = ^8
	leaq -12(%rbp), %r9
	# LowerAlloca(4900:3): size = 4, type = i32*, var = ^9
	leaq -16(%rbp), %rbx
	# LowerAlloca(4901:3): size = 2, type = i16*, var = ^10
	leaq -18(%rbp), %r10
	# tt = Pointer, type = %union.U4
	# LowerGetelementptr(4902:3): struct-type: ptr ^6 -> ^11, indices=0,0
	movq %rax, %r12
	# LowerGetelementptr(4902:3): type of ^11 is i16*
	# LowerStore(4903:3).9: mov i16 %dx, (^11)
	movw %dx, (%r12)
	# tt = Pointer, type = %union.U0
	# LowerGetelementptr(4904:3): struct-type: ptr ^7 -> ^12, indices=0,0
	movq %r11, %rax
	# LowerGetelementptr(4904:3): type of ^12 is i32*
	# LowerStore(4905:3).9: mov i32 %r8d, (^12)
	movl %r8d, (%rax)
	# LowerStore(4906:3).9: mov i32 %edi, (^8)
	movl %edi, (%r9)
	# LowerStore(4908:3).9: mov i32 %esi, (^9)
	movl %esi, (%rbx)
	# LowerStore(4911:3).9: mov i16 %cx, (^10)
	movw %cx, (%r10)
	# LowerLoad(4914:3).4: _ZL5g_140 into ^13
	movq _ZL5g_140(%rip), %rbx
	# LowerLoad(4915:3).2: (^13) into i32 ^14
	movl (%rbx), %eax
	movq -40(%rbp), %r12
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL7func_532U1
.p2align 4, 0x90
_ZL7func_532U1:
	.___ZL7func_532U1__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(3232 + 0, 16)
	subq $3232, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -2280(%rbp)
	movq %r12, -2272(%rbp)
	movq %r13, -2352(%rbp)
	movq %r14, -2360(%rbp)
	movq %r15, -2256(%rbp)
	# LowerAlloca(4921:3): size = 4, type = i32*, var = ^2
	# Fixing source-to-dest leaq -4(%rbp), -2056(%rbp)
	leaq -4(%rbp), %r15
	movq %r15, -2056(%rbp)
	# LowerAlloca(4922:3): size = 2, type = %union.U1*, var = ^3
	# Fixing source-to-dest leaq -6(%rbp), -2064(%rbp)
	leaq -6(%rbp), %r15
	movq %r15, -2064(%rbp)
	# LowerAlloca(4923:3): size = 4, type = %union.U0*, var = ^4
	leaq -12(%rbp), %rax
	# LowerAlloca(4924:3): size = 8, type = ptr*, var = ^5
	leaq -24(%rbp), %r12
	# LowerAlloca(4925:3): size = 72, type = [9 x ptr]*, var = ^6
	leaq -96(%rbp), %rcx
	# LowerAlloca(4926:3): size = 8, type = ptr*, var = ^7
	# Fixing source-to-dest leaq -104(%rbp), -2088(%rbp)
	leaq -104(%rbp), %r15
	movq %r15, -2088(%rbp)
	# LowerAlloca(4927:3): size = 8, type = ptr*, var = ^8
	# Fixing source-to-dest leaq -112(%rbp), -2136(%rbp)
	leaq -112(%rbp), %r15
	movq %r15, -2136(%rbp)
	# LowerAlloca(4928:3): size = 1344, type = [6 x [7 x [4 x ptr]]]*, var = ^9
	# Fixing source-to-dest leaq -1456(%rbp), -2120(%rbp)
	leaq -1456(%rbp), %r15
	movq %r15, -2120(%rbp)
	# LowerAlloca(4929:3): size = 8, type = ptr*, var = ^10
	# Fixing source-to-dest leaq -1464(%rbp), -2104(%rbp)
	leaq -1464(%rbp), %r15
	movq %r15, -2104(%rbp)
	# LowerAlloca(4930:3): size = 4, type = i32*, var = ^11
	leaq -1468(%rbp), %r15
	# LowerAlloca(4931:3): size = 4, type = i32*, var = ^12
	leaq -1472(%rbp), %r13
	# LowerAlloca(4932:3): size = 16, type = [4 x i32]*, var = ^13
	leaq -1488(%rbp), %r14
	# LowerAlloca(4933:3): size = 14, type = [7 x i16]*, var = ^14
	# Fixing source-to-dest leaq -1502(%rbp), -2080(%rbp)
	pushq %r15
	leaq -1502(%rbp), %r15
	movq %r15, -2080(%rbp)
	popq %r15
	# LowerAlloca(4934:3): size = 4, type = i32*, var = ^15
	leaq -1508(%rbp), %rbx
	# LowerAlloca(4935:3): size = 4, type = i32*, var = ^16
	leaq -1512(%rbp), %rbx
	# LowerAlloca(4936:3): size = 4, type = i32*, var = ^17
	leaq -1516(%rbp), %rbx
	# LowerAlloca(4937:3): size = 80, type = [1 x [10 x [1 x i64]]]*, var = ^18
	# Fixing source-to-dest leaq -1600(%rbp), -2160(%rbp)
	pushq %r15
	leaq -1600(%rbp), %r15
	movq %r15, -2160(%rbp)
	popq %r15
	# LowerAlloca(4938:3): size = 8, type = ptr*, var = ^19
	# Fixing source-to-dest leaq -1608(%rbp), -2144(%rbp)
	pushq %r15
	leaq -1608(%rbp), %r15
	movq %r15, -2144(%rbp)
	popq %r15
	# LowerAlloca(4939:3): size = 8, type = ptr*, var = ^20
	# Fixing source-to-dest leaq -1616(%rbp), -2152(%rbp)
	pushq %r15
	leaq -1616(%rbp), %r15
	movq %r15, -2152(%rbp)
	popq %r15
	# LowerAlloca(4940:3): size = 8, type = ptr*, var = ^21
	# Fixing source-to-dest leaq -1624(%rbp), -2216(%rbp)
	pushq %r15
	leaq -1624(%rbp), %r15
	movq %r15, -2216(%rbp)
	popq %r15
	# LowerAlloca(4941:3): size = 8, type = ptr*, var = ^22
	# Fixing source-to-dest leaq -1632(%rbp), -2128(%rbp)
	pushq %r15
	leaq -1632(%rbp), %r15
	movq %r15, -2128(%rbp)
	popq %r15
	# LowerAlloca(4942:3): size = 4, type = i32*, var = ^23
	# Fixing source-to-dest leaq -1636(%rbp), -2096(%rbp)
	pushq %r15
	leaq -1636(%rbp), %r15
	movq %r15, -2096(%rbp)
	popq %r15
	# LowerAlloca(4943:3): size = 8, type = ptr*, var = ^24
	# Fixing source-to-dest leaq -1648(%rbp), -2208(%rbp)
	pushq %r15
	leaq -1648(%rbp), %r15
	movq %r15, -2208(%rbp)
	popq %r15
	# LowerAlloca(4944:3): size = 360, type = [9 x [5 x ptr]]*, var = ^25
	# Fixing source-to-dest leaq -2016(%rbp), -2200(%rbp)
	pushq %r15
	leaq -2016(%rbp), %r15
	movq %r15, -2200(%rbp)
	popq %r15
	# LowerAlloca(4945:3): size = 8, type = i64*, var = ^26
	# Fixing source-to-dest leaq -2024(%rbp), -2168(%rbp)
	pushq %r15
	leaq -2024(%rbp), %r15
	movq %r15, -2168(%rbp)
	popq %r15
	# LowerAlloca(4946:3): size = 2, type = i16*, var = ^27
	# Fixing source-to-dest leaq -2026(%rbp), -2184(%rbp)
	pushq %r15
	leaq -2026(%rbp), %r15
	movq %r15, -2184(%rbp)
	popq %r15
	# LowerAlloca(4947:3): size = 2, type = i16*, var = ^28
	# Fixing source-to-dest leaq -2028(%rbp), -2176(%rbp)
	pushq %r15
	leaq -2028(%rbp), %r15
	movq %r15, -2176(%rbp)
	popq %r15
	# LowerAlloca(4948:3): size = 2, type = i16*, var = ^29
	# Fixing source-to-dest leaq -2030(%rbp), -2112(%rbp)
	pushq %r15
	leaq -2030(%rbp), %r15
	movq %r15, -2112(%rbp)
	popq %r15
	# LowerAlloca(4949:3): size = 4, type = i32*, var = ^30
	# Fixing source-to-dest leaq -2036(%rbp), -2192(%rbp)
	pushq %r15
	leaq -2036(%rbp), %r15
	movq %r15, -2192(%rbp)
	popq %r15
	# LowerAlloca(4950:3): size = 4, type = i32*, var = ^31
	leaq -2040(%rbp), %rbx
	# LowerAlloca(4951:3): size = 4, type = i32*, var = ^32
	leaq -2044(%rbp), %rbx
	# LowerAlloca(4952:3): size = 4, type = i32*, var = ^33
	leaq -2048(%rbp), %rbx
	# tt = Pointer, type = %union.U1
	# LowerGetelementptr(4953:3): struct-type: ptr ^3 -> ^34, indices=0,0
	movq -2064(%rbp), %rbx
	# LowerGetelementptr(4953:3): type of ^34 is i16*
	# LowerStore(4954:3).9: mov i16 %di, (^34)
	movw %di, (%rbx)
	# LowerStore(4957:3).3: mov $imm, (^4)
	movl $0, (%rax)
	# LowerStore(4959:3).6: load global
	leaq _ZL5g_366(%rip), %rax
	# LowerStore(4959:3).9: mov ptr ^172, (^5)
	movq %rax, (%r12)
	# Clobber %rcx
	movq %rcx, -2232(%rbp)
	# SetupCalls(4961:3): move argument ptr align 16 ^6
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(4961:3): move argument ptr align 16 @__const._ZL7func_532U1.l_659
	leaq __const._ZL7func_532U1.l_659(%rip), %rsi
	# SetupCalls(4961:3): move argument i64 72
	movq $72, %rdx
	callq memcpy@PLT
	# Unclobber %rcx
	movq -2232(%rbp), %rcx
	leaq _ZL5g_422(%rip), %rax
	# tt = Pointer, type = [6 x i32]
	leaq _ZL5g_422(%rip), %rbx
	# LowerGetelementptr(4963:3): struct-type: [6 x i32] ^154 -> ^152, indices=0,5
	movq %rbx, %rax
	addq $20, %rax
	# LowerGetelementptr(4963:3): type of ^152 is i32*
	# LowerStore(4963:3).9: mov [6 x i32]* ^152, (^7)
	movq -2088(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(4965:3).3: mov $imm, (^8)
	movq -2136(%rbp), %rax
	movq $0, (%rax)
	# SetupCalls(4967:3): move argument ptr align 16 ^9
	# Fixed movzx with identical source and destination widths
	movq -2120(%rbp), %rdi
	# SetupCalls(4967:3): move argument ptr align 16 @__const._ZL7func_532U1.l_672
	leaq __const._ZL7func_532U1.l_672(%rip), %rsi
	# SetupCalls(4967:3): move argument i64 1344
	movq $1344, %rdx
	callq memcpy@PLT
	# LowerStore(4969:3).3: mov $imm, (^10)
	movq -2104(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(4971:3).3: mov $imm, (^11)
	movl $-1416764660, (%r15)
	# LowerStore(4973:3).3: mov $imm, (^12)
	movl $-1, (%r13)
	# SetupCalls(4975:3): move argument ptr align 16 ^13
	# Fixed movzx with identical source and destination widths
	movq %r14, %rdi
	# SetupCalls(4975:3): move argument ptr align 16 @__const._ZL7func_532U1.l_681
	leaq __const._ZL7func_532U1.l_681(%rip), %rsi
	# SetupCalls(4975:3): move argument i64 16
	movq $16, %rdx
	callq memcpy@PLT
	# SetupCalls(4977:3): move argument ptr align 2 ^14
	# Fixed movzx with identical source and destination widths
	movq -2080(%rbp), %rdi
	# SetupCalls(4977:3): move argument ptr align 2 @__const._ZL7func_532U1.l_689
	leaq __const._ZL7func_532U1.l_689(%rip), %rsi
	# SetupCalls(4977:3): move argument i64 14
	movq $14, %rdx
	callq memcpy@PLT
	# LowerLoad(4981:3).4: _ZL5g_422 into ^35
	movl _ZL5g_422(%rip), %eax
	# LowerIcmp(4982:3): i32 ^35 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_532U1__M202
	jmp .___ZL7func_532U1__M205
	.___ZL7func_532U1__M202:
	# MovePhi: intlike -> ^54 (in new block 190 whose parent is 165)
	movb $1, -2224(%rbp)
	jmp .___ZL7func_532U1__M298
	.___ZL7func_532U1__M205:
	# LowerLoad(4986:3).2: (^5) into ptr ^38
	movq (%r12), %rax
	# LowerStore(4987:3).8a: leaq var, %temp
	leaq _ZL5g_365(%rip), %rbx
	# LowerStore(4987:3).8b: movq ^38, (%temp)
	movq %rax, (%rbx)
	leaq _ZL5g_366(%rip), %rbx
	# LowerIcmp(4988:3): @_ZL5g_366 ^171 vs. operand ptr ^38
	cmpq %rax, %rbx
	sete %al
	andq $1, %rax
	# LowerBasicConversion(4989:3): ptr ^39 -> i32 ^40
	movl %eax, %ebx
	# LowerLoad(4990:3).4: _ZL5g_448 into ^41
	movq _ZL5g_448(%rip), %rax
	# LowerLoad(4991:3).2: (^41) into i32 ^42
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -2232(%rbp)
	# SetupCalls(4992:3): move argument i32 1
	movq $1, %rdi
	# SetupCalls(4992:3): move argument i32 ^42
	# Fixed movzx with 32-bit source operand
	movl %ecx, %esi
	callq _ZL26safe_add_func_uint32_t_u_ujj
	# SetupCalls(4992:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rcx
	movq -2232(%rbp), %rcx
	# LowerLoad(4993:3).4: _ZL5g_246 into ^44
	movl _ZL5g_246(%rip), %eax
	# LowerTrunc(4994:3): 32 to 16, move
	# LowerTrunc(4994:3): 32 to 16, apply mask
	andq $65535, %rax
	# LowerLoad(4995:3).2: (^3) into i8 ^46
	movq -2064(%rbp), %rdx
	movb (%rdx), %cl
	movsbw %cl, %dx
	# Clobber %rdx
	movq %rdx, -2240(%rbp)
	# Clobber %rax
	movq %rax, -2248(%rbp)
	# SetupCalls(4997:3): move argument i16 signext ^45
	movzwq %ax, %rdi
	movswq %di, %rdi
	# SetupCalls(4997:3): move argument i16 signext ^47
	movzwq %dx, %rsi
	movswq %si, %rsi
	callq _ZL25safe_add_func_int16_t_s_sss
	# SetupCalls(4997:3): move i16 result from %rax
	movw %ax, %r12w
	# Unclobber %rax
	movq -2248(%rbp), %rax
	# Unclobber %rdx
	movq -2240(%rbp), %rdx
	movswl %r12w, %eax
	# LowerIcmp(4999:3): i32 ^40 vs. operand i32 ^49
	cmpl %eax, %ebx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(5000:3): i32 ^50 -> i64 ^51
	movq %rax, %rbx
	# LowerIcmp(5001:3): i64 ^51 vs. intlike 1
	cmpq $1, %rbx
	setb %al
	andq $1, %rax
	# MovePhi: ^52 -> ^54
	movb %al, -2224(%rbp)
	.___ZL7func_532U1__M298:
	# LowerBasicConversion(5006:3): i1 ^54 -> i32 ^55
	movl -2224(%rbp), %eax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerLogic(5008:3): ^55, 12039 into i32 ^56
	movl %eax, %ebx
	orl $12039, %ebx
	movslq %ebx, %rax
	# LowerStore(5009:3).8a: leaq var, %temp
	leaq _ZL5g_245(%rip), %rbx
	# LowerStore(5009:3).8b: movq ^57, (%temp)
	movq %rax, (%rbx)
	# LowerLoad(5010:3).2: (^3) into i8 ^58
	movq -2064(%rbp), %rcx
	movb (%rcx), %bl
	movsbq %bl, %rcx
	# LowerIcmp(5012:3): i64 ^57 vs. operand i64 ^59
	cmpq %rcx, %rax
	setg %al
	andq $1, %rax
	# LowerBasicConversion(5013:3): i64 ^60 -> i32 ^61
	movl %eax, %ebx
	# LowerLoad(5014:3).2: (^3) into i8 ^62
	movq -2064(%rbp), %rcx
	movb (%rcx), %al
	movsbl %al, %ecx
	# LowerIcmp(5016:3): i32 ^61 vs. operand i32 ^63
	cmpl %ecx, %ebx
	setg %al
	andq $1, %rax
	# LowerBasicConversion(5017:3): i32 ^64 -> i32 ^65
	movl %eax, %ebx
	# LowerLoad(5018:3).2: (^7) into ptr ^66
	movq -2088(%rbp), %rdx
	movq (%rdx), %rcx
	# LowerStore(5019:3).9: mov i32 ^65, (^66)
	movl %ebx, (%rcx)
	cmpb $0, %al
	jne .___ZL7func_532U1__M333
	jmp .___ZL7func_532U1__M339
	.___ZL7func_532U1__M333:
	# LowerLoad(5023:3).2: (^3) into i8 ^68
	movq -2064(%rbp), %rbx
	movb (%rbx), %al
	movsbl %al, %ebx
	# LowerStore(5025:3).9: mov i32 ^69, (^2)
	movq -2056(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL7func_532U1__M901
	.___ZL7func_532U1__M339:
	# SetupCalls(5030:3): move argument ptr align 16 ^18
	# Fixed movzx with identical source and destination widths
	movq -2160(%rbp), %rdi
	# SetupCalls(5030:3): move argument ptr align 16 @__const._ZL7func_532U1.l_665
	leaq __const._ZL7func_532U1.l_665(%rip), %rsi
	# SetupCalls(5030:3): move argument i64 80
	movq $80, %rdx
	callq memcpy@PLT
	# LowerStore(5032:3).6: load global
	leaq _ZL5g_667(%rip), %rax
	# LowerStore(5032:3).9: mov ptr ^175, (^19)
	movq -2144(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(5034:3).9: mov ptr* ^19, (^20)
	movq -2152(%rbp), %rax
	# Fixing source-to-dest movq -2144(%rbp), (%rax)
	movq -2144(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5036:3).6: load global
	leaq _ZL5g_667(%rip), %rax
	# LowerStore(5036:3).9: mov ptr ^176, (^21)
	movq -2216(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(5038:3).9: mov ptr* ^21, (^22)
	movq -2128(%rbp), %rax
	# Fixing source-to-dest movq -2216(%rbp), (%rax)
	movq -2216(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5040:3).3: mov $imm, (^23)
	movq -2096(%rbp), %rax
	movl $-9, (%rax)
	leaq _ZL5g_149(%rip), %rax
	# tt = Pointer, type = [4 x [2 x %union.U2]]
	leaq _ZL5g_149(%rip), %rax
	# LowerGetelementptr(5042:3): struct-type: [4 x [2 x %union.U2]] ^157 -> ^155, indices=0,3,1
	movq %rax, %rbx
	addq $48, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5042:3): type of ^155 is %union.U2*
	# LowerStore(5042:3).9: mov [4 x [2 x %union.U2]]* ^155, (^24)
	movq -2208(%rbp), %rax
	movq %rbx, (%rax)
	# tt = Pointer, type = [9 x [5 x ptr]]
	# LowerGetelementptr(5044:3): struct-type: ptr ^25 -> ^71, indices=0,0
	movq -2200(%rbp), %rbx
	# LowerGetelementptr(5044:3): type of ^71 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5045:3): struct-type: ptr ^71 -> ^72, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5045:3): type of ^72 is ptr*
	# SetupCalls(5046:3): move argument ptr align 8 ^71
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(5046:3): move argument ptr align 8 @constinit.132
	leaq constinit.132(%rip), %rsi
	# SetupCalls(5046:3): move argument i64 40
	movq $40, %rdx
	callq memcpy@PLT
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5047:3): struct-type: ptr ^71 -> ^73, indices=1
	movq %rbx, %rcx
	addq $40, %rcx
	# LowerGetelementptr(5047:3): type of ^73 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5048:3): struct-type: ptr ^73 -> ^74, indices=0,0
	movq %rcx, %rbx
	# LowerGetelementptr(5048:3): type of ^74 is ptr*
	# LowerStore(5049:3).6: load global
	leaq _ZL5g_422(%rip), %rax
	# LowerStore(5049:3).9: mov ptr ^177, (^74)
	movq %rax, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5050:3): struct-type: ptr ^74 -> ^75, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5050:3): type of ^75 is ptr*
	# LowerStore(5051:3).3: mov $imm, (^75)
	movq $0, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5052:3): struct-type: ptr ^75 -> ^76, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5052:3): type of ^76 is ptr*
	# LowerStore(5053:3).9: mov i32* ^23, (^76)
	# Fixing source-to-dest movq -2096(%rbp), (%rbx)
	movq -2096(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5054:3): struct-type: ptr ^76 -> ^77, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5054:3): type of ^77 is ptr*
	# LowerStore(5055:3).6: load global
	leaq _ZL3g_2(%rip), %rbx
	# LowerStore(5055:3).9: mov ptr ^178, (^77)
	movq %rbx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5056:3): struct-type: ptr ^77 -> ^78, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5056:3): type of ^78 is ptr*
	# LowerStore(5057:3).9: mov i32* ^23, (^78)
	# Fixing source-to-dest movq -2096(%rbp), (%rbx)
	movq -2096(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5058:3): struct-type: ptr ^73 -> ^79, indices=1
	movq %rcx, %rax
	addq $40, %rax
	# LowerGetelementptr(5058:3): type of ^79 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5059:3): struct-type: ptr ^79 -> ^80, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5059:3): type of ^80 is ptr*
	# LowerStore(5060:3).9: mov i32* ^23, (^80)
	# Fixing source-to-dest movq -2096(%rbp), (%rbx)
	movq -2096(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5061:3): struct-type: ptr ^80 -> ^81, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5061:3): type of ^81 is ptr*
	# LowerStore(5062:3).9: mov i32* ^23, (^81)
	# Fixing source-to-dest movq -2096(%rbp), (%rcx)
	movq -2096(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5063:3): struct-type: ptr ^81 -> ^82, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5063:3): type of ^82 is ptr*
	# LowerStore(5064:3).3: mov $imm, (^82)
	movq $0, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5065:3): struct-type: ptr ^82 -> ^83, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5065:3): type of ^83 is ptr*
	# LowerStore(5066:3).6: load global
	leaq _ZL3g_2(%rip), %rbx
	# LowerStore(5066:3).9: mov ptr ^179, (^83)
	movq %rbx, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5067:3): struct-type: ptr ^83 -> ^84, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5067:3): type of ^84 is ptr*
	# LowerStore(5068:3).6: load global
	leaq _ZL3g_2(%rip), %rcx
	# LowerStore(5068:3).9: mov ptr ^180, (^84)
	movq %rcx, (%rbx)
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5069:3): struct-type: ptr ^79 -> ^85, indices=1
	movq %rax, %rbx
	addq $40, %rbx
	# LowerGetelementptr(5069:3): type of ^85 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5070:3): struct-type: ptr ^85 -> ^86, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5070:3): type of ^86 is ptr*
	# LowerStore(5071:3).3: mov $imm, (^86)
	movq $0, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5072:3): struct-type: ptr ^86 -> ^87, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5072:3): type of ^87 is ptr*
	# LowerStore(5073:3).6: load global
	leaq _ZL5g_422(%rip), %rax
	# LowerStore(5073:3).9: mov ptr ^181, (^87)
	movq %rax, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5074:3): struct-type: ptr ^87 -> ^88, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5074:3): type of ^88 is ptr*
	# LowerStore(5075:3).6: load global
	leaq _ZL5g_422(%rip), %rcx
	# LowerStore(5075:3).9: mov ptr ^182, (^88)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5076:3): struct-type: ptr ^88 -> ^89, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5076:3): type of ^89 is ptr*
	# LowerStore(5077:3).3: mov $imm, (^89)
	movq $0, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5078:3): struct-type: ptr ^89 -> ^90, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5078:3): type of ^90 is ptr*
	# LowerStore(5079:3).9: mov i32* ^23, (^90)
	# Fixing source-to-dest movq -2096(%rbp), (%rax)
	movq -2096(%rbp), %r15
	movq %r15, (%rax)
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5080:3): struct-type: ptr ^85 -> ^91, indices=1
	movq %rbx, %rax
	addq $40, %rax
	# LowerGetelementptr(5080:3): type of ^91 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5081:3): struct-type: ptr ^91 -> ^92, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5081:3): type of ^92 is ptr*
	# LowerStore(5082:3).3: mov $imm, (^92)
	movq $0, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5083:3): struct-type: ptr ^92 -> ^93, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5083:3): type of ^93 is ptr*
	# LowerStore(5084:3).6: load global
	leaq _ZL3g_2(%rip), %rbx
	# LowerStore(5084:3).9: mov ptr ^183, (^93)
	movq %rbx, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5085:3): struct-type: ptr ^93 -> ^94, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5085:3): type of ^94 is ptr*
	# LowerStore(5086:3).9: mov i32* ^23, (^94)
	# Fixing source-to-dest movq -2096(%rbp), (%rbx)
	movq -2096(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5087:3): struct-type: ptr ^94 -> ^95, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5087:3): type of ^95 is ptr*
	# LowerStore(5088:3).9: mov i32* ^23, (^95)
	# Fixing source-to-dest movq -2096(%rbp), (%rcx)
	movq -2096(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5089:3): struct-type: ptr ^95 -> ^96, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5089:3): type of ^96 is ptr*
	# LowerStore(5090:3).6: load global
	leaq _ZL3g_2(%rip), %rcx
	# LowerStore(5090:3).9: mov ptr ^184, (^96)
	movq %rcx, (%rbx)
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5091:3): struct-type: ptr ^91 -> ^97, indices=1
	movq %rax, %rbx
	addq $40, %rbx
	# LowerGetelementptr(5091:3): type of ^97 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5092:3): struct-type: ptr ^97 -> ^98, indices=0,0
	movq %rbx, %rcx
	# LowerGetelementptr(5092:3): type of ^98 is ptr*
	# LowerStore(5093:3).9: mov i32* ^23, (^98)
	# Fixing source-to-dest movq -2096(%rbp), (%rcx)
	movq -2096(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5094:3): struct-type: ptr ^98 -> ^99, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5094:3): type of ^99 is ptr*
	# LowerStore(5095:3).6: load global
	leaq _ZL5g_422(%rip), %rcx
	# LowerStore(5095:3).9: mov ptr ^185, (^99)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5096:3): struct-type: ptr ^99 -> ^100, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5096:3): type of ^100 is ptr*
	# LowerStore(5097:3).9: mov i32* ^23, (^100)
	# Fixing source-to-dest movq -2096(%rbp), (%rcx)
	movq -2096(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5098:3): struct-type: ptr ^100 -> ^101, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5098:3): type of ^101 is ptr*
	# LowerStore(5099:3).3: mov $imm, (^101)
	movq $0, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5100:3): struct-type: ptr ^101 -> ^102, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5100:3): type of ^102 is ptr*
	# LowerStore(5101:3).3: mov $imm, (^102)
	movq $0, (%rcx)
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5102:3): struct-type: ptr ^97 -> ^103, indices=1
	movq %rbx, %rax
	addq $40, %rax
	# LowerGetelementptr(5102:3): type of ^103 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5103:3): struct-type: ptr ^103 -> ^104, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5103:3): type of ^104 is ptr*
	# LowerStore(5104:3).6: load global
	leaq _ZL5g_422(%rip), %rcx
	# LowerStore(5104:3).9: mov ptr ^186, (^104)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5105:3): struct-type: ptr ^104 -> ^105, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5105:3): type of ^105 is ptr*
	# LowerStore(5106:3).9: mov i32* ^23, (^105)
	# Fixing source-to-dest movq -2096(%rbp), (%rcx)
	movq -2096(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5107:3): struct-type: ptr ^105 -> ^106, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5107:3): type of ^106 is ptr*
	# LowerStore(5108:3).6: load global
	leaq _ZL5g_422(%rip), %rcx
	# LowerStore(5108:3).9: mov ptr ^187, (^106)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5109:3): struct-type: ptr ^106 -> ^107, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5109:3): type of ^107 is ptr*
	# LowerStore(5110:3).9: mov i32* ^23, (^107)
	# Fixing source-to-dest movq -2096(%rbp), (%rcx)
	movq -2096(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5111:3): struct-type: ptr ^107 -> ^108, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5111:3): type of ^108 is ptr*
	# LowerStore(5112:3).3: mov $imm, (^108)
	movq $0, (%rbx)
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5113:3): struct-type: ptr ^103 -> ^109, indices=1
	movq %rax, %rbx
	addq $40, %rbx
	# LowerGetelementptr(5113:3): type of ^109 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5114:3): struct-type: ptr ^109 -> ^110, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5114:3): type of ^110 is ptr*
	# SetupCalls(5115:3): move argument ptr align 8 ^109
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(5115:3): move argument ptr align 8 @constinit.133
	leaq constinit.133(%rip), %rsi
	# SetupCalls(5115:3): move argument i64 40
	movq $40, %rdx
	callq memcpy@PLT
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5116:3): struct-type: ptr ^109 -> ^111, indices=1
	movq %rbx, %rax
	addq $40, %rax
	# LowerGetelementptr(5116:3): type of ^111 is [5 x ptr]*
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5117:3): struct-type: ptr ^111 -> ^112, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5117:3): type of ^112 is ptr*
	# LowerStore(5118:3).6: load global
	leaq _ZL5g_422(%rip), %rax
	# LowerStore(5118:3).9: mov ptr ^188, (^112)
	movq %rax, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5119:3): struct-type: ptr ^112 -> ^113, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5119:3): type of ^113 is ptr*
	# LowerStore(5120:3).3: mov $imm, (^113)
	movq $0, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5121:3): struct-type: ptr ^113 -> ^114, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5121:3): type of ^114 is ptr*
	# LowerStore(5122:3).9: mov i32* ^23, (^114)
	# Fixing source-to-dest movq -2096(%rbp), (%rbx)
	movq -2096(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5123:3): struct-type: ptr ^114 -> ^115, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5123:3): type of ^115 is ptr*
	# LowerStore(5124:3).6: load global
	leaq _ZL3g_2(%rip), %rbx
	# LowerStore(5124:3).9: mov ptr ^189, (^115)
	movq %rbx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5125:3): struct-type: ptr ^115 -> ^116, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5125:3): type of ^116 is ptr*
	# LowerStore(5126:3).9: mov i32* ^23, (^116)
	# Fixing source-to-dest movq -2096(%rbp), (%rbx)
	movq -2096(%rbp), %r15
	movq %r15, (%rbx)
	# LowerStore(5128:3).3: mov $imm, (^26)
	movq -2168(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(5130:3).3: mov $imm, (^27)
	movq -2184(%rbp), %rax
	movw $-27602, (%rax)
	# LowerStore(5132:3).3: mov $imm, (^28)
	movq -2176(%rbp), %rax
	movw $27048, (%rax)
	# LowerStore(5134:3).3: mov $imm, (^29)
	movq -2112(%rbp), %rax
	movw $1461, (%rax)
	# LowerStore(5136:3).3: mov $imm, (^30)
	movq -2192(%rbp), %rax
	movl $1827560133, (%rax)
	# tt = Pointer, type = [1 x [10 x [1 x i64]]]
	# LowerGetelementptr(5140:3): struct-type: ptr ^18 -> ^117, indices=0,0
	movq -2160(%rbp), %rax
	# LowerGetelementptr(5140:3): type of ^117 is [10 x [1 x i64]]*
	# tt = Pointer, type = [10 x [1 x i64]]
	# LowerGetelementptr(5141:3): struct-type: ptr ^117 -> ^118, indices=0,1
	addq $8, %rax
	# LowerGetelementptr(5141:3): type of ^118 is [1 x i64]*
	# tt = Pointer, type = [1 x i64]
	# LowerGetelementptr(5142:3): struct-type: ptr ^118 -> ^119, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5142:3): type of ^119 is i64*
	# LowerLoad(5143:3).2: (^119) into i64 ^120
	movq (%rbx), %rax
	# LowerIcmp(5144:3): i64 ^120 vs. intlike 0
	cmpq $0, %rax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_532U1__M790
	.___ZL7func_532U1__M787:
	# MovePhi: intlike -> ^139 (in new block 191 whose parent is 169)
	movb $0, -2072(%rbp)
	jmp .___ZL7func_532U1__M865
	.___ZL7func_532U1__M790:
	leaq _ZL5g_666(%rip), %rax
	# tt = Pointer, type = [10 x [2 x ptr]]
	leaq _ZL5g_666(%rip), %rax
	# LowerGetelementptr(5148:3): struct-type: [10 x [2 x ptr]] ^160 -> ^158, indices=0,1,1
	movq %rax, %rbx
	addq $16, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5148:3): type of ^158 is ptr*
	# LowerLoad(5148:3).2: (^158) into ptr ^123
	movq (%rbx), %rcx
	# LowerStore(5149:3).9: mov ptr ^123, (^8)
	movq -2136(%rbp), %rax
	movq %rcx, (%rax)
	leaq _ZL5g_666(%rip), %rax
	# tt = Pointer, type = [3 x [10 x [2 x ptr]]]
	leaq _ZL5g_666(%rip), %rbx
	# LowerGetelementptr(5150:3): struct-type: [3 x [10 x [2 x ptr]]] ^163 -> ^161, indices=0,2,4
	movq %rbx, %rax
	addq $320, %rax
	addq $64, %rax
	# LowerGetelementptr(5150:3): type of ^161 is [2 x ptr]*
	# LowerStore(5150:3).9: mov ptr ^123, (^161)
	movq %rcx, (%rax)
	# LowerLoad(5151:3).2: (^19) into ptr ^124
	movq -2144(%rbp), %rbx
	movq (%rbx), %rax
	# LowerLoad(5152:3).2: (^20) into ptr ^125
	movq -2152(%rbp), %rdx
	movq (%rdx), %rbx
	# LowerStore(5153:3).9: mov ptr ^124, (^125)
	movq %rax, (%rbx)
	# tt = Pointer, type = [6 x [7 x [4 x ptr]]]
	# LowerGetelementptr(5154:3): struct-type: ptr ^9 -> ^126, indices=0,3
	movq -2120(%rbp), %rbx
	addq $672, %rbx
	# LowerGetelementptr(5154:3): type of ^126 is [7 x [4 x ptr]]*
	# tt = Pointer, type = [7 x [4 x ptr]]
	# LowerGetelementptr(5155:3): struct-type: ptr ^126 -> ^127, indices=0,6
	movq %rbx, %rdx
	addq $192, %rdx
	# LowerGetelementptr(5155:3): type of ^127 is [4 x ptr]*
	# tt = Pointer, type = [4 x ptr]
	# LowerGetelementptr(5156:3): struct-type: ptr ^127 -> ^128, indices=0,0
	movq %rdx, %rbx
	# LowerGetelementptr(5156:3): type of ^128 is ptr*
	# LowerStore(5157:3).9: mov ptr ^124, (^128)
	movq %rax, (%rbx)
	# LowerLoad(5158:3).2: (^22) into ptr ^129
	movq -2128(%rbp), %rdx
	movq (%rdx), %rbx
	# LowerStore(5159:3).9: mov ptr ^124, (^129)
	movq %rax, (%rbx)
	# LowerIcmp(5160:3): ptr ^123 vs. operand ptr ^124
	cmpq %rax, %rcx
	sete %al
	andq $1, %rax
	# LowerBasicConversion(5161:3): ptr ^130 -> i32 ^131
	movl %eax, %ebx
	# LowerLoad(5162:3).2: (^10) into ptr ^132
	movq -2104(%rbp), %rcx
	movq (%rcx), %rax
	# LowerLoad(5163:3).2: (^10) into ptr ^133
	movq -2104(%rbp), %rdx
	movq (%rdx), %rcx
	# LowerIcmp(5164:3): ptr ^132 vs. operand ptr ^133
	cmpq %rcx, %rax
	sete %cl
	andq $1, %rcx
	# LowerBasicConversion(5165:3): ptr ^134 -> i32 ^135
	movl %ecx, %eax
	# LowerLogic(5167:3): ^131, ^135 into i32 ^136
	movl %ebx, %ecx
	andl %eax, %ecx
	# LowerIcmp(5167:3): i32 ^136 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	# MovePhi: ^137 -> ^139
	movb %al, -2072(%rbp)
	.___ZL7func_532U1__M865:
	# LowerBasicConversion(5172:3): i1 ^139 -> i32 ^140
	movl -2072(%rbp), %eax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerLoad(5173:3).2: (^7) into ptr ^141
	movq -2088(%rbp), %rcx
	movq (%rcx), %rbx
	# LowerStore(5174:3).9: mov i32 ^140, (^141)
	movl %eax, (%rbx)
	# LowerStore(5175:3).9: mov i32 ^140, (^23)
	movq -2096(%rbp), %rbx
	movl %eax, (%rbx)
	# LowerLoad(5176:3).2: (^29) into i16 ^142
	movq -2112(%rbp), %rbx
	movw (%rbx), %ax
	# LowerMath(5177:3): ^142, -1 into i16 ^143
	addw $-1, %ax
	# LowerStore(5178:3).9: mov i16 ^143, (^29)
	movq -2112(%rbp), %rbx
	movw %ax, (%rbx)
	# tt = Pointer, type = [7 x i16]
	# LowerGetelementptr(5179:3): struct-type: ptr ^14 -> ^144, indices=0,1
	movq -2080(%rbp), %rbx
	addq $2, %rbx
	# LowerGetelementptr(5179:3): type of ^144 is i16*
	# LowerLoad(5180:3).2: (^144) into i16 ^145
	movw (%rbx), %ax
	# LowerMath(5181:3): ^145, 1 into i16 ^146
	addw $1, %ax
	# LowerStore(5182:3).9: mov i16 ^146, (^144)
	movw %ax, (%rbx)
	# LowerLoad(5186:3).2: (^3) into i8 ^148
	movq -2064(%rbp), %rax
	movb (%rax), %bl
	movsbl %bl, %eax
	# LowerStore(5188:3).9: mov i32 ^149, (^2)
	movq -2056(%rbp), %rbx
	movl %eax, (%rbx)
	.___ZL7func_532U1__M901:
	# LowerLoad(5192:3).2: (^2) into i32 ^151
	movq -2056(%rbp), %rbx
	movl (%rbx), %eax
	movq -2256(%rbp), %r15
	movq -2360(%rbp), %r14
	movq -2352(%rbp), %r13
	movq -2272(%rbp), %r12
	movq -2280(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL7func_552U0
.p2align 4, 0x90
_ZL7func_552U0:
	.___ZL7func_552U0__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(5198:3): size = 2, type = %union.U1*, var = ^2
	leaq -2(%rbp), %rax
	# LowerAlloca(5199:3): size = 4, type = %union.U0*, var = ^3
	leaq -8(%rbp), %rcx
	# tt = Pointer, type = %union.U0
	# LowerGetelementptr(5200:3): struct-type: ptr ^3 -> ^4, indices=0,0
	movq %rcx, %rbx
	# LowerGetelementptr(5200:3): type of ^4 is i32*
	# LowerStore(5201:3).9: mov i32 %edi, (^4)
	movl %edi, (%rbx)
	# LowerStore(5204:3).3: mov $imm, (^2)
	movb $1, (%rax)
	# tt = Pointer, type = %union.U1
	# LowerGetelementptr(5205:3): struct-type: ptr ^2 -> ^5, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5205:3): type of ^5 is i16*
	# LowerLoad(5206:3).2: (^5) into i16 ^6
	movw (%rbx), %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL7func_57majs2U2
.p2align 4, 0x90
_ZL7func_57majs2U2:
	.___ZL7func_57majs2U2__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(5464 + 0, 16)
	subq $5472, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -3600(%rbp)
	movq %r12, -4648(%rbp)
	movq %r13, -4656(%rbp)
	movq %r14, -4664(%rbp)
	movq %r15, -3520(%rbp)
	# LowerAlloca(5212:3): size = 4, type = %union.U0*, var = ^6
	# Fixing source-to-dest leaq -4(%rbp), -3000(%rbp)
	leaq -4(%rbp), %r15
	movq %r15, -3000(%rbp)
	# LowerAlloca(5213:3): size = 8, type = %union.U2*, var = ^7
	# Fixing source-to-dest leaq -16(%rbp), -3216(%rbp)
	leaq -16(%rbp), %r15
	movq %r15, -3216(%rbp)
	# LowerAlloca(5214:3): size = 8, type = i64*, var = ^8
	# Fixing source-to-dest leaq -24(%rbp), -3224(%rbp)
	leaq -24(%rbp), %r15
	movq %r15, -3224(%rbp)
	# LowerAlloca(5215:3): size = 1, type = i8*, var = ^9
	# Fixing source-to-dest leaq -25(%rbp), -3232(%rbp)
	leaq -25(%rbp), %r15
	movq %r15, -3232(%rbp)
	# LowerAlloca(5216:3): size = 4, type = i32*, var = ^10
	# Fixing source-to-dest leaq -32(%rbp), -3240(%rbp)
	leaq -32(%rbp), %r15
	movq %r15, -3240(%rbp)
	# LowerAlloca(5217:3): size = 2, type = i16*, var = ^11
	# Fixing source-to-dest leaq -34(%rbp), -3248(%rbp)
	leaq -34(%rbp), %r15
	movq %r15, -3248(%rbp)
	# LowerAlloca(5218:3): size = 4, type = [2 x i16]*, var = ^12
	# Fixing source-to-dest leaq -38(%rbp), -3256(%rbp)
	leaq -38(%rbp), %r15
	movq %r15, -3256(%rbp)
	# LowerAlloca(5219:3): size = 8, type = ptr*, var = ^13
	# Fixing source-to-dest leaq -48(%rbp), -3264(%rbp)
	leaq -48(%rbp), %r15
	movq %r15, -3264(%rbp)
	# LowerAlloca(5220:3): size = 4, type = i32*, var = ^14
	# Fixing source-to-dest leaq -52(%rbp), -3272(%rbp)
	leaq -52(%rbp), %r15
	movq %r15, -3272(%rbp)
	# LowerAlloca(5221:3): size = 864, type = [8 x [9 x [3 x i32]]]*, var = ^15
	# Fixing source-to-dest leaq -928(%rbp), -3008(%rbp)
	leaq -928(%rbp), %r15
	movq %r15, -3008(%rbp)
	# LowerAlloca(5222:3): size = 8, type = ptr*, var = ^16
	leaq -936(%rbp), %rbx
	# LowerAlloca(5223:3): size = 480, type = [10 x [6 x %union.U2]]*, var = ^17
	# Fixing source-to-dest leaq -1424(%rbp), -3016(%rbp)
	leaq -1424(%rbp), %r15
	movq %r15, -3016(%rbp)
	# LowerAlloca(5224:3): size = 64, type = [8 x ptr]*, var = ^18
	# Fixing source-to-dest leaq -1488(%rbp), -3424(%rbp)
	leaq -1488(%rbp), %r15
	movq %r15, -3424(%rbp)
	# LowerAlloca(5225:3): size = 8, type = ptr*, var = ^19
	# Fixing source-to-dest leaq -1496(%rbp), -3472(%rbp)
	leaq -1496(%rbp), %r15
	movq %r15, -3472(%rbp)
	# LowerAlloca(5226:3): size = 8, type = ptr*, var = ^20
	# Fixing source-to-dest leaq -1504(%rbp), -3432(%rbp)
	leaq -1504(%rbp), %r15
	movq %r15, -3432(%rbp)
	# LowerAlloca(5227:3): size = 8, type = ptr*, var = ^21
	# Fixing source-to-dest leaq -1512(%rbp), -3440(%rbp)
	leaq -1512(%rbp), %r15
	movq %r15, -3440(%rbp)
	# LowerAlloca(5228:3): size = 8, type = ptr*, var = ^22
	# Fixing source-to-dest leaq -1520(%rbp), -3456(%rbp)
	leaq -1520(%rbp), %r15
	movq %r15, -3456(%rbp)
	# LowerAlloca(5229:3): size = 8, type = ptr*, var = ^23
	# Fixing source-to-dest leaq -1528(%rbp), -3408(%rbp)
	leaq -1528(%rbp), %r15
	movq %r15, -3408(%rbp)
	# LowerAlloca(5230:3): size = 8, type = [1 x ptr]*, var = ^24
	# Fixing source-to-dest leaq -1536(%rbp), -3416(%rbp)
	leaq -1536(%rbp), %r15
	movq %r15, -3416(%rbp)
	# LowerAlloca(5231:3): size = 8, type = ptr*, var = ^25
	# Fixing source-to-dest leaq -1544(%rbp), -3464(%rbp)
	leaq -1544(%rbp), %r15
	movq %r15, -3464(%rbp)
	# LowerAlloca(5232:3): size = 4, type = i32*, var = ^26
	# Fixing source-to-dest leaq -1548(%rbp), -3448(%rbp)
	leaq -1548(%rbp), %r15
	movq %r15, -3448(%rbp)
	# LowerAlloca(5233:3): size = 2, type = [1 x i16]*, var = ^27
	# Fixing source-to-dest leaq -1550(%rbp), -3032(%rbp)
	leaq -1550(%rbp), %r15
	movq %r15, -3032(%rbp)
	# LowerAlloca(5234:3): size = 1, type = i8*, var = ^28
	# Fixing source-to-dest leaq -1551(%rbp), -3480(%rbp)
	leaq -1551(%rbp), %r15
	movq %r15, -3480(%rbp)
	# LowerAlloca(5235:3): size = 2, type = %union.U4*, var = ^29
	# Fixing source-to-dest leaq -1554(%rbp), -3040(%rbp)
	leaq -1554(%rbp), %r15
	movq %r15, -3040(%rbp)
	# LowerAlloca(5236:3): size = 8, type = ptr*, var = ^30
	# Fixing source-to-dest leaq -1568(%rbp), -3024(%rbp)
	leaq -1568(%rbp), %r15
	movq %r15, -3024(%rbp)
	# LowerAlloca(5237:3): size = 4, type = i32*, var = ^31
	# Fixing source-to-dest leaq -1572(%rbp), -3400(%rbp)
	leaq -1572(%rbp), %r15
	movq %r15, -3400(%rbp)
	# LowerAlloca(5238:3): size = 4, type = i32*, var = ^32
	leaq -1576(%rbp), %rax
	# LowerAlloca(5239:3): size = 4, type = i32*, var = ^33
	leaq -1580(%rbp), %rax
	# LowerAlloca(5240:3): size = 4, type = i32*, var = ^34
	# Fixing source-to-dest leaq -1584(%rbp), -3280(%rbp)
	leaq -1584(%rbp), %r15
	movq %r15, -3280(%rbp)
	# LowerAlloca(5241:3): size = 640, type = [5 x [4 x [4 x i64]]]*, var = ^35
	# Fixing source-to-dest leaq -2224(%rbp), -3288(%rbp)
	leaq -2224(%rbp), %r15
	movq %r15, -3288(%rbp)
	# LowerAlloca(5242:3): size = 8, type = ptr*, var = ^36
	# Fixing source-to-dest leaq -2232(%rbp), -3296(%rbp)
	leaq -2232(%rbp), %r15
	movq %r15, -3296(%rbp)
	# LowerAlloca(5243:3): size = 8, type = ptr*, var = ^37
	# Fixing source-to-dest leaq -2240(%rbp), -3304(%rbp)
	leaq -2240(%rbp), %r15
	movq %r15, -3304(%rbp)
	# LowerAlloca(5244:3): size = 8, type = ptr*, var = ^38
	# Fixing source-to-dest leaq -2248(%rbp), -3312(%rbp)
	leaq -2248(%rbp), %r15
	movq %r15, -3312(%rbp)
	# LowerAlloca(5245:3): size = 8, type = ptr*, var = ^39
	# Fixing source-to-dest leaq -2256(%rbp), -3320(%rbp)
	leaq -2256(%rbp), %r15
	movq %r15, -3320(%rbp)
	# LowerAlloca(5246:3): size = 8, type = ptr*, var = ^40
	# Fixing source-to-dest leaq -2264(%rbp), -3328(%rbp)
	leaq -2264(%rbp), %r15
	movq %r15, -3328(%rbp)
	# LowerAlloca(5247:3): size = 8, type = ptr*, var = ^41
	# Fixing source-to-dest leaq -2272(%rbp), -3336(%rbp)
	leaq -2272(%rbp), %r15
	movq %r15, -3336(%rbp)
	# LowerAlloca(5248:3): size = 40, type = [5 x ptr]*, var = ^42
	# Fixing source-to-dest leaq -2320(%rbp), -3344(%rbp)
	leaq -2320(%rbp), %r15
	movq %r15, -3344(%rbp)
	# LowerAlloca(5249:3): size = 1, type = i8*, var = ^43
	# Fixing source-to-dest leaq -2321(%rbp), -3352(%rbp)
	leaq -2321(%rbp), %r15
	movq %r15, -3352(%rbp)
	# LowerAlloca(5250:3): size = 4, type = i32*, var = ^44
	leaq -2328(%rbp), %rax
	# LowerAlloca(5251:3): size = 4, type = i32*, var = ^45
	leaq -2332(%rbp), %rax
	# LowerAlloca(5252:3): size = 4, type = i32*, var = ^46
	leaq -2336(%rbp), %rax
	# LowerAlloca(5253:3): size = 2, type = %union.U3*, var = ^47
	# Fixing source-to-dest leaq -2338(%rbp), -3360(%rbp)
	leaq -2338(%rbp), %r15
	movq %r15, -3360(%rbp)
	# LowerAlloca(5254:3): size = 40, type = [5 x ptr]*, var = ^48
	# Fixing source-to-dest leaq -2384(%rbp), -3368(%rbp)
	leaq -2384(%rbp), %r15
	movq %r15, -3368(%rbp)
	# LowerAlloca(5255:3): size = 8, type = [1 x ptr]*, var = ^49
	# Fixing source-to-dest leaq -2392(%rbp), -3376(%rbp)
	leaq -2392(%rbp), %r15
	movq %r15, -3376(%rbp)
	# LowerAlloca(5256:3): size = 8, type = ptr*, var = ^50
	# Fixing source-to-dest leaq -2400(%rbp), -3384(%rbp)
	leaq -2400(%rbp), %r15
	movq %r15, -3384(%rbp)
	# LowerAlloca(5257:3): size = 4, type = i32*, var = ^51
	# Fixing source-to-dest leaq -2404(%rbp), -3392(%rbp)
	leaq -2404(%rbp), %r15
	movq %r15, -3392(%rbp)
	# LowerAlloca(5258:3): size = 8, type = ptr*, var = ^52
	# Fixing source-to-dest leaq -2416(%rbp), -3048(%rbp)
	leaq -2416(%rbp), %r15
	movq %r15, -3048(%rbp)
	# LowerAlloca(5259:3): size = 8, type = ptr*, var = ^53
	# Fixing source-to-dest leaq -2424(%rbp), -3056(%rbp)
	leaq -2424(%rbp), %r15
	movq %r15, -3056(%rbp)
	# LowerAlloca(5260:3): size = 48, type = [6 x ptr]*, var = ^54
	# Fixing source-to-dest leaq -2480(%rbp), -3064(%rbp)
	leaq -2480(%rbp), %r15
	movq %r15, -3064(%rbp)
	# LowerAlloca(5261:3): size = 8, type = ptr*, var = ^55
	# Fixing source-to-dest leaq -2488(%rbp), -3072(%rbp)
	leaq -2488(%rbp), %r15
	movq %r15, -3072(%rbp)
	# LowerAlloca(5262:3): size = 8, type = ptr*, var = ^56
	# Fixing source-to-dest leaq -2496(%rbp), -3080(%rbp)
	leaq -2496(%rbp), %r15
	movq %r15, -3080(%rbp)
	# LowerAlloca(5263:3): size = 8, type = ptr*, var = ^57
	# Fixing source-to-dest leaq -2504(%rbp), -3088(%rbp)
	leaq -2504(%rbp), %r15
	movq %r15, -3088(%rbp)
	# LowerAlloca(5264:3): size = 4, type = i32*, var = ^58
	# Fixing source-to-dest leaq -2508(%rbp), -3096(%rbp)
	leaq -2508(%rbp), %r15
	movq %r15, -3096(%rbp)
	# LowerAlloca(5265:3): size = 8, type = ptr*, var = ^59
	# Fixing source-to-dest leaq -2520(%rbp), -3104(%rbp)
	leaq -2520(%rbp), %r15
	movq %r15, -3104(%rbp)
	# LowerAlloca(5266:3): size = 8, type = ptr*, var = ^60
	# Fixing source-to-dest leaq -2528(%rbp), -3112(%rbp)
	leaq -2528(%rbp), %r15
	movq %r15, -3112(%rbp)
	# LowerAlloca(5267:3): size = 8, type = ptr*, var = ^61
	# Fixing source-to-dest leaq -2536(%rbp), -3120(%rbp)
	leaq -2536(%rbp), %r15
	movq %r15, -3120(%rbp)
	# LowerAlloca(5268:3): size = 8, type = %union.U2*, var = ^62
	# Fixing source-to-dest leaq -2544(%rbp), -3128(%rbp)
	leaq -2544(%rbp), %r15
	movq %r15, -3128(%rbp)
	# LowerAlloca(5269:3): size = 8, type = ptr*, var = ^63
	# Fixing source-to-dest leaq -2552(%rbp), -3136(%rbp)
	leaq -2552(%rbp), %r15
	movq %r15, -3136(%rbp)
	# LowerAlloca(5270:3): size = 2, type = %union.U3*, var = ^64
	# Fixing source-to-dest leaq -2554(%rbp), -3144(%rbp)
	leaq -2554(%rbp), %r15
	movq %r15, -3144(%rbp)
	# LowerAlloca(5271:3): size = 2, type = %union.U4*, var = ^65
	# Fixing source-to-dest leaq -2556(%rbp), -3152(%rbp)
	leaq -2556(%rbp), %r15
	movq %r15, -3152(%rbp)
	# LowerAlloca(5272:3): size = 18, type = [9 x [1 x %union.U1]]*, var = ^66
	# Fixing source-to-dest leaq -2576(%rbp), -3160(%rbp)
	leaq -2576(%rbp), %r15
	movq %r15, -3160(%rbp)
	# LowerAlloca(5273:3): size = 8, type = ptr*, var = ^67
	# Fixing source-to-dest leaq -2584(%rbp), -3168(%rbp)
	leaq -2584(%rbp), %r15
	movq %r15, -3168(%rbp)
	# LowerAlloca(5274:3): size = 80, type = [10 x ptr]*, var = ^68
	# Fixing source-to-dest leaq -2672(%rbp), -3176(%rbp)
	leaq -2672(%rbp), %r15
	movq %r15, -3176(%rbp)
	# LowerAlloca(5275:3): size = 8, type = ptr*, var = ^69
	# Fixing source-to-dest leaq -2680(%rbp), -3184(%rbp)
	leaq -2680(%rbp), %r15
	movq %r15, -3184(%rbp)
	# LowerAlloca(5276:3): size = 288, type = [6 x [1 x [6 x ptr]]]*, var = ^70
	# Fixing source-to-dest leaq -2976(%rbp), -3192(%rbp)
	leaq -2976(%rbp), %r15
	movq %r15, -3192(%rbp)
	# LowerAlloca(5277:3): size = 4, type = i32*, var = ^71
	# Fixing source-to-dest leaq -2980(%rbp), -3200(%rbp)
	leaq -2980(%rbp), %r15
	movq %r15, -3200(%rbp)
	# LowerAlloca(5278:3): size = 4, type = i32*, var = ^72
	leaq -2984(%rbp), %rax
	# LowerAlloca(5279:3): size = 4, type = i32*, var = ^73
	leaq -2988(%rbp), %rax
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5280:3): struct-type: ptr ^7 -> ^74, indices=0,0
	movq -3216(%rbp), %rax
	# LowerGetelementptr(5280:3): type of ^74 is i64*
	# LowerStore(5281:3).9: mov i64 %r8, (^74)
	movq %r8, (%rax)
	# LowerStore(5282:3).9: mov i64 %rdi, (^8)
	movq -3224(%rbp), %rax
	movq %rdi, (%rax)
	# LowerStore(5284:3).9: mov i8 %sil, (^9)
	movq -3232(%rbp), %rax
	movb %sil, (%rax)
	# LowerStore(5286:3).9: mov i32 %edx, (^10)
	movq -3240(%rbp), %rax
	movl %edx, (%rax)
	# LowerStore(5288:3).9: mov i16 %cx, (^11)
	movq -3248(%rbp), %rax
	movw %cx, (%rax)
	# LowerStore(5293:3).6: load global
	leaq _ZL4g_91(%rip), %rcx
	# LowerStore(5293:3).9: mov ptr ^465, (^13)
	movq -3264(%rbp), %rax
	movq %rcx, (%rax)
	# LowerStore(5295:3).3: mov $imm, (^14)
	movq -3272(%rbp), %rax
	movl $118983987, (%rax)
	# SetupCalls(5297:3): move argument ptr align 16 ^15
	# Fixed movzx with identical source and destination widths
	movq -3008(%rbp), %rdi
	# SetupCalls(5297:3): move argument ptr align 16 @__const._ZL7func_57majs2U2.l_116
	leaq __const._ZL7func_57majs2U2.l_116(%rip), %rsi
	# SetupCalls(5297:3): move argument i64 864
	movq $864, %rdx
	callq memcpy@PLT
	# tt = Pointer, type = [8 x [9 x [3 x i32]]]
	# LowerGetelementptr(5299:3): struct-type: ptr ^15 -> ^75, indices=0,7
	movq -3008(%rbp), %rax
	addq $756, %rax
	# LowerGetelementptr(5299:3): type of ^75 is [9 x [3 x i32]]*
	# tt = Pointer, type = [9 x [3 x i32]]
	# LowerGetelementptr(5300:3): struct-type: ptr ^75 -> ^76, indices=0,4
	movq %rax, %rcx
	addq $48, %rcx
	# LowerGetelementptr(5300:3): type of ^76 is [3 x i32]*
	# tt = Pointer, type = [3 x i32]
	# LowerGetelementptr(5301:3): struct-type: ptr ^76 -> ^77, indices=0,1
	movq %rcx, %rax
	addq $4, %rax
	# LowerGetelementptr(5301:3): type of ^77 is i32*
	# LowerStore(5302:3).9: mov [3 x i32]* ^77, (^16)
	movq %rax, (%rbx)
	# tt = Pointer, type = [10 x [6 x %union.U2]]
	# LowerGetelementptr(5304:3): struct-type: ptr ^17 -> ^78, indices=0,0
	movq -3016(%rbp), %rax
	# LowerGetelementptr(5304:3): type of ^78 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5305:3): struct-type: ptr ^78 -> ^79, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5305:3): type of ^79 is %union.U2*
	# LowerStore(5306:3).3: mov $imm, (^79)
	movq $-1, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5307:3): struct-type: ptr ^79 -> ^80, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5307:3): type of ^80 is %union.U2*
	# LowerStore(5308:3).3: mov $imm, (^80)
	movabsq $8465845472384687599, %rbx
	movq %rbx, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5309:3): struct-type: ptr ^80 -> ^81, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5309:3): type of ^81 is %union.U2*
	# LowerStore(5310:3).3: mov $imm, (^81)
	movabsq $9057255019317769000, %rcx
	movq %rcx, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5311:3): struct-type: ptr ^81 -> ^82, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5311:3): type of ^82 is %union.U2*
	# LowerStore(5312:3).3: mov $imm, (^82)
	movabsq $5257880311641606578, %rbx
	movq %rbx, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5313:3): struct-type: ptr ^82 -> ^83, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5313:3): type of ^83 is %union.U2*
	# LowerStore(5314:3).3: mov $imm, (^83)
	movabsq $5257880311641606578, %rcx
	movq %rcx, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5315:3): struct-type: ptr ^83 -> ^84, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5315:3): type of ^84 is %union.U2*
	# LowerStore(5316:3).3: mov $imm, (^84)
	movabsq $9057255019317769000, %rbx
	movq %rbx, (%rcx)
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5317:3): struct-type: ptr ^78 -> ^85, indices=1
	movq %rax, %rbx
	addq $48, %rbx
	# LowerGetelementptr(5317:3): type of ^85 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5318:3): struct-type: ptr ^85 -> ^86, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5318:3): type of ^86 is %union.U2*
	# LowerStore(5319:3).3: mov $imm, (^86)
	movq $-1, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5320:3): struct-type: ptr ^86 -> ^87, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5320:3): type of ^87 is %union.U2*
	# LowerStore(5321:3).3: mov $imm, (^87)
	movq $-1, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5322:3): struct-type: ptr ^87 -> ^88, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5322:3): type of ^88 is %union.U2*
	# LowerStore(5323:3).3: mov $imm, (^88)
	movq $-1, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5324:3): struct-type: ptr ^88 -> ^89, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5324:3): type of ^89 is %union.U2*
	# LowerStore(5325:3).3: mov $imm, (^89)
	movabsq $-8666319007712456100, %rax
	movq %rax, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5326:3): struct-type: ptr ^89 -> ^90, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5326:3): type of ^90 is %union.U2*
	# LowerStore(5327:3).3: mov $imm, (^90)
	movq $-1, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5328:3): struct-type: ptr ^90 -> ^91, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5328:3): type of ^91 is %union.U2*
	# LowerStore(5329:3).3: mov $imm, (^91)
	movabsq $5257880311641606578, %rax
	movq %rax, (%rcx)
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5330:3): struct-type: ptr ^85 -> ^92, indices=1
	movq %rbx, %rcx
	addq $48, %rcx
	# LowerGetelementptr(5330:3): type of ^92 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5331:3): struct-type: ptr ^92 -> ^93, indices=0,0
	movq %rcx, %rax
	# LowerGetelementptr(5331:3): type of ^93 is %union.U2*
	# LowerStore(5332:3).3: mov $imm, (^93)
	movq $-1, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5333:3): struct-type: ptr ^93 -> ^94, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5333:3): type of ^94 is %union.U2*
	# LowerStore(5334:3).3: mov $imm, (^94)
	movabsq $-5531817056347653028, %rax
	movq %rax, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5335:3): struct-type: ptr ^94 -> ^95, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5335:3): type of ^95 is %union.U2*
	# LowerStore(5336:3).3: mov $imm, (^95)
	movabsq $8465845472384687599, %rbx
	movq %rbx, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5337:3): struct-type: ptr ^95 -> ^96, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5337:3): type of ^96 is %union.U2*
	# LowerStore(5338:3).3: mov $imm, (^96)
	movabsq $-8666319007712456100, %rax
	movq %rax, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5339:3): struct-type: ptr ^96 -> ^97, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5339:3): type of ^97 is %union.U2*
	# LowerStore(5340:3).3: mov $imm, (^97)
	movabsq $-5531817056347653028, %rbx
	movq %rbx, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5341:3): struct-type: ptr ^97 -> ^98, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5341:3): type of ^98 is %union.U2*
	# LowerStore(5342:3).3: mov $imm, (^98)
	movq $-1, (%rbx)
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5343:3): struct-type: ptr ^92 -> ^99, indices=1
	movq %rcx, %rax
	addq $48, %rax
	# LowerGetelementptr(5343:3): type of ^99 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5344:3): struct-type: ptr ^99 -> ^100, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5344:3): type of ^100 is %union.U2*
	# LowerStore(5345:3).3: mov $imm, (^100)
	movq $-1, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5346:3): struct-type: ptr ^100 -> ^101, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5346:3): type of ^101 is %union.U2*
	# LowerStore(5347:3).3: mov $imm, (^101)
	movq $-1, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5348:3): struct-type: ptr ^101 -> ^102, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5348:3): type of ^102 is %union.U2*
	# LowerStore(5349:3).3: mov $imm, (^102)
	movabsq $8465845472384687599, %rcx
	movq %rcx, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5350:3): struct-type: ptr ^102 -> ^103, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5350:3): type of ^103 is %union.U2*
	# LowerStore(5351:3).3: mov $imm, (^103)
	movq $-1, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5352:3): struct-type: ptr ^103 -> ^104, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5352:3): type of ^104 is %union.U2*
	# LowerStore(5353:3).3: mov $imm, (^104)
	movq $-1, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5354:3): struct-type: ptr ^104 -> ^105, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5354:3): type of ^105 is %union.U2*
	# LowerStore(5355:3).3: mov $imm, (^105)
	movabsq $5257880311641606578, %rbx
	movq %rbx, (%rcx)
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5356:3): struct-type: ptr ^99 -> ^106, indices=1
	movq %rax, %rbx
	addq $48, %rbx
	# LowerGetelementptr(5356:3): type of ^106 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5357:3): struct-type: ptr ^106 -> ^107, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5357:3): type of ^107 is %union.U2*
	# LowerStore(5358:3).3: mov $imm, (^107)
	movabsq $-5217174645934436860, %rcx
	movq %rcx, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5359:3): struct-type: ptr ^107 -> ^108, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5359:3): type of ^108 is %union.U2*
	# LowerStore(5360:3).3: mov $imm, (^108)
	movq $-1, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5361:3): struct-type: ptr ^108 -> ^109, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5361:3): type of ^109 is %union.U2*
	# LowerStore(5362:3).3: mov $imm, (^109)
	movq $-1, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5363:3): struct-type: ptr ^109 -> ^110, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5363:3): type of ^110 is %union.U2*
	# LowerStore(5364:3).3: mov $imm, (^110)
	movabsq $-5217174645934436860, %rax
	movq %rax, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5365:3): struct-type: ptr ^110 -> ^111, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5365:3): type of ^111 is %union.U2*
	# LowerStore(5366:3).3: mov $imm, (^111)
	movabsq $-5531817056347653028, %rcx
	movq %rcx, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5367:3): struct-type: ptr ^111 -> ^112, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5367:3): type of ^112 is %union.U2*
	# LowerStore(5368:3).3: mov $imm, (^112)
	movq $8, (%rcx)
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5369:3): struct-type: ptr ^106 -> ^113, indices=1
	movq %rbx, %rax
	addq $48, %rax
	# LowerGetelementptr(5369:3): type of ^113 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5370:3): struct-type: ptr ^113 -> ^114, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5370:3): type of ^114 is %union.U2*
	# LowerStore(5371:3).3: mov $imm, (^114)
	movabsq $-5217174645934436860, %rcx
	movq %rcx, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5372:3): struct-type: ptr ^114 -> ^115, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5372:3): type of ^115 is %union.U2*
	# LowerStore(5373:3).3: mov $imm, (^115)
	movabsq $-5531817056347653028, %rbx
	movq %rbx, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5374:3): struct-type: ptr ^115 -> ^116, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5374:3): type of ^116 is %union.U2*
	# LowerStore(5375:3).3: mov $imm, (^116)
	movq $8, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5376:3): struct-type: ptr ^116 -> ^117, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5376:3): type of ^117 is %union.U2*
	# LowerStore(5377:3).3: mov $imm, (^117)
	movq $-1, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5378:3): struct-type: ptr ^117 -> ^118, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5378:3): type of ^118 is %union.U2*
	# LowerStore(5379:3).3: mov $imm, (^118)
	movq $-1, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5380:3): struct-type: ptr ^118 -> ^119, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5380:3): type of ^119 is %union.U2*
	# LowerStore(5381:3).3: mov $imm, (^119)
	movq $8, (%rcx)
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5382:3): struct-type: ptr ^113 -> ^120, indices=1
	movq %rax, %rbx
	addq $48, %rbx
	# LowerGetelementptr(5382:3): type of ^120 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5383:3): struct-type: ptr ^120 -> ^121, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5383:3): type of ^121 is %union.U2*
	# LowerStore(5384:3).3: mov $imm, (^121)
	movq $-1, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5385:3): struct-type: ptr ^121 -> ^122, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5385:3): type of ^122 is %union.U2*
	# LowerStore(5386:3).3: mov $imm, (^122)
	movq $-1, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5387:3): struct-type: ptr ^122 -> ^123, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5387:3): type of ^123 is %union.U2*
	# LowerStore(5388:3).3: mov $imm, (^123)
	movq $-1, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5389:3): struct-type: ptr ^123 -> ^124, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5389:3): type of ^124 is %union.U2*
	# LowerStore(5390:3).3: mov $imm, (^124)
	movabsq $-8666319007712456100, %rax
	movq %rax, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5391:3): struct-type: ptr ^124 -> ^125, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5391:3): type of ^125 is %union.U2*
	# LowerStore(5392:3).3: mov $imm, (^125)
	movq $-1, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5393:3): struct-type: ptr ^125 -> ^126, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5393:3): type of ^126 is %union.U2*
	# LowerStore(5394:3).3: mov $imm, (^126)
	movabsq $5257880311641606578, %rax
	movq %rax, (%rcx)
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5395:3): struct-type: ptr ^120 -> ^127, indices=1
	movq %rbx, %rax
	addq $48, %rax
	# LowerGetelementptr(5395:3): type of ^127 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5396:3): struct-type: ptr ^127 -> ^128, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5396:3): type of ^128 is %union.U2*
	# LowerStore(5397:3).3: mov $imm, (^128)
	movq $-1, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5398:3): struct-type: ptr ^128 -> ^129, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5398:3): type of ^129 is %union.U2*
	# LowerStore(5399:3).3: mov $imm, (^129)
	movabsq $-5531817056347653028, %rbx
	movq %rbx, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5400:3): struct-type: ptr ^129 -> ^130, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5400:3): type of ^130 is %union.U2*
	# LowerStore(5401:3).3: mov $imm, (^130)
	movabsq $8465845472384687599, %rcx
	movq %rcx, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5402:3): struct-type: ptr ^130 -> ^131, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5402:3): type of ^131 is %union.U2*
	# LowerStore(5403:3).3: mov $imm, (^131)
	movabsq $-8666319007712456100, %rbx
	movq %rbx, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5404:3): struct-type: ptr ^131 -> ^132, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5404:3): type of ^132 is %union.U2*
	# LowerStore(5405:3).3: mov $imm, (^132)
	movabsq $-5531817056347653028, %rcx
	movq %rcx, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5406:3): struct-type: ptr ^132 -> ^133, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5406:3): type of ^133 is %union.U2*
	# LowerStore(5407:3).3: mov $imm, (^133)
	movq $-1, (%rcx)
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5408:3): struct-type: ptr ^127 -> ^134, indices=1
	movq %rax, %rbx
	addq $48, %rbx
	# LowerGetelementptr(5408:3): type of ^134 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5409:3): struct-type: ptr ^134 -> ^135, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5409:3): type of ^135 is %union.U2*
	# LowerStore(5410:3).3: mov $imm, (^135)
	movq $-1, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5411:3): struct-type: ptr ^135 -> ^136, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5411:3): type of ^136 is %union.U2*
	# LowerStore(5412:3).3: mov $imm, (^136)
	movq $-1, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5413:3): struct-type: ptr ^136 -> ^137, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5413:3): type of ^137 is %union.U2*
	# LowerStore(5414:3).3: mov $imm, (^137)
	movabsq $8465845472384687599, %rcx
	movq %rcx, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5415:3): struct-type: ptr ^137 -> ^138, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5415:3): type of ^138 is %union.U2*
	# LowerStore(5416:3).3: mov $imm, (^138)
	movq $-1, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5417:3): struct-type: ptr ^138 -> ^139, indices=1
	movq %rcx, %rdx
	addq $8, %rdx
	# LowerGetelementptr(5417:3): type of ^139 is %union.U2*
	# LowerStore(5418:3).3: mov $imm, (^139)
	movq $-1, (%rdx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5419:3): struct-type: ptr ^139 -> ^140, indices=1
	movq %rdx, %rax
	addq $8, %rax
	# LowerGetelementptr(5419:3): type of ^140 is %union.U2*
	# LowerStore(5420:3).3: mov $imm, (^140)
	movabsq $5257880311641606578, %rcx
	movq %rcx, (%rax)
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5421:3): struct-type: ptr ^134 -> ^141, indices=1
	movq %rbx, %rax
	addq $48, %rax
	# LowerGetelementptr(5421:3): type of ^141 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5422:3): struct-type: ptr ^141 -> ^142, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5422:3): type of ^142 is %union.U2*
	# LowerStore(5423:3).3: mov $imm, (^142)
	movabsq $-5217174645934436860, %rax
	movq %rax, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5424:3): struct-type: ptr ^142 -> ^143, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5424:3): type of ^143 is %union.U2*
	# LowerStore(5425:3).3: mov $imm, (^143)
	movq $-1, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5426:3): struct-type: ptr ^143 -> ^144, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5426:3): type of ^144 is %union.U2*
	# LowerStore(5427:3).3: mov $imm, (^144)
	movq $-1, (%rbx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5428:3): struct-type: ptr ^144 -> ^145, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5428:3): type of ^145 is %union.U2*
	# LowerStore(5429:3).3: mov $imm, (^145)
	movabsq $-5217174645934436860, %rax
	movq %rax, (%rcx)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5430:3): struct-type: ptr ^145 -> ^146, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5430:3): type of ^146 is %union.U2*
	# LowerStore(5431:3).3: mov $imm, (^146)
	movabsq $-5531817056347653028, %rbx
	movq %rbx, (%rax)
	# tt = Pointer, type = %union.U2
	# LowerGetelementptr(5432:3): struct-type: ptr ^146 -> ^147, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5432:3): type of ^147 is %union.U2*
	# LowerStore(5433:3).3: mov $imm, (^147)
	movq $8, (%rbx)
	# LowerStore(5436:3).6: load global
	leaq _ZL4g_66(%rip), %rax
	# LowerStore(5436:3).9: mov ptr ^466, (^19)
	movq -3472(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(5438:3).6: load global
	leaq _ZL5g_367(%rip), %rax
	# LowerStore(5438:3).9: mov ptr ^467, (^20)
	movq -3432(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(5440:3).9: mov ptr* ^20, (^21)
	movq -3440(%rbp), %rax
	# Fixing source-to-dest movq -3432(%rbp), (%rax)
	movq -3432(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5442:3).9: mov ptr* ^21, (^22)
	movq -3456(%rbp), %rax
	# Fixing source-to-dest movq -3440(%rbp), (%rax)
	movq -3440(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5444:3).6: load global
	leaq _ZL5g_313(%rip), %rax
	# LowerStore(5444:3).9: mov ptr ^468, (^23)
	movq -3408(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(5447:3).3: mov $imm, (^25)
	movq -3464(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(5449:3).3: mov $imm, (^26)
	movq -3448(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(5452:3).3: mov $imm, (^28)
	movq -3480(%rbp), %rax
	movb $6, (%rax)
	# SetupCalls(5454:3): move argument ptr align 2 ^29
	# Fixed movzx with identical source and destination widths
	movq -3040(%rbp), %rdi
	# SetupCalls(5454:3): move argument ptr align 2 @__const._ZL7func_57majs2U2.l_572
	leaq __const._ZL7func_57majs2U2.l_572(%rip), %rsi
	# SetupCalls(5454:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	# LowerStore(5456:3).6: load global
	leaq _ZL4g_66(%rip), %rbx
	# LowerStore(5456:3).9: mov ptr ^469, (^30)
	movq -3024(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5460:3).3: mov $imm, (^31)
	movq -3400(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M750:
	# LowerLoad(5464:3).2: (^31) into i32 ^149
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5465:3): i32 ^149 vs. intlike 2
	cmpl $2, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M757
	jmp .___ZL7func_57majs2U2__M782
	.___ZL7func_57majs2U2__M757:
	# LowerLoad(5469:3).2: (^31) into i32 ^152
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [2 x i16]
	# LowerGetelementptr(5471:3): array/pointer-type, dynamic index -> ^154
	# index ^153 -> temp ^458
	movq %rbx, %rcx
	# Multiply temp ^458 by 2 start
	shlq $1, %rcx
	# Multiply end
	# temp ^458 -> operand ^154
	movq %rcx, %rax
	# Result ^154 += base pointer ^12
	addq -3256(%rbp), %rax
	# LowerStore(5472:3).3: mov $imm, (^154)
	movw $1, (%rax)
	# LowerLoad(5476:3).2: (^31) into i32 ^156
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(5477:3): ^156, 1 into i32 ^157
	addl $1, %eax
	# LowerStore(5478:3).9: mov i32 ^157, (^31)
	movq -3400(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL7func_57majs2U2__M750
	.___ZL7func_57majs2U2__M782:
	# LowerStore(5482:3).3: mov $imm, (^31)
	movq -3400(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M785:
	# LowerLoad(5486:3).2: (^31) into i32 ^160
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5487:3): i32 ^160 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M792
	jmp .___ZL7func_57majs2U2__M817
	.___ZL7func_57majs2U2__M792:
	# LowerLoad(5491:3).2: (^31) into i32 ^163
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [8 x ptr]
	# LowerGetelementptr(5493:3): array/pointer-type, dynamic index -> ^165
	# index ^164 -> temp ^459
	movq %rbx, %rcx
	# Multiply temp ^459 by 8 start
	shlq $3, %rcx
	# Multiply end
	# temp ^459 -> operand ^165
	movq %rcx, %rax
	# Result ^165 += base pointer ^18
	addq -3424(%rbp), %rax
	# LowerStore(5494:3).3: mov $imm, (^165)
	movq $0, (%rax)
	# LowerLoad(5498:3).2: (^31) into i32 ^167
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(5499:3): ^167, 1 into i32 ^168
	addl $1, %eax
	# LowerStore(5500:3).9: mov i32 ^168, (^31)
	movq -3400(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL7func_57majs2U2__M785
	.___ZL7func_57majs2U2__M817:
	# LowerStore(5504:3).3: mov $imm, (^31)
	movq -3400(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M820:
	# LowerLoad(5508:3).2: (^31) into i32 ^171
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5509:3): i32 ^171 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M827
	jmp .___ZL7func_57majs2U2__M852
	.___ZL7func_57majs2U2__M827:
	# LowerLoad(5513:3).2: (^31) into i32 ^174
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [1 x ptr]
	# LowerGetelementptr(5515:3): array/pointer-type, dynamic index -> ^176
	# index ^175 -> temp ^460
	movq %rbx, %rcx
	# Multiply temp ^460 by 8 start
	shlq $3, %rcx
	# Multiply end
	# temp ^460 -> operand ^176
	movq %rcx, %rax
	# Result ^176 += base pointer ^24
	addq -3416(%rbp), %rax
	# LowerStore(5516:3).9: mov ptr* ^23, (^176)
	# Fixing source-to-dest movq -3408(%rbp), (%rax)
	movq -3408(%rbp), %r15
	movq %r15, (%rax)
	# LowerLoad(5520:3).2: (^31) into i32 ^178
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(5521:3): ^178, 1 into i32 ^179
	addl $1, %eax
	# LowerStore(5522:3).9: mov i32 ^179, (^31)
	movq -3400(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL7func_57majs2U2__M820
	.___ZL7func_57majs2U2__M852:
	# LowerStore(5526:3).3: mov $imm, (^31)
	movq -3400(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M855:
	# LowerLoad(5530:3).2: (^31) into i32 ^182
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5531:3): i32 ^182 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M862
	jmp .___ZL7func_57majs2U2__M887
	.___ZL7func_57majs2U2__M862:
	# LowerLoad(5535:3).2: (^31) into i32 ^185
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [1 x i16]
	# LowerGetelementptr(5537:3): array/pointer-type, dynamic index -> ^187
	# index ^186 -> temp ^461
	movq %rbx, %rcx
	# Multiply temp ^461 by 2 start
	shlq $1, %rcx
	# Multiply end
	# temp ^461 -> operand ^187
	movq %rcx, %rax
	# Result ^187 += base pointer ^27
	addq -3032(%rbp), %rax
	# LowerStore(5538:3).3: mov $imm, (^187)
	movw $-13122, (%rax)
	# LowerLoad(5542:3).2: (^31) into i32 ^189
	movq -3400(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(5543:3): ^189, 1 into i32 ^190
	addl $1, %eax
	# LowerStore(5544:3).9: mov i32 ^190, (^31)
	movq -3400(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL7func_57majs2U2__M855
	.___ZL7func_57majs2U2__M887:
	# LowerStore(5548:3).3: mov $imm, (^7)
	movq -3216(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M890:
	# LowerLoad(5552:3).2: (^7) into i32 ^193
	movq -3216(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5553:3): i32 ^193 vs. intlike 1
	cmpl $1, %eax
	setle %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M897
	jmp .___ZL7func_57majs2U2__M1488
	.___ZL7func_57majs2U2__M897:
	# LowerStore(5558:3).3: mov $imm, (^34)
	movq -3280(%rbp), %rax
	movl $-1, (%rax)
	# SetupCalls(5560:3): move argument ptr align 16 ^35
	# Fixed movzx with identical source and destination widths
	movq -3288(%rbp), %rdi
	# SetupCalls(5560:3): move argument ptr align 16 @__const._ZL7func_57majs2U2.l_102
	leaq __const._ZL7func_57majs2U2.l_102(%rip), %rsi
	# SetupCalls(5560:3): move argument i64 640
	movq $640, %rdx
	callq memcpy@PLT
	# LowerStore(5562:3).9: mov i32* ^14, (^36)
	movq -3296(%rbp), %rax
	# Fixing source-to-dest movq -3272(%rbp), (%rax)
	movq -3272(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5564:3).9: mov i32* ^14, (^37)
	movq -3304(%rbp), %rax
	# Fixing source-to-dest movq -3272(%rbp), (%rax)
	movq -3272(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5566:3).9: mov i32* ^14, (^38)
	movq -3312(%rbp), %rax
	# Fixing source-to-dest movq -3272(%rbp), (%rax)
	movq -3272(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5568:3).9: mov i32* ^14, (^39)
	movq -3320(%rbp), %rax
	# Fixing source-to-dest movq -3272(%rbp), (%rax)
	movq -3272(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5570:3).3: mov $imm, (^40)
	movq -3328(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(5572:3).9: mov i32* ^14, (^41)
	movq -3336(%rbp), %rax
	# Fixing source-to-dest movq -3272(%rbp), (%rax)
	movq -3272(%rbp), %r15
	movq %r15, (%rax)
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5574:3): struct-type: ptr ^42 -> ^196, indices=0,0
	movq -3344(%rbp), %rax
	# LowerGetelementptr(5574:3): type of ^196 is ptr*
	# LowerStore(5575:3).9: mov i32* ^14, (^196)
	# Fixing source-to-dest movq -3272(%rbp), (%rax)
	movq -3272(%rbp), %r15
	movq %r15, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5576:3): struct-type: ptr ^196 -> ^197, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5576:3): type of ^197 is ptr*
	# LowerStore(5577:3).9: mov i32* ^14, (^197)
	# Fixing source-to-dest movq -3272(%rbp), (%rbx)
	movq -3272(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5578:3): struct-type: ptr ^197 -> ^198, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5578:3): type of ^198 is ptr*
	# LowerStore(5579:3).9: mov i32* ^14, (^198)
	# Fixing source-to-dest movq -3272(%rbp), (%rax)
	movq -3272(%rbp), %r15
	movq %r15, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5580:3): struct-type: ptr ^198 -> ^199, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5580:3): type of ^199 is ptr*
	# LowerStore(5581:3).9: mov i32* ^14, (^199)
	# Fixing source-to-dest movq -3272(%rbp), (%rbx)
	movq -3272(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5582:3): struct-type: ptr ^199 -> ^200, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5582:3): type of ^200 is ptr*
	# LowerStore(5583:3).9: mov i32* ^14, (^200)
	# Fixing source-to-dest movq -3272(%rbp), (%rax)
	movq -3272(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5585:3).3: mov $imm, (^43)
	movq -3352(%rbp), %rax
	movb $0, (%rax)
	# LowerStore(5589:3).2a: mov $imm, %temp
	movl $0, _ZL4g_66(%rip)
	# LowerStore(5589:3).2b: mov %temp, (global)
	.___ZL7func_57majs2U2__M977:
	# LowerLoad(5593:3).4: _ZL4g_66 into ^202
	movl _ZL4g_66(%rip), %eax
	# LowerIcmp(5594:3): i32 ^202 vs. intlike 1
	cmpl $1, %eax
	setbe %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M984
	jmp .___ZL7func_57majs2U2__M1448
	.___ZL7func_57majs2U2__M984:
	# SetupCalls(5599:3): move argument ptr align 2 ^47
	# Fixed movzx with identical source and destination widths
	movq -3360(%rbp), %rdi
	# SetupCalls(5599:3): move argument ptr align 2 @__const._ZL7func_57majs2U2.l_99
	leaq __const._ZL7func_57majs2U2.l_99(%rip), %rsi
	# SetupCalls(5599:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	# SetupCalls(5601:3): move argument ptr align 16 ^48
	# Fixed movzx with identical source and destination widths
	movq -3368(%rbp), %rdi
	# SetupCalls(5601:3): move argument ptr align 16 @__const._ZL7func_57majs2U2.l_104
	leaq __const._ZL7func_57majs2U2.l_104(%rip), %rsi
	# SetupCalls(5601:3): move argument i64 40
	movq $40, %rdx
	callq memcpy@PLT
	# LowerStore(5604:3).9: mov i32* ^14, (^50)
	movq -3384(%rbp), %rax
	# Fixing source-to-dest movq -3272(%rbp), (%rax)
	movq -3272(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5606:3).3: mov $imm, (^51)
	movq -3392(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M1039:
	# LowerLoad(5610:3).2: (^51) into i32 ^206
	movq -3392(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5611:3): i32 ^206 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M1046
	jmp .___ZL7func_57majs2U2__M1073
	.___ZL7func_57majs2U2__M1046:
	# LowerLoad(5615:3).2: (^51) into i32 ^209
	movq -3392(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [1 x ptr]
	# LowerGetelementptr(5617:3): array/pointer-type, dynamic index -> ^211
	# index ^210 -> temp ^462
	movq %rbx, %rcx
	# Multiply temp ^462 by 8 start
	shlq $3, %rcx
	# Multiply end
	# temp ^462 -> operand ^211
	movq %rcx, %rax
	# Result ^211 += base pointer ^49
	addq -3376(%rbp), %rax
	# LowerStore(5618:3).6: load global
	leaq _ZL5g_106(%rip), %rbx
	# LowerStore(5618:3).9: mov ptr ^471, (^211)
	movq %rbx, (%rax)
	# LowerLoad(5622:3).2: (^51) into i32 ^213
	movq -3392(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(5623:3): ^213, 1 into i32 ^214
	addl $1, %eax
	# LowerStore(5624:3).9: mov i32 ^214, (^51)
	movq -3392(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL7func_57majs2U2__M1039
	.___ZL7func_57majs2U2__M1073:
	# LowerLoad(5628:3).4: _ZL4g_66 into ^216
	# Fixing source-to-dest movl _ZL4g_66(%rip), -3488(%rbp)
	movl _ZL4g_66(%rip), %r15d
	movl %r15d, -3488(%rbp)
	# LowerLoad(5629:3).2: (^8) into i64 ^217
	movq -3224(%rbp), %rax
	movq (%rax), %r12
	# LowerLoad(5630:3).4: _ZL3g_2 into ^218
	movl _ZL3g_2(%rip), %r13d
	# LowerLoad(5631:3).2: (^13) into ptr ^219
	movq -3264(%rbp), %rax
	movq (%rax), %r14
	# LowerLoad(5632:3).2: (^34) into i32 ^220
	movq -3280(%rbp), %rbx
	movl (%rbx), %eax
	# LowerTrunc(5633:3): 32 to 16, move
	# LowerTrunc(5633:3): 32 to 16, apply mask
	andq $65535, %rax
	# LowerLoad(5634:3).2: (^7) into i32 ^222
	movq -3216(%rbp), %rcx
	movl (%rcx), %ebx
	movslq %ebx, %rcx
	# tt = Pointer, type = [2 x i16]
	# LowerGetelementptr(5636:3): array/pointer-type, dynamic index -> ^224
	# index ^223 -> temp ^463
	movq %rcx, %rdx
	# Multiply temp ^463 by 2 start
	shlq $1, %rdx
	# Multiply end
	# temp ^463 -> operand ^224
	movq %rdx, %rbx
	# Result ^224 += base pointer ^12
	addq -3256(%rbp), %rbx
	# LowerStore(5637:3).9: mov i16 ^221, (^224)
	movw %ax, (%rbx)
	movswl %ax, %ebx
	# LowerLoad(5639:3).2: (^34) into i32 ^226
	movq -3280(%rbp), %rcx
	movl (%rcx), %eax
	# LowerIcmp(5640:3): i32 ^226 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M1114
	.___ZL7func_57majs2U2__M1111:
	# MovePhi: intlike -> ^263 (in new block 502 whose parent is 215)
	movb $0, -3208(%rbp)
	jmp .___ZL7func_57majs2U2__M1315
	.___ZL7func_57majs2U2__M1114:
	# tt = Pointer, type = [5 x [4 x [4 x i64]]]
	# LowerGetelementptr(5644:3): struct-type: ptr ^35 -> ^229, indices=0,0
	movq -3288(%rbp), %rax
	# LowerGetelementptr(5644:3): type of ^229 is [4 x [4 x i64]]*
	# tt = Pointer, type = [4 x [4 x i64]]
	# LowerGetelementptr(5645:3): struct-type: ptr ^229 -> ^230, indices=0,1
	addq $32, %rax
	# LowerGetelementptr(5645:3): type of ^230 is [4 x i64]*
	# tt = Pointer, type = [4 x i64]
	# LowerGetelementptr(5646:3): struct-type: ptr ^230 -> ^231, indices=0,2
	movq %rax, %rcx
	addq $16, %rcx
	# LowerGetelementptr(5646:3): type of ^231 is i64*
	# LowerLoad(5647:3).2: (^231) into i64 ^232
	movq (%rcx), %rax
	# LowerLoad(5648:3).2: (^14) into i32 ^233
	movq -3272(%rbp), %rdx
	movl (%rdx), %ecx
	movslq %ecx, %rdx
	# LowerIcmp(5650:3): i64 ^232 vs. operand i64 ^234
	cmpq %rdx, %rax
	setb %al
	andq $1, %rax
	# LowerBasicConversion(5651:3): i64 ^235 -> i32 ^236
	movl %eax, %ecx
	# LowerLoad(5652:3).2: (^10) into i32 ^237
	movq -3240(%rbp), %rdx
	movl (%rdx), %eax
	# LowerIcmp(5653:3): i32 ^236 vs. operand i32 ^237
	cmpl %eax, %ecx
	setb %al
	andq $1, %rax
	# LowerBasicConversion(5654:3): i32 ^238 -> i64 ^239
	movq %rax, %rcx
	# LowerIcmp(5655:3): i64 ^239 vs. intlike 65535
	cmpq $65535, %rcx
	setae %al
	andq $1, %rax
	# LowerBasicConversion(5656:3): i64 ^240 -> i64 ^241
	movq %rax, %rcx
	# LowerLoad(5657:3).2: (^11) into i16 ^242
	movq -3248(%rbp), %rdx
	movw (%rdx), %ax
	movswq %ax, %rdx
	# Clobber %rdx
	movq %rdx, -3496(%rbp)
	# Clobber %rcx
	movq %rcx, -3504(%rbp)
	# SetupCalls(5659:3): move argument i64 ^241
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(5659:3): move argument i64 ^243
	# Fixed movzx with identical source and destination widths
	movq %rdx, %rsi
	callq _ZL25safe_sub_func_int64_t_s_sll
	# SetupCalls(5659:3): move i64 result from %rax
	movq %rax, %r15
	# Unclobber %rcx
	movq -3504(%rbp), %rcx
	# Unclobber %rdx
	movq -3496(%rbp), %rdx
	# LowerLoad(5660:3).2: (^9) into i8 ^245
	movq -3232(%rbp), %rcx
	movb (%rcx), %al
	movsbq %al, %rcx
	# LowerIcmp(5662:3): i64 ^244 vs. operand i64 ^246
	cmpq %rcx, %r15
	setge %al
	andq $1, %rax
	# LowerBasicConversion(5663:3): i64 ^247 -> i64 ^248
	movq %rax, %rcx
	# LowerLoad(5664:3).4: _ZL4g_66 into ^249
	movl _ZL4g_66(%rip), %eax
	# Clobber %rcx
	movq %rcx, -3504(%rbp)
	# Clobber %rax
	movq %rax, -3512(%rbp)
	# SetupCalls(5665:3): move argument i64 ^248
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(5665:3): move argument i32 ^249
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	callq _ZL28safe_rshift_func_int64_t_s_ulj
	# SetupCalls(5665:3): move i64 result from %rax
	movq %rax, %rax
	# Unclobber %rax
	movq -3512(%rbp), %rax
	# Unclobber %rcx
	movq -3504(%rbp), %rcx
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5666:3): struct-type: ptr ^48 -> ^251, indices=0,2
	movq -3368(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(5666:3): type of ^251 is ptr*
	# LowerLoad(5667:3).2: (^251) into ptr ^252
	movq (%rax), %rcx
	# LowerIcmp(5668:3): ptr ^252 vs. global _ZL4g_91
	leaq _ZL4g_91(%rip), %rax
	cmpq %rax, %rcx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(5669:3): ptr ^253 -> i8 ^254
	movb %al, %cl
	# Clobber %rcx
	movq %rcx, -3504(%rbp)
	# SetupCalls(5670:3): move argument i8 zeroext ^254
	movzbq %cl, %rdi
	andq $255, %rdi
	# SetupCalls(5670:3): move argument i8 zeroext -1
	movq $-1, %rsi
	andq $255, %rsi
	callq _ZL25safe_mul_func_uint8_t_u_uhh
	# SetupCalls(5670:3): move i8 result from %rax
	movb %al, %r15b
	# Unclobber %rcx
	movq -3504(%rbp), %rcx
	# LowerBasicConversion(5671:3): i8 ^255 -> i16 ^256
	movw %r15w, %ax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerStore(5672:3).8a: leaq var, %temp
	leaq _ZL5g_106(%rip), %rcx
	# LowerStore(5672:3).8b: movq ^256, (%temp)
	movw %ax, (%rcx)
	# LowerBasicConversion(5673:3): i16 ^256 -> i32 ^257
	movl %eax, %ecx
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerStore(5674:3).8a: leaq var, %temp
	leaq _ZL5g_107(%rip), %rax
	# LowerStore(5674:3).8b: movq ^257, (%temp)
	movl %ecx, (%rax)
	# LowerTrunc(5675:3): 32 to 16, move
	movw %cx, %dx
	# LowerTrunc(5675:3): 32 to 16, apply mask
	andq $65535, %rdx
	# LowerLoad(5676:3).2: (^7) into i32 ^259
	movq -3216(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rdx
	movq %rdx, -3496(%rbp)
	# Clobber %rcx
	movq %rcx, -3504(%rbp)
	# SetupCalls(5677:3): move argument i16 zeroext ^258
	movzwq %dx, %rdi
	andq $65535, %rdi
	# SetupCalls(5677:3): move argument i32 ^259
	# Fixed movzx with 32-bit source operand
	movl %ecx, %esi
	callq _ZL29safe_rshift_func_uint16_t_u_sti
	# SetupCalls(5677:3): move i16 result from %rax
	movw %ax, %r15w
	# Unclobber %rcx
	movq -3504(%rbp), %rcx
	# Unclobber %rdx
	movq -3496(%rbp), %rdx
	# LowerIcmp(5678:3): i16 ^260 vs. intlike 0
	cmpw $0, %r15w
	setne %al
	andq $1, %rax
	# MovePhi: ^261 -> ^263
	movb %al, -3208(%rbp)
	.___ZL7func_57majs2U2__M1315:
	# LowerBasicConversion(5683:3): i1 ^263 -> i32 ^264
	movl -3208(%rbp), %eax
	# Truncate value to 8 bits
	andl $255, %eax
	# LowerLoad(5684:3).4: _ZL3g_5 into ^265
	movl _ZL3g_5(%rip), %ecx
	# LowerIcmp(5685:3): i32 ^264 vs. operand i32 ^265
	cmpl %ecx, %eax
	setle %al
	andq $1, %rax
	# LowerBasicConversion(5686:3): i32 ^266 -> i32 ^267
	movl %eax, %ecx
	# LowerIcmp(5687:3): i32 ^225 vs. operand i32 ^267
	cmpl %ecx, %ebx
	sete %al
	andq $1, %rax
	# LowerBasicConversion(5688:3): i32 ^268 -> i32 ^269
	movl %eax, %ebx
	# LowerLoad(5689:3).2: (^9) into i8 ^270
	movq -3232(%rbp), %rcx
	movb (%rcx), %al
	movsbl %al, %ecx
	# LowerIcmp(5691:3): i32 ^269 vs. operand i32 ^271
	cmpl %ecx, %ebx
	setg %al
	andq $1, %rax
	# tt = Pointer, type = [5 x ptr]
	# LowerGetelementptr(5692:3): struct-type: ptr ^48 -> ^273, indices=0,1
	movq -3368(%rbp), %rax
	addq $8, %rax
	# LowerGetelementptr(5692:3): type of ^273 is ptr*
	# LowerLoad(5693:3).2: (^273) into ptr ^274
	movq (%rax), %rbx
	# LowerIcmp(5694:3): ptr ^219 vs. operand ptr ^274
	cmpq %rbx, %r14
	sete %al
	andq $1, %rax
	# LowerBasicConversion(5695:3): ptr ^275 -> i64 ^276
	movq %rax, %rbx
	# LowerIcmp(5696:3): i64 ^276 vs. intlike 8
	cmpq $8, %rbx
	sete %al
	andq $1, %rax
	# LowerBasicConversion(5697:3): i64 ^277 -> i32 ^278
	movl %eax, %ebx
	# LowerLoad(5698:3).2: (^14) into i32 ^279
	movq -3272(%rbp), %rcx
	movl (%rcx), %eax
	# LowerLogic(5700:3): ^278, ^279 into i32 ^280
	movl %ebx, %ecx
	andl %eax, %ecx
	# LowerLogic(5701:3): ^218, ^280 into i32 ^281
	movl %r13d, %eax
	xorl %ecx, %eax
	# LowerIcmp(5701:3): i64 ^217 vs. intlike 1
	cmpq $1, %r12
	sete %al
	andq $1, %rax
	# LowerBasicConversion(5702:3): i64 ^282 -> i32 ^283
	movl %eax, %ebx
	# LowerIcmp(5703:3): i32 ^216 vs. operand i32 ^283
	cmpl %ebx, -3488(%rbp)
	sete %al
	andq $1, %rax
	# LowerBasicConversion(5704:3): i32 ^284 -> i32 ^285
	movl %eax, %ebx
	# LowerLoad(5705:3).2: (^9) into i8 ^286
	movq -3232(%rbp), %rcx
	movb (%rcx), %al
	movsbl %al, %ecx
	# LowerIcmp(5707:3): i32 ^285 vs. operand i32 ^287
	cmpl %ecx, %ebx
	setg %al
	andq $1, %rax
	# LowerBasicConversion(5708:3): i32 ^288 -> i64 ^289
	movq %rax, %rbx
	# LowerLoad(5709:3).4: _ZL4g_91 into ^290
	movb _ZL4g_91(%rip), %al
	# LowerBasicConversion(5710:3): i8 ^290 -> i64 ^291
	movq %rax, %rcx
	# Truncate value to 8 bits
	andl $255, %ecx
	# Clobber %rcx
	movq %rcx, -3504(%rbp)
	# SetupCalls(5711:3): move argument i64 ^289
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(5711:3): move argument i64 ^291
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rsi
	callq _ZL25safe_mod_func_int64_t_s_sll
	# SetupCalls(5711:3): move i64 result from %rax
	movq %rax, %rbx
	# Unclobber %rcx
	movq -3504(%rbp), %rcx
	# LowerIcmp(5712:3): i64 ^292 vs. intlike 128
	cmpq $128, %rbx
	setne %al
	andq $1, %rax
	# LowerBasicConversion(5713:3): i64 ^293 -> i64 ^294
	movq %rax, %rbx
	# LowerIcmp(5714:3): i64 ^294 vs. intlike 0
	cmpq $0, %rbx
	setbe %al
	andq $1, %rax
	# LowerBasicConversion(5715:3): i64 ^295 -> i32 ^296
	movl %eax, %ebx
	# LowerLoad(5716:3).2: (^50) into ptr ^297
	movq -3384(%rbp), %rcx
	movq (%rcx), %rax
	# LowerStore(5717:3).9: mov i32 ^296, (^297)
	movl %ebx, (%rax)
	# LowerLoad(5721:3).4: _ZL4g_66 into ^299
	movl _ZL4g_66(%rip), %eax
	# LowerMath(5722:3): ^299, 1 into i32 ^300
	addl $1, %eax
	# LowerStore(5723:3).8a: leaq var, %temp
	leaq _ZL4g_66(%rip), %rbx
	# LowerStore(5723:3).8b: movq ^300, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL7func_57majs2U2__M977
	.___ZL7func_57majs2U2__M1448:
	# LowerLoad(5727:3).2: (^43) into i8 ^302
	movq -3352(%rbp), %rbx
	movb (%rbx), %al
	# LowerMath(5728:3): ^302, 1 into i8 ^303
	addb $1, %al
	# LowerStore(5729:3).9: mov i8 ^303, (^43)
	movq -3352(%rbp), %rbx
	movb %al, (%rbx)
	# LowerLoad(5730:3).2: (^9) into i8 ^304
	movq -3232(%rbp), %rbx
	movb (%rbx), %al
	movsbl %al, %ebx
	# LowerLoad(5732:3).4: _ZL5g_124 into ^306
	movw _ZL5g_124(%rip), %ax
	# LowerBasicConversion(5733:3): i16 ^306 -> i32 ^307
	# Truncate value to 16 bits
	andl $65535, %eax
	# LowerLogic(5735:3): ^307, ^305 into i32 ^308
	movl %eax, %ecx
	orl %ebx, %ecx
	# LowerTrunc(5735:3): 32 to 16, move
	movw %cx, %ax
	# LowerTrunc(5735:3): 32 to 16, apply mask
	andq $65535, %rax
	# LowerStore(5736:3).8a: leaq var, %temp
	leaq _ZL5g_124(%rip), %rbx
	# LowerStore(5736:3).8b: movq ^309, (%temp)
	movw %ax, (%rbx)
	# LowerLoad(5737:3).2: (^41) into ptr ^310
	movq -3336(%rbp), %rbx
	movq (%rbx), %rax
	# LowerStore(5738:3).3: mov $imm, (^310)
	movl $-5, (%rax)
	# LowerLoad(5742:3).2: (^7) into i32 ^312
	movq -3216(%rbp), %rax
	movl (%rax), %ebx
	# LowerMath(5743:3): ^312, 1 into i32 ^313
	addl $1, %ebx
	# LowerStore(5744:3).9: mov i32 ^313, (^7)
	movq -3216(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL7func_57majs2U2__M890
	.___ZL7func_57majs2U2__M1488:
	# LowerStore(5748:3).2a: mov $imm, %temp
	movw $0, _ZL5g_120(%rip)
	# LowerStore(5748:3).2b: mov %temp, (global)
	.___ZL7func_57majs2U2__M1493:
	# LowerLoad(5752:3).4: _ZL5g_120 into ^316
	movw _ZL5g_120(%rip), %ax
	movswl %ax, %ebx
	# LowerIcmp(5754:3): i32 ^317 vs. intlike 5
	cmpl $5, %ebx
	setg %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M1501
	jmp .___ZL7func_57majs2U2__M2240
	.___ZL7func_57majs2U2__M1501:
	# LowerStore(5759:3).6: load global
	leaq _ZL5g_124(%rip), %rbx
	# LowerStore(5759:3).9: mov ptr ^477, (^52)
	movq -3048(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5761:3).3: mov $imm, (^53)
	movq -3056(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(5764:3).6: load global
	leaq _ZL5g_140(%rip), %rbx
	# LowerStore(5764:3).9: mov ptr ^478, (^55)
	movq -3072(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5766:3).9: mov ptr* ^55, (^56)
	movq -3080(%rbp), %rax
	# Fixing source-to-dest movq -3072(%rbp), (%rax)
	movq -3072(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5768:3).9: mov ptr* ^56, (^57)
	movq -3088(%rbp), %rax
	# Fixing source-to-dest movq -3080(%rbp), (%rax)
	movq -3080(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5770:3).3: mov $imm, (^58)
	movq -3096(%rbp), %rax
	movl $1278886306, (%rax)
	# LowerStore(5772:3).6: load global
	leaq _ZL4g_91(%rip), %rbx
	# LowerStore(5772:3).9: mov ptr ^479, (^59)
	movq -3104(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5774:3).6: load global
	leaq _ZL5g_294(%rip), %rbx
	# LowerStore(5774:3).9: mov ptr ^480, (^60)
	movq -3112(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5776:3).6: load global
	leaq _ZL5g_132(%rip), %rbx
	# LowerStore(5776:3).9: mov ptr ^481, (^61)
	movq -3120(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5778:3).3: mov $imm, (^62)
	movq -3128(%rbp), %rax
	movq $-1, (%rax)
	# LowerStore(5780:3).9: mov i32* ^58, (^63)
	movq -3136(%rbp), %rax
	# Fixing source-to-dest movq -3096(%rbp), (%rax)
	movq -3096(%rbp), %r15
	movq %r15, (%rax)
	# SetupCalls(5782:3): move argument ptr align 2 ^64
	# Fixed movzx with identical source and destination widths
	movq -3144(%rbp), %rdi
	# SetupCalls(5782:3): move argument ptr align 2 @__const._ZL7func_57majs2U2.l_545
	leaq __const._ZL7func_57majs2U2.l_545(%rip), %rsi
	# SetupCalls(5782:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	# SetupCalls(5784:3): move argument ptr align 2 ^65
	# Fixed movzx with identical source and destination widths
	movq -3152(%rbp), %rdi
	# SetupCalls(5784:3): move argument ptr align 2 @__const._ZL7func_57majs2U2.l_571
	leaq __const._ZL7func_57majs2U2.l_571(%rip), %rsi
	# SetupCalls(5784:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT
	# tt = Pointer, type = [9 x [1 x %union.U1]]
	# LowerGetelementptr(5786:3): struct-type: ptr ^66 -> ^320, indices=0,0
	movq -3160(%rbp), %rax
	# LowerGetelementptr(5786:3): type of ^320 is [1 x %union.U1]*
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5787:3): struct-type: ptr ^320 -> ^321, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5787:3): type of ^321 is %union.U1*
	# LowerStore(5788:3).3: mov $imm, (^321)
	movb $-80, (%rbx)
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5789:3): struct-type: ptr ^320 -> ^322, indices=1
	movq %rax, %rbx
	addq $2, %rbx
	# LowerGetelementptr(5789:3): type of ^322 is [1 x %union.U1]*
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5790:3): struct-type: ptr ^322 -> ^323, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5790:3): type of ^323 is %union.U1*
	# LowerStore(5791:3).3: mov $imm, (^323)
	movb $-80, (%rax)
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5792:3): struct-type: ptr ^322 -> ^324, indices=1
	movq %rbx, %rax
	addq $2, %rax
	# LowerGetelementptr(5792:3): type of ^324 is [1 x %union.U1]*
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5793:3): struct-type: ptr ^324 -> ^325, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5793:3): type of ^325 is %union.U1*
	# LowerStore(5794:3).3: mov $imm, (^325)
	movb $-80, (%rbx)
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5795:3): struct-type: ptr ^324 -> ^326, indices=1
	movq %rax, %rbx
	addq $2, %rbx
	# LowerGetelementptr(5795:3): type of ^326 is [1 x %union.U1]*
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5796:3): struct-type: ptr ^326 -> ^327, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5796:3): type of ^327 is %union.U1*
	# LowerStore(5797:3).3: mov $imm, (^327)
	movb $-80, (%rax)
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5798:3): struct-type: ptr ^326 -> ^328, indices=1
	movq %rbx, %rax
	addq $2, %rax
	# LowerGetelementptr(5798:3): type of ^328 is [1 x %union.U1]*
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5799:3): struct-type: ptr ^328 -> ^329, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5799:3): type of ^329 is %union.U1*
	# LowerStore(5800:3).3: mov $imm, (^329)
	movb $-80, (%rbx)
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5801:3): struct-type: ptr ^328 -> ^330, indices=1
	movq %rax, %rbx
	addq $2, %rbx
	# LowerGetelementptr(5801:3): type of ^330 is [1 x %union.U1]*
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5802:3): struct-type: ptr ^330 -> ^331, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5802:3): type of ^331 is %union.U1*
	# LowerStore(5803:3).3: mov $imm, (^331)
	movb $-80, (%rax)
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5804:3): struct-type: ptr ^330 -> ^332, indices=1
	movq %rbx, %rax
	addq $2, %rax
	# LowerGetelementptr(5804:3): type of ^332 is [1 x %union.U1]*
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5805:3): struct-type: ptr ^332 -> ^333, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5805:3): type of ^333 is %union.U1*
	# LowerStore(5806:3).3: mov $imm, (^333)
	movb $-80, (%rbx)
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5807:3): struct-type: ptr ^332 -> ^334, indices=1
	movq %rax, %rbx
	addq $2, %rbx
	# LowerGetelementptr(5807:3): type of ^334 is [1 x %union.U1]*
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5808:3): struct-type: ptr ^334 -> ^335, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5808:3): type of ^335 is %union.U1*
	# LowerStore(5809:3).3: mov $imm, (^335)
	movb $-80, (%rax)
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5810:3): struct-type: ptr ^334 -> ^336, indices=1
	movq %rbx, %rax
	addq $2, %rax
	# LowerGetelementptr(5810:3): type of ^336 is [1 x %union.U1]*
	# tt = Pointer, type = [1 x %union.U1]
	# LowerGetelementptr(5811:3): struct-type: ptr ^336 -> ^337, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5811:3): type of ^337 is %union.U1*
	# LowerStore(5812:3).3: mov $imm, (^337)
	movb $-80, (%rbx)
	# LowerStore(5814:3).9: mov %union.U4* ^29, (^67)
	movq -3168(%rbp), %rax
	# Fixing source-to-dest movq -3040(%rbp), (%rax)
	movq -3040(%rbp), %r15
	movq %r15, (%rax)
	# tt = Pointer, type = [10 x ptr]
	# LowerGetelementptr(5816:3): struct-type: ptr ^68 -> ^338, indices=0,0
	movq -3176(%rbp), %rax
	# LowerGetelementptr(5816:3): type of ^338 is ptr*
	# tt = Pointer, type = [10 x [6 x %union.U2]]
	# LowerGetelementptr(5817:3): struct-type: ptr ^17 -> ^339, indices=0,9
	movq -3016(%rbp), %rbx
	addq $432, %rbx
	# LowerGetelementptr(5817:3): type of ^339 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5818:3): struct-type: ptr ^339 -> ^340, indices=0,1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5818:3): type of ^340 is %union.U2*
	# LowerStore(5819:3).9: mov [6 x %union.U2]* ^340, (^338)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5820:3): struct-type: ptr ^338 -> ^341, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5820:3): type of ^341 is ptr*
	# tt = Pointer, type = [10 x [6 x %union.U2]]
	# LowerGetelementptr(5821:3): struct-type: ptr ^17 -> ^342, indices=0,9
	movq -3016(%rbp), %rax
	addq $432, %rax
	# LowerGetelementptr(5821:3): type of ^342 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5822:3): struct-type: ptr ^342 -> ^343, indices=0,1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5822:3): type of ^343 is %union.U2*
	# LowerStore(5823:3).9: mov [6 x %union.U2]* ^343, (^341)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5824:3): struct-type: ptr ^341 -> ^344, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5824:3): type of ^344 is ptr*
	# LowerStore(5825:3).3: mov $imm, (^344)
	movq $0, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5826:3): struct-type: ptr ^344 -> ^345, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5826:3): type of ^345 is ptr*
	# tt = Pointer, type = [10 x [6 x %union.U2]]
	# LowerGetelementptr(5827:3): struct-type: ptr ^17 -> ^346, indices=0,9
	movq -3016(%rbp), %rax
	addq $432, %rax
	# LowerGetelementptr(5827:3): type of ^346 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5828:3): struct-type: ptr ^346 -> ^347, indices=0,1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5828:3): type of ^347 is %union.U2*
	# LowerStore(5829:3).9: mov [6 x %union.U2]* ^347, (^345)
	movq %rbx, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5830:3): struct-type: ptr ^345 -> ^348, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5830:3): type of ^348 is ptr*
	# tt = Pointer, type = [10 x [6 x %union.U2]]
	# LowerGetelementptr(5831:3): struct-type: ptr ^17 -> ^349, indices=0,9
	movq -3016(%rbp), %rcx
	addq $432, %rcx
	# LowerGetelementptr(5831:3): type of ^349 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5832:3): struct-type: ptr ^349 -> ^350, indices=0,1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5832:3): type of ^350 is %union.U2*
	# LowerStore(5833:3).9: mov [6 x %union.U2]* ^350, (^348)
	movq %rax, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5834:3): struct-type: ptr ^348 -> ^351, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5834:3): type of ^351 is ptr*
	# LowerStore(5835:3).3: mov $imm, (^351)
	movq $0, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5836:3): struct-type: ptr ^351 -> ^352, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5836:3): type of ^352 is ptr*
	# tt = Pointer, type = [10 x [6 x %union.U2]]
	# LowerGetelementptr(5837:3): struct-type: ptr ^17 -> ^353, indices=0,9
	movq -3016(%rbp), %rax
	addq $432, %rax
	# LowerGetelementptr(5837:3): type of ^353 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5838:3): struct-type: ptr ^353 -> ^354, indices=0,1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5838:3): type of ^354 is %union.U2*
	# LowerStore(5839:3).9: mov [6 x %union.U2]* ^354, (^352)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5840:3): struct-type: ptr ^352 -> ^355, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5840:3): type of ^355 is ptr*
	# tt = Pointer, type = [10 x [6 x %union.U2]]
	# LowerGetelementptr(5841:3): struct-type: ptr ^17 -> ^356, indices=0,9
	movq -3016(%rbp), %rbx
	addq $432, %rbx
	# LowerGetelementptr(5841:3): type of ^356 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5842:3): struct-type: ptr ^356 -> ^357, indices=0,1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5842:3): type of ^357 is %union.U2*
	# LowerStore(5843:3).9: mov [6 x %union.U2]* ^357, (^355)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5844:3): struct-type: ptr ^355 -> ^358, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5844:3): type of ^358 is ptr*
	# LowerStore(5845:3).3: mov $imm, (^358)
	movq $0, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5846:3): struct-type: ptr ^358 -> ^359, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5846:3): type of ^359 is ptr*
	# tt = Pointer, type = [10 x [6 x %union.U2]]
	# LowerGetelementptr(5847:3): struct-type: ptr ^17 -> ^360, indices=0,9
	movq -3016(%rbp), %rbx
	addq $432, %rbx
	# LowerGetelementptr(5847:3): type of ^360 is [6 x %union.U2]*
	# tt = Pointer, type = [6 x %union.U2]
	# LowerGetelementptr(5848:3): struct-type: ptr ^360 -> ^361, indices=0,1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5848:3): type of ^361 is %union.U2*
	# LowerStore(5849:3).9: mov [6 x %union.U2]* ^361, (^359)
	movq %rcx, (%rax)
	# LowerStore(5851:3).6: load global
	leaq _ZL4g_66(%rip), %rbx
	# LowerStore(5851:3).9: mov ptr ^482, (^69)
	movq -3184(%rbp), %rax
	movq %rbx, (%rax)
	# tt = Pointer, type = [6 x [1 x [6 x ptr]]]
	# LowerGetelementptr(5853:3): struct-type: ptr ^70 -> ^362, indices=0,0
	movq -3192(%rbp), %rbx
	# LowerGetelementptr(5853:3): type of ^362 is [1 x [6 x ptr]]*
	# tt = Pointer, type = [1 x [6 x ptr]]
	# LowerGetelementptr(5854:3): struct-type: ptr ^362 -> ^363, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5854:3): type of ^363 is [6 x ptr]*
	# tt = Pointer, type = [6 x ptr]
	# LowerGetelementptr(5855:3): struct-type: ptr ^363 -> ^364, indices=0,0
	# LowerGetelementptr(5855:3): type of ^364 is ptr*
	# LowerStore(5856:3).6: load global
	leaq _ZL5g_313(%rip), %rcx
	# LowerStore(5856:3).9: mov ptr ^483, (^364)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5857:3): struct-type: ptr ^364 -> ^365, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5857:3): type of ^365 is ptr*
	# LowerStore(5858:3).9: mov %union.U4* ^65, (^365)
	# Fixing source-to-dest movq -3152(%rbp), (%rcx)
	movq -3152(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5859:3): struct-type: ptr ^365 -> ^366, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5859:3): type of ^366 is ptr*
	# LowerStore(5860:3).6: load global
	leaq _ZL5g_106(%rip), %rcx
	# LowerStore(5860:3).9: mov ptr ^484, (^366)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5861:3): struct-type: ptr ^366 -> ^367, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5861:3): type of ^367 is ptr*
	# LowerStore(5862:3).9: mov %union.U4* ^29, (^367)
	# Fixing source-to-dest movq -3040(%rbp), (%rcx)
	movq -3040(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5863:3): struct-type: ptr ^367 -> ^368, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5863:3): type of ^368 is ptr*
	# LowerStore(5864:3).6: load global
	leaq _ZL5g_106(%rip), %rcx
	# LowerStore(5864:3).9: mov ptr ^485, (^368)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5865:3): struct-type: ptr ^368 -> ^369, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5865:3): type of ^369 is ptr*
	# LowerStore(5866:3).9: mov %union.U4* ^65, (^369)
	# Fixing source-to-dest movq -3152(%rbp), (%rcx)
	movq -3152(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = [1 x [6 x ptr]]
	# LowerGetelementptr(5867:3): struct-type: ptr ^362 -> ^370, indices=1
	movq %rbx, %rax
	addq $48, %rax
	# LowerGetelementptr(5867:3): type of ^370 is [1 x [6 x ptr]]*
	# tt = Pointer, type = [1 x [6 x ptr]]
	# LowerGetelementptr(5868:3): struct-type: ptr ^370 -> ^371, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5868:3): type of ^371 is [6 x ptr]*
	# tt = Pointer, type = [6 x ptr]
	# LowerGetelementptr(5869:3): struct-type: ptr ^371 -> ^372, indices=0,0
	# LowerGetelementptr(5869:3): type of ^372 is ptr*
	# LowerStore(5870:3).6: load global
	leaq _ZL5g_313(%rip), %rcx
	# LowerStore(5870:3).9: mov ptr ^486, (^372)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5871:3): struct-type: ptr ^372 -> ^373, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5871:3): type of ^373 is ptr*
	# LowerStore(5872:3).9: mov %union.U4* ^65, (^373)
	# Fixing source-to-dest movq -3152(%rbp), (%rcx)
	movq -3152(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5873:3): struct-type: ptr ^373 -> ^374, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5873:3): type of ^374 is ptr*
	# LowerStore(5874:3).6: load global
	leaq _ZL5g_106(%rip), %rcx
	# LowerStore(5874:3).9: mov ptr ^487, (^374)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5875:3): struct-type: ptr ^374 -> ^375, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5875:3): type of ^375 is ptr*
	# LowerStore(5876:3).9: mov %union.U4* ^29, (^375)
	# Fixing source-to-dest movq -3040(%rbp), (%rcx)
	movq -3040(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5877:3): struct-type: ptr ^375 -> ^376, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5877:3): type of ^376 is ptr*
	# LowerStore(5878:3).6: load global
	leaq _ZL5g_106(%rip), %rcx
	# LowerStore(5878:3).9: mov ptr ^488, (^376)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5879:3): struct-type: ptr ^376 -> ^377, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5879:3): type of ^377 is ptr*
	# LowerStore(5880:3).9: mov %union.U4* ^65, (^377)
	# Fixing source-to-dest movq -3152(%rbp), (%rcx)
	movq -3152(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = [1 x [6 x ptr]]
	# LowerGetelementptr(5881:3): struct-type: ptr ^370 -> ^378, indices=1
	movq %rax, %rbx
	addq $48, %rbx
	# LowerGetelementptr(5881:3): type of ^378 is [1 x [6 x ptr]]*
	# tt = Pointer, type = [1 x [6 x ptr]]
	# LowerGetelementptr(5882:3): struct-type: ptr ^378 -> ^379, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5882:3): type of ^379 is [6 x ptr]*
	# tt = Pointer, type = [6 x ptr]
	# LowerGetelementptr(5883:3): struct-type: ptr ^379 -> ^380, indices=0,0
	# LowerGetelementptr(5883:3): type of ^380 is ptr*
	# LowerStore(5884:3).6: load global
	leaq _ZL5g_313(%rip), %rcx
	# LowerStore(5884:3).9: mov ptr ^489, (^380)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5885:3): struct-type: ptr ^380 -> ^381, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5885:3): type of ^381 is ptr*
	# LowerStore(5886:3).9: mov %union.U4* ^65, (^381)
	# Fixing source-to-dest movq -3152(%rbp), (%rcx)
	movq -3152(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5887:3): struct-type: ptr ^381 -> ^382, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5887:3): type of ^382 is ptr*
	# LowerStore(5888:3).6: load global
	leaq _ZL5g_106(%rip), %rcx
	# LowerStore(5888:3).9: mov ptr ^490, (^382)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5889:3): struct-type: ptr ^382 -> ^383, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5889:3): type of ^383 is ptr*
	# LowerStore(5890:3).9: mov %union.U4* ^29, (^383)
	# Fixing source-to-dest movq -3040(%rbp), (%rcx)
	movq -3040(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5891:3): struct-type: ptr ^383 -> ^384, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5891:3): type of ^384 is ptr*
	# LowerStore(5892:3).6: load global
	leaq _ZL5g_106(%rip), %rcx
	# LowerStore(5892:3).9: mov ptr ^491, (^384)
	movq %rcx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5893:3): struct-type: ptr ^384 -> ^385, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5893:3): type of ^385 is ptr*
	# LowerStore(5894:3).9: mov %union.U4* ^65, (^385)
	# Fixing source-to-dest movq -3152(%rbp), (%rcx)
	movq -3152(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = [1 x [6 x ptr]]
	# LowerGetelementptr(5895:3): struct-type: ptr ^378 -> ^386, indices=1
	movq %rbx, %rcx
	addq $48, %rcx
	# LowerGetelementptr(5895:3): type of ^386 is [1 x [6 x ptr]]*
	# tt = Pointer, type = [1 x [6 x ptr]]
	# LowerGetelementptr(5896:3): struct-type: ptr ^386 -> ^387, indices=0,0
	movq %rcx, %rax
	# LowerGetelementptr(5896:3): type of ^387 is [6 x ptr]*
	# tt = Pointer, type = [6 x ptr]
	# LowerGetelementptr(5897:3): struct-type: ptr ^387 -> ^388, indices=0,0
	# LowerGetelementptr(5897:3): type of ^388 is ptr*
	# LowerStore(5898:3).6: load global
	leaq _ZL5g_313(%rip), %rbx
	# LowerStore(5898:3).9: mov ptr ^492, (^388)
	movq %rbx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5899:3): struct-type: ptr ^388 -> ^389, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5899:3): type of ^389 is ptr*
	# LowerStore(5900:3).9: mov %union.U4* ^65, (^389)
	# Fixing source-to-dest movq -3152(%rbp), (%rbx)
	movq -3152(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5901:3): struct-type: ptr ^389 -> ^390, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5901:3): type of ^390 is ptr*
	# LowerStore(5902:3).6: load global
	leaq _ZL5g_106(%rip), %rbx
	# LowerStore(5902:3).9: mov ptr ^493, (^390)
	movq %rbx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5903:3): struct-type: ptr ^390 -> ^391, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5903:3): type of ^391 is ptr*
	# LowerStore(5904:3).9: mov %union.U4* ^29, (^391)
	# Fixing source-to-dest movq -3040(%rbp), (%rbx)
	movq -3040(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5905:3): struct-type: ptr ^391 -> ^392, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5905:3): type of ^392 is ptr*
	# LowerStore(5906:3).6: load global
	leaq _ZL5g_106(%rip), %rbx
	# LowerStore(5906:3).9: mov ptr ^494, (^392)
	movq %rbx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5907:3): struct-type: ptr ^392 -> ^393, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5907:3): type of ^393 is ptr*
	# LowerStore(5908:3).9: mov %union.U4* ^65, (^393)
	# Fixing source-to-dest movq -3152(%rbp), (%rbx)
	movq -3152(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = [1 x [6 x ptr]]
	# LowerGetelementptr(5909:3): struct-type: ptr ^386 -> ^394, indices=1
	movq %rcx, %rax
	addq $48, %rax
	# LowerGetelementptr(5909:3): type of ^394 is [1 x [6 x ptr]]*
	# tt = Pointer, type = [1 x [6 x ptr]]
	# LowerGetelementptr(5910:3): struct-type: ptr ^394 -> ^395, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5910:3): type of ^395 is [6 x ptr]*
	# tt = Pointer, type = [6 x ptr]
	# LowerGetelementptr(5911:3): struct-type: ptr ^395 -> ^396, indices=0,0
	# LowerGetelementptr(5911:3): type of ^396 is ptr*
	# LowerStore(5912:3).6: load global
	leaq _ZL5g_313(%rip), %rcx
	# LowerStore(5912:3).9: mov ptr ^495, (^396)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5913:3): struct-type: ptr ^396 -> ^397, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5913:3): type of ^397 is ptr*
	# LowerStore(5914:3).9: mov %union.U4* ^65, (^397)
	# Fixing source-to-dest movq -3152(%rbp), (%rcx)
	movq -3152(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5915:3): struct-type: ptr ^397 -> ^398, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5915:3): type of ^398 is ptr*
	# LowerStore(5916:3).6: load global
	leaq _ZL5g_106(%rip), %rcx
	# LowerStore(5916:3).9: mov ptr ^496, (^398)
	movq %rcx, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5917:3): struct-type: ptr ^398 -> ^399, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5917:3): type of ^399 is ptr*
	# LowerStore(5918:3).9: mov %union.U4* ^29, (^399)
	# Fixing source-to-dest movq -3040(%rbp), (%rcx)
	movq -3040(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5919:3): struct-type: ptr ^399 -> ^400, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5919:3): type of ^400 is ptr*
	# tt = Pointer, type = [1 x i16]
	# LowerGetelementptr(5920:3): struct-type: ptr ^27 -> ^401, indices=0,0
	# Fixing source-to-dest movq -3032(%rbp), (%rbx)
	movq -3032(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(5920:3): type of ^401 is i16*
	# LowerStore(5921:3).9: mov [1 x i16]* ^401, (^400)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5922:3): struct-type: ptr ^400 -> ^402, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5922:3): type of ^402 is ptr*
	# LowerStore(5923:3).6: load global
	leaq _ZL5g_106(%rip), %rbx
	# LowerStore(5923:3).9: mov ptr ^497, (^402)
	movq %rbx, (%rcx)
	# tt = Pointer, type = [1 x [6 x ptr]]
	# LowerGetelementptr(5924:3): struct-type: ptr ^394 -> ^403, indices=1
	movq %rax, %rbx
	addq $48, %rbx
	# LowerGetelementptr(5924:3): type of ^403 is [1 x [6 x ptr]]*
	# tt = Pointer, type = [1 x [6 x ptr]]
	# LowerGetelementptr(5925:3): struct-type: ptr ^403 -> ^404, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5925:3): type of ^404 is [6 x ptr]*
	# tt = Pointer, type = [6 x ptr]
	# LowerGetelementptr(5926:3): struct-type: ptr ^404 -> ^405, indices=0,0
	# LowerGetelementptr(5926:3): type of ^405 is ptr*
	# LowerStore(5927:3).6: load global
	leaq _ZL5g_106(%rip), %rbx
	# LowerStore(5927:3).9: mov ptr ^498, (^405)
	movq %rbx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5928:3): struct-type: ptr ^405 -> ^406, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5928:3): type of ^406 is ptr*
	# LowerStore(5929:3).6: load global
	leaq _ZL5g_106(%rip), %rax
	# LowerStore(5929:3).9: mov ptr ^499, (^406)
	movq %rax, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5930:3): struct-type: ptr ^406 -> ^407, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5930:3): type of ^407 is ptr*
	# tt = Pointer, type = [1 x i16]
	# LowerGetelementptr(5931:3): struct-type: ptr ^27 -> ^408, indices=0,0
	# Fixing source-to-dest movq -3032(%rbp), (%rax)
	movq -3032(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5931:3): type of ^408 is i16*
	# LowerStore(5932:3).9: mov [1 x i16]* ^408, (^407)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5933:3): struct-type: ptr ^407 -> ^409, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5933:3): type of ^409 is ptr*
	# LowerStore(5934:3).9: mov %union.U4* ^65, (^409)
	# Fixing source-to-dest movq -3152(%rbp), (%rbx)
	movq -3152(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5935:3): struct-type: ptr ^409 -> ^410, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5935:3): type of ^410 is ptr*
	# tt = Pointer, type = [1 x i16]
	# LowerGetelementptr(5936:3): struct-type: ptr ^27 -> ^411, indices=0,0
	# Fixing source-to-dest movq -3032(%rbp), (%rax)
	movq -3032(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5936:3): type of ^411 is i16*
	# LowerStore(5937:3).9: mov [1 x i16]* ^411, (^410)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(5938:3): struct-type: ptr ^410 -> ^412, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5938:3): type of ^412 is ptr*
	# LowerStore(5939:3).6: load global
	leaq _ZL5g_106(%rip), %rax
	# LowerStore(5939:3).9: mov ptr ^500, (^412)
	movq %rax, (%rbx)
	# LowerStore(5943:3).3: mov $imm, (^71)
	movq -3200(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M2182:
	# LowerLoad(5947:3).2: (^71) into i32 ^414
	movq -3200(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(5948:3): i32 ^414 vs. intlike 6
	cmpl $6, %ebx
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M2189
	jmp .___ZL7func_57majs2U2__M2229
	.___ZL7func_57majs2U2__M2189:
	# tt = Pointer, type = [8 x [9 x [3 x i32]]]
	# LowerGetelementptr(5952:3): struct-type: ptr ^15 -> ^417, indices=0,7
	movq -3008(%rbp), %rax
	addq $756, %rax
	# LowerGetelementptr(5952:3): type of ^417 is [9 x [3 x i32]]*
	# tt = Pointer, type = [9 x [3 x i32]]
	# LowerGetelementptr(5953:3): struct-type: ptr ^417 -> ^418, indices=0,4
	movq %rax, %rbx
	addq $48, %rbx
	# LowerGetelementptr(5953:3): type of ^418 is [3 x i32]*
	# tt = Pointer, type = [3 x i32]
	# LowerGetelementptr(5954:3): struct-type: ptr ^418 -> ^419, indices=0,1
	movq %rbx, %rcx
	addq $4, %rcx
	# LowerGetelementptr(5954:3): type of ^419 is i32*
	# LowerLoad(5955:3).2: (^71) into i32 ^420
	movq -3200(%rbp), %rax
	movl (%rax), %ebx
	movslq %ebx, %rax
	# tt = Pointer, type = [6 x ptr]
	# LowerGetelementptr(5957:3): array/pointer-type, dynamic index -> ^422
	# index ^421 -> temp ^464
	movq %rax, %rbx
	# Multiply temp ^464 by 8 start
	shlq $3, %rbx
	# Multiply end
	# temp ^464 -> operand ^422
	movq %rbx, %rax
	# Result ^422 += base pointer ^54
	addq -3064(%rbp), %rax
	# LowerStore(5958:3).9: mov [3 x i32]* ^419, (^422)
	movq %rcx, (%rax)
	# LowerLoad(5962:3).2: (^71) into i32 ^424
	movq -3200(%rbp), %rax
	movl (%rax), %ebx
	# LowerMath(5963:3): ^424, 1 into i32 ^425
	addl $1, %ebx
	# LowerStore(5964:3).9: mov i32 ^425, (^71)
	movq -3200(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL7func_57majs2U2__M2182
	.___ZL7func_57majs2U2__M2229:
	# LowerLoad(5971:3).4: _ZL5g_120 into ^428
	movw _ZL5g_120(%rip), %ax
	# LowerMath(5972:3): ^428, 1 into i16 ^429
	addw $1, %ax
	# LowerStore(5973:3).8a: leaq var, %temp
	leaq _ZL5g_120(%rip), %rbx
	# LowerStore(5973:3).8b: movq ^429, (%temp)
	movw %ax, (%rbx)
	jmp .___ZL7func_57majs2U2__M1493
	.___ZL7func_57majs2U2__M2240:
	# LowerLoad(5977:3).4: _ZL5g_139 into ^431
	movq _ZL5g_139(%rip), %rax
	# LowerLoad(5978:3).2: (^431) into ptr ^432
	movq (%rax), %rbx
	# LowerLoad(5979:3).4: _ZL5g_139 into ^433
	movq _ZL5g_139(%rip), %rax
	# LowerStore(5980:3).9: mov ptr ^432, (^433)
	movq %rbx, (%rax)
	# LowerLoad(5981:3).2: (^30) into ptr ^434
	movq -3024(%rbp), %rax
	movq (%rax), %rbx
	# SetupCalls(5982:3): move argument ptr align 4 ^6
	# Fixed movzx with identical source and destination widths
	movq -3000(%rbp), %rdi
	# SetupCalls(5982:3): move argument ptr align 4 ^434
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rsi
	# SetupCalls(5982:3): move argument i64 4
	movq $4, %rdx
	callq memcpy@PLT
	# tt = Pointer, type = %union.U0
	# LowerGetelementptr(5983:3): struct-type: ptr ^6 -> ^435, indices=0,0
	movq -3000(%rbp), %rax
	# LowerGetelementptr(5983:3): type of ^435 is i32*
	# LowerLoad(5984:3).2: (^435) into i32 ^436
	movl (%rax), %ebx
	movl %ebx, %eax
	movq -3520(%rbp), %r15
	movq -4664(%rbp), %r14
	movq -4656(%rbp), %r13
	movq -4648(%rbp), %r12
	movq -3600(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_mul_func_uint64_t_u_umm
.p2align 4, 0x90
_ZL26safe_mul_func_uint64_t_u_umm:
	.___ZL26safe_mul_func_uint64_t_u_umm__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(3949:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(3950:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(3951:3).9: mov i64 %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(3953:3).9: mov i64 %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(3955:3).2: (^3) into i64 ^5
	movq (%rcx), %rbx
	# LowerLoad(3956:3).2: (^4) into i64 ^6
	movq (%rax), %rcx
	# LowerMath(3957:3): ^5, ^6 into i64 ^7
	movq %rbx, %rax
	mulq %rcx
	movq %rax, %rbx
	movq %rbx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZN2U0aSERKS_
.p2align 4, 0x90
_ZN2U0aSERKS_:
	.___ZN2U0aSERKS___M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -48(%rbp)
	movq %r12, -56(%rbp)
	movq %r13, -40(%rbp)
	# LowerAlloca(5990:3): size = 8, type = ptr*, var = ^3
	leaq -8(%rbp), %r13
	# LowerAlloca(5991:3): size = 8, type = ptr*, var = ^4
	leaq -16(%rbp), %rax
	# LowerAlloca(5992:3): size = 8, type = ptr*, var = ^5
	leaq -24(%rbp), %rbx
	# LowerStore(5993:3).9: mov ptr %rdi, (^4)
	movq %rdi, (%rax)
	# LowerStore(5995:3).9: mov ptr %rsi, (^5)
	movq %rsi, (%rbx)
	# LowerLoad(5997:3).2: (^4) into ptr ^6
	movq (%rax), %r12
	# LowerLoad(5998:3).2: (^5) into ptr ^7
	movq (%rbx), %rax
	# LowerIcmp(5999:3): ptr ^6 vs. operand ptr ^7
	cmpq %rax, %r12
	sete %al
	andq $1, %rax
	cmpb $0, %al
	jne .___ZN2U0aSERKS___M19
	jmp .___ZN2U0aSERKS___M22
	.___ZN2U0aSERKS___M19:
	# LowerStore(6003:3).9: mov ptr ^6, (^3)
	movq %r12, (%r13)
	jmp .___ZN2U0aSERKS___M52
	.___ZN2U0aSERKS___M22:
	# LowerLoad(6007:3).2: (^5) into ptr ^11
	movq (%rbx), %rax
	# Clobber %rax
	movq %rax, -32(%rbp)
	# SetupCalls(6008:3): move argument ptr align 4 ^6
	# Fixed movzx with identical source and destination widths
	movq %r12, %rdi
	# SetupCalls(6008:3): move argument ptr align 4 ^11
	# Fixed movzx with identical source and destination widths
	movq %rax, %rsi
	# SetupCalls(6008:3): move argument i64 4
	movq $4, %rdx
	callq memcpy@PLT
	# Unclobber %rax
	movq -32(%rbp), %rax
	# LowerStore(6009:3).9: mov ptr ^6, (^3)
	movq %r12, (%r13)
	.___ZN2U0aSERKS___M52:
	# LowerLoad(6013:3).2: (^3) into ptr ^13
	movq (%r13), %rax
	movq -40(%rbp), %r13
	movq -56(%rbp), %r12
	movq -48(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_mod_func_uint8_t_u_uhh
.p2align 4, 0x90
_ZL25safe_mod_func_uint8_t_u_uhh:
	.___ZL25safe_mod_func_uint8_t_u_uhh__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(40 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(6019:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rcx
	# LowerAlloca(6020:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(6021:3).9: mov i8 %dil, (^3)
	movb %dil, (%rcx)
	# LowerStore(6023:3).9: mov i8 %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(6025:3).2: (^4) into i8 ^5
	movb (%rax), %bl
	# LowerBasicConversion(6026:3): i8 ^5 -> i32 ^6
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerIcmp(6027:3): i32 ^6 vs. intlike 0
	cmpl $0, %ebx
	sete %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_uint8_t_u_uhh__M19
	jmp .___ZL25safe_mod_func_uint8_t_u_uhh__M28
	.___ZL25safe_mod_func_uint8_t_u_uhh__M19:
	# LowerLoad(6031:3).2: (^3) into i8 ^9
	movb (%rcx), %al
	# LowerBasicConversion(6032:3): i8 ^9 -> i32 ^10
	# Truncate value to 8 bits
	andl $255, %eax
	# MovePhi: ^10 -> ^18
	movl %eax, %r8d
	jmp .___ZL25safe_mod_func_uint8_t_u_uhh__M52
	.___ZL25safe_mod_func_uint8_t_u_uhh__M28:
	# LowerLoad(6036:3).2: (^3) into i8 ^12
	movb (%rcx), %sil
	# LowerBasicConversion(6037:3): i8 ^12 -> i32 ^13
	# Truncate value to 8 bits
	andl $255, %esi
	# LowerLoad(6038:3).2: (^4) into i8 ^14
	movb (%rax), %bl
	# LowerBasicConversion(6039:3): i8 ^14 -> i32 ^15
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerSrem(6040:3): ^13, ^15 into i32 ^16
	movl $0, %edx
	movl %esi, %eax
	idivl %ebx
	movl %edx, %ebx
	# MovePhi: ^16 -> ^18
	movl %ebx, %r8d
	.___ZL25safe_mod_func_uint8_t_u_uhh__M52:
	# LowerTrunc(6045:3): 32 to 8, move
	movb %r8b, %al
	# LowerTrunc(6045:3): 32 to 8, apply mask
	andq $255, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_int16_t_s_ssi
.p2align 4, 0x90
_ZL28safe_lshift_func_int16_t_s_ssi:
	.___ZL28safe_lshift_func_int16_t_s_ssi__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(96 + 0, 16)
	subq $96, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(6095:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rdx
	# LowerAlloca(6096:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(6097:3).9: mov i16 %di, (^3)
	movw %di, (%rdx)
	# LowerStore(6099:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(6101:3).2: (^3) into i16 ^5
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerIcmp(6103:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_ssi__M45
	.___ZL28safe_lshift_func_int16_t_s_ssi__M16:
	# LowerLoad(6107:3).2: (^4) into i32 ^9
	movl (%rax), %ebx
	# LowerIcmp(6108:3): i32 ^9 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_ssi__M45
	.___ZL28safe_lshift_func_int16_t_s_ssi__M23:
	# LowerLoad(6112:3).2: (^4) into i32 ^12
	movl (%rax), %ebx
	# LowerIcmp(6113:3): i32 ^12 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_ssi__M45
	.___ZL28safe_lshift_func_int16_t_s_ssi__M30:
	# LowerLoad(6117:3).2: (^3) into i16 ^15
	movw (%rdx), %bx
	movswl %bx, %esi
	# LowerLoad(6119:3).2: (^4) into i32 ^17
	movl (%rax), %ecx
	# LowerAshr(6120:3): 32767, ^17 into i32 ^18
	# LowerShift(6120:3): operand ^17 changed to %ecx
	movl $32767, %ebx
	sarl %cl, %ebx
	# LowerIcmp(6121:3): i32 ^16 vs. operand i32 ^18
	cmpl %ebx, %esi
	setg %bl
	andq $1, %rbx
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_ssi__M45
	jmp .___ZL28safe_lshift_func_int16_t_s_ssi__M51
	.___ZL28safe_lshift_func_int16_t_s_ssi__M45:
	# LowerLoad(6125:3).2: (^3) into i16 ^21
	movw (%rdx), %bx
	movswl %bx, %eax
	# MovePhi: ^22 -> ^29
	movl %eax, %r8d
	jmp .___ZL28safe_lshift_func_int16_t_s_ssi__M64
	.___ZL28safe_lshift_func_int16_t_s_ssi__M51:
	# LowerLoad(6130:3).2: (^3) into i16 ^24
	movw (%rdx), %bx
	movswl %bx, %edx
	# LowerLoad(6132:3).2: (^4) into i32 ^26
	movl (%rax), %ecx
	# LowerMath(6133:3): ^25, ^26 into i32 ^27
	# LowerShift(6133:3): operand ^26 changed to %ecx
	movl %edx, %eax
	shll %cl, %eax
	# MovePhi: ^27 -> ^29
	movl %eax, %r8d
	.___ZL28safe_lshift_func_int16_t_s_ssi__M64:
	# LowerTrunc(6138:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(6138:3): 32 to 16, apply mask
	andq $65535, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

