.section .rodata
.align 8
.str:
.ascii "1\x00"

.section .rodata
.align 8
.str.1:
.ascii "g_2\x00"

.section .rodata
.align 8
.str.10:
.ascii "g_124\x00"

.section .rodata
.align 8
.str.100:
.ascii "g_1935\x00"

.section .rodata
.align 8
.str.101:
.ascii "g_1936\x00"

.section .rodata
.align 8
.str.102:
.ascii "g_1937\x00"

.section .rodata
.align 8
.str.103:
.ascii "g_1938\x00"

.section .rodata
.align 8
.str.104:
.ascii "g_1939\x00"

.section .rodata
.align 8
.str.105:
.ascii "g_1940\x00"

.section .rodata
.align 8
.str.106:
.ascii "g_1941\x00"

.section .rodata
.align 8
.str.107:
.ascii "g_1942[i][j][k]\x00"

.section .rodata
.align 8
.str.108:
.ascii "g_1943\x00"

.section .rodata
.align 8
.str.109:
.ascii "g_1944[i]\x00"

.section .rodata
.align 8
.str.11:
.ascii "g_132.f0\x00"

.section .rodata
.align 8
.str.110:
.ascii "g_1945[i]\x00"

.section .rodata
.align 8
.str.111:
.ascii "g_1946\x00"

.section .rodata
.align 8
.str.112:
.ascii "g_1947\x00"

.section .rodata
.align 8
.str.113:
.ascii "g_1948\x00"

.section .rodata
.align 8
.str.114:
.ascii "g_2024.f0\x00"

.section .rodata
.align 8
.str.115:
.ascii "g_2072\x00"

.section .rodata
.align 8
.str.116:
.ascii "g_2186\x00"

.section .rodata
.align 8
.str.117:
.ascii "g_2199.f0\x00"

.section .rodata
.align 8
.str.118:
.ascii "g_2324[i][j]\x00"

.section .rodata
.align 8
.str.119:
.ascii "g_2354\x00"

.section .rodata
.align 8
.str.12:
.ascii "g_137\x00"

.section .rodata
.align 8
.str.120:
.ascii "g_2382\x00"

.section .rodata
.align 8
.str.121:
.ascii "g_2427[i][j].f0\x00"

.section .rodata
.align 8
.str.122:
.ascii "g_2519\x00"

.section .rodata
.align 8
.str.123:
.ascii "g_2599\x00"

.section .rodata
.align 8
.str.128:
.ascii "...checksum after hashing %s : %lX\x0A\x00"

.section .rodata
.align 8
.str.13:
.ascii "g_203\x00"

.section .rodata
.align 8
.str.131:
.ascii "checksum = %X\x0A\x00"

.section .rodata
.align 8
.str.14:
.ascii "g_232[i]\x00"

.section .rodata
.align 8
.str.15:
.ascii "index = [%d]\x0A\x00"

.section .rodata
.align 8
.str.16:
.ascii "g_245\x00"

.section .rodata
.align 8
.str.17:
.ascii "g_246\x00"

.section .rodata
.align 8
.str.18:
.ascii "g_247\x00"

.section .rodata
.align 8
.str.19:
.ascii "g_259\x00"

.section .rodata
.align 8
.str.2:
.ascii "g_5\x00"

.section .rodata
.align 8
.str.20:
.ascii "g_265\x00"

.section .rodata
.align 8
.str.21:
.ascii "g_294\x00"

.section .rodata
.align 8
.str.22:
.ascii "g_338\x00"

.section .rodata
.align 8
.str.23:
.ascii "g_367.f0\x00"

.section .rodata
.align 8
.str.24:
.ascii "g_422[i]\x00"

.section .rodata
.align 8
.str.25:
.ascii "g_445.f0\x00"

.section .rodata
.align 8
.str.26:
.ascii "g_449[i]\x00"

.section .rodata
.align 8
.str.27:
.ascii "g_453.f0\x00"

.section .rodata
.align 8
.str.28:
.ascii "g_455.f0\x00"

.section .rodata
.align 8
.str.29:
.ascii "g_648\x00"

.section .rodata
.align 8
.str.3:
.ascii "g_91\x00"

.section .rodata
.align 8
.str.30:
.ascii "g_651\x00"

.section .rodata
.align 8
.str.31:
.ascii "g_693.f0\x00"

.section .rodata
.align 8
.str.32:
.ascii "g_695\x00"

.section .rodata
.align 8
.str.33:
.ascii "g_862\x00"

.section .rodata
.align 8
.str.34:
.ascii "g_1175\x00"

.section .rodata
.align 8
.str.35:
.ascii "g_1221\x00"

.section .rodata
.align 8
.str.36:
.ascii "g_1335\x00"

.section .rodata
.align 8
.str.37:
.ascii "g_1357.f0\x00"

.section .rodata
.align 8
.str.38:
.ascii "g_1391.f0\x00"

.section .rodata
.align 8
.str.39:
.ascii "g_1487\x00"

.section .rodata
.align 8
.str.4:
.ascii "g_106\x00"

.section .rodata
.align 8
.str.40:
.ascii "g_1499\x00"

.section .rodata
.align 8
.str.41:
.ascii "g_1554[i][j][k]\x00"

.section .rodata
.align 8
.str.42:
.ascii "index = [%d][%d][%d]\x0A\x00"

.section .rodata
.align 8
.str.43:
.ascii "g_1650.f0\x00"

.section .rodata
.align 8
.str.44:
.ascii "g_1712\x00"

.section .rodata
.align 8
.str.45:
.ascii "g_1717[i].f0\x00"

.section .rodata
.align 8
.str.46:
.ascii "g_1877\x00"

.section .rodata
.align 8
.str.47:
.ascii "g_1883\x00"

.section .rodata
.align 8
.str.48:
.ascii "g_1884\x00"

.section .rodata
.align 8
.str.49:
.ascii "g_1885\x00"

.section .rodata
.align 8
.str.5:
.ascii "g_107\x00"

.section .rodata
.align 8
.str.50:
.ascii "g_1886\x00"

.section .rodata
.align 8
.str.51:
.ascii "g_1887\x00"

.section .rodata
.align 8
.str.52:
.ascii "g_1888\x00"

.section .rodata
.align 8
.str.53:
.ascii "g_1889[i]\x00"

.section .rodata
.align 8
.str.54:
.ascii "g_1890\x00"

.section .rodata
.align 8
.str.55:
.ascii "g_1891\x00"

.section .rodata
.align 8
.str.56:
.ascii "g_1892[i]\x00"

.section .rodata
.align 8
.str.57:
.ascii "g_1893[i]\x00"

.section .rodata
.align 8
.str.58:
.ascii "g_1894[i]\x00"

.section .rodata
.align 8
.str.59:
.ascii "g_1895\x00"

.section .rodata
.align 8
.str.6:
.ascii "g_117\x00"

.section .rodata
.align 8
.str.60:
.ascii "g_1896\x00"

.section .rodata
.align 8
.str.61:
.ascii "g_1897\x00"

.section .rodata
.align 8
.str.62:
.ascii "g_1898\x00"

.section .rodata
.align 8
.str.63:
.ascii "g_1899\x00"

.section .rodata
.align 8
.str.64:
.ascii "g_1900[i]\x00"

.section .rodata
.align 8
.str.65:
.ascii "g_1901\x00"

.section .rodata
.align 8
.str.66:
.ascii "g_1902\x00"

.section .rodata
.align 8
.str.67:
.ascii "g_1903\x00"

.section .rodata
.align 8
.str.68:
.ascii "g_1904\x00"

.section .rodata
.align 8
.str.69:
.ascii "g_1905\x00"

.section .rodata
.align 8
.str.7:
.ascii "g_118\x00"

.section .rodata
.align 8
.str.70:
.ascii "g_1906\x00"

.section .rodata
.align 8
.str.71:
.ascii "g_1907\x00"

.section .rodata
.align 8
.str.72:
.ascii "g_1908\x00"

.section .rodata
.align 8
.str.73:
.ascii "g_1909\x00"

.section .rodata
.align 8
.str.74:
.ascii "g_1910\x00"

.section .rodata
.align 8
.str.75:
.ascii "g_1911\x00"

.section .rodata
.align 8
.str.76:
.ascii "g_1912\x00"

.section .rodata
.align 8
.str.77:
.ascii "g_1913\x00"

.section .rodata
.align 8
.str.78:
.ascii "g_1914\x00"

.section .rodata
.align 8
.str.79:
.ascii "g_1915\x00"

.section .rodata
.align 8
.str.8:
.ascii "g_119\x00"

.section .rodata
.align 8
.str.80:
.ascii "g_1916[i]\x00"

.section .rodata
.align 8
.str.81:
.ascii "g_1917\x00"

.section .rodata
.align 8
.str.82:
.ascii "g_1918\x00"

.section .rodata
.align 8
.str.83:
.ascii "g_1919\x00"

.section .rodata
.align 8
.str.84:
.ascii "g_1920\x00"

.section .rodata
.align 8
.str.85:
.ascii "g_1921\x00"

.section .rodata
.align 8
.str.86:
.ascii "g_1922[i][j]\x00"

.section .rodata
.align 8
.str.87:
.ascii "index = [%d][%d]\x0A\x00"

.section .rodata
.align 8
.str.88:
.ascii "g_1923\x00"

.section .rodata
.align 8
.str.89:
.ascii "g_1924\x00"

.section .rodata
.align 8
.str.9:
.ascii "g_120\x00"

.section .rodata
.align 8
.str.90:
.ascii "g_1925\x00"

.section .rodata
.align 8
.str.91:
.ascii "g_1926\x00"

.section .rodata
.align 8
.str.92:
.ascii "g_1927\x00"

.section .rodata
.align 8
.str.93:
.ascii "g_1928\x00"

.section .rodata
.align 8
.str.94:
.ascii "g_1929\x00"

.section .rodata
.align 8
.str.95:
.ascii "g_1930\x00"

.section .rodata
.align 8
.str.96:
.ascii "g_1931\x00"

.section .rodata
.align 8
.str.97:
.ascii "g_1932\x00"

.section .rodata
.align 8
.str.98:
.ascii "g_1933[i]\x00"

.section .rodata
.align 8
.str.99:
.ascii "g_1934\x00"

.section .data
.align 8
_ZL13crc32_context:
.int -1

.section .data
.align 8
_ZL3g_2:
.int 321396001

.section .data
.align 8
_ZL3g_5:
.int -440236594

.section .data
.align 8
_ZL4g_66:
.int 7

.section .data
.align 8
_ZL4g_91:
.byte -89

.section .data
.align 8
_ZL5g_106:
.word 4

.section .data
.align 8
_ZL5g_107:
.int 1420364725

.section .data
.align 8
_ZL5g_117:
.word 26209

.section .data
.align 8
_ZL5g_118:
.int -9

.section .data
.align 8
_ZL5g_119:
.int 960066178

.section .data
.align 8
_ZL5g_120:
.word -10

.section .data
.align 8
_ZL5g_124:
.word 17554

.section .data
.align 8
_ZL5g_132:
.word 1

.section .data
.align 8
_ZL5g_139:
.quad _ZL5g_140

.section .data
.align 8
_ZL5g_140:
.quad _ZL3g_5

.section .data
.align 8
_ZL5g_149:
.quad 5
.quad 5
.quad 5
.quad 5
.quad 5
.quad 5
.quad 5
.quad 5

.section .data
.align 8
_ZL5g_150:
.quad _ZL5g_149+64

.section .data
.align 8
_ZL5g_203:
.byte -5

.section .rodata
.align 8
_ZL5g_232:
.ascii "\xD1\xD1\xD1\xD1\xD1"

.section .data
.align 8
_ZL5g_245:
.quad 3

.section .data
.align 8
_ZL5g_246:
.int -439009062

.section .data
.align 8
_ZL5g_247:
.word 9

.section .data
.align 8
_ZL5g_259:
.byte 5

.section .data
.align 8
_ZL5g_265:
.word -1

.section .data
.align 8
_ZL5g_294:
.int -275451831

.section .data
.align 8
_ZL5g_313:
.word -29162

.section .data
.align 8
_ZL5g_337:
.quad _ZL5g_338

.section .data
.align 8
_ZL5g_338:
.quad 0

.section .data
.align 8
_ZL5g_365:
.quad _ZL5g_366

.section .data
.align 8
_ZL5g_366:
.quad _ZL5g_367

.section .data
.align 8
_ZL5g_367:
.word 12039

.section .data
.align 8
_ZL5g_422:
.int 582490830
.int 582490830
.int 582490830
.int 582490830
.int 582490830
.int 582490830

.section .data
.align 8
_ZL5g_445:
.byte -1
.fill 1, 1, 0

.section .data
.align 8
_ZL5g_448:
.quad _ZL5g_449+96

.section .data
.align 8
_ZL5g_449:
.int -1622083099
.int -1622083099
.int -2069577285
.int -1622083099
.int -1622083099
.int -2069577285
.int -1622083099
.int -1622083099
.int -2069577285
.int -1622083099

.section .data
.align 8
_ZL5g_452:
.quad _ZL5g_453

.section .data
.align 8
_ZL5g_453:
.word 19720

.section .data
.align 8
_ZL5g_455:
.word -14156

.section .data
.align 8
_ZL5g_648:
.byte 99

.section .data
.align 8
_ZL5g_651:
.word -1

.section .data
.align 8
_ZL5g_652:
.quad _ZL5g_653

.section .data
.align 8
_ZL5g_653:
.quad _ZL5g_654

.section .data
.align 8
_ZL5g_654:
.quad _ZL5g_655

.section .data
.align 8
_ZL5g_655:
.fill 8, 1, 0

.section .data
.align 8
_ZL5g_666:
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667

.section .data
.align 8
_ZL5g_667:
.quad _ZL5g_668

.section .data
.align 8
_ZL5g_668:
.quad _ZL5g_132

.section .data
.align 8
_ZL5g_693:
.int 9

.section .data
.align 8
_ZL5g_695:
.int 1853746151

.section .data
.align 8
_ZL5g_744:
.int -808993188

.section .data
.align 8
_ZL5g_837:
.byte -3
.fill 1, 1, 0

.section .data
.align 8
_ZL5g_862:
.quad 7

.section .data
.align 8
_ZL6g_1117:
.fill 8, 1, 0

.section .data
.align 8
_ZL6g_1175:
.word 2099

.section .data
.align 8
_ZL6g_1221:
.quad -1

.section .data
.align 8
_ZL6g_1335:
.byte -1

.section .data
.align 8
_ZL6g_1357:
.int -2133451005

.section .data
.align 8
_ZL6g_1391:
.byte -94
.fill 1, 1, 0

.section .data
.align 8
_ZL6g_1487:
.quad 0

.section .data
.align 8
_ZL6g_1499:
.int -1986020263

.section .data
.align 8
_ZL6g_1554:
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947
.int 1462326940
.int -1449334377
.int 1462326940
.int -916288947
.int -916288947
.int -1449334377
.int -916288947
.int -916288947

.section .data
.align 8
_ZL6g_1650:
.word 5215

.section .data
.align 8
_ZL6g_1680:
.quad _ZL6g_1681

.section .data
.align 8
_ZL6g_1681:
.quad _ZL6g_1682

.section .data
.align 8
_ZL6g_1682:
.quad _ZL5g_448

.section .data
.align 8
_ZL6g_1717:
.word -7
.word -7
.word -7
.word -7
.word -7
.word -7
.word -7
.word -7

.section .data
.align 8
_ZL6g_1877:
.int -497869374

.section .data
.align 8
_ZL6g_1883:
.int 1102553480

.section .data
.align 8
_ZL6g_1884:
.int 0

.section .data
.align 8
_ZL6g_1885:
.int 1

.section .data
.align 8
_ZL6g_1886:
.int 861366921

.section .data
.align 8
_ZL6g_1887:
.int -1

.section .data
.align 8
_ZL6g_1888:
.int 25839817

.section .data
.align 8
_ZL6g_1889:
.int 3
.int 3
.int 3
.int 3
.int 3
.int 3
.int 3
.int 3
.int 3
.int 3

.section .data
.align 8
_ZL6g_1890:
.int 7

.section .data
.align 8
_ZL6g_1891:
.int -1155024305

.section .data
.align 8
_ZL6g_1892:
.int 9
.int 9
.int 9
.int 9
.int 9

.section .data
.align 8
_ZL6g_1893:
.int 1
.int -1
.int -1
.int 1
.int -1
.int -1
.int 1

.section .data
.align 8
_ZL6g_1894:
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1

.section .data
.align 8
_ZL6g_1895:
.int -387690135

.section .data
.align 8
_ZL6g_1896:
.int 1

.section .data
.align 8
_ZL6g_1897:
.int -9

.section .data
.align 8
_ZL6g_1898:
.int -876145449

.section .data
.align 8
_ZL6g_1899:
.int -10

.section .data
.align 8
_ZL6g_1900:
.int -3
.int -3
.int -3

.section .data
.align 8
_ZL6g_1901:
.int -630089068

.section .data
.align 8
_ZL6g_1902:
.int -5

.section .data
.align 8
_ZL6g_1903:
.int -1359504650

.section .data
.align 8
_ZL6g_1904:
.int 1

.section .data
.align 8
_ZL6g_1905:
.int -5

.section .data
.align 8
_ZL6g_1906:
.int 0

.section .data
.align 8
_ZL6g_1907:
.int -1343935289

.section .data
.align 8
_ZL6g_1908:
.int -1278937823

.section .data
.align 8
_ZL6g_1909:
.int -8

.section .data
.align 8
_ZL6g_1910:
.int -10

.section .data
.align 8
_ZL6g_1911:
.int -1

.section .data
.align 8
_ZL6g_1912:
.int 7

.section .data
.align 8
_ZL6g_1913:
.int -4

.section .data
.align 8
_ZL6g_1914:
.int 955858442

.section .data
.align 8
_ZL6g_1915:
.int -6

.section .data
.align 8
_ZL6g_1916:
.int -11587196

.section .data
.align 8
_ZL6g_1917:
.int 7

.section .data
.align 8
_ZL6g_1918:
.int 116031467

.section .data
.align 8
_ZL6g_1919:
.int -1502158191

.section .data
.align 8
_ZL6g_1920:
.int 0

.section .data
.align 8
_ZL6g_1921:
.int -2000127066

.section .data
.align 8
_ZL6g_1922:
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int 135708172
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1
.int -1

.section .data
.align 8
_ZL6g_1923:
.int -1

.section .data
.align 8
_ZL6g_1924:
.int -1469769669

.section .data
.align 8
_ZL6g_1925:
.int -2

.section .data
.align 8
_ZL6g_1926:
.int -1

.section .data
.align 8
_ZL6g_1927:
.int 3

.section .data
.align 8
_ZL6g_1928:
.int 1948184196

.section .data
.align 8
_ZL6g_1929:
.int 2015585424

.section .data
.align 8
_ZL6g_1930:
.int 1431763380

.section .data
.align 8
_ZL6g_1931:
.int -199081461

.section .data
.align 8
_ZL6g_1932:
.int -1664503428

.section .data
.align 8
_ZL6g_1933:
.int 1836494699
.int 1836494699
.int 1836494699
.int 1836494699
.int 1836494699
.int 1836494699
.int 1836494699
.int 1836494699

.section .data
.align 8
_ZL6g_1934:
.int 1

.section .data
.align 8
_ZL6g_1935:
.int -1613090230

.section .data
.align 8
_ZL6g_1936:
.int 5

.section .data
.align 8
_ZL6g_1937:
.int -4

.section .data
.align 8
_ZL6g_1938:
.int -1753196125

.section .data
.align 8
_ZL6g_1939:
.int 1075735522

.section .data
.align 8
_ZL6g_1940:
.int 280916863

.section .data
.align 8
_ZL6g_1941:
.int 1669581321

.section .data
.align 8
_ZL6g_1942:
.int 1259935042
.int 1259935042
.int -1716021877
.int -6
.int 883023951
.int -6
.int 8
.int 4
.int 0
.int -6
.int 0
.int 8
.int -1
.int -6
.int 0
.int 4
.int -6
.int -6
.int 0
.int -1090100040
.int 1624602653
.int 8
.int 68931085
.int -1716021877
.int -905327648
.int -1817676719
.int -1317224659
.int 3
.int 0
.int -1259378644
.int 1259935042
.int -7
.int 1405156444
.int 446402858
.int 1
.int -6
.int -1471432512
.int 2
.int 1213796766
.int 8
.int -6
.int 883023951
.int -6
.int 446402858
.int 2
.int -1
.int 0
.int 365379932
.int 1387306853
.int 0
.int 1387306853
.int 2022890936
.int 446402858
.int -1817676719
.int 3
.int 0
.int -578629847
.int 887108380
.int -10
.int -1817676719
.int 1405156444
.int -905327648
.int -10
.int 652681088
.int -578629847
.int 1387306853
.int 3
.int 8
.int 446402858
.int 0
.int 1387306853
.int 1
.int 1387306853
.int 1
.int 0
.int 1405156444
.int 2
.int -578629847
.int -6
.int 1213796766
.int -6
.int -1817676719
.int 1213796766
.int 245270828
.int -1471432512
.int 0
.int 1
.int -9
.int 1405156444
.int 652681088
.int 1259935042
.int -1
.int 0
.int 1624602653
.int -1317224659
.int 8
.int -905327648
.int 68931085
.int 68931085
.int -905327648
.int 1624602653
.int 4
.int 0
.int 6
.int -6
.int -1471432512
.int 0
.int -1317224659
.int -1
.int -1817676719
.int 0
.int -1317224659
.int 0
.int -1471432512
.int 8
.int 6
.int 1405156444
.int 4
.int -1
.int -905327648
.int 8
.int 68931085
.int -1716021877
.int 8
.int 652681088
.int 1624602653
.int 883023951
.int -1

.section .data
.align 8
_ZL6g_1943:
.int -6

.section .data
.align 8
_ZL6g_1944:
.int 692300518
.int 1270180300
.int 4
.int 4
.int 1270180300
.int 692300518
.int 1270180300
.int 4
.int 4
.int 1270180300

.section .data
.align 8
_ZL6g_1945:
.int 53127161
.int -112896984
.int -112896984
.int 53127161
.int -112896984
.int -112896984
.int 53127161

.section .data
.align 8
_ZL6g_1946:
.int -707239258

.section .data
.align 8
_ZL6g_1947:
.int 1

.section .data
.align 8
_ZL6g_1948:
.int -2129396774

.section .data
.align 8
_ZL6g_2024:
.int 9

.section .data
.align 8
_ZL6g_2025:
.fill 8, 1, 0

.section .data
.align 8
_ZL6g_2072:
.int -5

.section .data
.align 8
_ZL6g_2175:
.fill 8, 1, 0

.section .data
.align 8
_ZL6g_2186:
.quad -7849629611674676947

.section .data
.align 8
_ZL6g_2199:
.word 15412

.section .data
.align 8
_ZL6g_2324:
.int 846055261
.int 846055261
.int 846055261
.int 846055261
.int 846055261

.section .data
.align 8
_ZL6g_2354:
.int 0

.section .data
.align 8
_ZL6g_2357:
.quad _ZL5g_149+448

.section .data
.align 8
_ZL6g_2364:
.quad _ZL6g_2365

.section .data
.align 8
_ZL6g_2365:
.fill 8, 1, 0

.section .data
.align 8
_ZL6g_2382:
.int -673340876

.section .data
.align 8
_ZL6g_2423:
.quad _ZL6g_2424

.section .data
.align 8
_ZL6g_2424:
.quad _ZL6g_2425

.section .data
.align 8
_ZL6g_2425:
.quad _ZL6g_2426

.section .data
.align 8
_ZL6g_2426:
.quad _ZL6g_2427+112

.section .data
.align 8
_ZL6g_2427:
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506
.word -14506

.section .data
.align 8
_ZL6g_2504:
.quad _ZL6g_2505

.section .data
.align 8
_ZL6g_2505:
.quad _ZL5g_124

.section .data
.align 8
_ZL6g_2519:
.word 1

.section .data
.align 8
_ZL6g_2599:
.word 1

.section .data
.align 8
_ZL9crc32_tab:
.fill 1024, 1, 0

.section .data
.align 8
__const._ZL6func_1v.l_1138:
.word 19532
.word 19532
.word 1
.word -18216
.word -3
.word -23628
.word -1
.word -21420
.word -10934
.fill 2, 1, 0
.word 19532
.word -1
.word 1
.word -18216
.word 1
.word -1
.word -1
.word -1
.word -8
.fill 2, 1, 0
.word -1
.word 19532
.word 1
.word -22925
.word -3
.word -1
.word -23628
.word -21420
.word -8
.word -21420
.word 19532
.word 19532
.word 1
.word -18216
.word -3
.word -23628
.word -1
.word -21420
.word -10934
.fill 2, 1, 0
.word 19532
.word -1
.word 1
.word -18216
.word 1
.word -1
.word -1
.word -1
.word -8
.fill 2, 1, 0
.word -1
.word 19532
.word 1
.word -22925
.word -3
.word -1
.word -23628
.word -21420
.word -8
.word -21420

.section .data
.align 8
__const._ZL6func_1v.l_2300:
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_422

.section .data
.align 8
__const._ZL6func_1v.l_2323:
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL6g_1221
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL5g_245
.quad _ZL6g_1221
.quad _ZL6g_1221
.fill 8, 1, 0
.quad _ZL5g_245

.section .data
.align 8
__const._ZL6func_1v.l_2393:
.int -1
.int -1
.int -1
.int -1

.section .data
.align 8
__const._ZL6func_1v.l_2398:
.ascii "\xF8\x80\xF8\xFF\xF8\x80\xF8"
.ascii "p\xFC\xFCp\x01\x00\x00"
.ascii "\xFF\x80\xF6\x80\xFF\x80\xF6"
.ascii "\x01p\xFC\xFCp\x01\x00"
.ascii "\xF8\xFF\xF8\x80\xF8\xFF\xF8"

.section .data
.align 8
__const._ZL6func_1v.l_2419:
.word 24610
.fill 2, 1, 0
.word 24610
.fill 2, 1, 0

.section .data
.align 8
__const._ZL6func_1v.l_2420:
.word 1

.section .data
.align 8
__const._ZL6func_1v.l_2431:
.int -1
.int 1
.int -1
.int -9
.int -9
.int -1
.int 1
.int -1458929281
.int -2037217862
.int 1
.int 1
.int -2037217862
.int -1458929281
.int -2037217862
.int -1
.int -9
.int -9
.int -1
.int 1
.int -1
.int -9

.section .data
.align 8
__const._ZL6func_1v.l_2438:
.word -27195

.section .data
.align 8
__const._ZL6func_1v.l_2445:
.quad -3917657813870140125
.quad 3849861353668823529
.quad 0
.quad 6766247232868170495
.quad 8
.quad -3917657813870140125
.quad -728465569216903947
.quad -8166104977095878231
.quad -8166104977095878231
.quad -728465569216903947
.quad -3917657813870140125
.quad -728465569216903947
.quad -8166104977095878231
.quad -8166104977095878231
.quad -728465569216903947
.quad -3917657813870140125
.quad 8
.quad 6766247232868170495
.quad 0
.quad 3849861353668823529
.quad -3917657813870140125
.quad 8
.quad 6766247232868170495
.quad 0
.quad 3849861353668823529
.quad -3917657813870140125
.quad 4
.quad -8381085126885076989
.quad -8215331073916930251
.quad 3147099856984416980
.quad -3917657813870140125
.quad 4
.quad -8381085126885076989
.quad -8215331073916930251
.quad 3147099856984416980
.quad -3917657813870140125
.quad 3147099856984416980
.quad -8215331073916930251
.quad -8381085126885076989
.quad 4
.quad -3917657813870140125
.quad 3147099856984416980
.quad -8215331073916930251
.quad -8381085126885076989
.quad 4
.quad -3917657813870140125
.quad 3849861353668823529
.quad 0
.quad 6766247232868170495
.quad 8

.section .data
.align 8
__const._ZL6func_1v.l_2462:
.int -939128380
.int -1436823455
.int -939128380
.int -10
.int -10
.int -939128380
.int -1436823455
.int -939128380
.int -10
.int -10

.section .data
.align 8
__const._ZL6func_1v.l_2475:
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.quad _ZL5g_150
.fill 8, 1, 0
.quad _ZL5g_150
.fill 8, 1, 0

.section .data
.align 8
__const._ZL6func_1v.l_2541:
.int -1626403490
.int -1626403490
.int 268188372
.int -822529915
.int 268188372
.int -1626403490
.int -1626403490
.int 268188372
.int 100689136
.int 268188372
.int 268188372
.int 100689136
.int -1183618212
.int 100689136
.int 268188372
.int 268188372
.int 268188372
.int -1183618212
.int -822529915
.int -822529915
.int -1183618212
.int 268188372
.int -1183618212
.int -822529915
.int 100689136
.int -1183618212
.int 100689136
.int 268188372
.int 268188372
.int 100689136
.int -1183618212
.int 100689136
.int -1626403490
.int 268188372
.int -822529915
.int 268188372
.int -1626403490
.int -1626403490
.int 268188372
.int -822529915
.int -1626403490
.int -1626403490
.int 268188372
.int -822529915
.int 268188372
.int -1626403490
.int 268188372
.int 100689136
.int -822529915
.int 100689136
.int 100689136
.int -822529915
.int -1626403490
.int -822529915
.int 100689136
.int 100689136

.section .data
.align 8
__const._ZL6func_1v.l_2552:
.int 1
.int 1323863556
.int 1
.int 1
.int 1323863556
.int 1
.int 1
.int 1323863556

.section .data
.align 8
__const._ZL6func_1v.l_2564:
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_313
.fill 8, 1, 0
.quad _ZL5g_313
.quad _ZL5g_313
.fill 8, 1, 0
.quad _ZL5g_313
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_453
.quad _ZL5g_313
.quad _ZL5g_313
.fill 8, 1, 0
.quad _ZL5g_313
.quad _ZL5g_313
.fill 8, 1, 0
.quad _ZL5g_313
.quad _ZL5g_313

.section .data
.align 8
__const._ZL6func_1v.l_2573:
.word 24992

.section .data
.align 8
__const._ZL6func_1v.l_2605:
.word -25579

.section .data
.align 8
__const._ZL7func_39i2U0j.l_65:
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66
.quad _ZL4g_66

.section .data
.align 8
__const._ZL7func_39i2U0j.l_692:
.fill 2, 1, 0
.word -963
.word -963
.fill 2, 1, 0
.word -963
.word -963

.section .data
.align 8
__const._ZL7func_39i2U0j.l_694:
.quad _ZL3g_5
.quad _ZL3g_5
.quad _ZL5g_149+448
.quad _ZL3g_2
.quad _ZL5g_149+448
.quad _ZL3g_5
.quad _ZL3g_5
.quad _ZL5g_149+448
.quad _ZL3g_2
.quad _ZL5g_149+448

.section .data
.align 8
__const._ZL7func_532U1.l_659:
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_365
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_365
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL5g_365

.section .data
.align 8
__const._ZL7func_532U1.l_665:
.quad -8650298959325932638
.quad -3
.quad -8650298959325932638
.quad -3
.quad -8650298959325932638
.quad -3
.quad -8650298959325932638
.quad -3
.quad -8650298959325932638
.quad -3

.section .data
.align 8
__const._ZL7func_532U1.l_672:
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667
.quad _ZL5g_667

.section .data
.align 8
__const._ZL7func_532U1.l_681:
.int 1646807761
.int 1646807761
.int 1646807761
.int 1646807761

.section .data
.align 8
__const._ZL7func_532U1.l_689:
.word -6
.word -24617
.word -24617
.word -6
.word -24617
.word -24617
.word -6

.section .data
.align 8
__const._ZL7func_57majs2U2.l_102:
.quad -7965347547192635289
.quad -1
.quad 8687842191135717611
.quad 8687842191135717611
.quad 6304065726303921533
.quad 6304065726303921533
.quad 8687842191135717611
.quad 0
.quad -7965347547192635289
.quad 1
.quad 6793063423703358781
.quad -1
.quad 6
.quad 6793063423703358781
.quad 0
.quad 6793063423703358781
.quad 0
.quad 6793063423703358781
.quad 6
.quad -1
.quad 6793063423703358781
.quad 1
.quad -7965347547192635289
.quad 0
.quad 8687842191135717611
.quad 6304065726303921533
.quad 6304065726303921533
.quad 8687842191135717611
.quad 8687842191135717611
.quad -1
.quad -7965347547192635289
.quad -2018131615923420070
.quad 6793063423703358781
.quad 8687842191135717611
.quad 6
.quad 4625240128305499996
.quad 0
.quad -6949724734613251999
.quad 0
.quad 4625240128305499996
.quad 6
.quad 8687842191135717611
.quad 6793063423703358781
.quad -2018131615923420070
.quad -7965347547192635289
.quad -1
.quad 8687842191135717611
.quad 8687842191135717611
.quad 6304065726303921533
.quad 6304065726303921533
.quad 8687842191135717611
.quad 0
.quad -7965347547192635289
.quad 1
.quad 6793063423703358781
.quad -1
.quad 6
.quad 6793063423703358781
.quad 0
.quad 6793063423703358781
.quad 0
.quad 6793063423703358781
.quad 6
.quad -1
.quad 6793063423703358781
.quad 1
.quad -7965347547192635289
.quad 0
.quad 8687842191135717611
.quad 6304065726303921533
.quad 6304065726303921533
.quad 8687842191135717611
.quad 8687842191135717611
.quad -1
.quad -7965347547192635289
.quad -2018131615923420070
.quad 6793063423703358781
.quad 8687842191135717611
.quad 6
.quad 4625240128305499996

.section .data
.align 8
__const._ZL7func_57majs2U2.l_104:
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91

.section .data
.align 8
__const._ZL7func_57majs2U2.l_116:
.int -846516339
.int -902765594
.int -846516339
.int 1
.int -5
.int 113742486
.int -4
.int 1031099311
.int 2136063165
.int -5
.int -164524034
.int -3
.int -10
.int 2136063165
.int -7
.int -5
.int -872931236
.int -2
.int -4
.int 980693711
.int 980693711
.int 1
.int -3
.int -1
.int -846516339
.int -10
.int 8
.int 0
.int -381729268
.int 780415476
.int 1
.int 1445354951
.int 1
.int 113742486
.int 1
.int 0
.int -10
.int 980693711
.int -846516339
.int -7
.int -7
.int 1
.int 1
.int 0
.int -4
.int 583556693
.int -2
.int -5
.int -4
.int 1
.int -10
.int -9
.int 583556693
.int -5
.int -7
.int 1445354951
.int -4
.int 1
.int 0
.int 1
.int -1
.int 2136063165
.int -846516339
.int -381729268
.int 427963075
.int 0
.int 2136063165
.int -10
.int 1
.int -1
.int 0
.int -3
.int 2136063165
.int 8
.int -6
.int -381729268
.int -3
.int -3
.int -1
.int 1
.int 0
.int 1
.int -1
.int -164524034
.int -7
.int 1
.int 6
.int -9
.int 1512356527
.int -7
.int -4
.int 1
.int 1
.int 583556693
.int -1
.int -381729268
.int 1
.int 1
.int 1
.int -7
.int -3
.int 113742486
.int -10
.int 8
.int -902765594
.int 113742486
.int 0
.int 583556693
.int 812717484
.int -10
.int -902765594
.int 780415476
.int 427963075
.int 113742486
.int 1
.int 2136063165
.int 1
.int -872931236
.int 0
.int -381729268
.int -846516339
.int 1445354951
.int 1
.int 0
.int 583556693
.int -7
.int 980693711
.int 1
.int 6
.int 0
.int -2
.int -164524034
.int -846516339
.int 0
.int 0
.int -872931236
.int -7
.int -3
.int 1
.int 980693711
.int -6
.int 780415476
.int 1
.int -3
.int 812717484
.int 1
.int 1
.int 113742486
.int 1
.int 0
.int -10
.int 980693711
.int -846516339
.int -7
.int -7
.int 1
.int 1
.int 0
.int -4
.int 583556693
.int -2
.int -5
.int -4
.int 1
.int -10
.int -9
.int 583556693
.int -5
.int -7
.int 1445354951
.int -4
.int 1
.int 0
.int 1
.int -1
.int 2136063165
.int -846516339
.int -381729268
.int 427963075
.int 0
.int 2136063165
.int -10
.int 1
.int -1
.int 0
.int -3
.int 2136063165
.int 8
.int -6
.int -381729268
.int -3
.int -3
.int -1
.int 1
.int 0
.int 1
.int -1
.int -164524034
.int -7
.int 1
.int 6
.int -9
.int 1512356527
.int -7
.int -4
.int 1
.int 1
.int 583556693
.int -1
.int -381729268
.int 1
.int 1
.int 1
.int -7
.int -3
.int 113742486

.section .data
.align 8
__const._ZL7func_57majs2U2.l_545:
.word 1

.section .data
.align 8
__const._ZL7func_57majs2U2.l_571:
.word 4

.section .data
.align 8
__const._ZL7func_57majs2U2.l_572:
.word 1

.section .data
.align 8
__const._ZL7func_57majs2U2.l_99:
.word -5

.section .data
.align 8
constinit:
.quad _ZL5g_259
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL5g_259
.quad _ZL4g_91

.section .data
.align 8
constinit.124:
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91
.quad _ZL4g_91

.section .data
.align 8
constinit.126:
.quad _ZL3g_2
.fill 8, 1, 0
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL3g_2

.section .data
.align 8
constinit.127:
.quad _ZL3g_2
.fill 8, 1, 0
.fill 8, 1, 0
.fill 8, 1, 0
.quad _ZL3g_2

.section .text
.global _ZL10crc32_byteh
.p2align 4, 0x90
_ZL10crc32_byteh:
	.___ZL10crc32_byteh__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(6144:3): size = 1, type = i8*, var = ^2
	leaq -1(%rbp), %rax
	# LowerStore(6145:3).9: mov %dil, (^2)
	movb %dil, (%rax)
	# LowerLoad(6147:3).4: _ZL13crc32_context into ^3
	movq _ZL13crc32_context, %rcx
	movl %ecx, %ebx
	shrl $8, %ebx
	movl %ebx, %ecx
	andl $16777215, %ecx
	# LowerLoad(6150:3).4: _ZL13crc32_context into ^6
	movq _ZL13crc32_context, %rbx
	# LowerLoad(6151:3).2: (^2) into ^7
	movb (%rax), %sil
	# LowerBasicConversion(6152:3): ^7 -> ^8
	movl %esi, %edx
	movl %ebx, %eax
	xorl %edx, %eax
	movl %eax, %ebx
	andl $255, %ebx
	# LowerBasicConversion(6155:3): ^10 -> ^11
	movq %rbx, %rsi
	movq _ZL9crc32_tab, %rax
	movq _ZL9crc32_tab, %rax
	# LowerGetelementptr(6156:3): struct-type: ptr ^16 -> ^12, indices=0,%11
	movq %rax, %rdx
	movq %rsi, %rax
	shlq $3, %rax
	addq %rax, %rdx
	# LowerGetelementptr(6156:3): type of ^12 is ptr*
	# LowerLoad(6157:3).2: (^12) into ^13
	movl (%rdx), %ebx
	movl %ecx, %eax
	xorl %ebx, %eax
	# LowerStore(6159:3).8a: movq var, %temp
	movq _ZL13crc32_context@GOTPCREL(%rip), %rbx
	# LowerStore(6159:3).8b: movq ^14, (%temp)
	movl %eax, (%rbx)
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_div_func_uint32_t_u_ujj
.p2align 4, 0x90
_ZL26safe_div_func_uint32_t_u_ujj:
	.___ZL26safe_div_func_uint32_t_u_ujj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4080:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(4081:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4082:3).9: mov %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(4084:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4086:3).2: (^4) into ^5
	movl (%rax), %ebx
	# LowerIcmp(4087:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	sete %bl
	cmpb $0, %bl
	jne .___ZL26safe_div_func_uint32_t_u_ujj__M14
	jmp .___ZL26safe_div_func_uint32_t_u_ujj__M19
	.___ZL26safe_div_func_uint32_t_u_ujj__M14:
	# LowerLoad(4091:3).2: (^3) into ^8
	movl (%rcx), %ebx
	# MovePhi: ^8 -> ^14
	movl %ebx, %eax
	jmp .___ZL26safe_div_func_uint32_t_u_ujj__M34
	.___ZL26safe_div_func_uint32_t_u_ujj__M19:
	# LowerLoad(4095:3).2: (^3) into ^10
	movl (%rcx), %ebx
	# LowerLoad(4096:3).2: (^4) into ^11
	movl (%rax), %ecx
	# Clobber %rax
	movq %rax, -16(%rbp)
	movl $0, %edx
	movl %ebx, %eax
	divl %ecx
	movl %eax, %ebx
	# Unclobber %rax
	movq -16(%rbp), %rax
	# MovePhi: ^12 -> ^14
	movl %ebx, %eax
	.___ZL26safe_div_func_uint32_t_u_ujj__M34:
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL15transparent_crcmPci
.p2align 4, 0x90
_ZL15transparent_crcmPci:
	.___ZL15transparent_crcmPci__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	movq %rbx, -32(%rbp)
	movq %r12, -40(%rbp)
	# LowerAlloca(3343:3): size = 8, type = i64*, var = ^4
	leaq -8(%rbp), %rax
	# LowerAlloca(3344:3): size = 8, type = ptr*, var = ^5
	leaq -16(%rbp), %rbx
	# LowerAlloca(3345:3): size = 4, type = i32*, var = ^6
	leaq -20(%rbp), %r12
	# LowerStore(3346:3).9: mov %rdi, (^4)
	movq %rdi, (%rax)
	# LowerStore(3348:3).9: mov %rsi, (^5)
	movq %rsi, (%rbx)
	# LowerStore(3350:3).9: mov %edx, (^6)
	movl %edx, (%r12)
	# LowerLoad(3352:3).2: (^4) into ^7
	movq (%rax), %rcx
	# SetupCalls(3353:3): move argument i64 ^7
	movq %rcx, %rdi
	callq _ZL12crc32_8bytesm@GOTPCREL(%rip)
	# LowerLoad(3354:3).2: (^6) into ^8
	movl (%r12), %eax
	# LowerIcmp(3355:3): i32 ^8 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .___ZL15transparent_crcmPci__M41
	jmp .___ZL15transparent_crcmPci__M79
	.___ZL15transparent_crcmPci__M41:
	# LowerLoad(3359:3).2: (^5) into ^11
	movq (%rbx), %rcx
	# LowerLoad(3360:3).4: _ZL13crc32_context into ^12
	movq _ZL13crc32_context, %rax
	# LowerBasicConversion(3361:3): ^12 -> ^13
	movq %rax, %rbx
	movq %rbx, %rax
	movabsq $4294967295, %rbx
	xorq %rbx, %rax
	# SetupCalls(3363:3): move argument ptr @.str.128
	movq .str.128, %rdi
	# SetupCalls(3363:3): move argument ptr ^11
	movq %rcx, %rsi
	# SetupCalls(3363:3): move argument i64 ^14
	movq %rax, %rdx
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(3363:3): move result from %rax
	movl %eax, %eax
	.___ZL15transparent_crcmPci__M79:
	movq -40(%rbp), %r12
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_mod_func_int16_t_s_sss
.p2align 4, 0x90
_ZL25safe_mod_func_int16_t_s_sss:
	.___ZL25safe_mod_func_int16_t_s_sss__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(104 + 0, 16)
	subq $112, %rsp
	movq %rbx, -32(%rbp)
	# LowerAlloca(4036:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rdx
	# LowerAlloca(4037:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(4038:3).9: mov %di, (^3)
	movw %di, (%rdx)
	# LowerStore(4040:3).9: mov %si, (^4)
	movw %si, (%rax)
	# LowerLoad(4042:3).2: (^4) into ^5
	movw (%rax), %bx
	movswl %bx, %ecx
	# LowerIcmp(4044:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	sete %bl
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int16_t_s_sss__M29
	.___ZL25safe_mod_func_int16_t_s_sss__M15:
	# LowerLoad(4048:3).2: (^3) into ^9
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerIcmp(4050:3): i32 ^10 vs. intlike -32768
	cmpl $-32768, %ecx
	sete %bl
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int16_t_s_sss__M22
	jmp .___ZL25safe_mod_func_int16_t_s_sss__M35
	.___ZL25safe_mod_func_int16_t_s_sss__M22:
	# LowerLoad(4054:3).2: (^4) into ^13
	movw (%rax), %cx
	movswl %cx, %ebx
	# LowerIcmp(4056:3): i32 ^14 vs. intlike -1
	cmpl $-1, %ebx
	sete %bl
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int16_t_s_sss__M29
	jmp .___ZL25safe_mod_func_int16_t_s_sss__M35
	.___ZL25safe_mod_func_int16_t_s_sss__M29:
	# LowerLoad(4060:3).2: (^3) into ^17
	movw (%rdx), %bx
	movswl %bx, %eax
	# MovePhi: ^18 -> ^26
	movl %eax, %r8d
	jmp .___ZL25safe_mod_func_int16_t_s_sss__M52
	.___ZL25safe_mod_func_int16_t_s_sss__M35:
	# LowerLoad(4065:3).2: (^3) into ^20
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerLoad(4067:3).2: (^4) into ^22
	movw (%rax), %bx
	movswl %bx, %esi
	# Clobber %rax
	movq %rax, -16(%rbp)
	# Clobber %rdx
	movq %rdx, -24(%rbp)
	movl $0, %edx
	movl %ecx, %eax
	idivl %esi
	movl %edx, %ebx
	# Unclobber %rdx
	movq -24(%rbp), %rdx
	# Unclobber %rax
	movq -16(%rbp), %rax
	# MovePhi: ^24 -> ^26
	movl %ebx, %r8d
	.___ZL25safe_mod_func_int16_t_s_sss__M52:
	# LowerTrunc(4074:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(4074:3): 32 to 16, apply mask
	andw $65535, %ax
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_add_func_int64_t_s_sll
.p2align 4, 0x90
_ZL25safe_add_func_int64_t_s_sll:
	.___ZL25safe_add_func_int64_t_s_sll__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(128 + 0, 16)
	subq $128, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(3953:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(3954:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(3955:3).9: mov %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(3957:3).9: mov %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(3959:3).2: (^3) into ^5
	movq (%rcx), %rbx
	# LowerIcmp(3960:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	setg %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M14
	jmp .___ZL25safe_add_func_int64_t_s_sll__M31
	.___ZL25safe_add_func_int64_t_s_sll__M14:
	# LowerLoad(3964:3).2: (^4) into ^8
	movq (%rax), %rbx
	# LowerIcmp(3965:3): i64 ^8 vs. intlike 0
	cmpq $0, %rbx
	setg %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M20
	jmp .___ZL25safe_add_func_int64_t_s_sll__M31
	.___ZL25safe_add_func_int64_t_s_sll__M20:
	# LowerLoad(3969:3).2: (^3) into ^11
	movq (%rcx), %rsi
	# LowerLoad(3970:3).2: (^4) into ^12
	movq (%rax), %rdx
	movabsq $9223372036854775807, %rdi
	movq %rdi, %rbx
	subq %rdx, %rbx
	# LowerIcmp(3972:3): i64 ^11 vs. operand i64 ^13
	cmpq %rbx, %rsi
	setg %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M54
	.___ZL25safe_add_func_int64_t_s_sll__M31:
	# LowerLoad(3976:3).2: (^3) into ^16
	movq (%rcx), %rbx
	# LowerIcmp(3977:3): i64 ^16 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M37
	jmp .___ZL25safe_add_func_int64_t_s_sll__M59
	.___ZL25safe_add_func_int64_t_s_sll__M37:
	# LowerLoad(3981:3).2: (^4) into ^19
	movq (%rax), %rbx
	# LowerIcmp(3982:3): i64 ^19 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M43
	jmp .___ZL25safe_add_func_int64_t_s_sll__M59
	.___ZL25safe_add_func_int64_t_s_sll__M43:
	# LowerLoad(3986:3).2: (^3) into ^22
	movq (%rcx), %rbx
	# LowerLoad(3987:3).2: (^4) into ^23
	movq (%rax), %rdx
	movabsq $-9223372036854775808, %rdi
	movq %rdi, %rsi
	subq %rdx, %rsi
	# LowerIcmp(3989:3): i64 ^22 vs. operand i64 ^24
	cmpq %rsi, %rbx
	setl %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int64_t_s_sll__M54
	jmp .___ZL25safe_add_func_int64_t_s_sll__M59
	.___ZL25safe_add_func_int64_t_s_sll__M54:
	# LowerLoad(3993:3).2: (^3) into ^27
	movq (%rcx), %rax
	# MovePhi: ^27 -> ^33
	movq %rax, %rbx
	jmp .___ZL25safe_add_func_int64_t_s_sll__M68
	.___ZL25safe_add_func_int64_t_s_sll__M59:
	# LowerLoad(3997:3).2: (^3) into ^29
	movq (%rcx), %rbx
	# LowerLoad(3998:3).2: (^4) into ^30
	movq (%rax), %rcx
	movq %rbx, %rax
	addq %rcx, %rax
	# MovePhi: ^31 -> ^33
	movq %rax, %rbx
	.___ZL25safe_add_func_int64_t_s_sll__M68:
	movq %rbx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_rshift_func_uint32_t_u_sji
.p2align 4, 0x90
_ZL29safe_rshift_func_uint32_t_u_sji:
	.___ZL29safe_rshift_func_uint32_t_u_sji__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3882:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(3883:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3884:3).9: mov %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(3886:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3888:3).2: (^4) into ^5
	movl (%rax), %ebx
	# LowerIcmp(3889:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL29safe_rshift_func_uint32_t_u_sji__M20
	.___ZL29safe_rshift_func_uint32_t_u_sji__M14:
	# LowerLoad(3893:3).2: (^4) into ^8
	movl (%rax), %ebx
	# LowerIcmp(3894:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	cmpb $0, %bl
	jne .___ZL29safe_rshift_func_uint32_t_u_sji__M20
	jmp .___ZL29safe_rshift_func_uint32_t_u_sji__M25
	.___ZL29safe_rshift_func_uint32_t_u_sji__M20:
	# LowerLoad(3898:3).2: (^3) into ^11
	movl (%rcx), %eax
	# MovePhi: ^11 -> ^17
	movl %eax, %ebx
	jmp .___ZL29safe_rshift_func_uint32_t_u_sji__M36
	.___ZL29safe_rshift_func_uint32_t_u_sji__M25:
	# LowerLoad(3902:3).2: (^3) into ^13
	movl (%rcx), %edx
	# LowerLoad(3903:3).2: (^4) into ^14
	movl (%rax), %ebx
	# LowerShift(3904:3): operand ^14 changed to %cl
	movb %bl, %cl
	movl %edx, %eax
	shrl %cl, %eax
	# MovePhi: ^15 -> ^17
	movl %eax, %ebx
	.___ZL29safe_rshift_func_uint32_t_u_sji__M36:
	movl %ebx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL17platform_main_endji
.p2align 4, 0x90
_ZL17platform_main_endji:
	.___ZL17platform_main_endji__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(16 + 0, 16)
	subq $16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3374:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rbx
	# LowerAlloca(3375:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3376:3).9: mov %edi, (^3)
	movl %edi, (%rbx)
	# LowerStore(3378:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3380:3).2: (^3) into ^5
	movl (%rbx), %eax
	# SetupCalls(3381:3): move argument ptr @.str.131
	movq .str.131, %rdi
	# SetupCalls(3381:3): move argument i32 ^5
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(3381:3): move result from %rax
	movl %eax, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_mul_func_uint16_t_u_utt
.p2align 4, 0x90
_ZL26safe_mul_func_uint16_t_u_utt:
	.___ZL26safe_mul_func_uint16_t_u_utt__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3663:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(3664:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(3665:3).9: mov %di, (^3)
	movw %di, (%rcx)
	# LowerStore(3667:3).9: mov %si, (^4)
	movw %si, (%rax)
	# LowerLoad(3669:3).2: (^3) into ^5
	movw (%rcx), %bx
	# LowerBasicConversion(3670:3): ^5 -> ^6
	movl %ebx, %ecx
	# LowerLoad(3671:3).2: (^4) into ^7
	movw (%rax), %dx
	# LowerBasicConversion(3672:3): ^7 -> ^8
	movl %edx, %ebx
	movq %rcx, %eax
	mull %ebx
	movl %eax, %ebx
	# LowerTrunc(3674:3): 32 to 16, move
	movw %bx, %ax
	# LowerTrunc(3674:3): 32 to 16, apply mask
	andw $65535, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_mul_func_int16_t_s_sss
.p2align 4, 0x90
_ZL25safe_mul_func_int16_t_s_sss:
	.___ZL25safe_mul_func_int16_t_s_sss__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4209:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(4210:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(4211:3).9: mov %di, (^3)
	movw %di, (%rcx)
	# LowerStore(4213:3).9: mov %si, (^4)
	movw %si, (%rax)
	# LowerLoad(4215:3).2: (^3) into ^5
	movw (%rcx), %bx
	movswl %bx, %ecx
	# LowerLoad(4217:3).2: (^4) into ^7
	movw (%rax), %dx
	movswl %dx, %ebx
	movq %rcx, %eax
	mull %ebx
	movl %eax, %ebx
	# LowerTrunc(4220:3): 32 to 16, move
	movw %bx, %ax
	# LowerTrunc(4220:3): 32 to 16, apply mask
	andw $65535, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_mul_func_uint8_t_u_uhh
.p2align 4, 0x90
_ZL25safe_mul_func_uint8_t_u_uhh:
	.___ZL25safe_mul_func_uint8_t_u_uhh__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3611:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rcx
	# LowerAlloca(3612:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(3613:3).9: mov %dil, (^3)
	movb %dil, (%rcx)
	# LowerStore(3615:3).9: mov %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(3617:3).2: (^3) into ^5
	movb (%rcx), %bl
	# LowerBasicConversion(3618:3): ^5 -> ^6
	movl %ebx, %ecx
	# LowerLoad(3619:3).2: (^4) into ^7
	movb (%rax), %dl
	# LowerBasicConversion(3620:3): ^7 -> ^8
	movl %edx, %ebx
	movq %rcx, %eax
	mull %ebx
	movl %eax, %ebx
	# LowerTrunc(3622:3): 32 to 8, move
	movb %bl, %al
	# LowerTrunc(3622:3): 32 to 8, apply mask
	andb $255, %al
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL12crc32_gentabv
.p2align 4, 0x90
_ZL12crc32_gentabv:
	.___ZL12crc32_gentabv__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(1569:3): size = 4, type = i32*, var = ^1
	leaq -4(%rbp), %rbx
	# LowerAlloca(1570:3): size = 4, type = i32*, var = ^2
	leaq -8(%rbp), %rax
	# LowerAlloca(1571:3): size = 4, type = i32*, var = ^3
	leaq -12(%rbp), %rdx
	# LowerAlloca(1572:3): size = 4, type = i32*, var = ^4
	leaq -16(%rbp), %rcx
	# LowerStore(1575:3).3: mov $imm, ^2
	movl $-306674912, (%rax)
	# LowerStore(1578:3).3: mov $imm, ^3
	movl $0, (%rdx)
	.___ZL12crc32_gentabv__M13:
	# LowerLoad(1582:3).2: (^3) into ^6
	movl (%rdx), %eax
	# LowerIcmp(1583:3): i32 ^6 vs. intlike 256
	cmpl $256, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL12crc32_gentabv__M19
	jmp .___ZL12crc32_gentabv__M87
	.___ZL12crc32_gentabv__M19:
	# LowerLoad(1587:3).2: (^3) into ^9
	movl (%rdx), %eax
	# LowerStore(1588:3).9: mov ^9, (^1)
	movl %eax, (%rbx)
	# LowerStore(1589:3).3: mov $imm, ^4
	movl $8, (%rcx)
	.___ZL12crc32_gentabv__M26:
	# LowerLoad(1593:3).2: (^4) into ^11
	movl (%rcx), %eax
	# LowerIcmp(1594:3): i32 ^11 vs. intlike 0
	cmpl $0, %eax
	setg %al
	cmpb $0, %al
	jne .___ZL12crc32_gentabv__M32
	jmp .___ZL12crc32_gentabv__M64
	.___ZL12crc32_gentabv__M32:
	# LowerLoad(1598:3).2: (^1) into ^14
	movl (%rbx), %eax
	movl %eax, %esi
	andl $1, %esi
	# LowerIcmp(1600:3): i32 ^15 vs. intlike 0
	cmpl $0, %esi
	setne %al
	cmpb $0, %al
	jne .___ZL12crc32_gentabv__M40
	jmp .___ZL12crc32_gentabv__M49
	.___ZL12crc32_gentabv__M40:
	# LowerLoad(1604:3).2: (^1) into ^18
	movl (%rbx), %eax
	movl %eax, %esi
	shrl $1, %esi
	movl %esi, %eax
	xorl $-306674912, %eax
	# LowerStore(1607:3).9: mov ^20, (^1)
	movl %eax, (%rbx)
	jmp .___ZL12crc32_gentabv__M56
	.___ZL12crc32_gentabv__M49:
	# LowerLoad(1611:3).2: (^1) into ^22
	movl (%rbx), %eax
	movl %eax, %esi
	shrl $1, %esi
	# LowerStore(1613:3).9: mov ^23, (^1)
	movl %esi, (%rbx)
	.___ZL12crc32_gentabv__M56:
	# LowerLoad(1620:3).2: (^4) into ^26
	movl (%rcx), %eax
	movl %eax, %esi
	addl $-1, %esi
	# LowerStore(1622:3).9: mov ^27, (^4)
	movl %esi, (%rcx)
	jmp .___ZL12crc32_gentabv__M26
	.___ZL12crc32_gentabv__M64:
	# LowerLoad(1626:3).2: (^1) into ^29
	movl (%rbx), %esi
	# LowerLoad(1627:3).2: (^3) into ^30
	movl (%rdx), %eax
	movslq %eax, %rdi
	movq _ZL9crc32_tab, %rax
	movq _ZL9crc32_tab, %rax
	# LowerGetelementptr(1629:3): struct-type: ptr ^38 -> ^32, indices=0,%31
	movq %rax, %r8
	movq %rdi, %rax
	shlq $3, %rax
	addq %rax, %r8
	# LowerGetelementptr(1629:3): type of ^32 is ptr*
	# LowerStore(1630:3).9: mov ^29, (^32)
	movl %esi, (%r8)
	# LowerLoad(1634:3).2: (^3) into ^34
	movl (%rdx), %eax
	movl %eax, %esi
	addl $1, %esi
	# LowerStore(1636:3).9: mov ^35, (^3)
	movl %esi, (%rdx)
	jmp .___ZL12crc32_gentabv__M13
	.___ZL12crc32_gentabv__M87:
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_div_func_uint16_t_u_utt
.p2align 4, 0x90
_ZL26safe_div_func_uint16_t_u_utt:
	.___ZL26safe_div_func_uint16_t_u_utt__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(72 + 0, 16)
	subq $80, %rsp
	movq %rbx, -32(%rbp)
	# LowerAlloca(3579:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rdx
	# LowerAlloca(3580:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(3581:3).9: mov %di, (^3)
	movw %di, (%rdx)
	# LowerStore(3583:3).9: mov %si, (^4)
	movw %si, (%rax)
	# LowerLoad(3585:3).2: (^4) into ^5
	movw (%rax), %bx
	# LowerBasicConversion(3586:3): ^5 -> ^6
	movl %ebx, %ecx
	# LowerIcmp(3587:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	sete %bl
	cmpb $0, %bl
	jne .___ZL26safe_div_func_uint16_t_u_utt__M16
	jmp .___ZL26safe_div_func_uint16_t_u_utt__M23
	.___ZL26safe_div_func_uint16_t_u_utt__M16:
	# LowerLoad(3591:3).2: (^3) into ^9
	movw (%rdx), %ax
	# LowerBasicConversion(3592:3): ^9 -> ^10
	movl %eax, %ebx
	# MovePhi: ^10 -> ^18
	movl %ebx, %r8d
	jmp .___ZL26safe_div_func_uint16_t_u_utt__M42
	.___ZL26safe_div_func_uint16_t_u_utt__M23:
	# LowerLoad(3596:3).2: (^3) into ^12
	movw (%rdx), %bx
	# LowerBasicConversion(3597:3): ^12 -> ^13
	movl %ebx, %ecx
	# LowerLoad(3598:3).2: (^4) into ^14
	movw (%rax), %bx
	# LowerBasicConversion(3599:3): ^14 -> ^15
	movl %ebx, %esi
	# Clobber %rax
	movq %rax, -16(%rbp)
	# Clobber %rdx
	movq %rdx, -24(%rbp)
	movl $0, %edx
	movl %ecx, %eax
	idivl %esi
	movl %eax, %ebx
	# Unclobber %rdx
	movq -24(%rbp), %rdx
	# Unclobber %rax
	movq -16(%rbp), %rax
	# MovePhi: ^16 -> ^18
	movl %ebx, %r8d
	.___ZL26safe_div_func_uint16_t_u_utt__M42:
	# LowerTrunc(3605:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(3605:3): 32 to 16, apply mask
	andw $65535, %ax
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_div_func_uint64_t_u_umm
.p2align 4, 0x90
_ZL26safe_div_func_uint64_t_u_umm:
	.___ZL26safe_div_func_uint64_t_u_umm__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(64 + 0, 16)
	subq $64, %rsp
	movq %rbx, -32(%rbp)
	# LowerAlloca(4136:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(4137:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(4138:3).9: mov %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(4140:3).9: mov %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(4142:3).2: (^4) into ^5
	movq (%rax), %rbx
	# LowerIcmp(4143:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	sete %bl
	cmpb $0, %bl
	jne .___ZL26safe_div_func_uint64_t_u_umm__M14
	jmp .___ZL26safe_div_func_uint64_t_u_umm__M19
	.___ZL26safe_div_func_uint64_t_u_umm__M14:
	# LowerLoad(4147:3).2: (^3) into ^8
	movq (%rcx), %rbx
	# MovePhi: ^8 -> ^14
	movq %rbx, %rax
	jmp .___ZL26safe_div_func_uint64_t_u_umm__M34
	.___ZL26safe_div_func_uint64_t_u_umm__M19:
	# LowerLoad(4151:3).2: (^3) into ^10
	movq (%rcx), %rbx
	# LowerLoad(4152:3).2: (^4) into ^11
	movq (%rax), %rcx
	# Clobber %rax
	movq %rax, -24(%rbp)
	movq $0, %rdx
	movq %rbx, %rax
	divq %rcx
	movq %rax, %rbx
	# Unclobber %rax
	movq -24(%rbp), %rax
	# MovePhi: ^12 -> ^14
	movq %rbx, %rax
	.___ZL26safe_div_func_uint64_t_u_umm__M34:
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_add_func_uint32_t_u_ujj
.p2align 4, 0x90
_ZL26safe_add_func_uint32_t_u_ujj:
	.___ZL26safe_add_func_uint32_t_u_ujj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(16 + 0, 16)
	subq $16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3565:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(3566:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3567:3).9: mov %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(3569:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3571:3).2: (^3) into ^5
	movl (%rcx), %ebx
	# LowerLoad(3572:3).2: (^4) into ^6
	movl (%rax), %ecx
	movl %ebx, %eax
	addl %ecx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL24safe_add_func_int8_t_s_saa
.p2align 4, 0x90
_ZL24safe_add_func_int8_t_s_saa:
	.___ZL24safe_add_func_int8_t_s_saa__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4263:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rcx
	# LowerAlloca(4264:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(4265:3).9: mov %dil, (^3)
	movb %dil, (%rcx)
	# LowerStore(4267:3).9: mov %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(4269:3).2: (^3) into ^5
	movb (%rcx), %bl
	movsbl %bl, %ecx
	# LowerLoad(4271:3).2: (^4) into ^7
	movb (%rax), %dl
	movsbl %dl, %ebx
	movl %ecx, %eax
	addl %ebx, %eax
	# LowerTrunc(4274:3): 32 to 8, move
	movb %al, %bl
	# LowerTrunc(4274:3): 32 to 8, apply mask
	andb $255, %bl
	movb %bl, %al
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_add_func_int16_t_s_sss
.p2align 4, 0x90
_ZL25safe_add_func_int16_t_s_sss:
	.___ZL25safe_add_func_int16_t_s_sss__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4743:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(4744:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(4745:3).9: mov %di, (^3)
	movw %di, (%rcx)
	# LowerStore(4747:3).9: mov %si, (^4)
	movw %si, (%rax)
	# LowerLoad(4749:3).2: (^3) into ^5
	movw (%rcx), %bx
	movswl %bx, %ecx
	# LowerLoad(4751:3).2: (^4) into ^7
	movw (%rax), %dx
	movswl %dx, %ebx
	movl %ecx, %eax
	addl %ebx, %eax
	# LowerTrunc(4754:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(4754:3): 32 to 16, apply mask
	andw $65535, %bx
	movw %bx, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_sub_func_uint16_t_u_utt
.p2align 4, 0x90
_ZL26safe_sub_func_uint16_t_u_utt:
	.___ZL26safe_sub_func_uint16_t_u_utt__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3914:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(3915:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(3916:3).9: mov %di, (^3)
	movw %di, (%rcx)
	# LowerStore(3918:3).9: mov %si, (^4)
	movw %si, (%rax)
	# LowerLoad(3920:3).2: (^3) into ^5
	movw (%rcx), %bx
	# LowerBasicConversion(3921:3): ^5 -> ^6
	movl %ebx, %ecx
	# LowerLoad(3922:3).2: (^4) into ^7
	movw (%rax), %dx
	# LowerBasicConversion(3923:3): ^7 -> ^8
	movl %edx, %ebx
	movl %ecx, %eax
	subl %ebx, %eax
	# LowerTrunc(3925:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(3925:3): 32 to 16, apply mask
	andw $65535, %bx
	movw %bx, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_sub_func_int64_t_s_sll
.p2align 4, 0x90
_ZL25safe_sub_func_int64_t_s_sll:
	.___ZL25safe_sub_func_int64_t_s_sll__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(88 + 0, 16)
	subq $96, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(3390:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rdx
	# LowerAlloca(3391:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(3392:3).9: mov %rdi, (^3)
	movq %rdi, (%rdx)
	# LowerStore(3394:3).9: mov %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(3396:3).2: (^3) into ^5
	movq (%rdx), %rbx
	# LowerLoad(3397:3).2: (^4) into ^6
	movq (%rax), %rcx
	movq %rbx, %rdi
	xorq %rcx, %rdi
	# LowerLoad(3399:3).2: (^3) into ^8
	movq (%rdx), %rcx
	# LowerLoad(3400:3).2: (^3) into ^9
	movq (%rdx), %rbx
	# LowerLoad(3401:3).2: (^4) into ^10
	movq (%rax), %rsi
	movq %rbx, %r8
	xorq %rsi, %r8
	movq %r8, %rbx
	movabsq $-9223372036854775808, %rsi
	andq %rsi, %rbx
	movq %rcx, %rsi
	xorq %rbx, %rsi
	# LowerLoad(3405:3).2: (^4) into ^14
	movq (%rax), %rbx
	movq %rsi, %rcx
	subq %rbx, %rcx
	# LowerLoad(3407:3).2: (^4) into ^16
	movq (%rax), %rbx
	movq %rcx, %rsi
	xorq %rbx, %rsi
	movq %rdi, %rbx
	andq %rsi, %rbx
	# LowerIcmp(3410:3): i64 ^18 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	cmpb $0, %bl
	jne .___ZL25safe_sub_func_int64_t_s_sll__M42
	jmp .___ZL25safe_sub_func_int64_t_s_sll__M47
	.___ZL25safe_sub_func_int64_t_s_sll__M42:
	# LowerLoad(3414:3).2: (^3) into ^21
	movq (%rdx), %rax
	# MovePhi: ^21 -> ^27
	movq %rax, %rbx
	jmp .___ZL25safe_sub_func_int64_t_s_sll__M56
	.___ZL25safe_sub_func_int64_t_s_sll__M47:
	# LowerLoad(3418:3).2: (^3) into ^23
	movq (%rdx), %rbx
	# LowerLoad(3419:3).2: (^4) into ^24
	movq (%rax), %rcx
	movq %rbx, %rax
	subq %rcx, %rax
	# MovePhi: ^25 -> ^27
	movq %rax, %rbx
	.___ZL25safe_sub_func_int64_t_s_sll__M56:
	movq %rbx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_mod_func_uint64_t_u_umm
.p2align 4, 0x90
_ZL26safe_mod_func_uint64_t_u_umm:
	.___ZL26safe_mod_func_uint64_t_u_umm__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(64 + 0, 16)
	subq $64, %rsp
	movq %rbx, -32(%rbp)
	# LowerAlloca(4009:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(4010:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(4011:3).9: mov %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(4013:3).9: mov %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(4015:3).2: (^4) into ^5
	movq (%rax), %rbx
	# LowerIcmp(4016:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	sete %bl
	cmpb $0, %bl
	jne .___ZL26safe_mod_func_uint64_t_u_umm__M14
	jmp .___ZL26safe_mod_func_uint64_t_u_umm__M19
	.___ZL26safe_mod_func_uint64_t_u_umm__M14:
	# LowerLoad(4020:3).2: (^3) into ^8
	movq (%rcx), %rbx
	# MovePhi: ^8 -> ^14
	movq %rbx, %rax
	jmp .___ZL26safe_mod_func_uint64_t_u_umm__M34
	.___ZL26safe_mod_func_uint64_t_u_umm__M19:
	# LowerLoad(4024:3).2: (^3) into ^10
	movq (%rcx), %rbx
	# LowerLoad(4025:3).2: (^4) into ^11
	movq (%rax), %rcx
	# Clobber %rax
	movq %rax, -24(%rbp)
	movq $0, %rdx
	movq %rbx, %rax
	divq %rcx
	movq %rdx, %rbx
	# Unclobber %rax
	movq -24(%rbp), %rax
	# MovePhi: ^12 -> ^14
	movq %rbx, %rax
	.___ZL26safe_mod_func_uint64_t_u_umm__M34:
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL24safe_sub_func_int8_t_s_saa
.p2align 4, 0x90
_ZL24safe_sub_func_int8_t_s_saa:
	.___ZL24safe_sub_func_int8_t_s_saa__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3444:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rcx
	# LowerAlloca(3445:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(3446:3).9: mov %dil, (^3)
	movb %dil, (%rcx)
	# LowerStore(3448:3).9: mov %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(3450:3).2: (^3) into ^5
	movb (%rcx), %bl
	movsbl %bl, %ecx
	# LowerLoad(3452:3).2: (^4) into ^7
	movb (%rax), %dl
	movsbl %dl, %ebx
	movl %ecx, %eax
	subl %ebx, %eax
	# LowerTrunc(3455:3): 32 to 8, move
	movb %al, %bl
	# LowerTrunc(3455:3): 32 to 8, apply mask
	andb $255, %bl
	movb %bl, %al
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZN2U2aSERKS_
.p2align 4, 0x90
_ZN2U2aSERKS_:
	.___ZN2U2aSERKS___M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	movq %rbx, -40(%rbp)
	movq %r12, -48(%rbp)
	movq %r13, -32(%rbp)
	# LowerAlloca(4107:3): size = 8, type = ptr*, var = ^3
	leaq -8(%rbp), %r13
	# LowerAlloca(4108:3): size = 8, type = ptr*, var = ^4
	leaq -16(%rbp), %rax
	# LowerAlloca(4109:3): size = 8, type = ptr*, var = ^5
	leaq -24(%rbp), %rbx
	# LowerStore(4110:3).9: mov %rdi, (^4)
	movq %rdi, (%rax)
	# LowerStore(4112:3).9: mov %rsi, (^5)
	movq %rsi, (%rbx)
	# LowerLoad(4114:3).2: (^4) into ^6
	movq (%rax), %r12
	# LowerLoad(4115:3).2: (^5) into ^7
	movq (%rbx), %rax
	# LowerIcmp(4116:3): ptr ^6 vs. operand ptr ^7
	cmpq %rax, %r12
	sete %al
	cmpb $0, %al
	jne .___ZN2U2aSERKS___M18
	jmp .___ZN2U2aSERKS___M21
	.___ZN2U2aSERKS___M18:
	# LowerStore(4120:3).9: mov ^6, (^3)
	movq %r12, (%r13)
	jmp .___ZN2U2aSERKS___M51
	.___ZN2U2aSERKS___M21:
	# LowerLoad(4124:3).2: (^5) into ^11
	movq (%rbx), %rax
	# SetupCalls(4125:3): move argument ptr align 8 ^6
	movq %r12, %rdi
	# SetupCalls(4125:3): move argument ptr align 8 ^11
	movq %rax, %rsi
	# SetupCalls(4125:3): move argument i64 8
	movq $8, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(4126:3).9: mov ^6, (^3)
	movq %r12, (%r13)
	.___ZN2U2aSERKS___M51:
	# LowerLoad(4130:3).2: (^3) into ^13
	movq (%r13), %rax
	movq -32(%rbp), %r13
	movq -48(%rbp), %r12
	movq -40(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL31safe_unary_minus_func_int16_t_ss
.p2align 4, 0x90
_ZL31safe_unary_minus_func_int16_t_ss:
	.___ZL31safe_unary_minus_func_int16_t_ss__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3931:3): size = 2, type = i16*, var = ^2
	leaq -2(%rbp), %rax
	# LowerStore(3932:3).9: mov %di, (^2)
	movw %di, (%rax)
	# LowerLoad(3934:3).2: (^2) into ^3
	movw (%rax), %bx
	movswl %bx, %eax
	movl $0, %ebx
	subl %eax, %ebx
	# LowerTrunc(3937:3): 32 to 16, move
	movw %bx, %ax
	# LowerTrunc(3937:3): 32 to 16, apply mask
	andw $65535, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_int64_t_s_ulj
.p2align 4, 0x90
_ZL28safe_lshift_func_int64_t_s_ulj:
	.___ZL28safe_lshift_func_int64_t_s_ulj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(88 + 0, 16)
	subq $96, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4557:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rdx
	# LowerAlloca(4558:3): size = 4, type = i32*, var = ^4
	leaq -12(%rbp), %rax
	# LowerStore(4559:3).9: mov %rdi, (^3)
	movq %rdi, (%rdx)
	# LowerStore(4561:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4563:3).2: (^3) into ^5
	movq (%rdx), %rbx
	# LowerIcmp(4564:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_ulj__M35
	.___ZL28safe_lshift_func_int64_t_s_ulj__M14:
	# LowerLoad(4568:3).2: (^4) into ^8
	movl (%rax), %ebx
	# LowerIcmp(4569:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_ulj__M35
	.___ZL28safe_lshift_func_int64_t_s_ulj__M20:
	# LowerLoad(4573:3).2: (^3) into ^11
	movq (%rdx), %rdi
	# LowerLoad(4574:3).2: (^4) into ^12
	movl (%rax), %ecx
	# LowerBasicConversion(4575:3): ^12 -> ^13
	movq %rcx, %rbx
	# LowerShift(4576:3): operand ^13 changed to %cl
	movb %bl, %cl
	movabsq $9223372036854775807, %rsi
	movq %rsi, %rbx
	sarq %cl, %rbx
	# LowerIcmp(4577:3): i64 ^11 vs. operand i64 ^14
	cmpq %rbx, %rdi
	setg %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_ulj__M35
	jmp .___ZL28safe_lshift_func_int64_t_s_ulj__M40
	.___ZL28safe_lshift_func_int64_t_s_ulj__M35:
	# LowerLoad(4581:3).2: (^3) into ^17
	movq (%rdx), %rax
	# MovePhi: ^17 -> ^24
	movq %rax, %rbx
	jmp .___ZL28safe_lshift_func_int64_t_s_ulj__M53
	.___ZL28safe_lshift_func_int64_t_s_ulj__M40:
	# LowerLoad(4585:3).2: (^3) into ^19
	movq (%rdx), %rbx
	# LowerLoad(4586:3).2: (^4) into ^20
	movl (%rax), %ecx
	# LowerBasicConversion(4587:3): ^20 -> ^21
	movq %rcx, %rax
	# LowerShift(4588:3): operand ^21 changed to %cl
	movb %al, %cl
	movq %rbx, %rax
	shlq %cl, %rax
	# MovePhi: ^22 -> ^24
	movq %rax, %rbx
	.___ZL28safe_lshift_func_int64_t_s_ulj__M53:
	movq %rbx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_lshift_func_uint64_t_u_smi
.p2align 4, 0x90
_ZL29safe_lshift_func_uint64_t_u_smi:
	.___ZL29safe_lshift_func_uint64_t_u_smi__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(88 + 0, 16)
	subq $96, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4626:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rdx
	# LowerAlloca(4627:3): size = 4, type = i32*, var = ^4
	leaq -12(%rbp), %rax
	# LowerStore(4628:3).9: mov %rdi, (^3)
	movq %rdi, (%rdx)
	# LowerStore(4630:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4632:3).2: (^4) into ^5
	movl (%rax), %ebx
	# LowerIcmp(4633:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint64_t_u_smi__M34
	.___ZL29safe_lshift_func_uint64_t_u_smi__M14:
	# LowerLoad(4637:3).2: (^4) into ^8
	movl (%rax), %ebx
	# LowerIcmp(4638:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint64_t_u_smi__M34
	.___ZL29safe_lshift_func_uint64_t_u_smi__M20:
	# LowerLoad(4642:3).2: (^3) into ^11
	movq (%rdx), %rsi
	# LowerLoad(4643:3).2: (^4) into ^12
	movl (%rax), %ecx
	# LowerBasicConversion(4644:3): ^12 -> ^13
	movq %rcx, %rbx
	# LowerShift(4645:3): operand ^13 changed to %cl
	movb %bl, %cl
	movq $-1, %rbx
	shrq %cl, %rbx
	# LowerIcmp(4646:3): i64 ^11 vs. operand i64 ^14
	cmpq %rbx, %rsi
	seta %bl
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint64_t_u_smi__M34
	jmp .___ZL29safe_lshift_func_uint64_t_u_smi__M39
	.___ZL29safe_lshift_func_uint64_t_u_smi__M34:
	# LowerLoad(4650:3).2: (^3) into ^17
	movq (%rdx), %rax
	# MovePhi: ^17 -> ^24
	movq %rax, %rbx
	jmp .___ZL29safe_lshift_func_uint64_t_u_smi__M52
	.___ZL29safe_lshift_func_uint64_t_u_smi__M39:
	# LowerLoad(4654:3).2: (^3) into ^19
	movq (%rdx), %rbx
	# LowerLoad(4655:3).2: (^4) into ^20
	movl (%rax), %ecx
	# LowerBasicConversion(4656:3): ^20 -> ^21
	movq %rcx, %rax
	# LowerShift(4657:3): operand ^21 changed to %cl
	movb %al, %cl
	movq %rbx, %rax
	shlq %cl, %rax
	# MovePhi: ^22 -> ^24
	movq %rax, %rbx
	.___ZL29safe_lshift_func_uint64_t_u_smi__M52:
	movq %rbx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL7func_39i2U0j
.p2align 4, 0x90
_ZL7func_39i2U0j:
	.___ZL7func_39i2U0j__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(1032 + 0, 16)
	subq $1040, %rsp
	movq %rbx, -760(%rbp)
	movq %r12, -784(%rbp)
	movq %r13, -768(%rbp)
	movq %r14, -776(%rbp)
	movq %r15, -792(%rbp)
	# LowerAlloca(3680:3): size = 2, type = %union.U1*, var = ^4
	# Fixing leaq -2(%rbp), -616(%rbp)
	pushq %r15
	leaq -2(%rbp), %r15
	movq %r15, -616(%rbp)
	popq %r15
	# LowerAlloca(3681:3): size = 4, type = %union.U0*, var = ^5
	# Fixing leaq -8(%rbp), -744(%rbp)
	pushq %r15
	leaq -8(%rbp), %r15
	movq %r15, -744(%rbp)
	popq %r15
	# LowerAlloca(3682:3): size = 4, type = i32*, var = ^6
	# Fixing leaq -12(%rbp), -720(%rbp)
	pushq %r15
	leaq -12(%rbp), %r15
	movq %r15, -720(%rbp)
	popq %r15
	# LowerAlloca(3683:3): size = 4, type = i32*, var = ^7
	# Fixing leaq -16(%rbp), -736(%rbp)
	pushq %r15
	leaq -16(%rbp), %r15
	movq %r15, -736(%rbp)
	popq %r15
	# LowerAlloca(3684:3): size = 4, type = %union.U0*, var = ^8
	# Fixing leaq -20(%rbp), -752(%rbp)
	pushq %r15
	leaq -20(%rbp), %r15
	movq %r15, -752(%rbp)
	popq %r15
	# LowerAlloca(3685:3): size = 8, type = ptr*, var = ^9
	leaq -32(%rbp), %rbx
	# LowerAlloca(3686:3): size = 192, type = [8 x [3 x ptr]]*, var = ^10
	leaq -224(%rbp), %rcx
	# LowerAlloca(3687:3): size = 4, type = i32*, var = ^11
	# Fixing leaq -228(%rbp), -624(%rbp)
	pushq %r15
	leaq -228(%rbp), %r15
	movq %r15, -624(%rbp)
	popq %r15
	# LowerAlloca(3688:3): size = 8, type = i64*, var = ^12
	# Fixing leaq -240(%rbp), -688(%rbp)
	pushq %r15
	leaq -240(%rbp), %r15
	movq %r15, -688(%rbp)
	popq %r15
	# LowerAlloca(3689:3): size = 256, type = [8 x [4 x ptr]]*, var = ^13
	leaq -496(%rbp), %r13
	# LowerAlloca(3690:3): size = 4, type = i32*, var = ^14
	# Fixing leaq -500(%rbp), -696(%rbp)
	pushq %r15
	leaq -500(%rbp), %r15
	movq %r15, -696(%rbp)
	popq %r15
	# LowerAlloca(3691:3): size = 8, type = %union.U2*, var = ^15
	# Fixing leaq -512(%rbp), -672(%rbp)
	pushq %r15
	leaq -512(%rbp), %r15
	movq %r15, -672(%rbp)
	popq %r15
	# LowerAlloca(3692:3): size = 12, type = [6 x [1 x %union.U4]]*, var = ^16
	# Fixing leaq -524(%rbp), -648(%rbp)
	pushq %r15
	leaq -524(%rbp), %r15
	movq %r15, -648(%rbp)
	popq %r15
	# LowerAlloca(3693:3): size = 80, type = [10 x ptr]*, var = ^17
	leaq -608(%rbp), %r14
	andq $-4, %rsp
	# LowerAlloca(3694:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(3694:3): mov %rsp, ^18
	movq %rsp, %r12
	andq $-4, %rsp
	# LowerAlloca(3695:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(3695:3): mov %rsp, ^19
	movq %rsp, %r15
	andq $-2, %rsp
	# LowerAlloca(3696:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(3696:3): mov %rsp, ^20
	movq %rsp, -656(%rbp)
	andq $-4, %rsp
	# LowerAlloca(3697:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(3697:3): mov %rsp, ^21
	movq %rsp, -664(%rbp)
	andq $-8, %rsp
	# LowerAlloca(3698:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(3698:3): mov %rsp, ^22
	movq %rsp, -680(%rbp)
	andq $-2, %rsp
	# LowerAlloca(3699:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(3699:3): mov %rsp, ^23
	movq %rsp, -632(%rbp)
	andq $-4, %rsp
	# LowerAlloca(3700:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(3700:3): mov %rsp, ^24
	movq %rsp, -640(%rbp)
	# LowerGetelementptr(3701:3): struct-type: ptr ^5 -> ^25, indices=0,0
	movq -744(%rbp), %rax
	# LowerGetelementptr(3701:3): type of ^25 is ptr*
	# LowerStore(3702:3).9: mov %esi, (^25)
	movl %esi, (%rax)
	# LowerStore(3703:3).9: mov %edi, (^6)
	movq -720(%rbp), %rax
	movl %edi, (%rax)
	# LowerStore(3706:3).9: mov %edx, (^7)
	movq -736(%rbp), %rax
	movl %edx, (%rax)
	# LowerStore(3709:3).3: mov $imm, ^8
	movq -752(%rbp), %rax
	movl $8, (%rax)
	# LowerStore(3711:3).9: mov ^8, (^9)
	# Fixing movq -752(%rbp), (%rbx)
	pushq %r15
	movq -752(%rbp), %r15
	movq %r15, (%rbx)
	popq %r15
	# SetupCalls(3713:3): move argument ptr align 16 ^10
	movq %rcx, %rdi
	# SetupCalls(3713:3): move argument ptr align 16 @__const._ZL7func_39i2U0j.l_65
	movq __const._ZL7func_39i2U0j.l_65, %rsi
	# SetupCalls(3713:3): move argument i64 192
	movq $192, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(3715:3).3: mov $imm, ^11
	movq -624(%rbp), %rax
	movl $0, (%rax)
	# LowerStore(3717:3).3: mov $imm, ^12
	movq -688(%rbp), %rax
	movq $-1, (%rax)
	# LowerStore(3719:3).3: mov $imm, ^4
	movq -616(%rbp), %rax
	movb $0, (%rax)
	# LowerStore(3722:3).3: mov $imm, ^14
	movq -696(%rbp), %rax
	movl $-1587066959, (%rax)
	# LowerStore(3724:3).3: mov $imm, ^15
	movabsq $-3918988697788526482, %rcx
	movq -672(%rbp), %rax
	movq %rcx, (%rax)
	# SetupCalls(3726:3): move argument ptr align 2 ^16
	movq -648(%rbp), %rdi
	# SetupCalls(3726:3): move argument ptr align 2 @__const._ZL7func_39i2U0j.l_692
	movq __const._ZL7func_39i2U0j.l_692, %rsi
	# SetupCalls(3726:3): move argument i64 12
	movq $12, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# SetupCalls(3728:3): move argument ptr align 16 ^17
	movq %r14, %rdi
	# SetupCalls(3728:3): move argument ptr align 16 @__const._ZL7func_39i2U0j.l_694
	movq __const._ZL7func_39i2U0j.l_694, %rsi
	# SetupCalls(3728:3): move argument i64 80
	movq $80, %rdx
	# SetupCalls(3728:3): move argument i1 false
	movq $0, %rcx
	callq llvm.memcpy.p0.p0.i64@PLT@GOTPCREL(%rip)
	# LowerStore(3731:3).3: mov $imm, ^18
	movl $0, (%r12)
	.___ZL7func_39i2U0j__M168:
	# LowerLoad(3735:3).2: (^18) into ^27
	movl (%r12), %eax
	# LowerIcmp(3736:3): i32 ^27 vs. intlike 8
	cmpl $8, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL7func_39i2U0j__M174
	jmp .___ZL7func_39i2U0j__M221
	.___ZL7func_39i2U0j__M174:
	# LowerStore(3740:3).3: mov $imm, ^19
	movl $0, (%r15)
	.___ZL7func_39i2U0j__M177:
	# LowerLoad(3744:3).2: (^19) into ^31
	movl (%r15), %eax
	# LowerIcmp(3745:3): i32 ^31 vs. intlike 4
	cmpl $4, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL7func_39i2U0j__M183
	jmp .___ZL7func_39i2U0j__M213
	.___ZL7func_39i2U0j__M183:
	# LowerLoad(3749:3).2: (^18) into ^34
	movl (%r12), %eax
	movslq %eax, %rdx
	# LowerGetelementptr(3751:3): struct-type: ptr ^13 -> ^36, indices=0,%35
	movq %r13, %rcx
	movq %rdx, %rax
	shlq $3, %rax
	addq %rax, %rcx
	# LowerGetelementptr(3751:3): type of ^36 is ptr*
	# LowerLoad(3752:3).2: (^19) into ^37
	movl (%r15), %eax
	movslq %eax, %rdx
	# LowerGetelementptr(3754:3): struct-type: ptr ^36 -> ^39, indices=0,%38
	movq %rcx, %rax
	movq %rdx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(3754:3): type of ^39 is ptr*
	# LowerStore(3755:3).6: load global
	movq _ZL4g_66@GOTPCREL(%rip), %rcx
	# LowerStore(3755:3).9: mov ^136, (^39)
	movq %rcx, (%rax)
	# LowerLoad(3759:3).2: (^19) into ^41
	movl (%r15), %eax
	movl %eax, %ecx
	addl $1, %ecx
	# LowerStore(3761:3).9: mov ^42, (^19)
	movl %ecx, (%r15)
	jmp .___ZL7func_39i2U0j__M177
	.___ZL7func_39i2U0j__M213:
	# LowerLoad(3768:3).2: (^18) into ^45
	movl (%r12), %ecx
	movl %ecx, %eax
	addl $1, %eax
	# LowerStore(3770:3).9: mov ^46, (^18)
	movl %eax, (%r12)
	jmp .___ZL7func_39i2U0j__M168
	.___ZL7func_39i2U0j__M221:
	# LowerLoad(3774:3).2: (^9) into ^48
	movq (%rbx), %rax
	# SetupCalls(3775:3): move argument ptr nonnull dereferenceable(4) align 4 ^48
	movq %rax, %rdi
	# SetupCalls(3775:3): move argument ptr nonnull dereferenceable(4) align 4 ^8
	movq -752(%rbp), %rsi
	callq _ZN2U0aSERKS_@GOTPCREL(%rip)
	# SetupCalls(3775:3): move result from %rax
	movq %rax, %rbx
	# SetupCalls(3776:3): move argument ptr nonnull dereferenceable(4) align 4 ^5
	movq -744(%rbp), %rdi
	# SetupCalls(3776:3): move argument ptr nonnull dereferenceable(4) align 4 ^49
	movq %rbx, %rsi
	callq _ZN2U0aSERKS_@GOTPCREL(%rip)
	# SetupCalls(3776:3): move result from %rax
	movq %rax, %rax
	# LowerLoad(3777:3).4: _ZL3g_5 into ^51
	movq _ZL3g_5, %rax
	movslq %eax, %r14
	# LowerLoad(3779:3).4: _ZL3g_5 into ^53
	movq _ZL3g_5, %rax
	# LowerTrunc(3780:3): 32 to 8, move
	movb %al, -728(%rbp)
	# LowerTrunc(3780:3): 32 to 8, apply mask
	andb $255, -728(%rbp)
	# LowerLoad(3781:3).2: (^11) into ^55
	movq -624(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerLoad(3783:3).2: (^12) into ^57
	movq -688(%rbp), %rax
	movq (%rax), %rcx
	# LowerTrunc(3784:3): 64 to 32, move
	movl %ecx, %r12d
	# LowerTrunc(3784:3): 64 to 32, apply mask
	movabsq $4294967295, %rax
	andl %eax, %r12d
	# LowerLoad(3785:3).2: (^6) into ^59
	movq -720(%rbp), %rax
	movl (%rax), %ecx
	# LowerLoad(3786:3).2: (^7) into ^60
	movq -736(%rbp), %rax
	movl (%rax), %edx
	# LowerIcmp(3787:3): i32 ^59 vs. operand i32 ^60
	cmpl %edx, %ecx
	seta %al
	# LowerBasicConversion(3788:3): ^61 -> ^62
	movw %ax, %cx
	# LowerLoad(3789:3).2: (^6) into ^63
	movq -720(%rbp), %rdx
	movl (%rdx), %eax
	# SetupCalls(3790:3): move argument i16 signext ^62
	movw %cx, %di
	movswq %di, %rdi
	# SetupCalls(3790:3): move argument i32 ^63
	movl %eax, %esi
	callq _ZL28safe_lshift_func_int16_t_s_ssi@GOTPCREL(%rip)
	# SetupCalls(3790:3): move result from %rax
	movw %ax, %r13w
	# LowerIcmp(3791:3): i16 ^64 vs. intlike 0
	cmpw $0, %r13w
	setne %al
	cmpb $0, %al
	jne .___ZL7func_39i2U0j__M334
	jmp .___ZL7func_39i2U0j__M337
	.___ZL7func_39i2U0j__M334:
	# MovePhi: intlike -> ^68 (in new block 138 whose parent is 127)
	movb $1, -704(%rbp)
	jmp .___ZL7func_39i2U0j__M340
	.___ZL7func_39i2U0j__M337:
	# MovePhi: intlike -> ^68
	movb $1, -704(%rbp)
	.___ZL7func_39i2U0j__M340:
	# LowerBasicConversion(3799:3): ^68 -> ^69
	movl -704(%rbp), %eax
	# SetupCalls(3800:3): move argument i32 ^58
	movl %r12d, %edi
	# SetupCalls(3800:3): move argument i32 ^69
	movl %eax, %esi
	callq _ZL26safe_mod_func_uint32_t_u_ujj@GOTPCREL(%rip)
	# SetupCalls(3800:3): move result from %rax
	movl %eax, %r12d
	# LowerBasicConversion(3801:3): ^70 -> ^71
	movq %r12, %rax
	# SetupCalls(3802:3): move argument i64 ^71
	movq %rax, %rdi
	# SetupCalls(3802:3): move argument i64 1
	movq $1, %rsi
	callq _ZL26safe_div_func_uint64_t_u_umm@GOTPCREL(%rip)
	# SetupCalls(3802:3): move result from %rax
	movq %rax, %r12
	# LowerLoad(3803:3).4: _ZL3g_2 into ^73
	movq _ZL3g_2, %rax
	movslq %eax, %rcx
	# LowerIcmp(3805:3): i64 ^72 vs. operand i64 ^74
	cmpq %rcx, %r12
	setae %al
	# LowerLoad(3806:3).2: (^4) into ^76
	movq -616(%rbp), %rax
	movb (%rax), %cl
	movsbw %cl, %ax
	# LowerLoad(3808:3).4: _ZL3g_5 into ^78
	movq _ZL3g_5, %rcx
	# LowerTrunc(3809:3): 32 to 16, move
	movw %cx, %dx
	# LowerTrunc(3809:3): 32 to 16, apply mask
	andw $65535, %dx
	# SetupCalls(3810:3): move argument i16 zeroext ^77
	movw %ax, %di
	andq $65535, %rdi
	# SetupCalls(3810:3): move argument i16 zeroext ^79
	movw %dx, %si
	andq $65535, %rsi
	callq _ZL26safe_add_func_uint16_t_u_utt@GOTPCREL(%rip)
	# SetupCalls(3810:3): move result from %rax
	movw %ax, %r12w
	# LowerBasicConversion(3811:3): ^80 -> ^81
	movl %r12d, %eax
	# LowerStore(3812:3).9: mov ^81, (^14)
	movq -696(%rbp), %rcx
	movl %eax, (%rcx)
	movslq %eax, %rcx
	movq $3, %rax
	# LowerIcmp(3814:3): i64 ^132 vs. operand i64 ^82
	cmpq %rcx, %rax
	setbe %al
	# LowerBasicConversion(3815:3): ^83 -> ^84
	movq %rax, %rcx
	# LowerLoad(3816:3).2: (^11) into ^85
	movq -624(%rbp), %rax
	movl (%rax), %edx
	movslq %edx, %rax
	# SetupCalls(3818:3): move argument i64 ^84
	movq %rcx, %rdi
	# SetupCalls(3818:3): move argument i64 ^86
	movq %rax, %rsi
	callq _ZL25safe_sub_func_int64_t_s_sll@GOTPCREL(%rip)
	# SetupCalls(3818:3): move result from %rax
	movq %rax, %r12
	# LowerIcmp(3819:3): i64 ^56 vs. operand i64 ^87
	cmpq %r12, %rbx
	setge %al
	# LowerBasicConversion(3820:3): ^88 -> ^89
	movq %rax, %rbx
	# LowerIcmp(3821:3): i64 ^89 vs. intlike 151
	cmpq $151, %rbx
	setg %al
	# LowerBasicConversion(3822:3): ^90 -> ^91
	movq %rax, %rbx
	movq $1, %rax
	# LowerIcmp(3823:3): i64 ^133 vs. operand i64 ^91
	cmpq %rbx, %rax
	setle %al
	# LowerBasicConversion(3824:3): ^92 -> ^93
	movb %al, %bl
	# LowerLoad(3825:3).2: (^12) into ^94
	movq -688(%rbp), %rax
	movq (%rax), %rcx
	# LowerTrunc(3826:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(3826:3): 64 to 8, apply mask
	andb $255, %al
	# SetupCalls(3827:3): move argument i8 zeroext ^93
	movb %bl, %dil
	andq $255, %rdi
	# SetupCalls(3827:3): move argument i8 zeroext ^95
	movb %al, %sil
	andq $255, %rsi
	callq _ZL25safe_mod_func_uint8_t_u_uhh@GOTPCREL(%rip)
	# SetupCalls(3827:3): move result from %rax
	movb %al, %bl
	# LowerBasicConversion(3828:3): ^96 -> ^97
	movl %ebx, %r12d
	# LowerLoad(3829:3).4: _ZL3g_5 into ^98
	movq _ZL3g_5, %rax
	# LowerTrunc(3830:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(3830:3): 32 to 16, apply mask
	andw $65535, %bx
	# SetupCalls(3831:3): move argument ptr align 8 ^22
	movq -680(%rbp), %rdi
	# SetupCalls(3831:3): move argument ptr align 8 ^15
	movq -672(%rbp), %rsi
	# SetupCalls(3831:3): move argument i64 8
	movq $8, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerGetelementptr(3832:3): struct-type: ptr ^22 -> ^100, indices=0,0
	movq -680(%rbp), %rax
	# LowerGetelementptr(3832:3): type of ^100 is ptr*
	# LowerLoad(3833:3).2: (^100) into ^101
	movq (%rax), %r9
	# SetupCalls(3834:3): move argument i64 ^52
	movq %r14, %rdi
	# SetupCalls(3834:3): move argument i8 signext ^54
	movb -728(%rbp), %sil
	movsbq %sil, %rsi
	# SetupCalls(3834:3): move argument i32 ^97
	movl %r12d, %edx
	# SetupCalls(3834:3): move argument i16 signext ^99
	movw %bx, %cx
	movswq %cx, %rcx
	# SetupCalls(3834:3): move argument i64 ^101
	movq %r9, %r8
	callq _ZL7func_57majs2U2@GOTPCREL(%rip)
	# SetupCalls(3834:3): move result from %rax
	movl %eax, %ebx
	# LowerGetelementptr(3835:3): struct-type: ptr ^21 -> ^103, indices=0,0
	movq -664(%rbp), %rax
	# LowerGetelementptr(3835:3): type of ^103 is ptr*
	# LowerStore(3836:3).9: mov ^102, (^103)
	movl %ebx, (%rax)
	# LowerGetelementptr(3837:3): struct-type: ptr ^21 -> ^104, indices=0,0
	movq -664(%rbp), %rax
	# LowerGetelementptr(3837:3): type of ^104 is ptr*
	# LowerLoad(3838:3).2: (^104) into ^105
	movl (%rax), %ebx
	# SetupCalls(3839:3): move argument i32 ^105
	movl %ebx, %edi
	callq _ZL7func_552U0@GOTPCREL(%rip)
	# SetupCalls(3839:3): move result from %rax
	movw %ax, %bx
	# LowerGetelementptr(3840:3): struct-type: ptr ^20 -> ^107, indices=0,0
	movq -656(%rbp), %rax
	# LowerGetelementptr(3840:3): type of ^107 is ptr*
	# LowerStore(3841:3).9: mov ^106, (^107)
	movw %bx, (%rax)
	# LowerGetelementptr(3842:3): struct-type: ptr ^20 -> ^108, indices=0,0
	movq -656(%rbp), %rax
	# LowerGetelementptr(3842:3): type of ^108 is ptr*
	# LowerLoad(3843:3).2: (^108) into ^109
	movw (%rax), %bx
	# SetupCalls(3844:3): move argument i16 ^109
	movw %bx, %di
	callq _ZL7func_532U1@GOTPCREL(%rip)
	# SetupCalls(3844:3): move result from %rax
	movl %eax, %r12d
	# LowerLoad(3845:3).4: _ZL3g_2 into ^111
	movq _ZL3g_2, %r13
	# LowerGetelementptr(3846:3): struct-type: ptr ^16 -> ^112, indices=0,2
	movq -648(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(3846:3): type of ^112 is ptr*
	# LowerGetelementptr(3847:3): struct-type: ptr ^112 -> ^113, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(3847:3): type of ^113 is ptr*
	# SetupCalls(3848:3): move argument ptr align 2 ^23
	movq -632(%rbp), %rdi
	# SetupCalls(3848:3): move argument ptr align 2 ^113
	movq %rbx, %rsi
	# SetupCalls(3848:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerLoad(3849:3).2: (^11) into ^114
	movq -624(%rbp), %rax
	movl (%rax), %ebx
	# LowerTrunc(3850:3): 32 to 16, move
	movw %bx, %r14w
	# LowerTrunc(3850:3): 32 to 16, apply mask
	andw $65535, %r14w
	# SetupCalls(3851:3): move argument ptr align 4 ^24
	movq -640(%rbp), %rdi
	# SetupCalls(3851:3): move argument ptr align 4 @_ZL5g_693
	movq _ZL5g_693, %rsi
	# SetupCalls(3851:3): move argument i64 4
	movq $4, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerGetelementptr(3852:3): struct-type: ptr ^23 -> ^116, indices=0,0
	movq -632(%rbp), %rax
	# LowerGetelementptr(3852:3): type of ^116 is ptr*
	# LowerLoad(3853:3).2: (^116) into ^117
	movw (%rax), %bx
	# LowerGetelementptr(3854:3): struct-type: ptr ^24 -> ^118, indices=0,0
	movq -640(%rbp), %rax
	# LowerGetelementptr(3854:3): type of ^118 is ptr*
	# LowerLoad(3855:3).2: (^118) into ^119
	movl (%rax), %r9d
	# SetupCalls(3856:3): move argument i32 ^110
	movl %r12d, %edi
	# SetupCalls(3856:3): move argument i32 ^111
	movl %r13d, %esi
	# SetupCalls(3856:3): move argument i16 ^117
	movw %bx, %dx
	# SetupCalls(3856:3): move argument i16 zeroext ^115
	movw %r14w, %cx
	andq $65535, %rcx
	# SetupCalls(3856:3): move argument i32 ^119
	movl %r9d, %r8d
	callq _ZL7func_47ij2U4t2U0@GOTPCREL(%rip)
	# SetupCalls(3856:3): move result from %rax
	movl %eax, %ebx
	# SetupCalls(3857:3): move argument i32 ^120
	movl %ebx, %edi
	# SetupCalls(3857:3): move argument i32 -1748839321
	movq $-1748839321, %rsi
	callq _ZL25safe_add_func_int32_t_s_sii@GOTPCREL(%rip)
	# SetupCalls(3857:3): move result from %rax
	movl %eax, %ebx
	# LowerLoad(3858:3).4: _ZL5g_695 into ^122
	movq _ZL5g_695, %rax
	movl %eax, %ecx
	xorl %ebx, %ecx
	# LowerStore(3860:3).8a: movq var, %temp
	movq _ZL5g_695@GOTPCREL(%rip), %rax
	# LowerStore(3860:3).8b: movq ^123, (%temp)
	movl %ecx, (%rax)
	# LowerGetelementptr(3861:3): struct-type: ptr ^4 -> ^124, indices=0,0
	movq -616(%rbp), %rax
	# LowerGetelementptr(3861:3): type of ^124 is ptr*
	# LowerLoad(3862:3).2: (^124) into ^125
	movw (%rax), %bx
	movw %bx, %ax
	movq -792(%rbp), %r15
	movq -776(%rbp), %r14
	movq -768(%rbp), %r13
	movq -784(%rbp), %r12
	movq -760(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global main
.p2align 4, 0x90
main:
	.__main__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(1864 + 0, 16)
	subq $1872, %rsp
	movq %rbx, -64(%rbp)
	movq %r12, -72(%rbp)
	movq %r13, -88(%rbp)
	movq %r14, -96(%rbp)
	movq %r15, -80(%rbp)
	# LowerAlloca(336:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rdx
	# LowerAlloca(337:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rbx
	# LowerAlloca(338:3): size = 8, type = ptr*, var = ^5
	leaq -16(%rbp), %rcx
	# LowerAlloca(339:3): size = 4, type = i32*, var = ^6
	leaq -20(%rbp), %r12
	# LowerAlloca(340:3): size = 4, type = i32*, var = ^7
	leaq -24(%rbp), %r15
	# LowerAlloca(341:3): size = 4, type = i32*, var = ^8
	leaq -28(%rbp), %r13
	# LowerAlloca(342:3): size = 4, type = i32*, var = ^9
	# Fixing leaq -32(%rbp), -48(%rbp)
	pushq %r15
	leaq -32(%rbp), %r15
	movq %r15, -48(%rbp)
	popq %r15
	# LowerAlloca(343:3): size = 2, type = %union.U4*, var = ^10
	leaq -34(%rbp), %r14
	# LowerStore(344:3).3: mov $imm, ^3
	movl $0, (%rdx)
	# LowerStore(345:3).9: mov %edi, (^4)
	movl %edi, (%rbx)
	# LowerStore(347:3).9: mov %rsi, (^5)
	movq %rsi, (%rcx)
	# LowerStore(353:3).3: mov $imm, ^9
	movq -48(%rbp), %rax
	movl $0, (%rax)
	# LowerLoad(354:3).2: (^4) into ^11
	movl (%rbx), %eax
	# LowerIcmp(355:3): i32 ^11 vs. intlike 2
	cmpl $2, %eax
	sete %al
	cmpb $0, %al
	jne .__main__M30
	jmp .__main__M70
	.__main__M30:
	# LowerLoad(359:3).2: (^5) into ^14
	movq (%rcx), %rax
	# LowerGetelementptr(360:3): struct-type: ptr ^14 -> ^15, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(360:3): type of ^15 is ptr*
	# LowerLoad(361:3).2: (^15) into ^16
	movq (%rbx), %rax
	# Clobber %rcx
	movq %rcx, -56(%rbp)
	# SetupCalls(362:3): move argument ptr ^16
	movq %rax, %rdi
	# SetupCalls(362:3): move argument ptr @.str
	movq .str, %rsi
	callq strcmp@PLT@GOTPCREL(%rip)
	# SetupCalls(362:3): move result from %rax
	movl %eax, %ebx
	# Unclobber %rcx
	movq -56(%rbp), %rcx
	# LowerIcmp(363:3): i32 ^17 vs. intlike 0
	cmpl $0, %ebx
	sete %al
	cmpb $0, %al
	jne .__main__M67
	jmp .__main__M70
	.__main__M67:
	# LowerStore(367:3).3: mov $imm, ^9
	movq -48(%rbp), %rax
	movl $1, (%rax)
	.__main__M70:
	callq _ZL12crc32_gentabv@GOTPCREL(%rip)
	callq _ZL6func_1v@GOTPCREL(%rip)
	# SetupCalls(373:3): move result from %rax
	movw %ax, %bx
	# LowerGetelementptr(374:3): struct-type: ptr ^10 -> ^22, indices=0,0
	movq %r14, %rax
	# LowerGetelementptr(374:3): type of ^22 is ptr*
	# LowerStore(375:3).9: mov ^21, (^22)
	movw %bx, (%rax)
	# LowerLoad(376:3).4: _ZL3g_2 into ^23
	movq _ZL3g_2, %rax
	movslq %eax, %rcx
	# LowerLoad(378:3).2: (^9) into ^25
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# SetupCalls(379:3): move argument i64 ^24
	movq %rcx, %rdi
	# SetupCalls(379:3): move argument ptr @.str.1
	movq .str.1, %rsi
	# SetupCalls(379:3): move argument i32 ^25
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(380:3).4: _ZL3g_5 into ^26
	movq _ZL3g_5, %rax
	movslq %eax, %rbx
	# LowerLoad(382:3).2: (^9) into ^28
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(383:3): move argument i64 ^27
	movq %rbx, %rdi
	# SetupCalls(383:3): move argument ptr @.str.2
	movq .str.2, %rsi
	# SetupCalls(383:3): move argument i32 ^28
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(384:3).4: _ZL4g_91 into ^29
	movq _ZL4g_91, %rax
	# LowerBasicConversion(385:3): ^29 -> ^30
	movq %rax, %rbx
	# LowerLoad(386:3).2: (^9) into ^31
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(387:3): move argument i64 ^30
	movq %rbx, %rdi
	# SetupCalls(387:3): move argument ptr @.str.3
	movq .str.3, %rsi
	# SetupCalls(387:3): move argument i32 ^31
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(388:3).4: _ZL5g_106 into ^32
	movq _ZL5g_106, %rax
	# LowerBasicConversion(389:3): ^32 -> ^33
	movq %rax, %rbx
	# LowerLoad(390:3).2: (^9) into ^34
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(391:3): move argument i64 ^33
	movq %rbx, %rdi
	# SetupCalls(391:3): move argument ptr @.str.4
	movq .str.4, %rsi
	# SetupCalls(391:3): move argument i32 ^34
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(392:3).4: _ZL5g_107 into ^35
	movq _ZL5g_107, %rbx
	# LowerBasicConversion(393:3): ^35 -> ^36
	movq %rbx, %rax
	# LowerLoad(394:3).2: (^9) into ^37
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(395:3): move argument i64 ^36
	movq %rax, %rdi
	# SetupCalls(395:3): move argument ptr @.str.5
	movq .str.5, %rsi
	# SetupCalls(395:3): move argument i32 ^37
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(396:3).4: _ZL5g_117 into ^38
	movq _ZL5g_117, %rbx
	movswq %bx, %rax
	# LowerLoad(398:3).2: (^9) into ^40
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(399:3): move argument i64 ^39
	movq %rax, %rdi
	# SetupCalls(399:3): move argument ptr @.str.6
	movq .str.6, %rsi
	# SetupCalls(399:3): move argument i32 ^40
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(400:3).4: _ZL5g_118 into ^41
	movq _ZL5g_118, %rax
	movslq %eax, %rbx
	# LowerLoad(402:3).2: (^9) into ^43
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(403:3): move argument i64 ^42
	movq %rbx, %rdi
	# SetupCalls(403:3): move argument ptr @.str.7
	movq .str.7, %rsi
	# SetupCalls(403:3): move argument i32 ^43
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(404:3).4: _ZL5g_119 into ^44
	movq _ZL5g_119, %rax
	movslq %eax, %rbx
	# LowerLoad(406:3).2: (^9) into ^46
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(407:3): move argument i64 ^45
	movq %rbx, %rdi
	# SetupCalls(407:3): move argument ptr @.str.8
	movq .str.8, %rsi
	# SetupCalls(407:3): move argument i32 ^46
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(408:3).4: _ZL5g_120 into ^47
	movq _ZL5g_120, %rax
	movswq %ax, %rbx
	# LowerLoad(410:3).2: (^9) into ^49
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(411:3): move argument i64 ^48
	movq %rbx, %rdi
	# SetupCalls(411:3): move argument ptr @.str.9
	movq .str.9, %rsi
	# SetupCalls(411:3): move argument i32 ^49
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(412:3).4: _ZL5g_124 into ^50
	movq _ZL5g_124, %rax
	# LowerBasicConversion(413:3): ^50 -> ^51
	movq %rax, %rbx
	# LowerLoad(414:3).2: (^9) into ^52
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(415:3): move argument i64 ^51
	movq %rbx, %rdi
	# SetupCalls(415:3): move argument ptr @.str.10
	movq .str.10, %rsi
	# SetupCalls(415:3): move argument i32 ^52
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(416:3).4: _ZL5g_132 into ^53
	movq _ZL5g_132, %rax
	movswq %ax, %rbx
	# LowerLoad(418:3).2: (^9) into ^55
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(419:3): move argument i64 ^54
	movq %rbx, %rdi
	# SetupCalls(419:3): move argument ptr @.str.11
	movq .str.11, %rsi
	# SetupCalls(419:3): move argument i32 ^55
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(420:3).2: (^9) into ^56
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# SetupCalls(421:3): move argument i64 1
	movq $1, %rdi
	# SetupCalls(421:3): move argument ptr @.str.12
	movq .str.12, %rsi
	# SetupCalls(421:3): move argument i32 ^56
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(422:3).4: _ZL5g_203 into ^57
	movq _ZL5g_203, %rax
	movsbq %al, %rbx
	# LowerLoad(424:3).2: (^9) into ^59
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(425:3): move argument i64 ^58
	movq %rbx, %rdi
	# SetupCalls(425:3): move argument ptr @.str.13
	movq .str.13, %rsi
	# SetupCalls(425:3): move argument i32 ^59
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(426:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M511:
	# LowerLoad(430:3).2: (^6) into ^61
	movl (%r12), %eax
	# LowerIcmp(431:3): i32 ^61 vs. intlike 5
	cmpl $5, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M517
	jmp .__main__M601
	.__main__M517:
	# LowerLoad(435:3).2: (^6) into ^64
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL5g_232, %rax
	movq _ZL5g_232, %rcx
	# LowerGetelementptr(437:3): struct-type: ptr ^773 -> ^66, indices=0,%65
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(437:3): type of ^66 is ptr*
	# LowerLoad(438:3).2: (^66) into ^67
	movb (%rax), %cl
	movsbq %cl, %rbx
	# LowerLoad(440:3).2: (^9) into ^69
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(441:3): move argument i64 ^68
	movq %rbx, %rdi
	# SetupCalls(441:3): move argument ptr @.str.14
	movq .str.14, %rsi
	# SetupCalls(441:3): move argument i32 ^69
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(442:3).2: (^9) into ^70
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(443:3): i32 ^70 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M564
	jmp .__main__M593
	.__main__M564:
	# LowerLoad(447:3).2: (^6) into ^73
	movl (%r12), %eax
	# SetupCalls(448:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(448:3): move argument i32 ^73
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(448:3): move result from %rax
	movl %eax, %eax
	.__main__M593:
	# LowerLoad(455:3).2: (^6) into ^77
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(457:3).9: mov ^78, (^6)
	movl %ebx, (%r12)
	jmp .__main__M511
	.__main__M601:
	# LowerLoad(461:3).4: _ZL5g_245 into ^80
	movq _ZL5g_245, %rax
	# LowerLoad(462:3).2: (^9) into ^81
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(463:3): move argument i64 ^80
	movq %rax, %rdi
	# SetupCalls(463:3): move argument ptr @.str.16
	movq .str.16, %rsi
	# SetupCalls(463:3): move argument i32 ^81
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(464:3).4: _ZL5g_246 into ^82
	movq _ZL5g_246, %rax
	movslq %eax, %rbx
	# LowerLoad(466:3).2: (^9) into ^84
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(467:3): move argument i64 ^83
	movq %rbx, %rdi
	# SetupCalls(467:3): move argument ptr @.str.17
	movq .str.17, %rsi
	# SetupCalls(467:3): move argument i32 ^84
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(468:3).4: _ZL5g_247 into ^85
	movq _ZL5g_247, %rax
	# LowerBasicConversion(469:3): ^85 -> ^86
	movq %rax, %rbx
	# LowerLoad(470:3).2: (^9) into ^87
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(471:3): move argument i64 ^86
	movq %rbx, %rdi
	# SetupCalls(471:3): move argument ptr @.str.18
	movq .str.18, %rsi
	# SetupCalls(471:3): move argument i32 ^87
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(472:3).4: _ZL5g_259 into ^88
	movq _ZL5g_259, %rax
	# LowerBasicConversion(473:3): ^88 -> ^89
	movq %rax, %rbx
	# LowerLoad(474:3).2: (^9) into ^90
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(475:3): move argument i64 ^89
	movq %rbx, %rdi
	# SetupCalls(475:3): move argument ptr @.str.19
	movq .str.19, %rsi
	# SetupCalls(475:3): move argument i32 ^90
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(476:3).4: _ZL5g_265 into ^91
	movq _ZL5g_265, %rax
	# LowerBasicConversion(477:3): ^91 -> ^92
	movq %rax, %rbx
	# LowerLoad(478:3).2: (^9) into ^93
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(479:3): move argument i64 ^92
	movq %rbx, %rdi
	# SetupCalls(479:3): move argument ptr @.str.20
	movq .str.20, %rsi
	# SetupCalls(479:3): move argument i32 ^93
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(480:3).2: (^9) into ^94
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# SetupCalls(481:3): move argument i64 -275451831
	movq $-275451831, %rdi
	# SetupCalls(481:3): move argument ptr @.str.21
	movq .str.21, %rsi
	# SetupCalls(481:3): move argument i32 ^94
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(482:3).4: _ZL5g_338 into ^95
	movq _ZL5g_338, %rax
	# LowerLoad(483:3).2: (^9) into ^96
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(484:3): move argument i64 ^95
	movq %rax, %rdi
	# SetupCalls(484:3): move argument ptr @.str.22
	movq .str.22, %rsi
	# SetupCalls(484:3): move argument i32 ^96
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(485:3).2: (^9) into ^97
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# SetupCalls(486:3): move argument i64 12039
	movq $12039, %rdi
	# SetupCalls(486:3): move argument ptr @.str.23
	movq .str.23, %rsi
	# SetupCalls(486:3): move argument i32 ^97
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(487:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M840:
	# LowerLoad(491:3).2: (^6) into ^99
	movl (%r12), %eax
	# LowerIcmp(492:3): i32 ^99 vs. intlike 6
	cmpl $6, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M846
	jmp .__main__M930
	.__main__M846:
	# LowerLoad(496:3).2: (^6) into ^102
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL5g_422, %rax
	movq _ZL5g_422, %rcx
	# LowerGetelementptr(498:3): struct-type: ptr ^776 -> ^104, indices=0,%103
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(498:3): type of ^104 is ptr*
	# LowerLoad(499:3).2: (^104) into ^105
	movl (%rax), %ebx
	movslq %ebx, %rax
	# LowerLoad(501:3).2: (^9) into ^107
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(502:3): move argument i64 ^106
	movq %rax, %rdi
	# SetupCalls(502:3): move argument ptr @.str.24
	movq .str.24, %rsi
	# SetupCalls(502:3): move argument i32 ^107
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(503:3).2: (^9) into ^108
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(504:3): i32 ^108 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M893
	jmp .__main__M922
	.__main__M893:
	# LowerLoad(508:3).2: (^6) into ^111
	movl (%r12), %eax
	# SetupCalls(509:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(509:3): move argument i32 ^111
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(509:3): move result from %rax
	movl %eax, %eax
	.__main__M922:
	# LowerLoad(516:3).2: (^6) into ^115
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(518:3).9: mov ^116, (^6)
	movl %ebx, (%r12)
	jmp .__main__M840
	.__main__M930:
	# LowerLoad(522:3).2: (^9) into ^118
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# SetupCalls(523:3): move argument i64 -1
	movq $-1, %rdi
	# SetupCalls(523:3): move argument ptr @.str.25
	movq .str.25, %rsi
	# SetupCalls(523:3): move argument i32 ^118
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(524:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M960:
	# LowerLoad(528:3).2: (^6) into ^120
	movl (%r12), %eax
	# LowerIcmp(529:3): i32 ^120 vs. intlike 10
	cmpl $10, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M966
	jmp .__main__M1051
	.__main__M966:
	# LowerLoad(533:3).2: (^6) into ^123
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL5g_449, %rax
	movq _ZL5g_449, %rcx
	# LowerGetelementptr(535:3): struct-type: ptr ^779 -> ^125, indices=0,%124
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(535:3): type of ^125 is ptr*
	# LowerLoad(536:3).2: (^125) into ^126
	movl (%rax), %ebx
	# LowerBasicConversion(537:3): ^126 -> ^127
	movq %rbx, %rax
	# LowerLoad(538:3).2: (^9) into ^128
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(539:3): move argument i64 ^127
	movq %rax, %rdi
	# SetupCalls(539:3): move argument ptr @.str.26
	movq .str.26, %rsi
	# SetupCalls(539:3): move argument i32 ^128
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(540:3).2: (^9) into ^129
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(541:3): i32 ^129 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M1014
	jmp .__main__M1043
	.__main__M1014:
	# LowerLoad(545:3).2: (^6) into ^132
	movl (%r12), %eax
	# SetupCalls(546:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(546:3): move argument i32 ^132
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(546:3): move result from %rax
	movl %eax, %eax
	.__main__M1043:
	# LowerLoad(553:3).2: (^6) into ^136
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(555:3).9: mov ^137, (^6)
	movl %ebx, (%r12)
	jmp .__main__M960
	.__main__M1051:
	# LowerLoad(559:3).4: _ZL5g_453 into ^139
	movq _ZL5g_453, %rax
	# LowerBasicConversion(560:3): ^139 -> ^140
	movq %rax, %rbx
	# LowerLoad(561:3).2: (^9) into ^141
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(562:3): move argument i64 ^140
	movq %rbx, %rdi
	# SetupCalls(562:3): move argument ptr @.str.27
	movq .str.27, %rsi
	# SetupCalls(562:3): move argument i32 ^141
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(563:3).4: _ZL5g_455 into ^142
	movq _ZL5g_455, %rax
	# LowerBasicConversion(564:3): ^142 -> ^143
	movq %rax, %rbx
	# LowerLoad(565:3).2: (^9) into ^144
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(566:3): move argument i64 ^143
	movq %rbx, %rdi
	# SetupCalls(566:3): move argument ptr @.str.28
	movq .str.28, %rsi
	# SetupCalls(566:3): move argument i32 ^144
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(567:3).4: _ZL5g_648 into ^145
	movq _ZL5g_648, %rax
	movsbq %al, %rbx
	# LowerLoad(569:3).2: (^9) into ^147
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(570:3): move argument i64 ^146
	movq %rbx, %rdi
	# SetupCalls(570:3): move argument ptr @.str.29
	movq .str.29, %rsi
	# SetupCalls(570:3): move argument i32 ^147
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(571:3).4: _ZL5g_651 into ^148
	movq _ZL5g_651, %rax
	# LowerBasicConversion(572:3): ^148 -> ^149
	movq %rax, %rbx
	# LowerLoad(573:3).2: (^9) into ^150
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(574:3): move argument i64 ^149
	movq %rbx, %rdi
	# SetupCalls(574:3): move argument ptr @.str.30
	movq .str.30, %rsi
	# SetupCalls(574:3): move argument i32 ^150
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(575:3).4: _ZL5g_693 into ^151
	movq _ZL5g_693, %rax
	movslq %eax, %rbx
	# LowerLoad(577:3).2: (^9) into ^153
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(578:3): move argument i64 ^152
	movq %rbx, %rdi
	# SetupCalls(578:3): move argument ptr @.str.31
	movq .str.31, %rsi
	# SetupCalls(578:3): move argument i32 ^153
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(579:3).4: _ZL5g_695 into ^154
	movq _ZL5g_695, %rax
	# LowerBasicConversion(580:3): ^154 -> ^155
	movq %rax, %rbx
	# LowerLoad(581:3).2: (^9) into ^156
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(582:3): move argument i64 ^155
	movq %rbx, %rdi
	# SetupCalls(582:3): move argument ptr @.str.32
	movq .str.32, %rsi
	# SetupCalls(582:3): move argument i32 ^156
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(583:3).4: _ZL5g_862 into ^157
	movq _ZL5g_862, %rbx
	# LowerLoad(584:3).2: (^9) into ^158
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(585:3): move argument i64 ^157
	movq %rbx, %rdi
	# SetupCalls(585:3): move argument ptr @.str.33
	movq .str.33, %rsi
	# SetupCalls(585:3): move argument i32 ^158
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(586:3).4: _ZL6g_1175 into ^159
	movq _ZL6g_1175, %rax
	# LowerBasicConversion(587:3): ^159 -> ^160
	movq %rax, %rbx
	# LowerLoad(588:3).2: (^9) into ^161
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(589:3): move argument i64 ^160
	movq %rbx, %rdi
	# SetupCalls(589:3): move argument ptr @.str.34
	movq .str.34, %rsi
	# SetupCalls(589:3): move argument i32 ^161
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(590:3).4: _ZL6g_1221 into ^162
	movq _ZL6g_1221, %rcx
	# LowerLoad(591:3).2: (^9) into ^163
	movq -48(%rbp), %rax
	movl (%rax), %ebx
	# SetupCalls(592:3): move argument i64 ^162
	movq %rcx, %rdi
	# SetupCalls(592:3): move argument ptr @.str.35
	movq .str.35, %rsi
	# SetupCalls(592:3): move argument i32 ^163
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(593:3).4: _ZL6g_1335 into ^164
	movq _ZL6g_1335, %rax
	movsbq %al, %rbx
	# LowerLoad(595:3).2: (^9) into ^166
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(596:3): move argument i64 ^165
	movq %rbx, %rdi
	# SetupCalls(596:3): move argument ptr @.str.36
	movq .str.36, %rsi
	# SetupCalls(596:3): move argument i32 ^166
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(597:3).4: _ZL6g_1357 into ^167
	movq _ZL6g_1357, %rax
	movslq %eax, %rbx
	# LowerLoad(599:3).2: (^9) into ^169
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(600:3): move argument i64 ^168
	movq %rbx, %rdi
	# SetupCalls(600:3): move argument ptr @.str.37
	movq .str.37, %rsi
	# SetupCalls(600:3): move argument i32 ^169
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(601:3).4: _ZL6g_1391 into ^170
	movq _ZL6g_1391, %rax
	movsbq %al, %rbx
	# LowerLoad(603:3).2: (^9) into ^172
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(604:3): move argument i64 ^171
	movq %rbx, %rdi
	# SetupCalls(604:3): move argument ptr @.str.38
	movq .str.38, %rsi
	# SetupCalls(604:3): move argument i32 ^172
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(605:3).4: _ZL6g_1487 into ^173
	movq _ZL6g_1487, %rax
	# LowerLoad(606:3).2: (^9) into ^174
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(607:3): move argument i64 ^173
	movq %rax, %rdi
	# SetupCalls(607:3): move argument ptr @.str.39
	movq .str.39, %rsi
	# SetupCalls(607:3): move argument i32 ^174
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(608:3).4: _ZL6g_1499 into ^175
	movq _ZL6g_1499, %rax
	movslq %eax, %rbx
	# LowerLoad(610:3).2: (^9) into ^177
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(611:3): move argument i64 ^176
	movq %rbx, %rdi
	# SetupCalls(611:3): move argument ptr @.str.40
	movq .str.40, %rsi
	# SetupCalls(611:3): move argument i32 ^177
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(612:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M1478:
	# LowerLoad(616:3).2: (^6) into ^179
	movl (%r12), %eax
	# LowerIcmp(617:3): i32 ^179 vs. intlike 10
	cmpl $10, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M1484
	jmp .__main__M1629
	.__main__M1484:
	# LowerStore(621:3).3: mov $imm, ^7
	movl $0, (%r15)
	.__main__M1487:
	# LowerLoad(625:3).2: (^7) into ^183
	movl (%r15), %eax
	# LowerIcmp(626:3): i32 ^183 vs. intlike 8
	cmpl $8, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M1493
	jmp .__main__M1621
	.__main__M1493:
	# LowerStore(630:3).3: mov $imm, ^8
	movl $0, (%r13)
	.__main__M1496:
	# LowerLoad(634:3).2: (^8) into ^187
	movl (%r13), %eax
	# LowerIcmp(635:3): i32 ^187 vs. intlike 2
	cmpl $2, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M1502
	jmp .__main__M1613
	.__main__M1502:
	# LowerLoad(639:3).2: (^6) into ^190
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1554, %rax
	movq _ZL6g_1554, %rcx
	# LowerGetelementptr(641:3): struct-type: ptr ^782 -> ^192, indices=0,%191
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(641:3): type of ^192 is ptr*
	# LowerLoad(642:3).2: (^7) into ^193
	movl (%r15), %ebx
	movslq %ebx, %rcx
	# LowerGetelementptr(644:3): struct-type: ptr ^192 -> ^195, indices=0,%194
	movq %rax, %rbx
	movq %rcx, %rax
	shlq $3, %rax
	addq %rax, %rbx
	# LowerGetelementptr(644:3): type of ^195 is ptr*
	# LowerLoad(645:3).2: (^8) into ^196
	movl (%r13), %eax
	movslq %eax, %rcx
	# LowerGetelementptr(647:3): struct-type: ptr ^195 -> ^198, indices=0,%197
	movq %rbx, %rax
	movq %rcx, %rbx
	shlq $3, %rbx
	addq %rbx, %rax
	# LowerGetelementptr(647:3): type of ^198 is ptr*
	# LowerLoad(648:3).2: (^198) into ^199
	movl (%rax), %ebx
	# LowerBasicConversion(649:3): ^199 -> ^200
	movq %rbx, %rax
	# LowerLoad(650:3).2: (^9) into ^201
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(651:3): move argument i64 ^200
	movq %rax, %rdi
	# SetupCalls(651:3): move argument ptr @.str.41
	movq .str.41, %rsi
	# SetupCalls(651:3): move argument i32 ^201
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(652:3).2: (^9) into ^202
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(653:3): i32 ^202 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M1568
	jmp .__main__M1605
	.__main__M1568:
	# LowerLoad(657:3).2: (^6) into ^205
	movl (%r12), %eax
	# LowerLoad(658:3).2: (^7) into ^206
	movl (%r15), %ebx
	# LowerLoad(659:3).2: (^8) into ^207
	movl (%r13), %r8d
	# SetupCalls(660:3): move argument ptr @.str.42
	movq .str.42, %rdi
	# SetupCalls(660:3): move argument i32 ^205
	movl %eax, %esi
	# SetupCalls(660:3): move argument i32 ^206
	movl %ebx, %edx
	# SetupCalls(660:3): move argument i32 ^207
	movl %r8d, %ecx
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(660:3): move result from %rax
	movl %eax, %eax
	.__main__M1605:
	# LowerLoad(667:3).2: (^8) into ^211
	movl (%r13), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(669:3).9: mov ^212, (^8)
	movl %ebx, (%r13)
	jmp .__main__M1496
	.__main__M1613:
	# LowerLoad(676:3).2: (^7) into ^215
	movl (%r15), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(678:3).9: mov ^216, (^7)
	movl %ebx, (%r15)
	jmp .__main__M1487
	.__main__M1621:
	# LowerLoad(685:3).2: (^6) into ^219
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(687:3).9: mov ^220, (^6)
	movl %ebx, (%r12)
	jmp .__main__M1478
	.__main__M1629:
	# LowerLoad(691:3).2: (^9) into ^222
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# SetupCalls(692:3): move argument i64 5215
	movq $5215, %rdi
	# SetupCalls(692:3): move argument ptr @.str.43
	movq .str.43, %rsi
	# SetupCalls(692:3): move argument i32 ^222
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(693:3).2: (^9) into ^223
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# SetupCalls(694:3): move argument i64 2
	movq $2, %rdi
	# SetupCalls(694:3): move argument ptr @.str.44
	movq .str.44, %rsi
	# SetupCalls(694:3): move argument i32 ^223
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(695:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M1686:
	# LowerLoad(699:3).2: (^6) into ^225
	movl (%r12), %eax
	# LowerIcmp(700:3): i32 ^225 vs. intlike 8
	cmpl $8, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M1692
	jmp .__main__M1776
	.__main__M1692:
	# LowerLoad(704:3).2: (^6) into ^228
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1717, %rax
	movq _ZL6g_1717, %rcx
	# LowerGetelementptr(706:3): struct-type: ptr ^787 -> ^230, indices=0,%229
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(706:3): type of ^230 is ptr*
	# LowerLoad(707:3).2: (^230) into ^231
	movw (%rax), %bx
	movswq %bx, %rax
	# LowerLoad(709:3).2: (^9) into ^233
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(710:3): move argument i64 ^232
	movq %rax, %rdi
	# SetupCalls(710:3): move argument ptr @.str.45
	movq .str.45, %rsi
	# SetupCalls(710:3): move argument i32 ^233
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(711:3).2: (^9) into ^234
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(712:3): i32 ^234 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M1739
	jmp .__main__M1768
	.__main__M1739:
	# LowerLoad(716:3).2: (^6) into ^237
	movl (%r12), %eax
	# SetupCalls(717:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(717:3): move argument i32 ^237
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(717:3): move result from %rax
	movl %eax, %eax
	.__main__M1768:
	# LowerLoad(724:3).2: (^6) into ^241
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(726:3).9: mov ^242, (^6)
	movl %ebx, (%r12)
	jmp .__main__M1686
	.__main__M1776:
	# LowerLoad(730:3).4: _ZL6g_1877 into ^244
	movq _ZL6g_1877, %rax
	# LowerBasicConversion(731:3): ^244 -> ^245
	movq %rax, %rbx
	# LowerLoad(732:3).2: (^9) into ^246
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(733:3): move argument i64 ^245
	movq %rbx, %rdi
	# SetupCalls(733:3): move argument ptr @.str.46
	movq .str.46, %rsi
	# SetupCalls(733:3): move argument i32 ^246
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(734:3).4: _ZL6g_1883 into ^247
	movq _ZL6g_1883, %rax
	# LowerBasicConversion(735:3): ^247 -> ^248
	movq %rax, %rbx
	# LowerLoad(736:3).2: (^9) into ^249
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(737:3): move argument i64 ^248
	movq %rbx, %rdi
	# SetupCalls(737:3): move argument ptr @.str.47
	movq .str.47, %rsi
	# SetupCalls(737:3): move argument i32 ^249
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(738:3).4: _ZL6g_1884 into ^250
	movq _ZL6g_1884, %rax
	# LowerBasicConversion(739:3): ^250 -> ^251
	movq %rax, %rbx
	# LowerLoad(740:3).2: (^9) into ^252
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(741:3): move argument i64 ^251
	movq %rbx, %rdi
	# SetupCalls(741:3): move argument ptr @.str.48
	movq .str.48, %rsi
	# SetupCalls(741:3): move argument i32 ^252
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(742:3).4: _ZL6g_1885 into ^253
	movq _ZL6g_1885, %rax
	# LowerBasicConversion(743:3): ^253 -> ^254
	movq %rax, %rbx
	# LowerLoad(744:3).2: (^9) into ^255
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(745:3): move argument i64 ^254
	movq %rbx, %rdi
	# SetupCalls(745:3): move argument ptr @.str.49
	movq .str.49, %rsi
	# SetupCalls(745:3): move argument i32 ^255
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(746:3).4: _ZL6g_1886 into ^256
	movq _ZL6g_1886, %rax
	# LowerBasicConversion(747:3): ^256 -> ^257
	movq %rax, %rbx
	# LowerLoad(748:3).2: (^9) into ^258
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(749:3): move argument i64 ^257
	movq %rbx, %rdi
	# SetupCalls(749:3): move argument ptr @.str.50
	movq .str.50, %rsi
	# SetupCalls(749:3): move argument i32 ^258
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(750:3).4: _ZL6g_1887 into ^259
	movq _ZL6g_1887, %rax
	# LowerBasicConversion(751:3): ^259 -> ^260
	movq %rax, %rbx
	# LowerLoad(752:3).2: (^9) into ^261
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(753:3): move argument i64 ^260
	movq %rbx, %rdi
	# SetupCalls(753:3): move argument ptr @.str.51
	movq .str.51, %rsi
	# SetupCalls(753:3): move argument i32 ^261
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(754:3).4: _ZL6g_1888 into ^262
	movq _ZL6g_1888, %rax
	# LowerBasicConversion(755:3): ^262 -> ^263
	movq %rax, %rbx
	# LowerLoad(756:3).2: (^9) into ^264
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(757:3): move argument i64 ^263
	movq %rbx, %rdi
	# SetupCalls(757:3): move argument ptr @.str.52
	movq .str.52, %rsi
	# SetupCalls(757:3): move argument i32 ^264
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(758:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M1997:
	# LowerLoad(762:3).2: (^6) into ^266
	movl (%r12), %eax
	# LowerIcmp(763:3): i32 ^266 vs. intlike 10
	cmpl $10, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M2003
	jmp .__main__M2088
	.__main__M2003:
	# LowerLoad(767:3).2: (^6) into ^269
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1889, %rax
	movq _ZL6g_1889, %rcx
	# LowerGetelementptr(769:3): struct-type: ptr ^790 -> ^271, indices=0,%270
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(769:3): type of ^271 is ptr*
	# LowerLoad(770:3).2: (^271) into ^272
	movl (%rax), %ebx
	# LowerBasicConversion(771:3): ^272 -> ^273
	movq %rbx, %rax
	# LowerLoad(772:3).2: (^9) into ^274
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(773:3): move argument i64 ^273
	movq %rax, %rdi
	# SetupCalls(773:3): move argument ptr @.str.53
	movq .str.53, %rsi
	# SetupCalls(773:3): move argument i32 ^274
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(774:3).2: (^9) into ^275
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(775:3): i32 ^275 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M2051
	jmp .__main__M2080
	.__main__M2051:
	# LowerLoad(779:3).2: (^6) into ^278
	movl (%r12), %eax
	# SetupCalls(780:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(780:3): move argument i32 ^278
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(780:3): move result from %rax
	movl %eax, %eax
	.__main__M2080:
	# LowerLoad(787:3).2: (^6) into ^282
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(789:3).9: mov ^283, (^6)
	movl %ebx, (%r12)
	jmp .__main__M1997
	.__main__M2088:
	# LowerLoad(793:3).4: _ZL6g_1890 into ^285
	movq _ZL6g_1890, %rax
	# LowerBasicConversion(794:3): ^285 -> ^286
	movq %rax, %rbx
	# LowerLoad(795:3).2: (^9) into ^287
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(796:3): move argument i64 ^286
	movq %rbx, %rdi
	# SetupCalls(796:3): move argument ptr @.str.54
	movq .str.54, %rsi
	# SetupCalls(796:3): move argument i32 ^287
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(797:3).4: _ZL6g_1891 into ^288
	movq _ZL6g_1891, %rax
	# LowerBasicConversion(798:3): ^288 -> ^289
	movq %rax, %rbx
	# LowerLoad(799:3).2: (^9) into ^290
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(800:3): move argument i64 ^289
	movq %rbx, %rdi
	# SetupCalls(800:3): move argument ptr @.str.55
	movq .str.55, %rsi
	# SetupCalls(800:3): move argument i32 ^290
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(801:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M2153:
	# LowerLoad(805:3).2: (^6) into ^292
	movl (%r12), %eax
	# LowerIcmp(806:3): i32 ^292 vs. intlike 5
	cmpl $5, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M2159
	jmp .__main__M2244
	.__main__M2159:
	# LowerLoad(810:3).2: (^6) into ^295
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1892, %rax
	movq _ZL6g_1892, %rcx
	# LowerGetelementptr(812:3): struct-type: ptr ^793 -> ^297, indices=0,%296
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(812:3): type of ^297 is ptr*
	# LowerLoad(813:3).2: (^297) into ^298
	movl (%rax), %ebx
	# LowerBasicConversion(814:3): ^298 -> ^299
	movq %rbx, %rax
	# LowerLoad(815:3).2: (^9) into ^300
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(816:3): move argument i64 ^299
	movq %rax, %rdi
	# SetupCalls(816:3): move argument ptr @.str.56
	movq .str.56, %rsi
	# SetupCalls(816:3): move argument i32 ^300
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(817:3).2: (^9) into ^301
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(818:3): i32 ^301 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M2207
	jmp .__main__M2236
	.__main__M2207:
	# LowerLoad(822:3).2: (^6) into ^304
	movl (%r12), %eax
	# SetupCalls(823:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(823:3): move argument i32 ^304
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(823:3): move result from %rax
	movl %eax, %eax
	.__main__M2236:
	# LowerLoad(830:3).2: (^6) into ^308
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(832:3).9: mov ^309, (^6)
	movl %ebx, (%r12)
	jmp .__main__M2153
	.__main__M2244:
	# LowerStore(836:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M2247:
	# LowerLoad(840:3).2: (^6) into ^312
	movl (%r12), %eax
	# LowerIcmp(841:3): i32 ^312 vs. intlike 7
	cmpl $7, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M2253
	jmp .__main__M2338
	.__main__M2253:
	# LowerLoad(845:3).2: (^6) into ^315
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1893, %rax
	movq _ZL6g_1893, %rcx
	# LowerGetelementptr(847:3): struct-type: ptr ^796 -> ^317, indices=0,%316
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(847:3): type of ^317 is ptr*
	# LowerLoad(848:3).2: (^317) into ^318
	movl (%rax), %ebx
	# LowerBasicConversion(849:3): ^318 -> ^319
	movq %rbx, %rax
	# LowerLoad(850:3).2: (^9) into ^320
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(851:3): move argument i64 ^319
	movq %rax, %rdi
	# SetupCalls(851:3): move argument ptr @.str.57
	movq .str.57, %rsi
	# SetupCalls(851:3): move argument i32 ^320
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(852:3).2: (^9) into ^321
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(853:3): i32 ^321 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M2301
	jmp .__main__M2330
	.__main__M2301:
	# LowerLoad(857:3).2: (^6) into ^324
	movl (%r12), %eax
	# SetupCalls(858:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(858:3): move argument i32 ^324
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(858:3): move result from %rax
	movl %eax, %eax
	.__main__M2330:
	# LowerLoad(865:3).2: (^6) into ^328
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(867:3).9: mov ^329, (^6)
	movl %ebx, (%r12)
	jmp .__main__M2247
	.__main__M2338:
	# LowerStore(871:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M2341:
	# LowerLoad(875:3).2: (^6) into ^332
	movl (%r12), %eax
	# LowerIcmp(876:3): i32 ^332 vs. intlike 8
	cmpl $8, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M2347
	jmp .__main__M2432
	.__main__M2347:
	# LowerLoad(880:3).2: (^6) into ^335
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1894, %rax
	movq _ZL6g_1894, %rcx
	# LowerGetelementptr(882:3): struct-type: ptr ^799 -> ^337, indices=0,%336
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(882:3): type of ^337 is ptr*
	# LowerLoad(883:3).2: (^337) into ^338
	movl (%rax), %ebx
	# LowerBasicConversion(884:3): ^338 -> ^339
	movq %rbx, %rax
	# LowerLoad(885:3).2: (^9) into ^340
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(886:3): move argument i64 ^339
	movq %rax, %rdi
	# SetupCalls(886:3): move argument ptr @.str.58
	movq .str.58, %rsi
	# SetupCalls(886:3): move argument i32 ^340
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(887:3).2: (^9) into ^341
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(888:3): i32 ^341 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M2395
	jmp .__main__M2424
	.__main__M2395:
	# LowerLoad(892:3).2: (^6) into ^344
	movl (%r12), %eax
	# SetupCalls(893:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(893:3): move argument i32 ^344
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(893:3): move result from %rax
	movl %eax, %eax
	.__main__M2424:
	# LowerLoad(900:3).2: (^6) into ^348
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(902:3).9: mov ^349, (^6)
	movl %ebx, (%r12)
	jmp .__main__M2341
	.__main__M2432:
	# LowerLoad(906:3).4: _ZL6g_1895 into ^351
	movq _ZL6g_1895, %rax
	# LowerBasicConversion(907:3): ^351 -> ^352
	movq %rax, %rbx
	# LowerLoad(908:3).2: (^9) into ^353
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(909:3): move argument i64 ^352
	movq %rbx, %rdi
	# SetupCalls(909:3): move argument ptr @.str.59
	movq .str.59, %rsi
	# SetupCalls(909:3): move argument i32 ^353
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(910:3).4: _ZL6g_1896 into ^354
	movq _ZL6g_1896, %rax
	# LowerBasicConversion(911:3): ^354 -> ^355
	movq %rax, %rbx
	# LowerLoad(912:3).2: (^9) into ^356
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(913:3): move argument i64 ^355
	movq %rbx, %rdi
	# SetupCalls(913:3): move argument ptr @.str.60
	movq .str.60, %rsi
	# SetupCalls(913:3): move argument i32 ^356
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(914:3).4: _ZL6g_1897 into ^357
	movq _ZL6g_1897, %rax
	# LowerBasicConversion(915:3): ^357 -> ^358
	movq %rax, %rbx
	# LowerLoad(916:3).2: (^9) into ^359
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(917:3): move argument i64 ^358
	movq %rbx, %rdi
	# SetupCalls(917:3): move argument ptr @.str.61
	movq .str.61, %rsi
	# SetupCalls(917:3): move argument i32 ^359
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(918:3).4: _ZL6g_1898 into ^360
	movq _ZL6g_1898, %rax
	# LowerBasicConversion(919:3): ^360 -> ^361
	movq %rax, %rbx
	# LowerLoad(920:3).2: (^9) into ^362
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(921:3): move argument i64 ^361
	movq %rbx, %rdi
	# SetupCalls(921:3): move argument ptr @.str.62
	movq .str.62, %rsi
	# SetupCalls(921:3): move argument i32 ^362
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(922:3).4: _ZL6g_1899 into ^363
	movq _ZL6g_1899, %rax
	# LowerBasicConversion(923:3): ^363 -> ^364
	movq %rax, %rbx
	# LowerLoad(924:3).2: (^9) into ^365
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(925:3): move argument i64 ^364
	movq %rbx, %rdi
	# SetupCalls(925:3): move argument ptr @.str.63
	movq .str.63, %rsi
	# SetupCalls(925:3): move argument i32 ^365
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(926:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M2591:
	# LowerLoad(930:3).2: (^6) into ^367
	movl (%r12), %eax
	# LowerIcmp(931:3): i32 ^367 vs. intlike 3
	cmpl $3, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M2597
	jmp .__main__M2682
	.__main__M2597:
	# LowerLoad(935:3).2: (^6) into ^370
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1900, %rax
	movq _ZL6g_1900, %rcx
	# LowerGetelementptr(937:3): struct-type: ptr ^802 -> ^372, indices=0,%371
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(937:3): type of ^372 is ptr*
	# LowerLoad(938:3).2: (^372) into ^373
	movl (%rax), %ebx
	# LowerBasicConversion(939:3): ^373 -> ^374
	movq %rbx, %rax
	# LowerLoad(940:3).2: (^9) into ^375
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(941:3): move argument i64 ^374
	movq %rax, %rdi
	# SetupCalls(941:3): move argument ptr @.str.64
	movq .str.64, %rsi
	# SetupCalls(941:3): move argument i32 ^375
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(942:3).2: (^9) into ^376
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(943:3): i32 ^376 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M2645
	jmp .__main__M2674
	.__main__M2645:
	# LowerLoad(947:3).2: (^6) into ^379
	movl (%r12), %eax
	# SetupCalls(948:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(948:3): move argument i32 ^379
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(948:3): move result from %rax
	movl %eax, %eax
	.__main__M2674:
	# LowerLoad(955:3).2: (^6) into ^383
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(957:3).9: mov ^384, (^6)
	movl %ebx, (%r12)
	jmp .__main__M2591
	.__main__M2682:
	# LowerLoad(961:3).4: _ZL6g_1901 into ^386
	movq _ZL6g_1901, %rax
	# LowerBasicConversion(962:3): ^386 -> ^387
	movq %rax, %rbx
	# LowerLoad(963:3).2: (^9) into ^388
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(964:3): move argument i64 ^387
	movq %rbx, %rdi
	# SetupCalls(964:3): move argument ptr @.str.65
	movq .str.65, %rsi
	# SetupCalls(964:3): move argument i32 ^388
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(965:3).4: _ZL6g_1902 into ^389
	movq _ZL6g_1902, %rax
	# LowerBasicConversion(966:3): ^389 -> ^390
	movq %rax, %rbx
	# LowerLoad(967:3).2: (^9) into ^391
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(968:3): move argument i64 ^390
	movq %rbx, %rdi
	# SetupCalls(968:3): move argument ptr @.str.66
	movq .str.66, %rsi
	# SetupCalls(968:3): move argument i32 ^391
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(969:3).4: _ZL6g_1903 into ^392
	movq _ZL6g_1903, %rax
	# LowerBasicConversion(970:3): ^392 -> ^393
	movq %rax, %rbx
	# LowerLoad(971:3).2: (^9) into ^394
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(972:3): move argument i64 ^393
	movq %rbx, %rdi
	# SetupCalls(972:3): move argument ptr @.str.67
	movq .str.67, %rsi
	# SetupCalls(972:3): move argument i32 ^394
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(973:3).4: _ZL6g_1904 into ^395
	movq _ZL6g_1904, %rax
	# LowerBasicConversion(974:3): ^395 -> ^396
	movq %rax, %rbx
	# LowerLoad(975:3).2: (^9) into ^397
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(976:3): move argument i64 ^396
	movq %rbx, %rdi
	# SetupCalls(976:3): move argument ptr @.str.68
	movq .str.68, %rsi
	# SetupCalls(976:3): move argument i32 ^397
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(977:3).4: _ZL6g_1905 into ^398
	movq _ZL6g_1905, %rax
	# LowerBasicConversion(978:3): ^398 -> ^399
	movq %rax, %rbx
	# LowerLoad(979:3).2: (^9) into ^400
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(980:3): move argument i64 ^399
	movq %rbx, %rdi
	# SetupCalls(980:3): move argument ptr @.str.69
	movq .str.69, %rsi
	# SetupCalls(980:3): move argument i32 ^400
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(981:3).4: _ZL6g_1906 into ^401
	movq _ZL6g_1906, %rax
	# LowerBasicConversion(982:3): ^401 -> ^402
	movq %rax, %rbx
	# LowerLoad(983:3).2: (^9) into ^403
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(984:3): move argument i64 ^402
	movq %rbx, %rdi
	# SetupCalls(984:3): move argument ptr @.str.70
	movq .str.70, %rsi
	# SetupCalls(984:3): move argument i32 ^403
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(985:3).4: _ZL6g_1907 into ^404
	movq _ZL6g_1907, %rax
	# LowerBasicConversion(986:3): ^404 -> ^405
	movq %rax, %rbx
	# LowerLoad(987:3).2: (^9) into ^406
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(988:3): move argument i64 ^405
	movq %rbx, %rdi
	# SetupCalls(988:3): move argument ptr @.str.71
	movq .str.71, %rsi
	# SetupCalls(988:3): move argument i32 ^406
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(989:3).4: _ZL6g_1908 into ^407
	movq _ZL6g_1908, %rax
	# LowerBasicConversion(990:3): ^407 -> ^408
	movq %rax, %rbx
	# LowerLoad(991:3).2: (^9) into ^409
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(992:3): move argument i64 ^408
	movq %rbx, %rdi
	# SetupCalls(992:3): move argument ptr @.str.72
	movq .str.72, %rsi
	# SetupCalls(992:3): move argument i32 ^409
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(993:3).4: _ZL6g_1909 into ^410
	movq _ZL6g_1909, %rax
	# LowerBasicConversion(994:3): ^410 -> ^411
	movq %rax, %rbx
	# LowerLoad(995:3).2: (^9) into ^412
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(996:3): move argument i64 ^411
	movq %rbx, %rdi
	# SetupCalls(996:3): move argument ptr @.str.73
	movq .str.73, %rsi
	# SetupCalls(996:3): move argument i32 ^412
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(997:3).4: _ZL6g_1910 into ^413
	movq _ZL6g_1910, %rax
	# LowerBasicConversion(998:3): ^413 -> ^414
	movq %rax, %rbx
	# LowerLoad(999:3).2: (^9) into ^415
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(1000:3): move argument i64 ^414
	movq %rbx, %rdi
	# SetupCalls(1000:3): move argument ptr @.str.74
	movq .str.74, %rsi
	# SetupCalls(1000:3): move argument i32 ^415
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1001:3).4: _ZL6g_1911 into ^416
	movq _ZL6g_1911, %rax
	# LowerBasicConversion(1002:3): ^416 -> ^417
	movq %rax, %rbx
	# LowerLoad(1003:3).2: (^9) into ^418
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1004:3): move argument i64 ^417
	movq %rbx, %rdi
	# SetupCalls(1004:3): move argument ptr @.str.75
	movq .str.75, %rsi
	# SetupCalls(1004:3): move argument i32 ^418
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1005:3).4: _ZL6g_1912 into ^419
	movq _ZL6g_1912, %rax
	# LowerBasicConversion(1006:3): ^419 -> ^420
	movq %rax, %rbx
	# LowerLoad(1007:3).2: (^9) into ^421
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(1008:3): move argument i64 ^420
	movq %rbx, %rdi
	# SetupCalls(1008:3): move argument ptr @.str.76
	movq .str.76, %rsi
	# SetupCalls(1008:3): move argument i32 ^421
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1009:3).4: _ZL6g_1913 into ^422
	movq _ZL6g_1913, %rax
	# LowerBasicConversion(1010:3): ^422 -> ^423
	movq %rax, %rbx
	# LowerLoad(1011:3).2: (^9) into ^424
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1012:3): move argument i64 ^423
	movq %rbx, %rdi
	# SetupCalls(1012:3): move argument ptr @.str.77
	movq .str.77, %rsi
	# SetupCalls(1012:3): move argument i32 ^424
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1013:3).4: _ZL6g_1914 into ^425
	movq _ZL6g_1914, %rax
	# LowerBasicConversion(1014:3): ^425 -> ^426
	movq %rax, %rbx
	# LowerLoad(1015:3).2: (^9) into ^427
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1016:3): move argument i64 ^426
	movq %rbx, %rdi
	# SetupCalls(1016:3): move argument ptr @.str.78
	movq .str.78, %rsi
	# SetupCalls(1016:3): move argument i32 ^427
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1017:3).4: _ZL6g_1915 into ^428
	movq _ZL6g_1915, %rax
	# LowerBasicConversion(1018:3): ^428 -> ^429
	movq %rax, %rbx
	# LowerLoad(1019:3).2: (^9) into ^430
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1020:3): move argument i64 ^429
	movq %rbx, %rdi
	# SetupCalls(1020:3): move argument ptr @.str.79
	movq .str.79, %rsi
	# SetupCalls(1020:3): move argument i32 ^430
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(1021:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M3153:
	# LowerLoad(1025:3).2: (^6) into ^432
	movl (%r12), %eax
	# LowerIcmp(1026:3): i32 ^432 vs. intlike 1
	cmpl $1, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M3159
	jmp .__main__M3244
	.__main__M3159:
	# LowerLoad(1030:3).2: (^6) into ^435
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1916, %rax
	movq _ZL6g_1916, %rcx
	# LowerGetelementptr(1032:3): struct-type: ptr ^805 -> ^437, indices=0,%436
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(1032:3): type of ^437 is ptr*
	# LowerLoad(1033:3).2: (^437) into ^438
	movl (%rax), %ebx
	# LowerBasicConversion(1034:3): ^438 -> ^439
	movq %rbx, %rax
	# LowerLoad(1035:3).2: (^9) into ^440
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(1036:3): move argument i64 ^439
	movq %rax, %rdi
	# SetupCalls(1036:3): move argument ptr @.str.80
	movq .str.80, %rsi
	# SetupCalls(1036:3): move argument i32 ^440
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1037:3).2: (^9) into ^441
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1038:3): i32 ^441 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M3207
	jmp .__main__M3236
	.__main__M3207:
	# LowerLoad(1042:3).2: (^6) into ^444
	movl (%r12), %eax
	# SetupCalls(1043:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(1043:3): move argument i32 ^444
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(1043:3): move result from %rax
	movl %eax, %eax
	.__main__M3236:
	# LowerLoad(1050:3).2: (^6) into ^448
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1052:3).9: mov ^449, (^6)
	movl %ebx, (%r12)
	jmp .__main__M3153
	.__main__M3244:
	# LowerLoad(1056:3).4: _ZL6g_1917 into ^451
	movq _ZL6g_1917, %rax
	# LowerBasicConversion(1057:3): ^451 -> ^452
	movq %rax, %rbx
	# LowerLoad(1058:3).2: (^9) into ^453
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1059:3): move argument i64 ^452
	movq %rbx, %rdi
	# SetupCalls(1059:3): move argument ptr @.str.81
	movq .str.81, %rsi
	# SetupCalls(1059:3): move argument i32 ^453
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1060:3).4: _ZL6g_1918 into ^454
	movq _ZL6g_1918, %rax
	# LowerBasicConversion(1061:3): ^454 -> ^455
	movq %rax, %rbx
	# LowerLoad(1062:3).2: (^9) into ^456
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1063:3): move argument i64 ^455
	movq %rbx, %rdi
	# SetupCalls(1063:3): move argument ptr @.str.82
	movq .str.82, %rsi
	# SetupCalls(1063:3): move argument i32 ^456
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1064:3).4: _ZL6g_1919 into ^457
	movq _ZL6g_1919, %rax
	# LowerBasicConversion(1065:3): ^457 -> ^458
	movq %rax, %rbx
	# LowerLoad(1066:3).2: (^9) into ^459
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1067:3): move argument i64 ^458
	movq %rbx, %rdi
	# SetupCalls(1067:3): move argument ptr @.str.83
	movq .str.83, %rsi
	# SetupCalls(1067:3): move argument i32 ^459
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1068:3).4: _ZL6g_1920 into ^460
	movq _ZL6g_1920, %rax
	# LowerBasicConversion(1069:3): ^460 -> ^461
	movq %rax, %rbx
	# LowerLoad(1070:3).2: (^9) into ^462
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1071:3): move argument i64 ^461
	movq %rbx, %rdi
	# SetupCalls(1071:3): move argument ptr @.str.84
	movq .str.84, %rsi
	# SetupCalls(1071:3): move argument i32 ^462
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1072:3).4: _ZL6g_1921 into ^463
	movq _ZL6g_1921, %rax
	# LowerBasicConversion(1073:3): ^463 -> ^464
	movq %rax, %rbx
	# LowerLoad(1074:3).2: (^9) into ^465
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1075:3): move argument i64 ^464
	movq %rbx, %rdi
	# SetupCalls(1075:3): move argument ptr @.str.85
	movq .str.85, %rsi
	# SetupCalls(1075:3): move argument i32 ^465
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(1076:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M3403:
	# LowerLoad(1080:3).2: (^6) into ^467
	movl (%r12), %eax
	# LowerIcmp(1081:3): i32 ^467 vs. intlike 4
	cmpl $4, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M3409
	jmp .__main__M3524
	.__main__M3409:
	# LowerStore(1085:3).3: mov $imm, ^7
	movl $0, (%r15)
	.__main__M3412:
	# LowerLoad(1089:3).2: (^7) into ^471
	movl (%r15), %eax
	# LowerIcmp(1090:3): i32 ^471 vs. intlike 9
	cmpl $9, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M3418
	jmp .__main__M3516
	.__main__M3418:
	# LowerLoad(1094:3).2: (^6) into ^474
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1922, %rax
	movq _ZL6g_1922, %rcx
	# LowerGetelementptr(1096:3): struct-type: ptr ^808 -> ^476, indices=0,%475
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(1096:3): type of ^476 is ptr*
	# LowerLoad(1097:3).2: (^7) into ^477
	movl (%r15), %ebx
	movslq %ebx, %rcx
	# LowerGetelementptr(1099:3): struct-type: ptr ^476 -> ^479, indices=0,%478
	movq %rax, %rbx
	movq %rcx, %rax
	shlq $3, %rax
	addq %rax, %rbx
	# LowerGetelementptr(1099:3): type of ^479 is ptr*
	# LowerLoad(1100:3).2: (^479) into ^480
	movl (%rbx), %eax
	# LowerBasicConversion(1101:3): ^480 -> ^481
	movq %rax, %rbx
	# LowerLoad(1102:3).2: (^9) into ^482
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1103:3): move argument i64 ^481
	movq %rbx, %rdi
	# SetupCalls(1103:3): move argument ptr @.str.86
	movq .str.86, %rsi
	# SetupCalls(1103:3): move argument i32 ^482
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1104:3).2: (^9) into ^483
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1105:3): i32 ^483 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M3475
	jmp .__main__M3508
	.__main__M3475:
	# LowerLoad(1109:3).2: (^6) into ^486
	movl (%r12), %ebx
	# LowerLoad(1110:3).2: (^7) into ^487
	movl (%r15), %eax
	# SetupCalls(1111:3): move argument ptr @.str.87
	movq .str.87, %rdi
	# SetupCalls(1111:3): move argument i32 ^486
	movl %ebx, %esi
	# SetupCalls(1111:3): move argument i32 ^487
	movl %eax, %edx
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(1111:3): move result from %rax
	movl %eax, %eax
	.__main__M3508:
	# LowerLoad(1118:3).2: (^7) into ^491
	movl (%r15), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1120:3).9: mov ^492, (^7)
	movl %ebx, (%r15)
	jmp .__main__M3412
	.__main__M3516:
	# LowerLoad(1127:3).2: (^6) into ^495
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1129:3).9: mov ^496, (^6)
	movl %ebx, (%r12)
	jmp .__main__M3403
	.__main__M3524:
	# LowerLoad(1133:3).4: _ZL6g_1923 into ^498
	movq _ZL6g_1923, %rax
	# LowerBasicConversion(1134:3): ^498 -> ^499
	movq %rax, %rbx
	# LowerLoad(1135:3).2: (^9) into ^500
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1136:3): move argument i64 ^499
	movq %rbx, %rdi
	# SetupCalls(1136:3): move argument ptr @.str.88
	movq .str.88, %rsi
	# SetupCalls(1136:3): move argument i32 ^500
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1137:3).4: _ZL6g_1924 into ^501
	movq _ZL6g_1924, %rax
	# LowerBasicConversion(1138:3): ^501 -> ^502
	movq %rax, %rbx
	# LowerLoad(1139:3).2: (^9) into ^503
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1140:3): move argument i64 ^502
	movq %rbx, %rdi
	# SetupCalls(1140:3): move argument ptr @.str.89
	movq .str.89, %rsi
	# SetupCalls(1140:3): move argument i32 ^503
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1141:3).4: _ZL6g_1925 into ^504
	movq _ZL6g_1925, %rax
	# LowerBasicConversion(1142:3): ^504 -> ^505
	movq %rax, %rbx
	# LowerLoad(1143:3).2: (^9) into ^506
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1144:3): move argument i64 ^505
	movq %rbx, %rdi
	# SetupCalls(1144:3): move argument ptr @.str.90
	movq .str.90, %rsi
	# SetupCalls(1144:3): move argument i32 ^506
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1145:3).4: _ZL6g_1926 into ^507
	movq _ZL6g_1926, %rax
	# LowerBasicConversion(1146:3): ^507 -> ^508
	movq %rax, %rbx
	# LowerLoad(1147:3).2: (^9) into ^509
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1148:3): move argument i64 ^508
	movq %rbx, %rdi
	# SetupCalls(1148:3): move argument ptr @.str.91
	movq .str.91, %rsi
	# SetupCalls(1148:3): move argument i32 ^509
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1149:3).4: _ZL6g_1927 into ^510
	movq _ZL6g_1927, %rax
	# LowerBasicConversion(1150:3): ^510 -> ^511
	movq %rax, %rbx
	# LowerLoad(1151:3).2: (^9) into ^512
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1152:3): move argument i64 ^511
	movq %rbx, %rdi
	# SetupCalls(1152:3): move argument ptr @.str.92
	movq .str.92, %rsi
	# SetupCalls(1152:3): move argument i32 ^512
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1153:3).4: _ZL6g_1928 into ^513
	movq _ZL6g_1928, %rax
	# LowerBasicConversion(1154:3): ^513 -> ^514
	movq %rax, %rbx
	# LowerLoad(1155:3).2: (^9) into ^515
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1156:3): move argument i64 ^514
	movq %rbx, %rdi
	# SetupCalls(1156:3): move argument ptr @.str.93
	movq .str.93, %rsi
	# SetupCalls(1156:3): move argument i32 ^515
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1157:3).4: _ZL6g_1929 into ^516
	movq _ZL6g_1929, %rax
	# LowerBasicConversion(1158:3): ^516 -> ^517
	movq %rax, %rbx
	# LowerLoad(1159:3).2: (^9) into ^518
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1160:3): move argument i64 ^517
	movq %rbx, %rdi
	# SetupCalls(1160:3): move argument ptr @.str.94
	movq .str.94, %rsi
	# SetupCalls(1160:3): move argument i32 ^518
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1161:3).4: _ZL6g_1930 into ^519
	movq _ZL6g_1930, %rax
	# LowerBasicConversion(1162:3): ^519 -> ^520
	movq %rax, %rbx
	# LowerLoad(1163:3).2: (^9) into ^521
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1164:3): move argument i64 ^520
	movq %rbx, %rdi
	# SetupCalls(1164:3): move argument ptr @.str.95
	movq .str.95, %rsi
	# SetupCalls(1164:3): move argument i32 ^521
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1165:3).4: _ZL6g_1931 into ^522
	movq _ZL6g_1931, %rax
	# LowerBasicConversion(1166:3): ^522 -> ^523
	movq %rax, %rbx
	# LowerLoad(1167:3).2: (^9) into ^524
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1168:3): move argument i64 ^523
	movq %rbx, %rdi
	# SetupCalls(1168:3): move argument ptr @.str.96
	movq .str.96, %rsi
	# SetupCalls(1168:3): move argument i32 ^524
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1169:3).4: _ZL6g_1932 into ^525
	movq _ZL6g_1932, %rax
	# LowerBasicConversion(1170:3): ^525 -> ^526
	movq %rax, %rbx
	# LowerLoad(1171:3).2: (^9) into ^527
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1172:3): move argument i64 ^526
	movq %rbx, %rdi
	# SetupCalls(1172:3): move argument ptr @.str.97
	movq .str.97, %rsi
	# SetupCalls(1172:3): move argument i32 ^527
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(1173:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M3839:
	# LowerLoad(1177:3).2: (^6) into ^529
	movl (%r12), %eax
	# LowerIcmp(1178:3): i32 ^529 vs. intlike 8
	cmpl $8, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M3845
	jmp .__main__M3930
	.__main__M3845:
	# LowerLoad(1182:3).2: (^6) into ^532
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1933, %rax
	movq _ZL6g_1933, %rcx
	# LowerGetelementptr(1184:3): struct-type: ptr ^812 -> ^534, indices=0,%533
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(1184:3): type of ^534 is ptr*
	# LowerLoad(1185:3).2: (^534) into ^535
	movl (%rax), %ebx
	# LowerBasicConversion(1186:3): ^535 -> ^536
	movq %rbx, %rax
	# LowerLoad(1187:3).2: (^9) into ^537
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(1188:3): move argument i64 ^536
	movq %rax, %rdi
	# SetupCalls(1188:3): move argument ptr @.str.98
	movq .str.98, %rsi
	# SetupCalls(1188:3): move argument i32 ^537
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1189:3).2: (^9) into ^538
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1190:3): i32 ^538 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M3893
	jmp .__main__M3922
	.__main__M3893:
	# LowerLoad(1194:3).2: (^6) into ^541
	movl (%r12), %eax
	# SetupCalls(1195:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(1195:3): move argument i32 ^541
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(1195:3): move result from %rax
	movl %eax, %eax
	.__main__M3922:
	# LowerLoad(1202:3).2: (^6) into ^545
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1204:3).9: mov ^546, (^6)
	movl %ebx, (%r12)
	jmp .__main__M3839
	.__main__M3930:
	# LowerLoad(1208:3).4: _ZL6g_1934 into ^548
	movq _ZL6g_1934, %rax
	# LowerBasicConversion(1209:3): ^548 -> ^549
	movq %rax, %rbx
	# LowerLoad(1210:3).2: (^9) into ^550
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1211:3): move argument i64 ^549
	movq %rbx, %rdi
	# SetupCalls(1211:3): move argument ptr @.str.99
	movq .str.99, %rsi
	# SetupCalls(1211:3): move argument i32 ^550
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1212:3).4: _ZL6g_1935 into ^551
	movq _ZL6g_1935, %rax
	# LowerBasicConversion(1213:3): ^551 -> ^552
	movq %rax, %rbx
	# LowerLoad(1214:3).2: (^9) into ^553
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1215:3): move argument i64 ^552
	movq %rbx, %rdi
	# SetupCalls(1215:3): move argument ptr @.str.100
	movq .str.100, %rsi
	# SetupCalls(1215:3): move argument i32 ^553
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1216:3).4: _ZL6g_1936 into ^554
	movq _ZL6g_1936, %rax
	# LowerBasicConversion(1217:3): ^554 -> ^555
	movq %rax, %rbx
	# LowerLoad(1218:3).2: (^9) into ^556
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1219:3): move argument i64 ^555
	movq %rbx, %rdi
	# SetupCalls(1219:3): move argument ptr @.str.101
	movq .str.101, %rsi
	# SetupCalls(1219:3): move argument i32 ^556
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1220:3).4: _ZL6g_1937 into ^557
	movq _ZL6g_1937, %rax
	# LowerBasicConversion(1221:3): ^557 -> ^558
	movq %rax, %rbx
	# LowerLoad(1222:3).2: (^9) into ^559
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1223:3): move argument i64 ^558
	movq %rbx, %rdi
	# SetupCalls(1223:3): move argument ptr @.str.102
	movq .str.102, %rsi
	# SetupCalls(1223:3): move argument i32 ^559
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1224:3).4: _ZL6g_1938 into ^560
	movq _ZL6g_1938, %rax
	# LowerBasicConversion(1225:3): ^560 -> ^561
	movq %rax, %rbx
	# LowerLoad(1226:3).2: (^9) into ^562
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1227:3): move argument i64 ^561
	movq %rbx, %rdi
	# SetupCalls(1227:3): move argument ptr @.str.103
	movq .str.103, %rsi
	# SetupCalls(1227:3): move argument i32 ^562
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1228:3).4: _ZL6g_1939 into ^563
	movq _ZL6g_1939, %rax
	# LowerBasicConversion(1229:3): ^563 -> ^564
	movq %rax, %rbx
	# LowerLoad(1230:3).2: (^9) into ^565
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1231:3): move argument i64 ^564
	movq %rbx, %rdi
	# SetupCalls(1231:3): move argument ptr @.str.104
	movq .str.104, %rsi
	# SetupCalls(1231:3): move argument i32 ^565
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1232:3).4: _ZL6g_1940 into ^566
	movq _ZL6g_1940, %rax
	# LowerBasicConversion(1233:3): ^566 -> ^567
	movq %rax, %rbx
	# LowerLoad(1234:3).2: (^9) into ^568
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1235:3): move argument i64 ^567
	movq %rbx, %rdi
	# SetupCalls(1235:3): move argument ptr @.str.105
	movq .str.105, %rsi
	# SetupCalls(1235:3): move argument i32 ^568
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1236:3).4: _ZL6g_1941 into ^569
	movq _ZL6g_1941, %rax
	# LowerBasicConversion(1237:3): ^569 -> ^570
	movq %rax, %rbx
	# LowerLoad(1238:3).2: (^9) into ^571
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1239:3): move argument i64 ^570
	movq %rbx, %rdi
	# SetupCalls(1239:3): move argument ptr @.str.106
	movq .str.106, %rsi
	# SetupCalls(1239:3): move argument i32 ^571
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(1240:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M4182:
	# LowerLoad(1244:3).2: (^6) into ^573
	movl (%r12), %eax
	# LowerIcmp(1245:3): i32 ^573 vs. intlike 4
	cmpl $4, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M4188
	jmp .__main__M4333
	.__main__M4188:
	# LowerStore(1249:3).3: mov $imm, ^7
	movl $0, (%r15)
	.__main__M4191:
	# LowerLoad(1253:3).2: (^7) into ^577
	movl (%r15), %eax
	# LowerIcmp(1254:3): i32 ^577 vs. intlike 8
	cmpl $8, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M4197
	jmp .__main__M4325
	.__main__M4197:
	# LowerStore(1258:3).3: mov $imm, ^8
	movl $0, (%r13)
	.__main__M4200:
	# LowerLoad(1262:3).2: (^8) into ^581
	movl (%r13), %eax
	# LowerIcmp(1263:3): i32 ^581 vs. intlike 4
	cmpl $4, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M4206
	jmp .__main__M4317
	.__main__M4206:
	# LowerLoad(1267:3).2: (^6) into ^584
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1942, %rax
	movq _ZL6g_1942, %rcx
	# LowerGetelementptr(1269:3): struct-type: ptr ^815 -> ^586, indices=0,%585
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(1269:3): type of ^586 is ptr*
	# LowerLoad(1270:3).2: (^7) into ^587
	movl (%r15), %ebx
	movslq %ebx, %rcx
	# LowerGetelementptr(1272:3): struct-type: ptr ^586 -> ^589, indices=0,%588
	movq %rax, %rbx
	movq %rcx, %rax
	shlq $3, %rax
	addq %rax, %rbx
	# LowerGetelementptr(1272:3): type of ^589 is ptr*
	# LowerLoad(1273:3).2: (^8) into ^590
	movl (%r13), %eax
	movslq %eax, %rcx
	# LowerGetelementptr(1275:3): struct-type: ptr ^589 -> ^592, indices=0,%591
	movq %rbx, %rax
	movq %rcx, %rbx
	shlq $3, %rbx
	addq %rbx, %rax
	# LowerGetelementptr(1275:3): type of ^592 is ptr*
	# LowerLoad(1276:3).2: (^592) into ^593
	movl (%rax), %ebx
	# LowerBasicConversion(1277:3): ^593 -> ^594
	movq %rbx, %rax
	# LowerLoad(1278:3).2: (^9) into ^595
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(1279:3): move argument i64 ^594
	movq %rax, %rdi
	# SetupCalls(1279:3): move argument ptr @.str.107
	movq .str.107, %rsi
	# SetupCalls(1279:3): move argument i32 ^595
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1280:3).2: (^9) into ^596
	movq -48(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(1281:3): i32 ^596 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	cmpb $0, %al
	jne .__main__M4272
	jmp .__main__M4309
	.__main__M4272:
	# LowerLoad(1285:3).2: (^6) into ^599
	movl (%r12), %eax
	# LowerLoad(1286:3).2: (^7) into ^600
	movl (%r15), %ebx
	# LowerLoad(1287:3).2: (^8) into ^601
	movl (%r13), %r8d
	# SetupCalls(1288:3): move argument ptr @.str.42
	movq .str.42, %rdi
	# SetupCalls(1288:3): move argument i32 ^599
	movl %eax, %esi
	# SetupCalls(1288:3): move argument i32 ^600
	movl %ebx, %edx
	# SetupCalls(1288:3): move argument i32 ^601
	movl %r8d, %ecx
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(1288:3): move result from %rax
	movl %eax, %eax
	.__main__M4309:
	# LowerLoad(1295:3).2: (^8) into ^605
	movl (%r13), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1297:3).9: mov ^606, (^8)
	movl %ebx, (%r13)
	jmp .__main__M4200
	.__main__M4317:
	# LowerLoad(1304:3).2: (^7) into ^609
	movl (%r15), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1306:3).9: mov ^610, (^7)
	movl %ebx, (%r15)
	jmp .__main__M4191
	.__main__M4325:
	# LowerLoad(1313:3).2: (^6) into ^613
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1315:3).9: mov ^614, (^6)
	movl %ebx, (%r12)
	jmp .__main__M4182
	.__main__M4333:
	# LowerLoad(1319:3).4: _ZL6g_1943 into ^616
	movq _ZL6g_1943, %rax
	# LowerBasicConversion(1320:3): ^616 -> ^617
	movq %rax, %rbx
	# LowerLoad(1321:3).2: (^9) into ^618
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1322:3): move argument i64 ^617
	movq %rbx, %rdi
	# SetupCalls(1322:3): move argument ptr @.str.108
	movq .str.108, %rsi
	# SetupCalls(1322:3): move argument i32 ^618
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(1323:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M4367:
	# LowerLoad(1327:3).2: (^6) into ^620
	movl (%r12), %eax
	# LowerIcmp(1328:3): i32 ^620 vs. intlike 10
	cmpl $10, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M4373
	jmp .__main__M4458
	.__main__M4373:
	# LowerLoad(1332:3).2: (^6) into ^623
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1944, %rax
	movq _ZL6g_1944, %rcx
	# LowerGetelementptr(1334:3): struct-type: ptr ^820 -> ^625, indices=0,%624
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(1334:3): type of ^625 is ptr*
	# LowerLoad(1335:3).2: (^625) into ^626
	movl (%rax), %ebx
	# LowerBasicConversion(1336:3): ^626 -> ^627
	movq %rbx, %rax
	# LowerLoad(1337:3).2: (^9) into ^628
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(1338:3): move argument i64 ^627
	movq %rax, %rdi
	# SetupCalls(1338:3): move argument ptr @.str.109
	movq .str.109, %rsi
	# SetupCalls(1338:3): move argument i32 ^628
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1339:3).2: (^9) into ^629
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1340:3): i32 ^629 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M4421
	jmp .__main__M4450
	.__main__M4421:
	# LowerLoad(1344:3).2: (^6) into ^632
	movl (%r12), %eax
	# SetupCalls(1345:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(1345:3): move argument i32 ^632
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(1345:3): move result from %rax
	movl %eax, %eax
	.__main__M4450:
	# LowerLoad(1352:3).2: (^6) into ^636
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1354:3).9: mov ^637, (^6)
	movl %ebx, (%r12)
	jmp .__main__M4367
	.__main__M4458:
	# LowerStore(1358:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M4461:
	# LowerLoad(1362:3).2: (^6) into ^640
	movl (%r12), %eax
	# LowerIcmp(1363:3): i32 ^640 vs. intlike 7
	cmpl $7, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M4467
	jmp .__main__M4552
	.__main__M4467:
	# LowerLoad(1367:3).2: (^6) into ^643
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_1945, %rax
	movq _ZL6g_1945, %rcx
	# LowerGetelementptr(1369:3): struct-type: ptr ^823 -> ^645, indices=0,%644
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(1369:3): type of ^645 is ptr*
	# LowerLoad(1370:3).2: (^645) into ^646
	movl (%rax), %ebx
	# LowerBasicConversion(1371:3): ^646 -> ^647
	movq %rbx, %rax
	# LowerLoad(1372:3).2: (^9) into ^648
	movq -48(%rbp), %rcx
	movl (%rcx), %ebx
	# SetupCalls(1373:3): move argument i64 ^647
	movq %rax, %rdi
	# SetupCalls(1373:3): move argument ptr @.str.110
	movq .str.110, %rsi
	# SetupCalls(1373:3): move argument i32 ^648
	movl %ebx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1374:3).2: (^9) into ^649
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1375:3): i32 ^649 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M4515
	jmp .__main__M4544
	.__main__M4515:
	# LowerLoad(1379:3).2: (^6) into ^652
	movl (%r12), %eax
	# SetupCalls(1380:3): move argument ptr @.str.15
	movq .str.15, %rdi
	# SetupCalls(1380:3): move argument i32 ^652
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(1380:3): move result from %rax
	movl %eax, %eax
	.__main__M4544:
	# LowerLoad(1387:3).2: (^6) into ^656
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1389:3).9: mov ^657, (^6)
	movl %ebx, (%r12)
	jmp .__main__M4461
	.__main__M4552:
	# LowerLoad(1393:3).4: _ZL6g_1946 into ^659
	movq _ZL6g_1946, %rax
	# LowerBasicConversion(1394:3): ^659 -> ^660
	movq %rax, %rbx
	# LowerLoad(1395:3).2: (^9) into ^661
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1396:3): move argument i64 ^660
	movq %rbx, %rdi
	# SetupCalls(1396:3): move argument ptr @.str.111
	movq .str.111, %rsi
	# SetupCalls(1396:3): move argument i32 ^661
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1397:3).4: _ZL6g_1947 into ^662
	movq _ZL6g_1947, %rax
	# LowerBasicConversion(1398:3): ^662 -> ^663
	movq %rax, %rbx
	# LowerLoad(1399:3).2: (^9) into ^664
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1400:3): move argument i64 ^663
	movq %rbx, %rdi
	# SetupCalls(1400:3): move argument ptr @.str.112
	movq .str.112, %rsi
	# SetupCalls(1400:3): move argument i32 ^664
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1401:3).4: _ZL6g_1948 into ^665
	movq _ZL6g_1948, %rax
	# LowerBasicConversion(1402:3): ^665 -> ^666
	movq %rax, %rbx
	# LowerLoad(1403:3).2: (^9) into ^667
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1404:3): move argument i64 ^666
	movq %rbx, %rdi
	# SetupCalls(1404:3): move argument ptr @.str.113
	movq .str.113, %rsi
	# SetupCalls(1404:3): move argument i32 ^667
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1405:3).4: _ZL6g_2024 into ^668
	movq _ZL6g_2024, %rax
	movslq %eax, %rbx
	# LowerLoad(1407:3).2: (^9) into ^670
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1408:3): move argument i64 ^669
	movq %rbx, %rdi
	# SetupCalls(1408:3): move argument ptr @.str.114
	movq .str.114, %rsi
	# SetupCalls(1408:3): move argument i32 ^670
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1409:3).4: _ZL6g_2072 into ^671
	movq _ZL6g_2072, %rax
	movslq %eax, %rbx
	# LowerLoad(1411:3).2: (^9) into ^673
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1412:3): move argument i64 ^672
	movq %rbx, %rdi
	# SetupCalls(1412:3): move argument ptr @.str.115
	movq .str.115, %rsi
	# SetupCalls(1412:3): move argument i32 ^673
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1413:3).2: (^9) into ^674
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# SetupCalls(1414:3): move argument i64 -7849629611674676947
	movabsq $-7849629611674676947, %rbx
	movq %rbx, %rdi
	# SetupCalls(1414:3): move argument ptr @.str.116
	movq .str.116, %rsi
	# SetupCalls(1414:3): move argument i32 ^674
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1415:3).2: (^9) into ^675
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# SetupCalls(1416:3): move argument i64 15412
	movq $15412, %rdi
	# SetupCalls(1416:3): move argument ptr @.str.117
	movq .str.117, %rsi
	# SetupCalls(1416:3): move argument i32 ^675
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(1417:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M4764:
	# LowerLoad(1421:3).2: (^6) into ^677
	movl (%r12), %eax
	# LowerIcmp(1422:3): i32 ^677 vs. intlike 1
	cmpl $1, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M4770
	jmp .__main__M4885
	.__main__M4770:
	# LowerStore(1426:3).3: mov $imm, ^7
	movl $0, (%r15)
	.__main__M4773:
	# LowerLoad(1430:3).2: (^7) into ^681
	movl (%r15), %eax
	# LowerIcmp(1431:3): i32 ^681 vs. intlike 5
	cmpl $5, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M4779
	jmp .__main__M4877
	.__main__M4779:
	# LowerLoad(1435:3).2: (^6) into ^684
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_2324, %rax
	movq _ZL6g_2324, %rcx
	# LowerGetelementptr(1437:3): struct-type: ptr ^826 -> ^686, indices=0,%685
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(1437:3): type of ^686 is ptr*
	# LowerLoad(1438:3).2: (^7) into ^687
	movl (%r15), %ebx
	movslq %ebx, %rcx
	# LowerGetelementptr(1440:3): struct-type: ptr ^686 -> ^689, indices=0,%688
	movq %rax, %rbx
	movq %rcx, %rax
	shlq $3, %rax
	addq %rax, %rbx
	# LowerGetelementptr(1440:3): type of ^689 is ptr*
	# LowerLoad(1441:3).2: (^689) into ^690
	movl (%rbx), %eax
	# LowerBasicConversion(1442:3): ^690 -> ^691
	movq %rax, %rbx
	# LowerLoad(1443:3).2: (^9) into ^692
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1444:3): move argument i64 ^691
	movq %rbx, %rdi
	# SetupCalls(1444:3): move argument ptr @.str.118
	movq .str.118, %rsi
	# SetupCalls(1444:3): move argument i32 ^692
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1445:3).2: (^9) into ^693
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1446:3): i32 ^693 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M4836
	jmp .__main__M4869
	.__main__M4836:
	# LowerLoad(1450:3).2: (^6) into ^696
	movl (%r12), %eax
	# LowerLoad(1451:3).2: (^7) into ^697
	movl (%r15), %ebx
	# SetupCalls(1452:3): move argument ptr @.str.87
	movq .str.87, %rdi
	# SetupCalls(1452:3): move argument i32 ^696
	movl %eax, %esi
	# SetupCalls(1452:3): move argument i32 ^697
	movl %ebx, %edx
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(1452:3): move result from %rax
	movl %eax, %eax
	.__main__M4869:
	# LowerLoad(1459:3).2: (^7) into ^701
	movl (%r15), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1461:3).9: mov ^702, (^7)
	movl %ebx, (%r15)
	jmp .__main__M4773
	.__main__M4877:
	# LowerLoad(1468:3).2: (^6) into ^705
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1470:3).9: mov ^706, (^6)
	movl %ebx, (%r12)
	jmp .__main__M4764
	.__main__M4885:
	# LowerLoad(1474:3).4: _ZL6g_2354 into ^708
	movq _ZL6g_2354, %rax
	movslq %eax, %rbx
	# LowerLoad(1476:3).2: (^9) into ^710
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1477:3): move argument i64 ^709
	movq %rbx, %rdi
	# SetupCalls(1477:3): move argument ptr @.str.119
	movq .str.119, %rsi
	# SetupCalls(1477:3): move argument i32 ^710
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1478:3).4: _ZL6g_2382 into ^711
	movq _ZL6g_2382, %rax
	# LowerBasicConversion(1479:3): ^711 -> ^712
	movq %rax, %rbx
	# LowerLoad(1480:3).2: (^9) into ^713
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1481:3): move argument i64 ^712
	movq %rbx, %rdi
	# SetupCalls(1481:3): move argument ptr @.str.120
	movq .str.120, %rsi
	# SetupCalls(1481:3): move argument i32 ^713
	movl %eax, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerStore(1482:3).3: mov $imm, ^6
	movl $0, (%r12)
	.__main__M4949:
	# LowerLoad(1486:3).2: (^6) into ^715
	movl (%r12), %eax
	# LowerIcmp(1487:3): i32 ^715 vs. intlike 4
	cmpl $4, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M4955
	jmp .__main__M5070
	.__main__M4955:
	# LowerStore(1491:3).3: mov $imm, ^7
	movl $0, (%r15)
	.__main__M4958:
	# LowerLoad(1495:3).2: (^7) into ^719
	movl (%r15), %eax
	# LowerIcmp(1496:3): i32 ^719 vs. intlike 6
	cmpl $6, %eax
	setl %al
	cmpb $0, %al
	jne .__main__M4964
	jmp .__main__M5062
	.__main__M4964:
	# LowerLoad(1500:3).2: (^6) into ^722
	movl (%r12), %eax
	movslq %eax, %rbx
	movq _ZL6g_2427, %rax
	movq _ZL6g_2427, %rcx
	# LowerGetelementptr(1502:3): struct-type: ptr ^830 -> ^724, indices=0,%723
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(1502:3): type of ^724 is ptr*
	# LowerLoad(1503:3).2: (^7) into ^725
	movl (%r15), %ebx
	movslq %ebx, %rcx
	# LowerGetelementptr(1505:3): struct-type: ptr ^724 -> ^727, indices=0,%726
	movq %rax, %rbx
	movq %rcx, %rax
	shlq $3, %rax
	addq %rax, %rbx
	# LowerGetelementptr(1505:3): type of ^727 is ptr*
	# LowerLoad(1506:3).2: (^727) into ^728
	movw (%rbx), %ax
	# LowerBasicConversion(1507:3): ^728 -> ^729
	movq %rax, %rbx
	# LowerLoad(1508:3).2: (^9) into ^730
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(1509:3): move argument i64 ^729
	movq %rbx, %rdi
	# SetupCalls(1509:3): move argument ptr @.str.121
	movq .str.121, %rsi
	# SetupCalls(1509:3): move argument i32 ^730
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1510:3).2: (^9) into ^731
	movq -48(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1511:3): i32 ^731 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .__main__M5021
	jmp .__main__M5054
	.__main__M5021:
	# LowerLoad(1515:3).2: (^6) into ^734
	movl (%r12), %eax
	# LowerLoad(1516:3).2: (^7) into ^735
	movl (%r15), %ebx
	# SetupCalls(1517:3): move argument ptr @.str.87
	movq .str.87, %rdi
	# SetupCalls(1517:3): move argument i32 ^734
	movl %eax, %esi
	# SetupCalls(1517:3): move argument i32 ^735
	movl %ebx, %edx
	movq $0, %rax
	callq printf@PLT@GOTPCREL(%rip)
	# SetupCalls(1517:3): move result from %rax
	movl %eax, %eax
	.__main__M5054:
	# LowerLoad(1524:3).2: (^7) into ^739
	movl (%r15), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1526:3).9: mov ^740, (^7)
	movl %ebx, (%r15)
	jmp .__main__M4958
	.__main__M5062:
	# LowerLoad(1533:3).2: (^6) into ^743
	movl (%r12), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1535:3).9: mov ^744, (^6)
	movl %ebx, (%r12)
	jmp .__main__M4949
	.__main__M5070:
	# LowerLoad(1539:3).4: _ZL6g_2519 into ^746
	movq _ZL6g_2519, %rax
	movswq %ax, %rbx
	# LowerLoad(1541:3).2: (^9) into ^748
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(1542:3): move argument i64 ^747
	movq %rbx, %rdi
	# SetupCalls(1542:3): move argument ptr @.str.122
	movq .str.122, %rsi
	# SetupCalls(1542:3): move argument i32 ^748
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1543:3).4: _ZL6g_2599 into ^749
	movq _ZL6g_2599, %rax
	# LowerBasicConversion(1544:3): ^749 -> ^750
	movq %rax, %rbx
	# LowerLoad(1545:3).2: (^9) into ^751
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(1546:3): move argument i64 ^750
	movq %rbx, %rdi
	# SetupCalls(1546:3): move argument ptr @.str.123
	movq .str.123, %rsi
	# SetupCalls(1546:3): move argument i32 ^751
	movl %ecx, %edx
	callq _ZL15transparent_crcmPci@GOTPCREL(%rip)
	# LowerLoad(1547:3).4: _ZL13crc32_context into ^752
	movq _ZL13crc32_context, %rax
	# LowerBasicConversion(1548:3): ^752 -> ^753
	movq %rax, %rbx
	movq %rbx, %rax
	movabsq $4294967295, %rbx
	xorq %rbx, %rax
	# LowerTrunc(1550:3): 64 to 32, move
	movl %eax, %ebx
	# LowerTrunc(1550:3): 64 to 32, apply mask
	movabsq $4294967295, %rax
	andl %eax, %ebx
	# LowerLoad(1551:3).2: (^9) into ^756
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# SetupCalls(1552:3): move argument i32 ^755
	movl %ebx, %edi
	# SetupCalls(1552:3): move argument i32 ^756
	movl %eax, %esi
	callq _ZL17platform_main_endji@GOTPCREL(%rip)
	movq $0, %rax
	movq -80(%rbp), %r15
	movq -96(%rbp), %r14
	movq -88(%rbp), %r13
	movq -72(%rbp), %r12
	movq -64(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL19platform_main_beginv
.p2align 4, 0x90
_ZL19platform_main_beginv:
	.___ZL19platform_main_beginv__M0:
	pushq %rbp
	movq %rsp, %rbp
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_lshift_func_uint32_t_u_sji
.p2align 4, 0x90
_ZL29safe_lshift_func_uint32_t_u_sji:
	.___ZL29safe_lshift_func_uint32_t_u_sji__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(80 + 0, 16)
	subq $80, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4303:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rdx
	# LowerAlloca(4304:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4305:3).9: mov %edi, (^3)
	movl %edi, (%rdx)
	# LowerStore(4307:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4309:3).2: (^4) into ^5
	movl (%rax), %ebx
	# LowerIcmp(4310:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint32_t_u_sji__M32
	.___ZL29safe_lshift_func_uint32_t_u_sji__M14:
	# LowerLoad(4314:3).2: (^4) into ^8
	movl (%rax), %ebx
	# LowerIcmp(4315:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint32_t_u_sji__M32
	.___ZL29safe_lshift_func_uint32_t_u_sji__M20:
	# LowerLoad(4319:3).2: (^3) into ^11
	movl (%rdx), %esi
	# LowerLoad(4320:3).2: (^4) into ^12
	movl (%rax), %ebx
	# LowerShift(4321:3): operand ^12 changed to %cl
	movb %bl, %cl
	movl $-1, %ebx
	shrl %cl, %ebx
	# LowerIcmp(4322:3): i32 ^11 vs. operand i32 ^13
	cmpl %ebx, %esi
	seta %bl
	cmpb $0, %bl
	jne .___ZL29safe_lshift_func_uint32_t_u_sji__M32
	jmp .___ZL29safe_lshift_func_uint32_t_u_sji__M37
	.___ZL29safe_lshift_func_uint32_t_u_sji__M32:
	# LowerLoad(4326:3).2: (^3) into ^16
	movl (%rdx), %eax
	# MovePhi: ^16 -> ^22
	movl %eax, %ebx
	jmp .___ZL29safe_lshift_func_uint32_t_u_sji__M48
	.___ZL29safe_lshift_func_uint32_t_u_sji__M37:
	# LowerLoad(4330:3).2: (^3) into ^18
	movl (%rdx), %ebx
	# LowerLoad(4331:3).2: (^4) into ^19
	movl (%rax), %edx
	# LowerShift(4332:3): operand ^19 changed to %cl
	movb %dl, %cl
	movl %ebx, %eax
	shll %cl, %eax
	# MovePhi: ^20 -> ^22
	movl %eax, %ebx
	.___ZL29safe_lshift_func_uint32_t_u_sji__M48:
	movl %ebx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL12crc32_8bytesm
.p2align 4, 0x90
_ZL12crc32_8bytesm:
	.___ZL12crc32_8bytesm__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(6096:3): size = 8, type = i64*, var = ^2
	leaq -8(%rbp), %rbx
	# LowerStore(6097:3).9: mov %rdi, (^2)
	movq %rdi, (%rbx)
	# LowerLoad(6099:3).2: (^2) into ^3
	movq (%rbx), %rcx
	movq %rcx, %rax
	shrq $0, %rax
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(6102:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(6102:3): 64 to 8, apply mask
	andb $255, %al
	# SetupCalls(6103:3): move argument i8 zeroext ^6
	movb %al, %dil
	andq $255, %rdi
	callq _ZL10crc32_byteh@GOTPCREL(%rip)
	# LowerLoad(6104:3).2: (^2) into ^7
	movq (%rbx), %rax
	movq %rax, %rcx
	shrq $8, %rcx
	movq %rcx, %rax
	andq $255, %rax
	# LowerTrunc(6107:3): 64 to 8, move
	movb %al, %cl
	# LowerTrunc(6107:3): 64 to 8, apply mask
	andb $255, %cl
	# SetupCalls(6108:3): move argument i8 zeroext ^10
	movb %cl, %dil
	andq $255, %rdi
	callq _ZL10crc32_byteh@GOTPCREL(%rip)
	# LowerLoad(6109:3).2: (^2) into ^11
	movq (%rbx), %rcx
	movq %rcx, %rax
	shrq $16, %rax
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(6112:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(6112:3): 64 to 8, apply mask
	andb $255, %al
	# SetupCalls(6113:3): move argument i8 zeroext ^14
	movb %al, %dil
	andq $255, %rdi
	callq _ZL10crc32_byteh@GOTPCREL(%rip)
	# LowerLoad(6114:3).2: (^2) into ^15
	movq (%rbx), %rcx
	movq %rcx, %rax
	shrq $24, %rax
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(6117:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(6117:3): 64 to 8, apply mask
	andb $255, %al
	# SetupCalls(6118:3): move argument i8 zeroext ^18
	movb %al, %dil
	andq $255, %rdi
	callq _ZL10crc32_byteh@GOTPCREL(%rip)
	# LowerLoad(6119:3).2: (^2) into ^19
	movq (%rbx), %rax
	movq %rax, %rcx
	shrq $32, %rcx
	movq %rcx, %rdx
	andq $255, %rdx
	# LowerTrunc(6122:3): 64 to 8, move
	movb %dl, %al
	# LowerTrunc(6122:3): 64 to 8, apply mask
	andb $255, %al
	# SetupCalls(6123:3): move argument i8 zeroext ^22
	movb %al, %dil
	andq $255, %rdi
	callq _ZL10crc32_byteh@GOTPCREL(%rip)
	# LowerLoad(6124:3).2: (^2) into ^23
	movq (%rbx), %rax
	movq %rax, %rcx
	shrq $40, %rcx
	movq %rcx, %rax
	andq $255, %rax
	# LowerTrunc(6127:3): 64 to 8, move
	movb %al, %cl
	# LowerTrunc(6127:3): 64 to 8, apply mask
	andb $255, %cl
	# SetupCalls(6128:3): move argument i8 zeroext ^26
	movb %cl, %dil
	andq $255, %rdi
	callq _ZL10crc32_byteh@GOTPCREL(%rip)
	# LowerLoad(6129:3).2: (^2) into ^27
	movq (%rbx), %rax
	movq %rax, %rcx
	shrq $48, %rcx
	movq %rcx, %rax
	andq $255, %rax
	# LowerTrunc(6132:3): 64 to 8, move
	movb %al, %cl
	# LowerTrunc(6132:3): 64 to 8, apply mask
	andb $255, %cl
	# SetupCalls(6133:3): move argument i8 zeroext ^30
	movb %cl, %dil
	andq $255, %rdi
	callq _ZL10crc32_byteh@GOTPCREL(%rip)
	# LowerLoad(6134:3).2: (^2) into ^31
	movq (%rbx), %rax
	movq %rax, %rbx
	shrq $56, %rbx
	movq %rbx, %rax
	andq $255, %rax
	# LowerTrunc(6137:3): 64 to 8, move
	movb %al, %bl
	# LowerTrunc(6137:3): 64 to 8, apply mask
	andb $255, %bl
	# SetupCalls(6138:3): move argument i8 zeroext ^34
	movb %bl, %dil
	andq $255, %rdi
	callq _ZL10crc32_byteh@GOTPCREL(%rip)
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_add_func_uint64_t_u_umm
.p2align 4, 0x90
_ZL26safe_add_func_uint64_t_u_umm:
	.___ZL26safe_add_func_uint64_t_u_umm__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(3430:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(3431:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(3432:3).9: mov %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(3434:3).9: mov %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(3436:3).2: (^3) into ^5
	movq (%rcx), %rbx
	# LowerLoad(3437:3).2: (^4) into ^6
	movq (%rax), %rcx
	movq %rbx, %rax
	addq %rcx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_int16_t_s_usj
.p2align 4, 0x90
_ZL28safe_lshift_func_int16_t_s_usj:
	.___ZL28safe_lshift_func_int16_t_s_usj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(88 + 0, 16)
	subq $96, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3521:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rdx
	# LowerAlloca(3522:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3523:3).9: mov %di, (^3)
	movw %di, (%rdx)
	# LowerStore(3525:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3527:3).2: (^3) into ^5
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerIcmp(3529:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_usj__M34
	.___ZL28safe_lshift_func_int16_t_s_usj__M15:
	# LowerLoad(3533:3).2: (^4) into ^9
	movl (%rax), %ebx
	# LowerIcmp(3534:3): i32 ^9 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_usj__M34
	.___ZL28safe_lshift_func_int16_t_s_usj__M21:
	# LowerLoad(3538:3).2: (^3) into ^12
	movw (%rdx), %bx
	movswl %bx, %esi
	# LowerLoad(3540:3).2: (^4) into ^14
	movl (%rax), %ebx
	# LowerShift(3541:3): operand ^14 changed to %cl
	movb %bl, %cl
	movl $32767, %ebx
	sarl %cl, %ebx
	# LowerIcmp(3542:3): i32 ^13 vs. operand i32 ^15
	cmpl %ebx, %esi
	setg %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_usj__M34
	jmp .___ZL28safe_lshift_func_int16_t_s_usj__M40
	.___ZL28safe_lshift_func_int16_t_s_usj__M34:
	# LowerLoad(3546:3).2: (^3) into ^18
	movw (%rdx), %ax
	movswl %ax, %ebx
	# MovePhi: ^19 -> ^26
	movl %ebx, %r8d
	jmp .___ZL28safe_lshift_func_int16_t_s_usj__M52
	.___ZL28safe_lshift_func_int16_t_s_usj__M40:
	# LowerLoad(3551:3).2: (^3) into ^21
	movw (%rdx), %cx
	movswl %cx, %ebx
	# LowerLoad(3553:3).2: (^4) into ^23
	movl (%rax), %edx
	# LowerShift(3554:3): operand ^23 changed to %cl
	movb %dl, %cl
	movl %ebx, %eax
	shll %cl, %eax
	# MovePhi: ^24 -> ^26
	movl %eax, %r8d
	.___ZL28safe_lshift_func_int16_t_s_usj__M52:
	# LowerTrunc(3559:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(3559:3): 32 to 16, apply mask
	andw $65535, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL32safe_unary_minus_func_uint64_t_um
.p2align 4, 0x90
_ZL32safe_unary_minus_func_uint64_t_um:
	.___ZL32safe_unary_minus_func_uint64_t_um__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(16 + 0, 16)
	subq $16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3943:3): size = 8, type = i64*, var = ^2
	leaq -8(%rbp), %rax
	# LowerStore(3944:3).9: mov %rdi, (^2)
	movq %rdi, (%rax)
	# LowerLoad(3946:3).2: (^2) into ^3
	movq (%rax), %rbx
	movq $0, %rax
	subq %rbx, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_add_func_uint8_t_u_uhh
.p2align 4, 0x90
_ZL25safe_add_func_uint8_t_u_uhh:
	.___ZL25safe_add_func_uint8_t_u_uhh__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3504:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rcx
	# LowerAlloca(3505:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(3506:3).9: mov %dil, (^3)
	movb %dil, (%rcx)
	# LowerStore(3508:3).9: mov %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(3510:3).2: (^3) into ^5
	movb (%rcx), %bl
	# LowerBasicConversion(3511:3): ^5 -> ^6
	movl %ebx, %ecx
	# LowerLoad(3512:3).2: (^4) into ^7
	movb (%rax), %dl
	# LowerBasicConversion(3513:3): ^7 -> ^8
	movl %edx, %ebx
	movl %ecx, %eax
	addl %ebx, %eax
	# LowerTrunc(3515:3): 32 to 8, move
	movb %al, %bl
	# LowerTrunc(3515:3): 32 to 8, apply mask
	andb $255, %bl
	movb %bl, %al
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_uint8_t_u_shi
.p2align 4, 0x90
_ZL28safe_lshift_func_uint8_t_u_shi:
	.___ZL28safe_lshift_func_uint8_t_u_shi__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(96 + 0, 16)
	subq $96, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3461:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rdx
	# LowerAlloca(3462:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3463:3).9: mov %dil, (^3)
	movb %dil, (%rdx)
	# LowerStore(3465:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3467:3).2: (^4) into ^5
	movl (%rax), %ebx
	# LowerIcmp(3468:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_uint8_t_u_shi__M34
	.___ZL28safe_lshift_func_uint8_t_u_shi__M14:
	# LowerLoad(3472:3).2: (^4) into ^8
	movl (%rax), %ebx
	# LowerIcmp(3473:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_uint8_t_u_shi__M34
	.___ZL28safe_lshift_func_uint8_t_u_shi__M20:
	# LowerLoad(3477:3).2: (^3) into ^11
	movb (%rdx), %bl
	# LowerBasicConversion(3478:3): ^11 -> ^12
	movl %ebx, %esi
	# LowerLoad(3479:3).2: (^4) into ^13
	movl (%rax), %ebx
	# LowerShift(3480:3): operand ^13 changed to %cl
	movb %bl, %cl
	movl $255, %ebx
	sarl %cl, %ebx
	# LowerIcmp(3481:3): i32 ^12 vs. operand i32 ^14
	cmpl %ebx, %esi
	setg %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_uint8_t_u_shi__M34
	jmp .___ZL28safe_lshift_func_uint8_t_u_shi__M41
	.___ZL28safe_lshift_func_uint8_t_u_shi__M34:
	# LowerLoad(3485:3).2: (^3) into ^17
	movb (%rdx), %bl
	# LowerBasicConversion(3486:3): ^17 -> ^18
	movl %ebx, %eax
	# MovePhi: ^18 -> ^25
	movl %eax, %r8d
	jmp .___ZL28safe_lshift_func_uint8_t_u_shi__M54
	.___ZL28safe_lshift_func_uint8_t_u_shi__M41:
	# LowerLoad(3490:3).2: (^3) into ^20
	movb (%rdx), %bl
	# LowerBasicConversion(3491:3): ^20 -> ^21
	movl %ebx, %edx
	# LowerLoad(3492:3).2: (^4) into ^22
	movl (%rax), %ebx
	# LowerShift(3493:3): operand ^22 changed to %cl
	movb %bl, %cl
	movl %edx, %eax
	shll %cl, %eax
	# MovePhi: ^23 -> ^25
	movl %eax, %r8d
	.___ZL28safe_lshift_func_uint8_t_u_shi__M54:
	# LowerTrunc(3498:3): 32 to 8, move
	movb %r8b, %al
	# LowerTrunc(3498:3): 32 to 8, apply mask
	andb $255, %al
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_rshift_func_uint32_t_u_ujj
.p2align 4, 0x90
_ZL29safe_rshift_func_uint32_t_u_ujj:
	.___ZL29safe_rshift_func_uint32_t_u_ujj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(40 + 0, 16)
	subq $48, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4498:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(4499:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4500:3).9: mov %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(4502:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4504:3).2: (^4) into ^5
	movl (%rax), %ebx
	# LowerIcmp(4505:3): i32 ^5 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	cmpb $0, %bl
	jne .___ZL29safe_rshift_func_uint32_t_u_ujj__M14
	jmp .___ZL29safe_rshift_func_uint32_t_u_ujj__M19
	.___ZL29safe_rshift_func_uint32_t_u_ujj__M14:
	# LowerLoad(4509:3).2: (^3) into ^8
	movl (%rcx), %ebx
	# MovePhi: ^8 -> ^14
	movl %ebx, %eax
	jmp .___ZL29safe_rshift_func_uint32_t_u_ujj__M30
	.___ZL29safe_rshift_func_uint32_t_u_ujj__M19:
	# LowerLoad(4513:3).2: (^3) into ^10
	movl (%rcx), %ebx
	# LowerLoad(4514:3).2: (^4) into ^11
	movl (%rax), %edx
	# LowerShift(4515:3): operand ^11 changed to %cl
	movb %dl, %cl
	movl %ebx, %edx
	shrl %cl, %edx
	# MovePhi: ^12 -> ^14
	movl %edx, %eax
	.___ZL29safe_rshift_func_uint32_t_u_ujj__M30:
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_int64_t_s_sli
.p2align 4, 0x90
_ZL28safe_lshift_func_int64_t_s_sli:
	.___ZL28safe_lshift_func_int64_t_s_sli__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(96 + 0, 16)
	subq $96, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4163:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rdx
	# LowerAlloca(4164:3): size = 4, type = i32*, var = ^4
	leaq -12(%rbp), %rax
	# LowerStore(4165:3).9: mov %rdi, (^3)
	movq %rdi, (%rdx)
	# LowerStore(4167:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4169:3).2: (^3) into ^5
	movq (%rdx), %rbx
	# LowerIcmp(4170:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_sli__M41
	.___ZL28safe_lshift_func_int64_t_s_sli__M14:
	# LowerLoad(4174:3).2: (^4) into ^8
	movl (%rax), %ebx
	# LowerIcmp(4175:3): i32 ^8 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_sli__M41
	.___ZL28safe_lshift_func_int64_t_s_sli__M20:
	# LowerLoad(4179:3).2: (^4) into ^11
	movl (%rax), %ebx
	# LowerIcmp(4180:3): i32 ^11 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_sli__M41
	.___ZL28safe_lshift_func_int64_t_s_sli__M26:
	# LowerLoad(4184:3).2: (^3) into ^14
	movq (%rdx), %rbx
	# LowerLoad(4185:3).2: (^4) into ^15
	movl (%rax), %ecx
	# LowerBasicConversion(4186:3): ^15 -> ^16
	movq %rcx, %rsi
	# LowerShift(4187:3): operand ^16 changed to %cl
	movb %sil, %cl
	movabsq $9223372036854775807, %rdi
	movq %rdi, %rsi
	sarq %cl, %rsi
	# LowerIcmp(4188:3): i64 ^14 vs. operand i64 ^17
	cmpq %rsi, %rbx
	setg %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int64_t_s_sli__M41
	jmp .___ZL28safe_lshift_func_int64_t_s_sli__M46
	.___ZL28safe_lshift_func_int64_t_s_sli__M41:
	# LowerLoad(4192:3).2: (^3) into ^20
	movq (%rdx), %rax
	# MovePhi: ^20 -> ^27
	movq %rax, %rbx
	jmp .___ZL28safe_lshift_func_int64_t_s_sli__M59
	.___ZL28safe_lshift_func_int64_t_s_sli__M46:
	# LowerLoad(4196:3).2: (^3) into ^22
	movq (%rdx), %rbx
	# LowerLoad(4197:3).2: (^4) into ^23
	movl (%rax), %ecx
	# LowerBasicConversion(4198:3): ^23 -> ^24
	movq %rcx, %rax
	# LowerShift(4199:3): operand ^24 changed to %cl
	movb %al, %cl
	movq %rbx, %rax
	shlq %cl, %rax
	# MovePhi: ^25 -> ^27
	movq %rax, %rbx
	.___ZL28safe_lshift_func_int64_t_s_sli__M59:
	movq %rbx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_uint8_t_u_uhj
.p2align 4, 0x90
_ZL28safe_lshift_func_uint8_t_u_uhj:
	.___ZL28safe_lshift_func_uint8_t_u_uhj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4423:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rdx
	# LowerAlloca(4424:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4425:3).9: mov %dil, (^3)
	movb %dil, (%rdx)
	# LowerStore(4427:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4429:3).2: (^4) into ^5
	movl (%rax), %ebx
	# LowerIcmp(4430:3): i32 ^5 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_uint8_t_u_uhj__M28
	.___ZL28safe_lshift_func_uint8_t_u_uhj__M14:
	# LowerLoad(4434:3).2: (^3) into ^8
	movb (%rdx), %cl
	# LowerBasicConversion(4435:3): ^8 -> ^9
	movl %ecx, %ebx
	# LowerLoad(4436:3).2: (^4) into ^10
	movl (%rax), %esi
	# LowerShift(4437:3): operand ^10 changed to %cl
	movb %sil, %cl
	movl $255, %esi
	sarl %cl, %esi
	# LowerIcmp(4438:3): i32 ^9 vs. operand i32 ^11
	cmpl %esi, %ebx
	setg %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_uint8_t_u_uhj__M28
	jmp .___ZL28safe_lshift_func_uint8_t_u_uhj__M35
	.___ZL28safe_lshift_func_uint8_t_u_uhj__M28:
	# LowerLoad(4442:3).2: (^3) into ^14
	movb (%rdx), %al
	# LowerBasicConversion(4443:3): ^14 -> ^15
	movl %eax, %ebx
	# MovePhi: ^15 -> ^22
	movl %ebx, %r8d
	jmp .___ZL28safe_lshift_func_uint8_t_u_uhj__M48
	.___ZL28safe_lshift_func_uint8_t_u_uhj__M35:
	# LowerLoad(4447:3).2: (^3) into ^17
	movb (%rdx), %cl
	# LowerBasicConversion(4448:3): ^17 -> ^18
	movl %ecx, %ebx
	# LowerLoad(4449:3).2: (^4) into ^19
	movl (%rax), %edx
	# LowerShift(4450:3): operand ^19 changed to %cl
	movb %dl, %cl
	movl %ebx, %eax
	shll %cl, %eax
	# MovePhi: ^20 -> ^22
	movl %eax, %r8d
	.___ZL28safe_lshift_func_uint8_t_u_uhj__M48:
	# LowerTrunc(4455:3): 32 to 8, move
	movb %r8b, %al
	# LowerTrunc(4455:3): 32 to 8, apply mask
	andb $255, %al
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_mod_func_int64_t_s_sll
.p2align 4, 0x90
_ZL25safe_mod_func_int64_t_s_sll:
	.___ZL25safe_mod_func_int64_t_s_sll__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(88 + 0, 16)
	subq $96, %rsp
	movq %rbx, -32(%rbp)
	# LowerAlloca(4226:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(4227:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(4228:3).9: mov %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(4230:3).9: mov %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(4232:3).2: (^4) into ^5
	movq (%rax), %rbx
	# LowerIcmp(4233:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	sete %bl
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int64_t_s_sll__M27
	.___ZL25safe_mod_func_int64_t_s_sll__M14:
	# LowerLoad(4237:3).2: (^3) into ^8
	movq (%rcx), %rbx
	# LowerIcmp(4238:3): i64 ^8 vs. intlike -9223372036854775808
	movabsq $-9223372036854775808, %rdx
	cmpq %rdx, %rbx
	sete %bl
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int64_t_s_sll__M21
	jmp .___ZL25safe_mod_func_int64_t_s_sll__M32
	.___ZL25safe_mod_func_int64_t_s_sll__M21:
	# LowerLoad(4242:3).2: (^4) into ^11
	movq (%rax), %rbx
	# LowerIcmp(4243:3): i64 ^11 vs. intlike -1
	cmpq $-1, %rbx
	sete %bl
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_int64_t_s_sll__M27
	jmp .___ZL25safe_mod_func_int64_t_s_sll__M32
	.___ZL25safe_mod_func_int64_t_s_sll__M27:
	# LowerLoad(4247:3).2: (^3) into ^14
	movq (%rcx), %rax
	# MovePhi: ^14 -> ^20
	movq %rax, %rcx
	jmp .___ZL25safe_mod_func_int64_t_s_sll__M47
	.___ZL25safe_mod_func_int64_t_s_sll__M32:
	# LowerLoad(4251:3).2: (^3) into ^16
	movq (%rcx), %rbx
	# LowerLoad(4252:3).2: (^4) into ^17
	movq (%rax), %rcx
	# Clobber %rax
	movq %rax, -24(%rbp)
	movq $0, %rdx
	movq %rbx, %rax
	idivq %rcx
	movq %rdx, %rbx
	# Unclobber %rax
	movq -24(%rbp), %rax
	# MovePhi: ^18 -> ^20
	movq %rbx, %rcx
	.___ZL25safe_mod_func_int64_t_s_sll__M47:
	movq %rcx, %rax
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL31safe_unary_minus_func_int64_t_sl
.p2align 4, 0x90
_ZL31safe_unary_minus_func_int64_t_sl:
	.___ZL31safe_unary_minus_func_int64_t_sl__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(40 + 0, 16)
	subq $48, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4280:3): size = 8, type = i64*, var = ^2
	leaq -8(%rbp), %rax
	# LowerStore(4281:3).9: mov %rdi, (^2)
	movq %rdi, (%rax)
	# LowerLoad(4283:3).2: (^2) into ^3
	movq (%rax), %rbx
	# LowerIcmp(4284:3): i64 ^3 vs. intlike -9223372036854775808
	movabsq $-9223372036854775808, %rcx
	cmpq %rcx, %rbx
	sete %bl
	cmpb $0, %bl
	jne .___ZL31safe_unary_minus_func_int64_t_sl__M11
	jmp .___ZL31safe_unary_minus_func_int64_t_sl__M16
	.___ZL31safe_unary_minus_func_int64_t_sl__M11:
	# LowerLoad(4288:3).2: (^2) into ^6
	movq (%rax), %rbx
	# MovePhi: ^6 -> ^11
	movq %rbx, %rcx
	jmp .___ZL31safe_unary_minus_func_int64_t_sl__M23
	.___ZL31safe_unary_minus_func_int64_t_sl__M16:
	# LowerLoad(4292:3).2: (^2) into ^8
	movq (%rax), %rbx
	movq $0, %rax
	subq %rbx, %rax
	# MovePhi: ^9 -> ^11
	movq %rax, %rcx
	.___ZL31safe_unary_minus_func_int64_t_sl__M23:
	movq %rcx, %rax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_rshift_func_int16_t_s_ssi
.p2align 4, 0x90
_ZL28safe_rshift_func_int16_t_s_ssi:
	.___ZL28safe_rshift_func_int16_t_s_ssi__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(80 + 0, 16)
	subq $80, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4382:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rdx
	# LowerAlloca(4383:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4384:3).9: mov %di, (^3)
	movw %di, (%rdx)
	# LowerStore(4386:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4388:3).2: (^3) into ^5
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerIcmp(4390:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int16_t_s_ssi__M27
	.___ZL28safe_rshift_func_int16_t_s_ssi__M15:
	# LowerLoad(4394:3).2: (^4) into ^9
	movl (%rax), %ebx
	# LowerIcmp(4395:3): i32 ^9 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int16_t_s_ssi__M27
	.___ZL28safe_rshift_func_int16_t_s_ssi__M21:
	# LowerLoad(4399:3).2: (^4) into ^12
	movl (%rax), %ebx
	# LowerIcmp(4400:3): i32 ^12 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int16_t_s_ssi__M27
	jmp .___ZL28safe_rshift_func_int16_t_s_ssi__M33
	.___ZL28safe_rshift_func_int16_t_s_ssi__M27:
	# LowerLoad(4404:3).2: (^3) into ^15
	movw (%rdx), %bx
	movswl %bx, %eax
	# MovePhi: ^16 -> ^23
	movl %eax, %r8d
	jmp .___ZL28safe_rshift_func_int16_t_s_ssi__M45
	.___ZL28safe_rshift_func_int16_t_s_ssi__M33:
	# LowerLoad(4409:3).2: (^3) into ^18
	movw (%rdx), %bx
	movswl %bx, %edx
	# LowerLoad(4411:3).2: (^4) into ^20
	movl (%rax), %ebx
	# LowerShift(4412:3): operand ^20 changed to %cl
	movb %bl, %cl
	movl %edx, %eax
	sarl %cl, %eax
	# MovePhi: ^21 -> ^23
	movl %eax, %r8d
	.___ZL28safe_rshift_func_int16_t_s_ssi__M45:
	# LowerTrunc(4417:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(4417:3): 32 to 16, apply mask
	andw $65535, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_rshift_func_int16_t_s_usj
.p2align 4, 0x90
_ZL28safe_rshift_func_int16_t_s_usj:
	.___ZL28safe_rshift_func_int16_t_s_usj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4667:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rdx
	# LowerAlloca(4668:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4669:3).9: mov %di, (^3)
	movw %di, (%rdx)
	# LowerStore(4671:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4673:3).2: (^3) into ^5
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerIcmp(4675:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int16_t_s_usj__M21
	.___ZL28safe_rshift_func_int16_t_s_usj__M15:
	# LowerLoad(4679:3).2: (^4) into ^9
	movl (%rax), %ebx
	# LowerIcmp(4680:3): i32 ^9 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int16_t_s_usj__M21
	jmp .___ZL28safe_rshift_func_int16_t_s_usj__M27
	.___ZL28safe_rshift_func_int16_t_s_usj__M21:
	# LowerLoad(4684:3).2: (^3) into ^12
	movw (%rdx), %bx
	movswl %bx, %eax
	# MovePhi: ^13 -> ^20
	movl %eax, %r8d
	jmp .___ZL28safe_rshift_func_int16_t_s_usj__M39
	.___ZL28safe_rshift_func_int16_t_s_usj__M27:
	# LowerLoad(4689:3).2: (^3) into ^15
	movw (%rdx), %cx
	movswl %cx, %ebx
	# LowerLoad(4691:3).2: (^4) into ^17
	movl (%rax), %edx
	# LowerShift(4692:3): operand ^17 changed to %cl
	movb %dl, %cl
	movl %ebx, %eax
	sarl %cl, %eax
	# MovePhi: ^18 -> ^20
	movl %eax, %r8d
	.___ZL28safe_rshift_func_int16_t_s_usj__M39:
	# LowerTrunc(4697:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(4697:3): 32 to 16, apply mask
	andw $65535, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_rshift_func_int32_t_s_sii
.p2align 4, 0x90
_ZL28safe_rshift_func_int32_t_s_sii:
	.___ZL28safe_rshift_func_int32_t_s_sii__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(72 + 0, 16)
	subq $80, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4342:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(4343:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4344:3).9: mov %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(4346:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4348:3).2: (^3) into ^5
	movl (%rcx), %ebx
	# LowerIcmp(4349:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int32_t_s_sii__M26
	.___ZL28safe_rshift_func_int32_t_s_sii__M14:
	# LowerLoad(4353:3).2: (^4) into ^8
	movl (%rax), %ebx
	# LowerIcmp(4354:3): i32 ^8 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int32_t_s_sii__M26
	.___ZL28safe_rshift_func_int32_t_s_sii__M20:
	# LowerLoad(4358:3).2: (^4) into ^11
	movl (%rax), %ebx
	# LowerIcmp(4359:3): i32 ^11 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int32_t_s_sii__M26
	jmp .___ZL28safe_rshift_func_int32_t_s_sii__M31
	.___ZL28safe_rshift_func_int32_t_s_sii__M26:
	# LowerLoad(4363:3).2: (^3) into ^14
	movl (%rcx), %eax
	# MovePhi: ^14 -> ^20
	movl %eax, %ebx
	jmp .___ZL28safe_rshift_func_int32_t_s_sii__M42
	.___ZL28safe_rshift_func_int32_t_s_sii__M31:
	# LowerLoad(4367:3).2: (^3) into ^16
	movl (%rcx), %ebx
	# LowerLoad(4368:3).2: (^4) into ^17
	movl (%rax), %edx
	# LowerShift(4369:3): operand ^17 changed to %cl
	movb %dl, %cl
	movl %ebx, %eax
	sarl %cl, %eax
	# MovePhi: ^18 -> ^20
	movl %eax, %ebx
	.___ZL28safe_rshift_func_int32_t_s_sii__M42:
	movl %ebx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_div_func_int64_t_s_sll
.p2align 4, 0x90
_ZL25safe_div_func_int64_t_s_sll:
	.___ZL25safe_div_func_int64_t_s_sll__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(88 + 0, 16)
	subq $96, %rsp
	movq %rbx, -32(%rbp)
	# LowerAlloca(4461:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(4462:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(4463:3).9: mov %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(4465:3).9: mov %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(4467:3).2: (^4) into ^5
	movq (%rax), %rbx
	# LowerIcmp(4468:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	sete %bl
	cmpb $0, %bl
	jne .___ZL25safe_div_func_int64_t_s_sll__M27
	.___ZL25safe_div_func_int64_t_s_sll__M14:
	# LowerLoad(4472:3).2: (^3) into ^8
	movq (%rcx), %rbx
	# LowerIcmp(4473:3): i64 ^8 vs. intlike -9223372036854775808
	movabsq $-9223372036854775808, %rdx
	cmpq %rdx, %rbx
	sete %bl
	cmpb $0, %bl
	jne .___ZL25safe_div_func_int64_t_s_sll__M21
	jmp .___ZL25safe_div_func_int64_t_s_sll__M32
	.___ZL25safe_div_func_int64_t_s_sll__M21:
	# LowerLoad(4477:3).2: (^4) into ^11
	movq (%rax), %rbx
	# LowerIcmp(4478:3): i64 ^11 vs. intlike -1
	cmpq $-1, %rbx
	sete %bl
	cmpb $0, %bl
	jne .___ZL25safe_div_func_int64_t_s_sll__M27
	jmp .___ZL25safe_div_func_int64_t_s_sll__M32
	.___ZL25safe_div_func_int64_t_s_sll__M27:
	# LowerLoad(4482:3).2: (^3) into ^14
	movq (%rcx), %rax
	# MovePhi: ^14 -> ^20
	movq %rax, %rcx
	jmp .___ZL25safe_div_func_int64_t_s_sll__M47
	.___ZL25safe_div_func_int64_t_s_sll__M32:
	# LowerLoad(4486:3).2: (^3) into ^16
	movq (%rcx), %rbx
	# LowerLoad(4487:3).2: (^4) into ^17
	movq (%rax), %rcx
	# Clobber %rax
	movq %rax, -24(%rbp)
	movq $0, %rdx
	movq %rbx, %rax
	idivq %rcx
	movq %rax, %rbx
	# Unclobber %rax
	movq -24(%rbp), %rax
	# MovePhi: ^18 -> ^20
	movq %rbx, %rcx
	.___ZL25safe_div_func_int64_t_s_sll__M47:
	movq %rcx, %rax
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_div_func_uint8_t_u_uhh
.p2align 4, 0x90
_ZL25safe_div_func_uint8_t_u_uhh:
	.___ZL25safe_div_func_uint8_t_u_uhh__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(72 + 0, 16)
	subq $80, %rsp
	movq %rbx, -32(%rbp)
	# LowerAlloca(4525:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rdx
	# LowerAlloca(4526:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(4527:3).9: mov %dil, (^3)
	movb %dil, (%rdx)
	# LowerStore(4529:3).9: mov %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(4531:3).2: (^4) into ^5
	movb (%rax), %bl
	# LowerBasicConversion(4532:3): ^5 -> ^6
	movl %ebx, %ecx
	# LowerIcmp(4533:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	sete %bl
	cmpb $0, %bl
	jne .___ZL25safe_div_func_uint8_t_u_uhh__M16
	jmp .___ZL25safe_div_func_uint8_t_u_uhh__M23
	.___ZL25safe_div_func_uint8_t_u_uhh__M16:
	# LowerLoad(4537:3).2: (^3) into ^9
	movb (%rdx), %al
	# LowerBasicConversion(4538:3): ^9 -> ^10
	movl %eax, %ebx
	# MovePhi: ^10 -> ^18
	movl %ebx, %r8d
	jmp .___ZL25safe_div_func_uint8_t_u_uhh__M42
	.___ZL25safe_div_func_uint8_t_u_uhh__M23:
	# LowerLoad(4542:3).2: (^3) into ^12
	movb (%rdx), %bl
	# LowerBasicConversion(4543:3): ^12 -> ^13
	movl %ebx, %ecx
	# LowerLoad(4544:3).2: (^4) into ^14
	movb (%rax), %bl
	# LowerBasicConversion(4545:3): ^14 -> ^15
	movl %ebx, %esi
	# Clobber %rax
	movq %rax, -16(%rbp)
	# Clobber %rdx
	movq %rdx, -24(%rbp)
	movl $0, %edx
	movl %ecx, %eax
	idivl %esi
	movl %eax, %ebx
	# Unclobber %rdx
	movq -24(%rbp), %rdx
	# Unclobber %rax
	movq -16(%rbp), %rax
	# MovePhi: ^16 -> ^18
	movl %ebx, %r8d
	.___ZL25safe_div_func_uint8_t_u_uhh__M42:
	# LowerTrunc(4551:3): 32 to 8, move
	movb %r8b, %al
	# LowerTrunc(4551:3): 32 to 8, apply mask
	andb $255, %al
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_add_func_uint16_t_u_utt
.p2align 4, 0x90
_ZL26safe_add_func_uint16_t_u_utt:
	.___ZL26safe_add_func_uint16_t_u_utt__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(5970:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(5971:3): size = 2, type = i16*, var = ^4
	leaq -4(%rbp), %rax
	# LowerStore(5972:3).9: mov %di, (^3)
	movw %di, (%rcx)
	# LowerStore(5974:3).9: mov %si, (^4)
	movw %si, (%rax)
	# LowerLoad(5976:3).2: (^3) into ^5
	movw (%rcx), %bx
	# LowerBasicConversion(5977:3): ^5 -> ^6
	movl %ebx, %ecx
	# LowerLoad(5978:3).2: (^4) into ^7
	movw (%rax), %dx
	# LowerBasicConversion(5979:3): ^7 -> ^8
	movl %edx, %ebx
	movl %ecx, %eax
	addl %ebx, %eax
	# LowerTrunc(5981:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(5981:3): 32 to 16, apply mask
	andw $65535, %bx
	movw %bx, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_rshift_func_uint16_t_u_sti
.p2align 4, 0x90
_ZL29safe_rshift_func_uint16_t_u_sti:
	.___ZL29safe_rshift_func_uint16_t_u_sti__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(64 + 0, 16)
	subq $64, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(3628:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rcx
	# LowerAlloca(3629:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(3630:3).9: mov %di, (^3)
	movw %di, (%rcx)
	# LowerStore(3632:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(3634:3).2: (^4) into ^5
	movl (%rax), %ebx
	# LowerIcmp(3635:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL29safe_rshift_func_uint16_t_u_sti__M20
	.___ZL29safe_rshift_func_uint16_t_u_sti__M14:
	# LowerLoad(3639:3).2: (^4) into ^8
	movl (%rax), %ebx
	# LowerIcmp(3640:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	cmpb $0, %bl
	jne .___ZL29safe_rshift_func_uint16_t_u_sti__M20
	jmp .___ZL29safe_rshift_func_uint16_t_u_sti__M27
	.___ZL29safe_rshift_func_uint16_t_u_sti__M20:
	# LowerLoad(3644:3).2: (^3) into ^11
	movw (%rcx), %bx
	# LowerBasicConversion(3645:3): ^11 -> ^12
	movl %ebx, %eax
	# MovePhi: ^12 -> ^19
	movl %eax, %r8d
	jmp .___ZL29safe_rshift_func_uint16_t_u_sti__M40
	.___ZL29safe_rshift_func_uint16_t_u_sti__M27:
	# LowerLoad(3649:3).2: (^3) into ^14
	movw (%rcx), %bx
	# LowerBasicConversion(3650:3): ^14 -> ^15
	movl %ebx, %edx
	# LowerLoad(3651:3).2: (^4) into ^16
	movl (%rax), %ebx
	# LowerShift(3652:3): operand ^16 changed to %cl
	movb %bl, %cl
	movl %edx, %eax
	sarl %cl, %eax
	# MovePhi: ^17 -> ^19
	movl %eax, %r8d
	.___ZL29safe_rshift_func_uint16_t_u_sti__M40:
	# LowerTrunc(3657:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(3657:3): 32 to 16, apply mask
	andw $65535, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_mod_func_uint32_t_u_ujj
.p2align 4, 0x90
_ZL26safe_mod_func_uint32_t_u_ujj:
	.___ZL26safe_mod_func_uint32_t_u_ujj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(5987:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(5988:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(5989:3).9: mov %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(5991:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(5993:3).2: (^4) into ^5
	movl (%rax), %ebx
	# LowerIcmp(5994:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	sete %bl
	cmpb $0, %bl
	jne .___ZL26safe_mod_func_uint32_t_u_ujj__M14
	jmp .___ZL26safe_mod_func_uint32_t_u_ujj__M19
	.___ZL26safe_mod_func_uint32_t_u_ujj__M14:
	# LowerLoad(5998:3).2: (^3) into ^8
	movl (%rcx), %ebx
	# MovePhi: ^8 -> ^14
	movl %ebx, %eax
	jmp .___ZL26safe_mod_func_uint32_t_u_ujj__M34
	.___ZL26safe_mod_func_uint32_t_u_ujj__M19:
	# LowerLoad(6002:3).2: (^3) into ^10
	movl (%rcx), %ebx
	# LowerLoad(6003:3).2: (^4) into ^11
	movl (%rax), %ecx
	# Clobber %rax
	movq %rax, -16(%rbp)
	movl $0, %edx
	movl %ebx, %eax
	divl %ecx
	movl %edx, %ebx
	# Unclobber %rax
	movq -16(%rbp), %rax
	# MovePhi: ^12 -> ^14
	movl %ebx, %eax
	.___ZL26safe_mod_func_uint32_t_u_ujj__M34:
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL29safe_rshift_func_uint64_t_u_umj
.p2align 4, 0x90
_ZL29safe_rshift_func_uint64_t_u_umj:
	.___ZL29safe_rshift_func_uint64_t_u_umj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(4598:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(4599:3): size = 4, type = i32*, var = ^4
	leaq -12(%rbp), %rax
	# LowerStore(4600:3).9: mov %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(4602:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4604:3).2: (^4) into ^5
	movl (%rax), %ebx
	# LowerIcmp(4605:3): i32 ^5 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	cmpb $0, %bl
	jne .___ZL29safe_rshift_func_uint64_t_u_umj__M14
	jmp .___ZL29safe_rshift_func_uint64_t_u_umj__M19
	.___ZL29safe_rshift_func_uint64_t_u_umj__M14:
	# LowerLoad(4609:3).2: (^3) into ^8
	movq (%rcx), %rax
	# MovePhi: ^8 -> ^15
	movq %rax, %rbx
	jmp .___ZL29safe_rshift_func_uint64_t_u_umj__M32
	.___ZL29safe_rshift_func_uint64_t_u_umj__M19:
	# LowerLoad(4613:3).2: (^3) into ^10
	movq (%rcx), %rbx
	# LowerLoad(4614:3).2: (^4) into ^11
	movl (%rax), %ecx
	# LowerBasicConversion(4615:3): ^11 -> ^12
	movq %rcx, %rax
	# LowerShift(4616:3): operand ^12 changed to %cl
	movb %al, %cl
	movq %rbx, %rax
	shrq %cl, %rax
	# MovePhi: ^13 -> ^15
	movq %rax, %rbx
	.___ZL29safe_rshift_func_uint64_t_u_umj__M32:
	movq %rbx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_sub_func_int32_t_s_sii
.p2align 4, 0x90
_ZL25safe_sub_func_int32_t_s_sii:
	.___ZL25safe_sub_func_int32_t_s_sii__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(80 + 0, 16)
	subq $80, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4703:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rdx
	# LowerAlloca(4704:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4705:3).9: mov %edi, (^3)
	movl %edi, (%rdx)
	# LowerStore(4707:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4709:3).2: (^3) into ^5
	movl (%rdx), %ebx
	# LowerLoad(4710:3).2: (^4) into ^6
	movl (%rax), %ecx
	movl %ebx, %edi
	xorl %ecx, %edi
	# LowerLoad(4712:3).2: (^3) into ^8
	movl (%rdx), %ecx
	# LowerLoad(4713:3).2: (^3) into ^9
	movl (%rdx), %ebx
	# LowerLoad(4714:3).2: (^4) into ^10
	movl (%rax), %esi
	movl %ebx, %r8d
	xorl %esi, %r8d
	movl %r8d, %ebx
	andl $-2147483648, %ebx
	movl %ecx, %esi
	xorl %ebx, %esi
	# LowerLoad(4718:3).2: (^4) into ^14
	movl (%rax), %ebx
	movl %esi, %ecx
	subl %ebx, %ecx
	# LowerLoad(4720:3).2: (^4) into ^16
	movl (%rax), %ebx
	movl %ecx, %esi
	xorl %ebx, %esi
	movl %edi, %ebx
	andl %esi, %ebx
	# LowerIcmp(4723:3): i32 ^18 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL25safe_sub_func_int32_t_s_sii__M41
	jmp .___ZL25safe_sub_func_int32_t_s_sii__M46
	.___ZL25safe_sub_func_int32_t_s_sii__M41:
	# LowerLoad(4727:3).2: (^3) into ^21
	movl (%rdx), %eax
	# MovePhi: ^21 -> ^27
	movl %eax, %ebx
	jmp .___ZL25safe_sub_func_int32_t_s_sii__M55
	.___ZL25safe_sub_func_int32_t_s_sii__M46:
	# LowerLoad(4731:3).2: (^3) into ^23
	movl (%rdx), %ebx
	# LowerLoad(4732:3).2: (^4) into ^24
	movl (%rax), %ecx
	movl %ebx, %eax
	subl %ecx, %eax
	# MovePhi: ^25 -> ^27
	movl %eax, %ebx
	.___ZL25safe_sub_func_int32_t_s_sii__M55:
	movl %ebx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL6func_1v
.p2align 4, 0x90
_ZL6func_1v:
	.___ZL6func_1v__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(5520 + 0, 16)
	subq $5520, %rsp
	movq %rbx, -3080(%rbp)
	movq %r12, -3088(%rbp)
	movq %r13, -3096(%rbp)
	movq %r14, -3104(%rbp)
	movq %r15, -4464(%rbp)
	# LowerAlloca(1645:3): size = 2, type = %union.U4*, var = ^1
	# Fixing leaq -2(%rbp), -2104(%rbp)
	leaq -2(%rbp), %r15
	movq %r15, -2104(%rbp)
	# LowerAlloca(1646:3): size = 4, type = %union.U0*, var = ^2
	# Fixing leaq -8(%rbp), -2128(%rbp)
	leaq -8(%rbp), %r15
	movq %r15, -2128(%rbp)
	# LowerAlloca(1647:3): size = 4, type = i32*, var = ^3
	# Fixing leaq -12(%rbp), -2480(%rbp)
	leaq -12(%rbp), %r15
	movq %r15, -2480(%rbp)
	# LowerAlloca(1648:3): size = 4, type = i32*, var = ^4
	# Fixing leaq -16(%rbp), -2168(%rbp)
	leaq -16(%rbp), %r15
	movq %r15, -2168(%rbp)
	# LowerAlloca(1649:3): size = 4, type = i32*, var = ^5
	# Fixing leaq -20(%rbp), -2208(%rbp)
	leaq -20(%rbp), %r15
	movq %r15, -2208(%rbp)
	# LowerAlloca(1650:3): size = 4, type = i32*, var = ^6
	# Fixing leaq -24(%rbp), -2264(%rbp)
	leaq -24(%rbp), %r15
	movq %r15, -2264(%rbp)
	# LowerAlloca(1651:3): size = 8, type = ptr*, var = ^7
	leaq -32(%rbp), %rcx
	# LowerAlloca(1652:3): size = 8, type = ptr*, var = ^8
	# Fixing leaq -40(%rbp), -2872(%rbp)
	leaq -40(%rbp), %r15
	movq %r15, -2872(%rbp)
	# LowerAlloca(1653:3): size = 8, type = i64*, var = ^9
	# Fixing leaq -48(%rbp), -2344(%rbp)
	leaq -48(%rbp), %r15
	movq %r15, -2344(%rbp)
	# LowerAlloca(1654:3): size = 2016, type = [7 x [9 x [4 x ptr]]]*, var = ^10
	leaq -2064(%rbp), %rbx
	# LowerAlloca(1655:3): size = 8, type = ptr*, var = ^11
	leaq -2072(%rbp), %r12
	# LowerAlloca(1656:3): size = 8, type = ptr*, var = ^12
	# Fixing leaq -2080(%rbp), -2456(%rbp)
	leaq -2080(%rbp), %r15
	movq %r15, -2456(%rbp)
	# LowerAlloca(1657:3): size = 8, type = ptr*, var = ^13
	# Fixing leaq -2088(%rbp), -2112(%rbp)
	leaq -2088(%rbp), %r15
	movq %r15, -2112(%rbp)
	# LowerAlloca(1658:3): size = 8, type = ptr*, var = ^14
	# Fixing leaq -2096(%rbp), -2384(%rbp)
	leaq -2096(%rbp), %r15
	movq %r15, -2384(%rbp)
	andq $-2, %rsp
	# LowerAlloca(1659:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1659:3): mov %rsp, ^15
	movq %rsp, -2120(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1660:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1660:3): mov %rsp, ^16
	movq %rsp, -3040(%rbp)
	andq $-2, %rsp
	# LowerAlloca(1661:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1661:3): mov %rsp, ^17
	movq %rsp, -2216(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1662:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1662:3): mov %rsp, ^18
	movq %rsp, -3048(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1663:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1663:3): mov %rsp, ^19
	movq %rsp, -3056(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1664:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1664:3): mov %rsp, ^20
	movq %rsp, -3064(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1665:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1665:3): mov %rsp, ^21
	movq %rsp, -3072(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1666:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1666:3): mov %rsp, ^22
	movq %rsp, -2368(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1667:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1667:3): mov %rsp, ^23
	movq %rsp, %r13
	andq $-8, %rsp
	# LowerAlloca(1668:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1668:3): mov %rsp, ^24
	movq %rsp, %r14
	andq $-16, %rsp
	# LowerAlloca(1669:3): %rsp -= to_sub
	subq $80, %rsp
	# LowerAlloca(1669:3): mov %rsp, ^25
	movq %rsp, -3024(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1670:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1670:3): mov %rsp, ^26
	movq %rsp, -2400(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1671:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1671:3): mov %rsp, ^27
	movq %rsp, -2416(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1672:3): %rsp -= to_sub
	subq $24, %rsp
	# LowerAlloca(1672:3): mov %rsp, ^28
	movq %rsp, -2392(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1673:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1673:3): mov %rsp, ^29
	movq %rsp, -3016(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1674:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1674:3): mov %rsp, ^30
	movq %rsp, -3032(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1675:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1675:3): mov %rsp, ^31
	movq %rsp, %rax
	andq $-2, %rsp
	# LowerAlloca(1676:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1676:3): mov %rsp, ^32
	movq %rsp, -2888(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1677:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1677:3): mov %rsp, ^33
	movq %rsp, -2896(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1678:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1678:3): mov %rsp, ^34
	movq %rsp, -2904(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1679:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1679:3): mov %rsp, ^35
	movq %rsp, -2912(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1680:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1680:3): mov %rsp, ^36
	movq %rsp, -2920(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1681:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1681:3): mov %rsp, ^37
	movq %rsp, -2928(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1682:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1682:3): mov %rsp, ^38
	movq %rsp, -2936(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1683:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1683:3): mov %rsp, ^39
	movq %rsp, -2944(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1684:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1684:3): mov %rsp, ^40
	movq %rsp, -2952(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1685:3): %rsp -= to_sub
	subq $288, %rsp
	# LowerAlloca(1685:3): mov %rsp, ^41
	movq %rsp, -2960(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1686:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1686:3): mov %rsp, ^42
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(1687:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1687:3): mov %rsp, ^43
	movq %rsp, %rax
	andq $-2, %rsp
	# LowerAlloca(1688:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1688:3): mov %rsp, ^44
	movq %rsp, -2968(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1689:3): %rsp -= to_sub
	subq $120, %rsp
	# LowerAlloca(1689:3): mov %rsp, ^45
	movq %rsp, -2992(%rbp)
	andq $-2, %rsp
	# LowerAlloca(1690:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1690:3): mov %rsp, ^46
	movq %rsp, -3000(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1691:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1691:3): mov %rsp, ^47
	movq %rsp, -3008(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1692:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1692:3): mov %rsp, ^48
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(1693:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1693:3): mov %rsp, ^49
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(1694:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1694:3): mov %rsp, ^50
	movq %rsp, %rax
	andq $-2, %rsp
	# LowerAlloca(1695:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1695:3): mov %rsp, ^51
	movq %rsp, -2712(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1696:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1696:3): mov %rsp, ^52
	movq %rsp, -2704(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1697:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1697:3): mov %rsp, ^53
	movq %rsp, -2136(%rbp)
	andq $-2, %rsp
	# LowerAlloca(1698:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1698:3): mov %rsp, ^54
	movq %rsp, -2584(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1699:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1699:3): mov %rsp, ^55
	movq %rsp, -2160(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1700:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1700:3): mov %rsp, ^56
	movq %rsp, -2552(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1701:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1701:3): mov %rsp, ^57
	movq %rsp, -2432(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1702:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1702:3): mov %rsp, ^58
	movq %rsp, -2536(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1703:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1703:3): mov %rsp, ^59
	movq %rsp, -2848(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1704:3): %rsp -= to_sub
	subq $48, %rsp
	# LowerAlloca(1704:3): mov %rsp, ^60
	movq %rsp, -2512(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1705:3): %rsp -= to_sub
	subq $48, %rsp
	# LowerAlloca(1705:3): mov %rsp, ^61
	movq %rsp, -2856(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1706:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1706:3): mov %rsp, ^62
	movq %rsp, -2360(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1707:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1707:3): mov %rsp, ^63
	movq %rsp, -2752(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1708:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1708:3): mov %rsp, ^64
	movq %rsp, -2768(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1709:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1709:3): mov %rsp, ^65
	movq %rsp, -2784(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1710:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1710:3): mov %rsp, ^66
	movq %rsp, -2800(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1711:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1711:3): mov %rsp, ^67
	movq %rsp, -2824(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1712:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1712:3): mov %rsp, ^68
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(1713:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1713:3): mov %rsp, ^69
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(1714:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1714:3): mov %rsp, ^70
	movq %rsp, -2576(%rbp)
	andq $-2, %rsp
	# LowerAlloca(1715:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1715:3): mov %rsp, ^71
	movq %rsp, -2568(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1716:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1716:3): mov %rsp, ^72
	movq %rsp, -2520(%rbp)
	andq $-2, %rsp
	# LowerAlloca(1717:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1717:3): mov %rsp, ^73
	movq %rsp, -2504(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1718:3): %rsp -= to_sub
	subq $16, %rsp
	# LowerAlloca(1718:3): mov %rsp, ^74
	movq %rsp, -2176(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1719:3): %rsp -= to_sub
	subq $32, %rsp
	# LowerAlloca(1719:3): mov %rsp, ^75
	movq %rsp, -2408(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1720:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1720:3): mov %rsp, ^76
	movq %rsp, -2184(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1721:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1721:3): mov %rsp, ^77
	movq %rsp, -2424(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1722:3): %rsp -= to_sub
	subq $40, %rsp
	# LowerAlloca(1722:3): mov %rsp, ^78
	movq %rsp, -2192(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1723:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1723:3): mov %rsp, ^79
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(1724:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1724:3): mov %rsp, ^80
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(1725:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1725:3): mov %rsp, ^81
	movq %rsp, -2200(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1726:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1726:3): mov %rsp, ^82
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(1727:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1727:3): mov %rsp, ^83
	movq %rsp, -2240(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1728:3): %rsp -= to_sub
	subq $400, %rsp
	# LowerAlloca(1728:3): mov %rsp, ^84
	movq %rsp, -2232(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1729:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1729:3): mov %rsp, ^85
	movq %rsp, -2224(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1730:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1730:3): mov %rsp, ^86
	movq %rsp, -2472(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1731:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1731:3): mov %rsp, ^87
	movq %rsp, -2440(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1732:3): %rsp -= to_sub
	subq $504, %rsp
	# LowerAlloca(1732:3): mov %rsp, ^88
	movq %rsp, -2464(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1733:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1733:3): mov %rsp, ^89
	movq %rsp, -2448(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1734:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1734:3): mov %rsp, ^90
	movq %rsp, %rax
	andq $-2, %rsp
	# LowerAlloca(1735:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1735:3): mov %rsp, ^91
	movq %rsp, -2272(%rbp)
	andq $-2, %rsp
	# LowerAlloca(1736:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1736:3): mov %rsp, ^92
	movq %rsp, -2280(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1737:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1737:3): mov %rsp, ^93
	movq %rsp, -2288(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1738:3): %rsp -= to_sub
	subq $40, %rsp
	# LowerAlloca(1738:3): mov %rsp, ^94
	movq %rsp, -2296(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1739:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1739:3): mov %rsp, ^95
	movq %rsp, -2304(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1740:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1740:3): mov %rsp, ^96
	movq %rsp, -2312(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1741:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1741:3): mov %rsp, ^97
	movq %rsp, %rax
	andq $-16, %rsp
	# LowerAlloca(1742:3): %rsp -= to_sub
	subq $88, %rsp
	# LowerAlloca(1742:3): mov %rsp, ^98
	movq %rsp, -2320(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1743:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1743:3): mov %rsp, ^99
	movq %rsp, -2328(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1744:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1744:3): mov %rsp, ^100
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(1745:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1745:3): mov %rsp, ^101
	movq %rsp, %rax
	andq $-8, %rsp
	# LowerAlloca(1746:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1746:3): mov %rsp, ^102
	movq %rsp, -2336(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1747:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1747:3): mov %rsp, ^103
	movq %rsp, %rax
	andq $-8, %rsp
	# LowerAlloca(1748:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1748:3): mov %rsp, ^104
	movq %rsp, -2880(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1749:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1749:3): mov %rsp, ^105
	movq %rsp, -2864(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1750:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1750:3): mov %rsp, ^106
	movq %rsp, -2544(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1751:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1751:3): mov %rsp, ^107
	movq %rsp, -2976(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1752:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1752:3): mov %rsp, ^108
	movq %rsp, -2984(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1753:3): %rsp -= to_sub
	subq $224, %rsp
	# LowerAlloca(1753:3): mov %rsp, ^109
	movq %rsp, -2496(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1754:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1754:3): mov %rsp, ^110
	movq %rsp, -2488(%rbp)
	andq $-2, %rsp
	# LowerAlloca(1755:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1755:3): mov %rsp, ^111
	movq %rsp, -2728(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1756:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1756:3): mov %rsp, ^112
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(1757:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1757:3): mov %rsp, ^113
	movq %rsp, %rax
	movq %rsp, %rax
	movq $8, %rax
	movq $0, %rdx
	divq %rsp
	movq %rdx, %rax
	subq %rax, %rsp
	# LowerAlloca(1758:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1758:3): mov %rsp, ^114
	movq %rsp, -2680(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1759:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1759:3): mov %rsp, ^115
	movq %rsp, -2792(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1760:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1760:3): mov %rsp, ^116
	movq %rsp, -2808(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1761:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1761:3): mov %rsp, ^117
	movq %rsp, -2832(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1762:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1762:3): mov %rsp, ^118
	movq %rsp, -2840(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1763:3): %rsp -= to_sub
	subq $32, %rsp
	# LowerAlloca(1763:3): mov %rsp, ^119
	movq %rsp, -2816(%rbp)
	andq $-2, %rsp
	# LowerAlloca(1764:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1764:3): mov %rsp, ^120
	movq %rsp, -2760(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1765:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1765:3): mov %rsp, ^121
	movq %rsp, -2776(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1766:3): %rsp -= to_sub
	subq $16, %rsp
	# LowerAlloca(1766:3): mov %rsp, ^122
	movq %rsp, -2672(%rbp)
	andq $-2, %rsp
	# LowerAlloca(1767:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1767:3): mov %rsp, ^123
	movq %rsp, -2696(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1768:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1768:3): mov %rsp, ^124
	movq %rsp, -2736(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1769:3): %rsp -= to_sub
	subq $240, %rsp
	# LowerAlloca(1769:3): mov %rsp, ^125
	movq %rsp, -2744(%rbp)
	andq $-2, %rsp
	# LowerAlloca(1770:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1770:3): mov %rsp, ^126
	movq %rsp, -2560(%rbp)
	andq $-8, %rsp
	# LowerAlloca(1771:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1771:3): mov %rsp, ^127
	movq %rsp, -2528(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1772:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1772:3): mov %rsp, ^128
	movq %rsp, -2688(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1773:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1773:3): mov %rsp, ^129
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(1774:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1774:3): mov %rsp, ^130
	movq %rsp, -2600(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1775:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1775:3): mov %rsp, ^131
	movq %rsp, -2608(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1776:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1776:3): mov %rsp, ^132
	movq %rsp, -2616(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1777:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1777:3): mov %rsp, ^133
	movq %rsp, -2624(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1778:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1778:3): mov %rsp, ^134
	movq %rsp, -2632(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1779:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1779:3): mov %rsp, ^135
	movq %rsp, -2640(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1780:3): %rsp -= to_sub
	subq $32, %rsp
	# LowerAlloca(1780:3): mov %rsp, ^136
	movq %rsp, -2648(%rbp)
	andq $-16, %rsp
	# LowerAlloca(1781:3): %rsp -= to_sub
	subq $320, %rsp
	# LowerAlloca(1781:3): mov %rsp, ^137
	movq %rsp, -2656(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1782:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1782:3): mov %rsp, ^138
	movq %rsp, -2664(%rbp)
	andq $-4, %rsp
	# LowerAlloca(1783:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(1783:3): mov %rsp, ^139
	movq %rsp, %rax
	# LowerStore(1785:3).3: mov $imm, ^2
	movq -2128(%rbp), %rax
	movl $-207668134, (%rax)
	# LowerStore(1787:3).3: mov $imm, ^3
	movq -2480(%rbp), %rax
	movl $-1795190700, (%rax)
	# LowerStore(1789:3).3: mov $imm, ^4
	movq -2168(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(1791:3).3: mov $imm, ^5
	movq -2208(%rbp), %rax
	movl $-1689060711, (%rax)
	# LowerStore(1793:3).3: mov $imm, ^6
	movq -2264(%rbp), %rax
	movl $1272617434, (%rax)
	# LowerStore(1795:3).6: load global
	movq _ZL6g_2199@GOTPCREL(%rip), %rax
	# LowerStore(1795:3).9: mov ^1160, (^7)
	movq %rax, (%rcx)
	# LowerStore(1797:3).9: mov ^7, (^8)
	movq -2872(%rbp), %rax
	movq %rcx, (%rax)
	# LowerStore(1799:3).3: mov $imm, ^9
	movabsq $903025031038103379, %rcx
	movq -2344(%rbp), %rax
	movq %rcx, (%rax)
	# SetupCalls(1801:3): move argument ptr align 16 ^10
	movq %rbx, %rdi
	# SetupCalls(1801:3): move argument ptr align 16 @__const._ZL6func_1v.l_2323
	movq __const._ZL6func_1v.l_2323, %rsi
	# SetupCalls(1801:3): move argument i64 2016
	movq $2016, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(1803:3).3: mov $imm, ^11
	movq $0, (%r12)
	# LowerStore(1805:3).9: mov ^11, (^12)
	movq -2456(%rbp), %rax
	movq %r12, (%rax)
	# LowerStore(1807:3).6: load global
	movq _ZL5g_313@GOTPCREL(%rip), %rbx
	# LowerStore(1807:3).9: mov ^1161, (^13)
	movq -2112(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(1809:3).3: mov $imm, ^14
	movq -2384(%rbp), %rax
	movq $0, (%rax)
	# SetupCalls(1811:3): move argument ptr align 2 ^15
	movq -2120(%rbp), %rdi
	# SetupCalls(1811:3): move argument ptr align 2 @__const._ZL6func_1v.l_2419
	movq __const._ZL6func_1v.l_2419, %rsi
	# SetupCalls(1811:3): move argument i64 8
	movq $8, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(1813:3).3: mov $imm, ^16
	movq -3040(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(1815:3).3: mov $imm, ^17
	movq -2216(%rbp), %rax
	movw $1, (%rax)
	# LowerStore(1817:3).3: mov $imm, ^18
	movq -3048(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(1819:3).3: mov $imm, ^19
	movq -3056(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(1821:3).3: mov $imm, ^20
	movq -3064(%rbp), %rax
	movl $594264973, (%rax)
	# LowerStore(1823:3).3: mov $imm, ^21
	movq -3072(%rbp), %rax
	movl $0, (%rax)
	# LowerStore(1825:3).3: mov $imm, ^22
	movq -2368(%rbp), %rax
	movl $-8, (%rax)
	# LowerStore(1827:3).3: mov $imm, ^23
	movl $-1, (%r13)
	# LowerStore(1829:3).3: mov $imm, ^24
	movq $0, (%r14)
	# LowerStore(1832:3).3: mov $imm, ^26
	movq -2400(%rbp), %rax
	movl $-1576952829, (%rax)
	# LowerStore(1834:3).3: mov $imm, ^27
	movabsq $5682451316754310983, %rbx
	movq -2416(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(1839:3).3: mov $imm, ^29
	movq -3016(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M776:
	# LowerLoad(1843:3).2: (^29) into ^141
	movq -3016(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1844:3): i32 ^141 vs. intlike 1
	cmpl $1, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL6func_1v__M782
	jmp .___ZL6func_1v__M828
	.___ZL6func_1v__M782:
	# LowerStore(1848:3).3: mov $imm, ^30
	movq -3032(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M785:
	# LowerLoad(1852:3).2: (^30) into ^145
	movq -3032(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1853:3): i32 ^145 vs. intlike 10
	cmpl $10, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL6func_1v__M791
	jmp .___ZL6func_1v__M820
	.___ZL6func_1v__M791:
	# LowerLoad(1857:3).2: (^29) into ^148
	movq -3016(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerGetelementptr(1859:3): struct-type: ptr ^25 -> ^150, indices=0,%149
	movq -3024(%rbp), %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(1859:3): type of ^150 is ptr*
	# LowerLoad(1860:3).2: (^30) into ^151
	movq -3032(%rbp), %rcx
	movl (%rcx), %ebx
	movslq %ebx, %rcx
	# LowerGetelementptr(1862:3): struct-type: ptr ^150 -> ^153, indices=0,%152
	movq %rax, %rbx
	movq %rcx, %rax
	shlq $3, %rax
	addq %rax, %rbx
	# LowerGetelementptr(1862:3): type of ^153 is ptr*
	# LowerStore(1863:3).3: mov $imm, ^153
	movabsq $3399871360421987074, %rax
	movq %rax, (%rbx)
	# LowerLoad(1867:3).2: (^30) into ^155
	movq -3032(%rbp), %rbx
	movl (%rbx), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1869:3).9: mov ^156, (^30)
	movq -3032(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M785
	.___ZL6func_1v__M820:
	# LowerLoad(1876:3).2: (^29) into ^159
	movq -3016(%rbp), %rbx
	movl (%rbx), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1878:3).9: mov ^160, (^29)
	movq -3016(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M776
	.___ZL6func_1v__M828:
	# LowerStore(1882:3).3: mov $imm, ^29
	movq -3016(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M831:
	# LowerLoad(1886:3).2: (^29) into ^163
	movq -3016(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1887:3): i32 ^163 vs. intlike 6
	cmpl $6, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL6func_1v__M837
	jmp .___ZL6func_1v__M856
	.___ZL6func_1v__M837:
	# LowerLoad(1891:3).2: (^29) into ^166
	movq -3016(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerGetelementptr(1893:3): struct-type: ptr ^28 -> ^168, indices=0,%167
	movq -2392(%rbp), %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(1893:3): type of ^168 is ptr*
	# LowerStore(1894:3).3: mov $imm, ^168
	movl $2087786319, (%rax)
	# LowerLoad(1898:3).2: (^29) into ^170
	movq -3016(%rbp), %rbx
	movl (%rbx), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1900:3).9: mov ^171, (^29)
	movq -3016(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M831
	.___ZL6func_1v__M856:
	# LowerStore(1904:3).2a: mov $imm, %temp
	movl $0, %eax
	# LowerStore(1904:3).2b: mov %temp, (global)
	movl %eax, _ZL3g_2@GOTPCREL(%rip)
	.___ZL6func_1v__M861:
	# LowerLoad(1908:3).4: _ZL3g_2 into ^174
	movq _ZL3g_2, %rax
	# LowerIcmp(1909:3): i32 ^174 vs. intlike 7
	cmpl $7, %eax
	sete %al
	cmpb $0, %al
	jne .___ZL6func_1v__M867
	jmp .___ZL6func_1v__M1025
	.___ZL6func_1v__M867:
	# LowerStore(1914:3).3: mov $imm, ^32
	movq -2888(%rbp), %rax
	movw $-3, (%rax)
	# LowerStore(1916:3).3: mov $imm, ^33
	movq -2896(%rbp), %rax
	movl $6, (%rax)
	# LowerStore(1918:3).3: mov $imm, ^34
	movq -2904(%rbp), %rax
	movl $7, (%rax)
	movq _ZL5g_149, %rax
	addq $32, %rax
	# LowerStore(1920:3).9: mov ^1121, (^35)
	movq -2912(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(1922:3).9: mov ^34, (^36)
	movq -2920(%rbp), %rax
	# Fixing movq -2904(%rbp), (%rax)
	movq -2904(%rbp), %r15
	movq %r15, (%rax)
	movq _ZL5g_422, %rax
	addq $8, %rax
	# LowerStore(1924:3).9: mov ^1122, (^37)
	movq -2928(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(1926:3).9: mov ^4, (^38)
	movq -2936(%rbp), %rax
	# Fixing movq -2168(%rbp), (%rax)
	movq -2168(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(1928:3).6: load global
	movq _ZL5g_422@GOTPCREL(%rip), %rax
	# LowerStore(1928:3).9: mov ^1163, (^39)
	movq -2944(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(1930:3).9: mov ^34, (^40)
	movq -2952(%rbp), %rax
	# Fixing movq -2904(%rbp), (%rax)
	movq -2904(%rbp), %r15
	movq %r15, (%rax)
	# SetupCalls(1932:3): move argument ptr align 16 ^41
	movq -2960(%rbp), %rdi
	# SetupCalls(1932:3): move argument ptr align 16 @__const._ZL6func_1v.l_2300
	movq __const._ZL6func_1v.l_2300, %rsi
	# SetupCalls(1932:3): move argument i64 288
	movq $288, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(1935:3).2a: mov $imm, %temp
	movl $12, %eax
	# LowerStore(1935:3).2b: mov %temp, (global)
	movl %eax, _ZL3g_5@GOTPCREL(%rip)
	.___ZL6func_1v__M921:
	# LowerLoad(1939:3).4: _ZL3g_5 into ^178
	movq _ZL3g_5, %rax
	# LowerIcmp(1940:3): i32 ^178 vs. intlike -3
	cmpl $-3, %eax
	setge %al
	cmpb $0, %al
	jne .___ZL6func_1v__M927
	jmp .___ZL6func_1v__M998
	.___ZL6func_1v__M927:
	# LowerStore(1945:3).3: mov $imm, ^44
	movq -2968(%rbp), %rax
	movw $30679, (%rax)
	# SetupCalls(1947:3): move argument ptr align 16 ^45
	movq -2992(%rbp), %rdi
	# SetupCalls(1947:3): move argument ptr align 16 @__const._ZL6func_1v.l_1138
	movq __const._ZL6func_1v.l_1138, %rsi
	# SetupCalls(1947:3): move argument i64 120
	movq $120, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(1949:3).3: mov $imm, ^46
	movq -3000(%rbp), %rax
	movw $-1, (%rax)
	# LowerStore(1951:3).3: mov $imm, ^47
	movabsq $6970159599675675478, %rax
	movq -3008(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerLoad(1958:3).4: _ZL3g_5 into ^182
	movq _ZL3g_5, %rax
	movslq %eax, %rbx
	# SetupCalls(1960:3): move argument i64 ^183
	movq %rbx, %rdi
	# SetupCalls(1960:3): move argument i64 7
	movq $7, %rsi
	callq _ZL25safe_sub_func_int64_t_s_sll@GOTPCREL(%rip)
	# SetupCalls(1960:3): move result from %rax
	movq %rax, %rbx
	# LowerTrunc(1961:3): 64 to 32, move
	movl %ebx, %eax
	# LowerTrunc(1961:3): 64 to 32, apply mask
	movabsq $4294967295, %rbx
	andl %ebx, %eax
	# LowerStore(1962:3).8a: movq var, %temp
	movq _ZL3g_5@GOTPCREL(%rip), %rbx
	# LowerStore(1962:3).8b: movq ^185, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M921
	.___ZL6func_1v__M998:
	# LowerLoad(1966:3).4: _ZL5g_139 into ^187
	movq _ZL5g_139, %rax
	# LowerLoad(1967:3).2: (^187) into ^188
	movq (%rax), %rbx
	# LowerLoad(1968:3).2: (^188) into ^189
	movl (%rbx), %eax
	# LowerIcmp(1969:3): i32 ^189 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M1008
	jmp .___ZL6func_1v__M1009
	.___ZL6func_1v__M1008:
	jmp .___ZL6func_1v__M1025
	.___ZL6func_1v__M1009:
	# LowerLoad(1976:3).2: (^6) into ^193
	movq -2264(%rbp), %rbx
	movl (%rbx), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1978:3).9: mov ^194, (^6)
	movq -2264(%rbp), %rax
	movl %ebx, (%rax)
	# LowerLoad(1982:3).4: _ZL3g_2 into ^196
	movq _ZL3g_2, %rax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(1984:3).8a: movq var, %temp
	movq _ZL3g_2@GOTPCREL(%rip), %rax
	# LowerStore(1984:3).8b: movq ^197, (%temp)
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M861
	.___ZL6func_1v__M1025:
	# LowerLoad(1988:3).2: (^5) into ^199
	movq -2208(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %r12
	# LowerLoad(1990:3).2: (^2) into ^201
	movq -2128(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(1991:3): i32 ^201 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M1034
	jmp .___ZL6func_1v__M1037
	.___ZL6func_1v__M1034:
	# MovePhi: intlike -> ^234 (in new block 1222 whose parent is 198)
	movb $1, -2720(%rbp)
	jmp .___ZL6func_1v__M1286
	.___ZL6func_1v__M1037:
	# LowerLoad(1995:3).2: (^6) into ^204
	movq -2264(%rbp), %rbx
	movl (%rbx), %eax
	# LowerBasicConversion(1996:3): ^204 -> ^205
	movq %rax, %r13
	# LowerLoad(1997:3).4: _ZL6g_1931 into ^206
	movq _ZL6g_1931, %rax
	# LowerTrunc(1998:3): 32 to 8, move
	movb %al, %r14b
	# LowerTrunc(1998:3): 32 to 8, apply mask
	andb $255, %r14b
	# LowerLoad(1999:3).4: _ZL6g_2025 into ^208
	movq _ZL6g_2025, %rax
	# LowerLoad(2000:3).2: (^8) into ^209
	movq -2872(%rbp), %rcx
	movq (%rcx), %rbx
	# LowerIcmp(2001:3): ptr ^208 vs. operand ptr ^209
	cmpq %rbx, %rax
	setne %al
	# LowerBasicConversion(2002:3): ^210 -> ^211
	movb %al, %bl
	# LowerLoad(2003:3).2: (^5) into ^212
	movq -2208(%rbp), %rcx
	movl (%rcx), %eax
	# LowerTrunc(2004:3): 32 to 8, move
	movb %al, %cl
	# LowerTrunc(2004:3): 32 to 8, apply mask
	andb $255, %cl
	# SetupCalls(2005:3): move argument i8 zeroext ^211
	movb %bl, %dil
	andq $255, %rdi
	# SetupCalls(2005:3): move argument i8 zeroext ^213
	movb %cl, %sil
	andq $255, %rsi
	callq _ZL25safe_mul_func_uint8_t_u_uhh@GOTPCREL(%rip)
	# SetupCalls(2005:3): move result from %rax
	movb %al, %bl
	# LowerBasicConversion(2006:3): ^214 -> ^215
	movw %bx, %ax
	# LowerLoad(2007:3).2: (^9) into ^216
	movq -2344(%rbp), %rcx
	movq (%rcx), %rbx
	# LowerTrunc(2008:3): 64 to 16, move
	movw %bx, %cx
	# LowerTrunc(2008:3): 64 to 16, apply mask
	andw $65535, %cx
	# SetupCalls(2009:3): move argument i16 zeroext ^215
	movw %ax, %di
	andq $65535, %rdi
	# SetupCalls(2009:3): move argument i16 zeroext ^217
	movw %cx, %si
	andq $65535, %rsi
	callq _ZL26safe_div_func_uint16_t_u_utt@GOTPCREL(%rip)
	# SetupCalls(2009:3): move result from %rax
	movw %ax, %bx
	# LowerBasicConversion(2010:3): ^218 -> ^219
	movl %ebx, %eax
	# LowerLoad(2011:3).2: (^2) into ^220
	movq -2128(%rbp), %rbx
	movl (%rbx), %ecx
	# SetupCalls(2012:3): move argument i32 ^219
	movl %eax, %edi
	# SetupCalls(2012:3): move argument i32 ^220
	movl %ecx, %esi
	callq _ZL26safe_add_func_uint32_t_u_ujj@GOTPCREL(%rip)
	# SetupCalls(2012:3): move result from %rax
	movl %eax, %ebx
	# LowerTrunc(2013:3): 32 to 16, move
	movw %bx, %ax
	# LowerTrunc(2013:3): 32 to 16, apply mask
	andw $65535, %ax
	# SetupCalls(2014:3): move argument i16 signext ^222
	movw %ax, %di
	movswq %di, %rdi
	# SetupCalls(2014:3): move argument i32 4
	movq $4, %rsi
	callq _ZL28safe_lshift_func_int16_t_s_usj@GOTPCREL(%rip)
	# SetupCalls(2014:3): move result from %rax
	movw %ax, %bx
	# LowerTrunc(2015:3): 16 to 8, move
	movb %bl, %al
	# LowerTrunc(2015:3): 16 to 8, apply mask
	andb $255, %al
	# SetupCalls(2016:3): move argument i8 zeroext ^207
	movb %r14b, %dil
	andq $255, %rdi
	# SetupCalls(2016:3): move argument i8 zeroext ^224
	movb %al, %sil
	andq $255, %rsi
	callq _ZL25safe_add_func_uint8_t_u_uhh@GOTPCREL(%rip)
	# SetupCalls(2016:3): move result from %rax
	movb %al, %al
	# LowerIcmp(2017:3): i64 ^205 vs. intlike 7
	cmpq $7, %r13
	sete %al
	# LowerBasicConversion(2018:3): ^226 -> ^227
	movb %al, %bl
	# SetupCalls(2019:3): move argument i8 zeroext ^227
	movb %bl, %dil
	andq $255, %rdi
	# SetupCalls(2019:3): move argument i32 1
	movq $1, %rsi
	callq _ZL28safe_lshift_func_uint8_t_u_shi@GOTPCREL(%rip)
	# SetupCalls(2019:3): move result from %rax
	movb %al, %bl
	# LowerLoad(2020:3).2: (^6) into ^229
	movq -2264(%rbp), %rcx
	movl (%rcx), %eax
	# LowerTrunc(2021:3): 32 to 8, move
	movb %al, %cl
	# LowerTrunc(2021:3): 32 to 8, apply mask
	andb $255, %cl
	# SetupCalls(2022:3): move argument i8 signext ^228
	movb %bl, %dil
	movsbq %dil, %rdi
	# SetupCalls(2022:3): move argument i8 signext ^230
	movb %cl, %sil
	movsbq %sil, %rsi
	callq _ZL24safe_sub_func_int8_t_s_saa@GOTPCREL(%rip)
	# SetupCalls(2022:3): move result from %rax
	movb %al, %bl
	# LowerIcmp(2023:3): i8 ^231 vs. intlike 0
	cmpb $0, %bl
	setne %al
	# MovePhi: ^232 -> ^234
	movb %al, -2720(%rbp)
	.___ZL6func_1v__M1286:
	# LowerBasicConversion(2028:3): ^234 -> ^235
	movq -2720(%rbp), %rax
	# SetupCalls(2029:3): move argument i64 7838281458710188276
	movabsq $7838281458710188276, %rbx
	movq %rbx, %rdi
	# SetupCalls(2029:3): move argument i64 ^235
	movq %rax, %rsi
	callq _ZL26safe_add_func_uint64_t_u_umm@GOTPCREL(%rip)
	# SetupCalls(2029:3): move result from %rax
	movq %rax, %rbx
	# LowerIcmp(2030:3): i64 ^200 vs. operand i64 ^236
	cmpq %rbx, %r12
	setae %al
	# LowerBasicConversion(2031:3): ^237 -> ^238
	movl %eax, %ebx
	# LowerLoad(2032:3).2: (^3) into ^239
	movq -2480(%rbp), %rax
	movl (%rax), %ecx
	movl %ecx, %eax
	andl %ebx, %eax
	# LowerStore(2034:3).9: mov ^240, (^3)
	movq -2480(%rbp), %rbx
	movl %eax, (%rbx)
	# LowerLoad(2035:3).4: _ZL6g_2324 into ^241
	movq _ZL6g_2324, %rbx
	movl %eax, %ecx
	orl %ebx, %ecx
	.___ZL6func_1v__M1330:
	# LowerStore(2041:3).3: mov $imm, ^51
	movq -2712(%rbp), %rax
	movw $14316, (%rax)
	# LowerStore(2043:3).6: load global
	movq _ZL5g_744@GOTPCREL(%rip), %rax
	# LowerStore(2043:3).9: mov ^1167, (^52)
	movq -2704(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(2045:3).6: load global
	movq _ZL5g_422@GOTPCREL(%rip), %rbx
	# LowerStore(2045:3).9: mov ^1168, (^53)
	movq -2136(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2047:3).3: mov $imm, ^54
	movq -2584(%rbp), %rax
	movw $-6, (%rax)
	# LowerStore(2049:3).6: load global
	movq _ZL5g_837@GOTPCREL(%rip), %rbx
	# LowerStore(2049:3).9: mov ^1169, (^55)
	movq -2160(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2051:3).3: mov $imm, ^56
	movq -2552(%rbp), %rax
	movl $569081037, (%rax)
	# LowerStore(2053:3).6: load global
	movq _ZL5g_338@GOTPCREL(%rip), %rbx
	# LowerStore(2053:3).9: mov ^1170, (^57)
	movq -2432(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2055:3).6: load global
	movq _ZL6g_1487@GOTPCREL(%rip), %rbx
	# LowerStore(2055:3).9: mov ^1171, (^58)
	movq -2536(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2057:3).6: load global
	movq _ZL6g_2175@GOTPCREL(%rip), %rax
	# LowerStore(2057:3).9: mov ^1172, (^59)
	movq -2848(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerGetelementptr(2059:3): struct-type: ptr ^60 -> ^244, indices=0,0
	movq -2512(%rbp), %rbx
	# LowerGetelementptr(2059:3): type of ^244 is ptr*
	# LowerGetelementptr(2060:3): struct-type: ptr ^244 -> ^245, indices=0,0
	movq %rbx, %rcx
	# LowerGetelementptr(2060:3): type of ^245 is ptr*
	# LowerStore(2061:3).9: mov ^59, (^245)
	# Fixing movq -2848(%rbp), (%rcx)
	movq -2848(%rbp), %r15
	movq %r15, (%rcx)
	# LowerGetelementptr(2062:3): struct-type: ptr ^245 -> ^246, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(2062:3): type of ^246 is ptr*
	# LowerStore(2063:3).9: mov ^59, (^246)
	# Fixing movq -2848(%rbp), (%rax)
	movq -2848(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(2064:3): struct-type: ptr ^244 -> ^247, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(2064:3): type of ^247 is ptr*
	# LowerGetelementptr(2065:3): struct-type: ptr ^247 -> ^248, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(2065:3): type of ^248 is ptr*
	# LowerStore(2066:3).9: mov ^59, (^248)
	# Fixing movq -2848(%rbp), (%rbx)
	movq -2848(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(2067:3): struct-type: ptr ^248 -> ^249, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(2067:3): type of ^249 is ptr*
	# LowerStore(2068:3).9: mov ^59, (^249)
	# Fixing movq -2848(%rbp), (%rcx)
	movq -2848(%rbp), %r15
	movq %r15, (%rcx)
	# LowerGetelementptr(2069:3): struct-type: ptr ^247 -> ^250, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(2069:3): type of ^250 is ptr*
	# LowerGetelementptr(2070:3): struct-type: ptr ^250 -> ^251, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(2070:3): type of ^251 is ptr*
	# LowerStore(2071:3).9: mov ^59, (^251)
	# Fixing movq -2848(%rbp), (%rax)
	movq -2848(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(2072:3): struct-type: ptr ^251 -> ^252, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(2072:3): type of ^252 is ptr*
	# LowerStore(2073:3).9: mov ^59, (^252)
	# Fixing movq -2848(%rbp), (%rbx)
	movq -2848(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(2075:3): struct-type: ptr ^61 -> ^253, indices=0,0
	movq -2856(%rbp), %rbx
	# LowerGetelementptr(2075:3): type of ^253 is ptr*
	# LowerGetelementptr(2076:3): struct-type: ptr ^60 -> ^254, indices=0,1
	movq -2512(%rbp), %rax
	addq $8, %rax
	# LowerGetelementptr(2076:3): type of ^254 is ptr*
	# LowerGetelementptr(2077:3): struct-type: ptr ^254 -> ^255, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(2077:3): type of ^255 is ptr*
	# LowerStore(2078:3).9: mov ^255, (^253)
	movq %rcx, (%rbx)
	# LowerGetelementptr(2079:3): struct-type: ptr ^253 -> ^256, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(2079:3): type of ^256 is ptr*
	# LowerGetelementptr(2080:3): struct-type: ptr ^60 -> ^257, indices=0,1
	movq -2512(%rbp), %rbx
	addq $8, %rbx
	# LowerGetelementptr(2080:3): type of ^257 is ptr*
	# LowerGetelementptr(2081:3): struct-type: ptr ^257 -> ^258, indices=0,0
	movq %rbx, %rcx
	# LowerGetelementptr(2081:3): type of ^258 is ptr*
	# LowerStore(2082:3).9: mov ^258, (^256)
	movq %rcx, (%rax)
	# LowerGetelementptr(2083:3): struct-type: ptr ^256 -> ^259, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(2083:3): type of ^259 is ptr*
	# LowerGetelementptr(2084:3): struct-type: ptr ^60 -> ^260, indices=0,2
	movq -2512(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(2084:3): type of ^260 is ptr*
	# LowerGetelementptr(2085:3): struct-type: ptr ^260 -> ^261, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(2085:3): type of ^261 is ptr*
	# LowerStore(2086:3).9: mov ^261, (^259)
	movq %rcx, (%rbx)
	# LowerGetelementptr(2087:3): struct-type: ptr ^259 -> ^262, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(2087:3): type of ^262 is ptr*
	# LowerGetelementptr(2088:3): struct-type: ptr ^60 -> ^263, indices=0,1
	movq -2512(%rbp), %rbx
	addq $8, %rbx
	# LowerGetelementptr(2088:3): type of ^263 is ptr*
	# LowerGetelementptr(2089:3): struct-type: ptr ^263 -> ^264, indices=0,0
	movq %rbx, %rcx
	# LowerGetelementptr(2089:3): type of ^264 is ptr*
	# LowerStore(2090:3).9: mov ^264, (^262)
	movq %rcx, (%rax)
	# LowerGetelementptr(2091:3): struct-type: ptr ^262 -> ^265, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(2091:3): type of ^265 is ptr*
	# LowerGetelementptr(2092:3): struct-type: ptr ^60 -> ^266, indices=0,1
	movq -2512(%rbp), %rax
	addq $8, %rax
	# LowerGetelementptr(2092:3): type of ^266 is ptr*
	# LowerGetelementptr(2093:3): struct-type: ptr ^266 -> ^267, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(2093:3): type of ^267 is ptr*
	# LowerStore(2094:3).9: mov ^267, (^265)
	movq %rcx, (%rbx)
	# LowerGetelementptr(2095:3): struct-type: ptr ^265 -> ^268, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(2095:3): type of ^268 is ptr*
	# LowerGetelementptr(2096:3): struct-type: ptr ^60 -> ^269, indices=0,2
	movq -2512(%rbp), %rbx
	addq $16, %rbx
	# LowerGetelementptr(2096:3): type of ^269 is ptr*
	# LowerGetelementptr(2097:3): struct-type: ptr ^269 -> ^270, indices=0,0
	movq %rbx, %rcx
	# LowerGetelementptr(2097:3): type of ^270 is ptr*
	# LowerStore(2098:3).9: mov ^270, (^268)
	movq %rcx, (%rax)
	# LowerStore(2100:3).6: load global
	movq _ZL6g_1117@GOTPCREL(%rip), %rbx
	# LowerStore(2100:3).9: mov ^1173, (^62)
	movq -2360(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2102:3).3: mov $imm, ^63
	movq -2752(%rbp), %rax
	movl $252273539, (%rax)
	# LowerStore(2104:3).3: mov $imm, ^64
	movq -2768(%rbp), %rax
	movl $-1732997855, (%rax)
	# LowerStore(2106:3).3: mov $imm, ^65
	movq -2784(%rbp), %rax
	movl $-638229174, (%rax)
	# LowerStore(2108:3).3: mov $imm, ^66
	movq -2800(%rbp), %rax
	movl $-1478310357, (%rax)
	# LowerStore(2110:3).3: mov $imm, ^67
	movq -2824(%rbp), %rax
	movl $-1343789299, (%rax)
	# LowerLoad(2113:3).4: _ZL6g_1946 into ^271
	movq _ZL6g_1946, %rax
	# LowerTrunc(2114:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(2114:3): 32 to 16, apply mask
	andw $65535, %bx
	# SetupCalls(2115:3): move argument i16 zeroext ^272
	movw %bx, %di
	andq $65535, %rdi
	# SetupCalls(2115:3): move argument i32 7
	movq $7, %rsi
	callq _ZL29safe_rshift_func_uint16_t_u_sti@GOTPCREL(%rip)
	# SetupCalls(2115:3): move result from %rax
	movw %ax, %bx
	# LowerBasicConversion(2116:3): ^273 -> ^274
	movl %ebx, %eax
	# LowerLoad(2117:3).2: (^51) into ^275
	movq -2712(%rbp), %rcx
	movw (%rcx), %bx
	movswl %bx, %ecx
	# LowerIcmp(2119:3): i32 ^274 vs. operand i32 ^276
	cmpl %ecx, %eax
	setne %al
	# LowerBasicConversion(2120:3): ^277 -> ^278
	movl %eax, %ebx
	# LowerLoad(2121:3).4: _ZL6g_1680 into ^279
	movq _ZL6g_1680, %rax
	# LowerLoad(2122:3).2: (^279) into ^280
	movq (%rax), %rcx
	# LowerLoad(2123:3).2: (^280) into ^281
	movq (%rcx), %rax
	# LowerLoad(2124:3).2: (^281) into ^282
	movq (%rax), %rcx
	# LowerLoad(2125:3).2: (^282) into ^283
	movl (%rcx), %eax
	# LowerLoad(2126:3).2: (^4) into ^284
	movq -2168(%rbp), %rdx
	movl (%rdx), %ecx
	movl %ecx, %edx
	andl %eax, %edx
	# LowerStore(2128:3).9: mov ^285, (^4)
	movq -2168(%rbp), %rax
	movl %edx, (%rax)
	movslq %edx, %rax
	movq $-2, %rcx
	andq %rax, %rcx
	# LowerTrunc(2131:3): 64 to 16, move
	movw %cx, %ax
	# LowerTrunc(2131:3): 64 to 16, apply mask
	andw $65535, %ax
	# LowerLoad(2132:3).2: (^52) into ^289
	movq -2704(%rbp), %rdx
	movq (%rdx), %rcx
	# LowerStore(2133:3).3: mov $imm, ^289
	movw $24035, (%rcx)
	# SetupCalls(2134:3): move argument i16 zeroext ^288
	movw %ax, %di
	andq $65535, %rdi
	# SetupCalls(2134:3): move argument i16 zeroext 24035
	movq $24035, %rsi
	andq $65535, %rsi
	callq _ZL26safe_mul_func_uint16_t_u_utt@GOTPCREL(%rip)
	# SetupCalls(2134:3): move result from %rax
	movw %ax, %r12w
	# LowerBasicConversion(2135:3): ^290 -> ^291
	movq %r12, %rcx
	# LowerLoad(2136:3).4: _ZL6g_1899 into ^292
	movq _ZL6g_1899, %rax
	# LowerBasicConversion(2137:3): ^292 -> ^293
	movq %rax, %rdx
	# LowerStore(2138:3).8a: movq var, %temp
	movq _ZL6g_1221@GOTPCREL(%rip), %rax
	# LowerStore(2138:3).8b: movq ^293, (%temp)
	movq %rdx, (%rax)
	# LowerLoad(2139:3).2: (^53) into ^294
	movq -2136(%rbp), %rax
	movq (%rax), %rsi
	movq $0, %rax
	# LowerIcmp(2140:3): i64 ^1132 vs. operand ptr ^294
	cmpq %rsi, %rax
	sete %al
	# LowerBasicConversion(2141:3): ^295 -> ^296
	movq %rax, %rsi
	# LowerIcmp(2142:3): i64 ^293 vs. operand i64 ^296
	cmpq %rsi, %rdx
	setne %al
	# LowerBasicConversion(2143:3): ^297 -> ^298
	movq %rax, %rdx
	movq %rdx, %rax
	orq $29, %rax
	movq %rcx, %rdx
	andq %rax, %rdx
	# LowerIcmp(2146:3): i64 ^300 vs. intlike 1
	cmpq $1, %rdx
	sete %al
	# LowerBasicConversion(2147:3): ^301 -> ^302
	movl %eax, %ecx
	movl %ebx, %edx
	xorl %ecx, %edx
	# LowerLoad(2149:3).4: _ZL5g_139 into ^304
	movq _ZL5g_139, %rax
	# LowerLoad(2150:3).2: (^304) into ^305
	movq (%rax), %rbx
	# LowerLoad(2151:3).2: (^305) into ^306
	movl (%rbx), %ecx
	movl %ecx, %eax
	andl %edx, %eax
	# LowerStore(2153:3).9: mov ^307, (^305)
	movl %eax, (%rbx)
	# LowerLoad(2154:3).2: (^53) into ^308
	movq -2136(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(2155:3).2: (^308) into ^309
	movl (%rbx), %eax
	# SetupCalls(2156:3): move argument i32 ^309
	movl %eax, %edi
	# SetupCalls(2156:3): move argument i32 28
	movq $28, %rsi
	callq _ZL29safe_rshift_func_uint32_t_u_sji@GOTPCREL(%rip)
	# SetupCalls(2156:3): move result from %rax
	movl %eax, %ebx
	# SetupCalls(2157:3): move argument i32 ^310
	movl %ebx, %edi
	# SetupCalls(2157:3): move argument i32 1
	movq $1, %rsi
	callq _ZL29safe_rshift_func_uint32_t_u_sji@GOTPCREL(%rip)
	# SetupCalls(2157:3): move result from %rax
	movl %eax, %ebx
	# LowerBasicConversion(2158:3): ^311 -> ^312
	movq %rbx, %rax
	movq _ZL6g_1944, %rcx
	addq $72, %rcx
	# LowerLoad(2159:3).2: (^1123) into ^313
	movl (%rcx), %ebx
	# LowerBasicConversion(2160:3): ^313 -> ^314
	movq %rbx, %rcx
	# SetupCalls(2161:3): move argument i64 ^312
	movq %rax, %rdi
	# SetupCalls(2161:3): move argument i64 ^314
	movq %rcx, %rsi
	callq _ZL26safe_mul_func_uint64_t_u_umm@GOTPCREL(%rip)
	# SetupCalls(2161:3): move result from %rax
	movq %rax, %rax
	# LowerLoad(2162:3).4: _ZL5g_422 into ^316
	movq _ZL5g_422, %rax
	# LowerTrunc(2163:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(2163:3): 32 to 16, apply mask
	andw $65535, %bx
	# SetupCalls(2164:3): move argument i64 0
	movq $0, %rdi
	callq _ZL32safe_unary_minus_func_uint64_t_um@GOTPCREL(%rip)
	# SetupCalls(2164:3): move result from %rax
	movq %rax, %r12
	# LowerTrunc(2165:3): 64 to 16, move
	movw %r12w, %ax
	# LowerTrunc(2165:3): 64 to 16, apply mask
	andw $65535, %ax
	# SetupCalls(2166:3): move argument i16 signext ^319
	movw %ax, %di
	movswq %di, %rdi
	callq _ZL31safe_unary_minus_func_int16_t_ss@GOTPCREL(%rip)
	# SetupCalls(2166:3): move result from %rax
	movw %ax, %r12w
	# LowerTrunc(2167:3): 16 to 8, move
	movb %r12b, %r13b
	# LowerTrunc(2167:3): 16 to 8, apply mask
	andb $255, %r13b
	movq _ZL6g_1922, %rcx
	addq $48, %rcx
	# LowerLoad(2168:3).2: (^1124) into ^322
	movl (%rcx), %eax
	# LowerBasicConversion(2169:3): ^322 -> ^323
	movq %rax, %rcx
	movq $-3, %r12
	orq %rcx, %r12
	# LowerLoad(2171:3).2: (^53) into ^325
	movq -2136(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2172:3).2: (^325) into ^326
	movl (%rcx), %edx
	# LowerTrunc(2173:3): 32 to 16, move
	movw %dx, %ax
	# LowerTrunc(2173:3): 32 to 16, apply mask
	andw $65535, %ax
	# SetupCalls(2174:3): move argument i16 zeroext ^327
	movw %ax, %di
	andq $65535, %rdi
	# SetupCalls(2174:3): move argument i16 zeroext -12655
	movq $-12655, %rsi
	andq $65535, %rsi
	callq _ZL26safe_sub_func_uint16_t_u_utt@GOTPCREL(%rip)
	# SetupCalls(2174:3): move result from %rax
	movw %ax, %r14w
	# LowerBasicConversion(2175:3): ^328 -> ^329
	movq %r14, %rax
	movq %r12, %rcx
	xorq %rax, %rcx
	# LowerTrunc(2177:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(2177:3): 64 to 8, apply mask
	andb $255, %al
	# SetupCalls(2178:3): move argument i8 signext ^321
	movb %r13b, %dil
	movsbq %dil, %rdi
	# SetupCalls(2178:3): move argument i8 signext ^331
	movb %al, %sil
	movsbq %sil, %rsi
	callq _ZL24safe_sub_func_int8_t_s_saa@GOTPCREL(%rip)
	# SetupCalls(2178:3): move result from %rax
	movb %al, %al
	movq _ZL6g_1892, %rax
	addq $24, %rax
	# LowerLoad(2179:3).2: (^1125) into ^333
	movl (%rax), %ecx
	# LowerLoad(2180:3).2: (^2) into ^334
	movq -2128(%rbp), %rax
	movl (%rax), %edx
	# LowerIcmp(2181:3): i32 ^333 vs. operand i32 ^334
	cmpl %edx, %ecx
	setne %al
	# LowerBasicConversion(2182:3): ^335 -> ^336
	movq %rax, %rcx
	# LowerStore(2183:3).8a: movq var, %temp
	movq _ZL6g_1221@GOTPCREL(%rip), %rax
	# LowerStore(2183:3).8b: movq ^336, (%temp)
	movq %rcx, (%rax)
	# LowerLoad(2184:3).2: (^3) into ^337
	movq -2480(%rbp), %rdx
	movl (%rdx), %eax
	movslq %eax, %rdx
	# SetupCalls(2186:3): move argument i64 ^336
	movq %rcx, %rdi
	# SetupCalls(2186:3): move argument i64 ^338
	movq %rdx, %rsi
	callq _ZL25safe_sub_func_int64_t_s_sll@GOTPCREL(%rip)
	# SetupCalls(2186:3): move result from %rax
	movq %rax, %r12
	# LowerIcmp(2187:3): i64 ^339 vs. intlike 0
	cmpq $0, %r12
	setne %al
	movb %al, %cl
	xorb $1, %cl
	# LowerLoad(2189:3).4: _ZL5g_150 into ^342
	movq _ZL5g_150, %rax
	# LowerLoad(2190:3).2: (^53) into ^343
	movq -2136(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2191:3).2: (^343) into ^344
	movl (%rcx), %eax
	# LowerIcmp(2192:3): i32 ^344 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M1926
	jmp .___ZL6func_1v__M1929
	.___ZL6func_1v__M1926:
	# MovePhi: intlike -> ^350 (in new block 1223 whose parent is 1094)
	movb $1, %cl
	jmp .___ZL6func_1v__M1937
	.___ZL6func_1v__M1929:
	# LowerLoad(2196:3).2: (^54) into ^347
	movq -2584(%rbp), %rcx
	movw (%rcx), %ax
	# LowerIcmp(2197:3): i16 ^347 vs. intlike 0
	cmpw $0, %ax
	setne %al
	# MovePhi: ^348 -> ^350
	movb %al, %cl
	.___ZL6func_1v__M1937:
	# LowerLoad(2202:3).2: (^6) into ^351
	movq -2264(%rbp), %rax
	movl (%rax), %ecx
	# LowerLoad(2203:3).2: (^53) into ^352
	movq -2136(%rbp), %rax
	movq (%rax), %rdx
	# LowerLoad(2204:3).2: (^352) into ^353
	movl (%rdx), %eax
	# LowerIcmp(2205:3): i32 ^351 vs. operand i32 ^353
	cmpl %eax, %ecx
	setbe %al
	# LowerBasicConversion(2206:3): ^354 -> ^355
	movw %ax, %cx
	# LowerLoad(2207:3).2: (^55) into ^356
	movq -2160(%rbp), %rdx
	movq (%rdx), %rax
	# LowerStore(2208:3).9: mov ^355, (^356)
	movw %cx, (%rax)
	# SetupCalls(2209:3): move argument i16 zeroext ^317
	movw %bx, %di
	andq $65535, %rdi
	# SetupCalls(2209:3): move argument i16 zeroext ^355
	movw %cx, %si
	andq $65535, %rsi
	callq _ZL26safe_sub_func_uint16_t_u_utt@GOTPCREL(%rip)
	# SetupCalls(2209:3): move result from %rax
	movw %ax, %bx
	# LowerBasicConversion(2210:3): ^357 -> ^358
	movq %rbx, %rax
	# LowerIcmp(2211:3): i64 ^358 vs. intlike 59803
	cmpq $59803, %rax
	setl %al
	# LowerBasicConversion(2212:3): ^359 -> ^360
	movl %eax, %ebx
	# SetupCalls(2213:3): move argument ptr align 4 ^70
	movq -2576(%rbp), %rdi
	# SetupCalls(2213:3): move argument ptr align 4 ^56
	movq -2552(%rbp), %rsi
	# SetupCalls(2213:3): move argument i64 4
	movq $4, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	movq _ZL6g_1892, %rcx
	addq $8, %rcx
	# LowerLoad(2214:3).2: (^1126) into ^361
	movl (%rcx), %eax
	# LowerGetelementptr(2215:3): struct-type: ptr ^70 -> ^362, indices=0,0
	movq -2576(%rbp), %rcx
	# LowerGetelementptr(2215:3): type of ^362 is ptr*
	# LowerLoad(2216:3).2: (^362) into ^363
	movl (%rcx), %edx
	# SetupCalls(2217:3): move argument i32 ^360
	movl %ebx, %edi
	# SetupCalls(2217:3): move argument i32 ^363
	movl %edx, %esi
	# SetupCalls(2217:3): move argument i32 ^361
	movl %eax, %edx
	callq _ZL7func_39i2U0j@GOTPCREL(%rip)
	# SetupCalls(2217:3): move result from %rax
	movw %ax, %bx
	# LowerGetelementptr(2218:3): struct-type: ptr ^71 -> ^365, indices=0,0
	movq -2568(%rbp), %rax
	# LowerGetelementptr(2218:3): type of ^365 is ptr*
	# LowerStore(2219:3).9: mov ^364, (^365)
	movw %bx, (%rax)
	# LowerLoad(2220:3).4: _ZL6g_2354 into ^366
	movq _ZL6g_2354, %rbx
	# LowerLoad(2221:3).2: (^53) into ^367
	movq -2136(%rbp), %rax
	movq (%rax), %rcx
	# LowerStore(2222:3).9: mov ^366, (^367)
	movl %ebx, (%rcx)
	# LowerStore(2223:3).2a: mov $imm, %temp
	movw $0, %ax
	# LowerStore(2223:3).2b: mov %temp, (global)
	movw %ax, _ZL5g_106@GOTPCREL(%rip)
	.___ZL6func_1v__M2064:
	# LowerLoad(2227:3).4: _ZL5g_106 into ^369
	movq _ZL5g_106, %rax
	# LowerBasicConversion(2228:3): ^369 -> ^370
	movl %eax, %ebx
	# LowerIcmp(2229:3): i32 ^370 vs. intlike 31
	cmpl $31, %ebx
	setg %al
	cmpb $0, %al
	jne .___ZL6func_1v__M2072
	jmp .___ZL6func_1v__M2088
	.___ZL6func_1v__M2072:
	# LowerLoad(2233:3).2: (^53) into ^373
	movq -2136(%rbp), %rax
	movq (%rax), %rbx
	# LowerStore(2234:3).8a: movq var, %temp
	movq _ZL6g_2357@GOTPCREL(%rip), %rax
	# LowerStore(2234:3).8b: movq ^373, (%temp)
	movq %rbx, (%rax)
	# LowerLoad(2238:3).4: _ZL5g_106 into ^375
	movq _ZL5g_106, %rax
	movw %ax, %bx
	addw $1, %bx
	# LowerStore(2240:3).8a: movq var, %temp
	movq _ZL5g_106@GOTPCREL(%rip), %rax
	# LowerStore(2240:3).8b: movq ^376, (%temp)
	movw %bx, (%rax)
	jmp .___ZL6func_1v__M2064
	.___ZL6func_1v__M2088:
	# LowerLoad(2244:3).2: (^3) into ^378
	movq -2480(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %r12
	# LowerLoad(2246:3).4: _ZL6g_2364 into ^380
	movq _ZL6g_2364, %r13
	# LowerLoad(2247:3).4: _ZL6g_1910 into ^381
	movq _ZL6g_1910, %r14
	# LowerLoad(2248:3).2: (^53) into ^382
	movq -2136(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(2249:3).2: (^382) into ^383
	movl (%rbx), %eax
	movslq %eax, %rbx
	# SetupCalls(2251:3): move argument i64 5063416666836942707
	movabsq $5063416666836942707, %rax
	movq %rax, %rdi
	# SetupCalls(2251:3): move argument i64 ^384
	movq %rbx, %rsi
	callq _ZL26safe_mul_func_uint64_t_u_umm@GOTPCREL(%rip)
	# SetupCalls(2251:3): move result from %rax
	movq %rax, %rbx
	# LowerIcmp(2252:3): i64 ^385 vs. intlike 0
	cmpq $0, %rbx
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M2130
	jmp .___ZL6func_1v__M2133
	.___ZL6func_1v__M2130:
	# MovePhi: intlike -> ^411 (in new block 1224 whose parent is 377)
	movb $1, %al
	jmp .___ZL6func_1v__M2217
	.___ZL6func_1v__M2133:
	movq _ZL6g_1922, %rbx
	addq $32, %rbx
	# LowerLoad(2256:3).2: (^1127) into ^388
	movl (%rbx), %eax
	# LowerBasicConversion(2257:3): ^388 -> ^389
	movq %rax, %rbx
	# LowerLoad(2258:3).2: (^12) into ^390
	movq -2456(%rbp), %rcx
	movq (%rcx), %rax
	movq $0, %rcx
	# LowerIcmp(2259:3): i64 ^1133 vs. operand ptr ^390
	cmpq %rax, %rcx
	setne %al
	# LowerBasicConversion(2260:3): ^391 -> ^392
	movq %rax, %rcx
	# SetupCalls(2261:3): move argument i64 ^389
	movq %rbx, %rdi
	# SetupCalls(2261:3): move argument i64 ^392
	movq %rcx, %rsi
	callq _ZL26safe_add_func_uint64_t_u_umm@GOTPCREL(%rip)
	# SetupCalls(2261:3): move result from %rax
	movq %rax, %rbx
	movq $-1, %rax
	# LowerIcmp(2262:3): i64 ^1134 vs. operand i64 ^393
	cmpq %rbx, %rax
	setae %al
	# LowerBasicConversion(2263:3): ^394 -> ^395
	movl %eax, %ebx
	# LowerLoad(2264:3).4: _ZL6g_1907 into ^396
	movq _ZL6g_1907, %rax
	# LowerIcmp(2265:3): i32 ^395 vs. operand i32 ^396
	cmpl %eax, %ebx
	setb %al
	movb %al, %bl
	xorb $1, %bl
	# LowerBasicConversion(2267:3): ^398 -> ^399
	movq %rbx, %rax
	# LowerIcmp(2268:3): i64 ^399 vs. intlike -1
	cmpq $-1, %rax
	sete %al
	# LowerBasicConversion(2269:3): ^400 -> ^401
	movq %rax, %rbx
	movq %rbx, %rax
	orq $238, %rax
	# LowerLoad(2271:3).2: (^57) into ^403
	movq -2432(%rbp), %rcx
	movq (%rcx), %rbx
	# LowerStore(2272:3).9: mov ^402, (^403)
	movq %rax, (%rbx)
	# LowerLoad(2273:3).2: (^58) into ^404
	movq -2536(%rbp), %rcx
	movq (%rcx), %rbx
	# LowerLoad(2274:3).2: (^404) into ^405
	movq (%rbx), %rcx
	movq %rcx, %rdx
	xorq %rax, %rdx
	# LowerStore(2276:3).9: mov ^406, (^404)
	movq %rdx, (%rbx)
	# LowerLoad(2277:3).2: (^13) into ^407
	movq -2112(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(2278:3).2: (^13) into ^408
	movq -2112(%rbp), %rax
	movq (%rax), %rcx
	# LowerIcmp(2279:3): ptr ^407 vs. operand ptr ^408
	cmpq %rcx, %rbx
	sete %al
	# MovePhi: intlike -> ^411
	movb $1, %al
	.___ZL6func_1v__M2217:
	# LowerLoad(2284:3).2: (^53) into ^412
	movq -2136(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(2285:3).2: (^412) into ^413
	movl (%rbx), %eax
	movl %r14d, %ebx
	andl %eax, %ebx
	# LowerLoad(2287:3).4: _ZL4g_91 into ^415
	movq _ZL4g_91, %rax
	# LowerBasicConversion(2288:3): ^415 -> ^416
	movq %rax, %rbx
	# LowerLoad(2289:3).4: _ZL6g_1943 into ^417
	movq _ZL6g_1943, %rax
	# LowerBasicConversion(2290:3): ^417 -> ^418
	movq %rax, %rcx
	# SetupCalls(2291:3): move argument i64 ^416
	movq %rbx, %rdi
	# SetupCalls(2291:3): move argument i64 ^418
	movq %rcx, %rsi
	callq _ZL26safe_mod_func_uint64_t_u_umm@GOTPCREL(%rip)
	# SetupCalls(2291:3): move result from %rax
	movq %rax, %rbx
	# LowerLoad(2292:3).2: (^53) into ^420
	movq -2136(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2293:3).2: (^420) into ^421
	movl (%rcx), %eax
	movslq %eax, %rcx
	# LowerIcmp(2295:3): i64 ^419 vs. operand i64 ^422
	cmpq %rcx, %rbx
	setae %al
	# LowerGetelementptr(2296:3): struct-type: ptr ^60 -> ^424, indices=0,2
	movq -2512(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(2296:3): type of ^424 is ptr*
	# LowerGetelementptr(2297:3): struct-type: ptr ^424 -> ^425, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(2297:3): type of ^425 is ptr*
	# LowerLoad(2298:3).2: (^425) into ^426
	movq (%rbx), %rax
	# LowerStore(2299:3).9: mov ^426, (^14)
	movq -2384(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerIcmp(2300:3): ptr ^380 vs. operand ptr ^426
	cmpq %rax, %r13
	setne %al
	# LowerBasicConversion(2301:3): ^427 -> ^428
	movl %eax, %ebx
	movl %ebx, %r13d
	xorl $-275451831, %r13d
	# SetupCalls(2303:3): move argument ptr align 4 ^72
	movq -2520(%rbp), %rdi
	# SetupCalls(2303:3): move argument ptr align 4 ^2
	movq -2128(%rbp), %rsi
	# SetupCalls(2303:3): move argument i64 4
	movq $4, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerLoad(2304:3).2: (^4) into ^430
	movq -2168(%rbp), %rbx
	movl (%rbx), %eax
	# LowerGetelementptr(2305:3): struct-type: ptr ^72 -> ^431, indices=0,0
	movq -2520(%rbp), %rbx
	# LowerGetelementptr(2305:3): type of ^431 is ptr*
	# LowerLoad(2306:3).2: (^431) into ^432
	movl (%rbx), %ecx
	# SetupCalls(2307:3): move argument i32 ^429
	movl %r13d, %edi
	# SetupCalls(2307:3): move argument i32 ^432
	movl %ecx, %esi
	# SetupCalls(2307:3): move argument i32 ^430
	movl %eax, %edx
	callq _ZL7func_39i2U0j@GOTPCREL(%rip)
	# SetupCalls(2307:3): move result from %rax
	movw %ax, %bx
	# LowerGetelementptr(2308:3): struct-type: ptr ^73 -> ^434, indices=0,0
	movq -2504(%rbp), %rax
	# LowerGetelementptr(2308:3): type of ^434 is ptr*
	# LowerStore(2309:3).9: mov ^433, (^434)
	movw %bx, (%rax)
	# LowerLoad(2310:3).2: (^4) into ^435
	movq -2168(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(2311:3): i32 ^435 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M2356
	.___ZL6func_1v__M2353:
	# MovePhi: intlike -> ^439 (in new block 1225 whose parent is 1097)
	movb $0, -2352(%rbp)
	jmp .___ZL6func_1v__M2359
	.___ZL6func_1v__M2356:
	# MovePhi: intlike -> ^439
	movb $1, -2352(%rbp)
	.___ZL6func_1v__M2359:
	movb -2352(%rbp), %al
	xorb $1, %al
	# LowerBasicConversion(2320:3): ^440 -> ^441
	movq %rax, %rbx
	# LowerIcmp(2321:3): i64 ^441 vs. intlike 0
	cmpq $0, %rbx
	seta %al
	# LowerBasicConversion(2322:3): ^442 -> ^443
	movl %eax, %ebx
	movl %ebx, %eax
	xorl $-1, %eax
	# LowerLoad(2324:3).4: _ZL6g_1937 into ^445
	movq _ZL6g_1937, %rbx
	# LowerIcmp(2325:3): i32 ^444 vs. operand i32 ^445
	cmpl %ebx, %eax
	sete %al
	# SetupCalls(2326:3): move argument i64 ^379
	movq %r12, %rdi
	# SetupCalls(2326:3): move argument i64 -5067512586769809598
	movabsq $-5067512586769809598, %rax
	movq %rax, %rsi
	callq _ZL25safe_add_func_int64_t_s_sll@GOTPCREL(%rip)
	# SetupCalls(2326:3): move result from %rax
	movq %rax, %rax
	# LowerLoad(2327:3).2: (^57) into ^448
	movq -2432(%rbp), %rbx
	movq (%rbx), %rax
	# LowerIcmp(2328:3): i64* ^9 vs. operand ptr ^448
	cmpq %rax, -2344(%rbp)
	sete %al
	# LowerBasicConversion(2329:3): ^449 -> ^450
	movl %eax, %ebx
	# LowerLoad(2330:3).4: _ZL6g_1899 into ^451
	movq _ZL6g_1899, %rax
	# LowerIcmp(2331:3): i32 ^450 vs. operand i32 ^451
	cmpl %eax, %ebx
	sete %al
	# LowerLoad(2332:3).4: _ZL6g_2382 into ^453
	movq _ZL6g_2382, %rax
	# LowerLoad(2333:3).4: _ZL6g_1905 into ^454
	movq _ZL6g_1905, %rbx
	# LowerIcmp(2334:3): i32 ^453 vs. operand i32 ^454
	cmpl %ebx, %eax
	setb %al
	# LowerBasicConversion(2335:3): ^455 -> ^456
	movw %ax, %bx
	# SetupCalls(2336:3): move argument i16 zeroext ^456
	movw %bx, %di
	andq $65535, %rdi
	# SetupCalls(2336:3): move argument i16 zeroext -12113
	movq $-12113, %rsi
	andq $65535, %rsi
	callq _ZL26safe_div_func_uint16_t_u_utt@GOTPCREL(%rip)
	# SetupCalls(2336:3): move result from %rax
	movw %ax, %bx
	# LowerIcmp(2337:3): i16 ^457 vs. intlike 0
	cmpw $0, %bx
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M2454
	jmp .___ZL6func_1v__M3461
	.___ZL6func_1v__M2454:
	# SetupCalls(2342:3): move argument ptr align 16 ^74
	movq -2176(%rbp), %rdi
	# SetupCalls(2342:3): move argument ptr align 16 @__const._ZL6func_1v.l_2393
	movq __const._ZL6func_1v.l_2393, %rsi
	# SetupCalls(2342:3): move argument i64 16
	movq $16, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(2345:3).3: mov $imm, ^76
	movq -2184(%rbp), %rax
	movl $6, (%rax)
	# LowerStore(2347:3).3: mov $imm, ^77
	movq -2424(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M2484:
	# LowerLoad(2351:3).2: (^77) into ^461
	movq -2424(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(2352:3): i32 ^461 vs. intlike 4
	cmpl $4, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL6func_1v__M2490
	jmp .___ZL6func_1v__M2511
	.___ZL6func_1v__M2490:
	# LowerLoad(2356:3).2: (^77) into ^464
	movq -2424(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerGetelementptr(2358:3): struct-type: ptr ^75 -> ^466, indices=0,%465
	movq -2408(%rbp), %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(2358:3): type of ^466 is ptr*
	# LowerStore(2359:3).6: load global
	movq _ZL5g_648@GOTPCREL(%rip), %rbx
	# LowerStore(2359:3).9: mov ^1179, (^466)
	movq %rbx, (%rax)
	# LowerLoad(2363:3).2: (^77) into ^468
	movq -2424(%rbp), %rbx
	movl (%rbx), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(2365:3).9: mov ^469, (^77)
	movq -2424(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M2484
	.___ZL6func_1v__M2511:
	# LowerLoad(2369:3).4: _ZL5g_337 into ^471
	movq _ZL5g_337, %rax
	# LowerLoad(2370:3).2: (^62) into ^472
	movq -2360(%rbp), %rbx
	movq (%rbx), %rax
	movq $0, %rbx
	# LowerIcmp(2371:3): i64 ^1135 vs. operand ptr ^472
	cmpq %rax, %rbx
	setne %al
	# LowerBasicConversion(2372:3): ^473 -> ^474
	movl %eax, %ebx
	# LowerStore(2373:3).2a: mov $imm, %temp
	movb $61, %al
	# LowerStore(2373:3).2b: mov %temp, (global)
	movb %al, _ZL5g_259@GOTPCREL(%rip)
	# LowerIcmp(2374:3): i32 ^474 vs. intlike 61
	cmpl $61, %ebx
	setne %al
	# LowerBasicConversion(2375:3): ^475 -> ^476
	movb %al, %bl
	# SetupCalls(2376:3): move argument i8 zeroext ^476
	movb %bl, %dil
	andq $255, %rdi
	# SetupCalls(2376:3): move argument i32 3
	movq $3, %rsi
	callq _ZL28safe_lshift_func_uint8_t_u_shi@GOTPCREL(%rip)
	# SetupCalls(2376:3): move result from %rax
	movb %al, %al
	# LowerLoad(2377:3).4: _ZL5g_150 into ^478
	movq _ZL5g_150, %rax
	# LowerLoad(2378:3).4: _ZL5g_150 into ^479
	movq _ZL5g_150, %rbx
	# SetupCalls(2379:3): move argument ptr nonnull dereferenceable(8) align 8 ^479
	movq %rbx, %rdi
	# SetupCalls(2379:3): move argument ptr nonnull dereferenceable(8) align 8 ^478
	movq %rax, %rsi
	callq _ZN2U2aSERKS_@GOTPCREL(%rip)
	# SetupCalls(2379:3): move result from %rax
	movq %rax, %rax
	# LowerIcmp(2380:3): ptr* ^53 vs. operand ptr* ^53
	cmpq -2136(%rbp), -2136(%rbp)
	setne %al
	# LowerBasicConversion(2381:3): ^481 -> ^482
	movq %rax, %rbx
	# SetupCalls(2382:3): move argument i64 ^482
	movq %rbx, %rdi
	callq _ZL32safe_unary_minus_func_uint64_t_um@GOTPCREL(%rip)
	# SetupCalls(2382:3): move result from %rax
	movq %rax, %r12
	# LowerLoad(2383:3).2: (^13) into ^484
	movq -2112(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(2384:3).2: (^62) into ^485
	movq -2360(%rbp), %rcx
	movq (%rcx), %rax
	# LowerLoad(2385:3).2: (^485) into ^486
	movq (%rax), %rcx
	# LowerIcmp(2386:3): ptr ^484 vs. operand ptr ^486
	cmpq %rcx, %rbx
	setne %al
	# LowerBasicConversion(2387:3): ^487 -> ^488
	movq %rax, %rbx
	movq %rbx, %rax
	orq $2, %rax
	# LowerLoad(2389:3).2: (^6) into ^490
	movq -2264(%rbp), %rbx
	movl (%rbx), %ecx
	# LowerBasicConversion(2390:3): ^490 -> ^491
	movq %rcx, %rbx
	# LowerIcmp(2391:3): i64 ^489 vs. operand i64 ^491
	cmpq %rbx, %rax
	setb %al
	# LowerBasicConversion(2392:3): ^492 -> ^493
	movl %eax, %ebx
	# LowerLoad(2393:3).2: (^53) into ^494
	movq -2136(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2394:3).2: (^494) into ^495
	movl (%rcx), %eax
	# LowerIcmp(2395:3): i32 ^493 vs. operand i32 ^495
	cmpl %eax, %ebx
	setge %al
	# LowerBasicConversion(2396:3): ^496 -> ^497
	movl %eax, %ebx
	movq _ZL6g_1894, %rax
	addq $32, %rax
	# LowerLoad(2397:3).2: (^1128) into ^498
	movl (%rax), %ecx
	# LowerIcmp(2398:3): i32 ^497 vs. operand i32 ^498
	cmpl %ecx, %ebx
	seta %al
	# LowerBasicConversion(2399:3): ^499 -> ^500
	movq %rax, %rbx
	# LowerIcmp(2400:3): i64 ^483 vs. operand i64 ^500
	cmpq %rbx, %r12
	setb %al
	# LowerBasicConversion(2401:3): ^501 -> ^502
	movl %eax, %ebx
	# LowerLoad(2402:3).2: (^53) into ^503
	movq -2136(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2403:3).2: (^503) into ^504
	movl (%rcx), %eax
	movl %ebx, %ecx
	xorl %eax, %ecx
	# LowerGetelementptr(2405:3): struct-type: ptr ^74 -> ^506, indices=0,0
	movq -2176(%rbp), %rax
	# LowerGetelementptr(2405:3): type of ^506 is ptr*
	# LowerLoad(2406:3).2: (^506) into ^507
	movl (%rax), %ebx
	movl %ebx, %edx
	orl %ecx, %edx
	# LowerStore(2408:3).9: mov ^508, (^506)
	movl %edx, (%rax)
	# LowerIcmp(2409:3): i32 ^508 vs. intlike 0
	cmpl $0, %edx
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M2682
	.___ZL6func_1v__M2679:
	# MovePhi: intlike -> ^515 (in new block 1226 whose parent is 1100)
	movb $0, -2256(%rbp)
	jmp .___ZL6func_1v__M2694
	.___ZL6func_1v__M2682:
	# LowerGetelementptr(2413:3): struct-type: ptr ^74 -> ^511, indices=0,2
	movq -2176(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(2413:3): type of ^511 is ptr*
	# LowerLoad(2414:3).2: (^511) into ^512
	movl (%rax), %ebx
	# LowerIcmp(2415:3): i32 ^512 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	# MovePhi: ^513 -> ^515
	movb %al, -2256(%rbp)
	.___ZL6func_1v__M2694:
	# LowerBasicConversion(2420:3): ^515 -> ^516
	movq -2256(%rbp), %rax
	# LowerIcmp(2421:3): i64 ^516 vs. intlike 1709356644
	cmpq $1709356644, %rax
	setg %al
	# LowerBasicConversion(2422:3): ^517 -> ^518
	movw %ax, %bx
	# SetupCalls(2423:3): move argument i16 zeroext ^518
	movw %bx, %di
	andq $65535, %rdi
	# SetupCalls(2423:3): move argument i32 7
	movq $7, %rsi
	callq _ZL29safe_rshift_func_uint16_t_u_sti@GOTPCREL(%rip)
	# SetupCalls(2423:3): move result from %rax
	movw %ax, %bx
	# LowerBasicConversion(2424:3): ^519 -> ^520
	movl %ebx, %eax
	# SetupCalls(2425:3): move argument i32 ^520
	movl %eax, %edi
	# SetupCalls(2425:3): move argument i32 1
	movq $1, %rsi
	callq _ZL26safe_div_func_uint32_t_u_ujj@GOTPCREL(%rip)
	# SetupCalls(2425:3): move result from %rax
	movl %eax, %ebx
	# LowerLoad(2426:3).2: (^76) into ^522
	movq -2184(%rbp), %rcx
	movl (%rcx), %eax
	movl %eax, %ecx
	andl %ebx, %ecx
	# LowerStore(2428:3).9: mov ^523, (^76)
	movq -2184(%rbp), %rax
	movl %ecx, (%rax)
	# LowerLoad(2429:3).2: (^5) into ^524
	movq -2208(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(2430:3): i32 ^523 vs. operand i32 ^524
	cmpl %eax, %ecx
	sete %al
	cmpb $0, %al
	jne .___ZL6func_1v__M2766
	jmp .___ZL6func_1v__M2769
	.___ZL6func_1v__M2766:
	# MovePhi: intlike -> ^528 (in new block 1227 whose parent is 514)
	movb $1, -2248(%rbp)
	jmp .___ZL6func_1v__M2772
	.___ZL6func_1v__M2769:
	# MovePhi: intlike -> ^528
	movb $1, -2248(%rbp)
	.___ZL6func_1v__M2772:
	# LowerBasicConversion(2438:3): ^528 -> ^529
	movw -2248(%rbp), %ax
	# SetupCalls(2439:3): move argument i16 signext ^529
	movw %ax, %di
	movswq %di, %rdi
	# SetupCalls(2439:3): move argument i16 signext 6553
	movq $6553, %rsi
	movswq %si, %rsi
	callq _ZL25safe_mod_func_int16_t_s_sss@GOTPCREL(%rip)
	# SetupCalls(2439:3): move result from %rax
	movw %ax, %bx
	movswl %bx, %eax
	movl %eax, %ebx
	xorl $15412, %ebx
	# LowerLoad(2442:3).4: _ZL5g_139 into ^533
	movq _ZL5g_139, %rax
	# LowerLoad(2443:3).2: (^533) into ^534
	movq (%rax), %rcx
	# LowerLoad(2444:3).2: (^534) into ^535
	movl (%rcx), %eax
	movl %eax, %edx
	xorl %ebx, %edx
	# LowerStore(2446:3).9: mov ^536, (^534)
	movl %edx, (%rcx)
	# LowerStore(2447:3).2a: mov $imm, %temp
	movl $0, %eax
	# LowerStore(2447:3).2b: mov %temp, (global)
	movl %eax, _ZL6g_1904@GOTPCREL(%rip)
	.___ZL6func_1v__M2819:
	# LowerLoad(2451:3).4: _ZL6g_1904 into ^538
	movq _ZL6g_1904, %rax
	# LowerIcmp(2452:3): i32 ^538 vs. intlike 7
	cmpl $7, %eax
	setbe %al
	cmpb $0, %al
	jne .___ZL6func_1v__M2825
	jmp .___ZL6func_1v__M3460
	.___ZL6func_1v__M2825:
	# LowerStore(2456:3).2a: mov $imm, %temp
	movl $0, %eax
	# LowerStore(2456:3).2b: mov %temp, (global)
	movl %eax, _ZL6g_1921@GOTPCREL(%rip)
	.___ZL6func_1v__M2830:
	# LowerLoad(2460:3).4: _ZL6g_1921 into ^542
	movq _ZL6g_1921, %rax
	# LowerIcmp(2461:3): i32 ^542 vs. intlike 7
	cmpl $7, %eax
	setbe %al
	cmpb $0, %al
	jne .___ZL6func_1v__M2836
	jmp .___ZL6func_1v__M3450
	.___ZL6func_1v__M2836:
	# SetupCalls(2466:3): move argument ptr align 16 ^78
	movq -2192(%rbp), %rdi
	# SetupCalls(2466:3): move argument ptr align 16 @__const._ZL6func_1v.l_2398
	movq __const._ZL6func_1v.l_2398, %rsi
	# SetupCalls(2466:3): move argument i64 35
	movq $35, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(2469:3).2a: mov $imm, %temp
	movl $0, %eax
	# LowerStore(2469:3).2b: mov %temp, (global)
	movl %eax, _ZL6g_1898@GOTPCREL(%rip)
	.___ZL6func_1v__M2866:
	# LowerLoad(2473:3).4: _ZL6g_1898 into ^546
	movq _ZL6g_1898, %rax
	# LowerIcmp(2474:3): i32 ^546 vs. intlike 7
	cmpl $7, %eax
	setbe %al
	cmpb $0, %al
	jne .___ZL6func_1v__M2872
	jmp .___ZL6func_1v__M3440
	.___ZL6func_1v__M2872:
	# LowerStore(2479:3).3: mov $imm, ^81
	movq -2200(%rbp), %rax
	movl $-290470832, (%rax)
	# LowerLoad(2481:3).4: _ZL6g_1921 into ^549
	movq _ZL6g_1921, %rbx
	movl %ebx, %eax
	addl $1, %eax
	# LowerBasicConversion(2483:3): ^550 -> ^551
	movq %rax, %rbx
	movq _ZL6g_1944, %rax
	movq _ZL6g_1944, %rcx
	# LowerGetelementptr(2484:3): struct-type: ptr ^1145 -> ^552, indices=0,%551
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(2484:3): type of ^552 is ptr*
	# LowerLoad(2485:3).2: (^552) into ^553
	movl (%rax), %ebx
	# LowerIcmp(2486:3): i32 ^553 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M2894
	jmp .___ZL6func_1v__M2895
	.___ZL6func_1v__M2894:
	jmp .___ZL6func_1v__M3440
	.___ZL6func_1v__M2895:
	# LowerGetelementptr(2493:3): struct-type: ptr ^74 -> ^557, indices=0,2
	movq -2176(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(2493:3): type of ^557 is ptr*
	# LowerLoad(2494:3).2: (^557) into ^558
	movl (%rax), %ebx
	movslq %ebx, %rax
	# LowerIcmp(2496:3): i64 ^559 vs. intlike 4098852423
	movabsq $4098852423, %rbx
	cmpq %rbx, %rax
	setle %al
	# LowerBasicConversion(2497:3): ^560 -> ^561
	movl %eax, %ebx
	# LowerGetelementptr(2498:3): struct-type: ptr ^78 -> ^562, indices=0,4
	movq -2192(%rbp), %rax
	addq $32, %rax
	# LowerGetelementptr(2498:3): type of ^562 is ptr*
	# LowerGetelementptr(2499:3): struct-type: ptr ^562 -> ^563, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(2499:3): type of ^563 is ptr*
	# LowerLoad(2500:3).2: (^563) into ^564
	movb (%rcx), %al
	# LowerBasicConversion(2501:3): ^564 -> ^565
	movq %rax, %r12
	# SetupCalls(2502:3): move argument i64 0
	movq $0, %rdi
	callq _ZL31safe_unary_minus_func_int64_t_sl@GOTPCREL(%rip)
	# SetupCalls(2502:3): move result from %rax
	movq %rax, %r13
	# LowerLoad(2503:3).2: (^55) into ^567
	movq -2160(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2504:3).2: (^567) into ^568
	movw (%rcx), %ax
	# LowerBasicConversion(2505:3): ^568 -> ^569
	movq %rax, %rdx
	movq %rdx, %rax
	andq %r13, %rax
	# LowerTrunc(2507:3): 64 to 16, move
	movw %ax, %dx
	# LowerTrunc(2507:3): 64 to 16, apply mask
	andw $65535, %dx
	# LowerStore(2508:3).9: mov ^571, (^567)
	movw %dx, (%rcx)
	# LowerBasicConversion(2509:3): ^571 -> ^572
	movq %rdx, %r13
	# LowerLoad(2510:3).4: _ZL5g_448 into ^573
	movq _ZL5g_448, %rax
	# LowerLoad(2511:3).2: (^573) into ^574
	movl (%rax), %r14d
	# LowerLoad(2512:3).4: _ZL6g_1898 into ^575
	movq _ZL6g_1898, %rax
	movl %eax, %ecx
	addl $2, %ecx
	# LowerBasicConversion(2514:3): ^576 -> ^577
	movq %rcx, %rax
	movq _ZL6g_1944, %rcx
	movq _ZL6g_1944, %rdx
	# LowerGetelementptr(2515:3): struct-type: ptr ^1148 -> ^578, indices=0,%577
	movq %rdx, %rcx
	movq %rax, %rdx
	shlq $3, %rdx
	addq %rdx, %rcx
	# LowerGetelementptr(2515:3): type of ^578 is ptr*
	# LowerStore(2516:3).9: mov ^574, (^578)
	movl %r14d, (%rcx)
	# LowerLoad(2517:3).2: (^76) into ^579
	movq -2184(%rbp), %rax
	movl (%rax), %ecx
	movslq %ecx, %rax
	movabsq $-383318305269343207, %rdx
	movq %rdx, %rcx
	# LowerIcmp(2519:3): i64 ^1136 vs. operand i64 ^580
	cmpq %rax, %rcx
	setne %al
	# LowerBasicConversion(2520:3): ^581 -> ^582
	movl %eax, %ecx
	# LowerLoad(2521:3).4: _ZL5g_246 into ^583
	movq _ZL5g_246, %rax
	# LowerIcmp(2522:3): i32 ^582 vs. operand i32 ^583
	cmpl %eax, %ecx
	setg %al
	# LowerBasicConversion(2523:3): ^584 -> ^585
	movq %rax, %rcx
	# LowerIcmp(2524:3): i64 ^585 vs. intlike 1
	cmpq $1, %rcx
	seta %al
	# LowerBasicConversion(2525:3): ^586 -> ^587
	movl %eax, %ecx
	# SetupCalls(2526:3): move argument i32 ^587
	movl %ecx, %edi
	# SetupCalls(2526:3): move argument i32 7
	movq $7, %rsi
	callq _ZL28safe_rshift_func_int32_t_s_sii@GOTPCREL(%rip)
	# SetupCalls(2526:3): move result from %rax
	movl %eax, %r15d
	# LowerTrunc(2527:3): 32 to 16, move
	movw %r15w, %ax
	# LowerTrunc(2527:3): 32 to 16, apply mask
	andw $65535, %ax
	# SetupCalls(2528:3): move argument i16 signext ^589
	movw %ax, %di
	movswq %di, %rdi
	# SetupCalls(2528:3): move argument i32 2
	movq $2, %rsi
	callq _ZL28safe_lshift_func_int16_t_s_usj@GOTPCREL(%rip)
	# SetupCalls(2528:3): move result from %rax
	movw %ax, %r15w
	movswl %r15w, %eax
	# SetupCalls(2530:3): move argument i32 ^574
	movl %r14d, %edi
	# SetupCalls(2530:3): move argument i32 ^591
	movl %eax, %esi
	callq _ZL29safe_lshift_func_uint32_t_u_sji@GOTPCREL(%rip)
	# SetupCalls(2530:3): move result from %rax
	movl %eax, %r14d
	# LowerBasicConversion(2531:3): ^592 -> ^593
	movq %r14, %rax
	# LowerLoad(2532:3).4: _ZL6g_1885 into ^594
	movq _ZL6g_1885, %rcx
	# LowerBasicConversion(2533:3): ^594 -> ^595
	movq %rcx, %rdx
	# SetupCalls(2534:3): move argument i64 ^593
	movq %rax, %rdi
	# SetupCalls(2534:3): move argument i64 ^595
	movq %rdx, %rsi
	callq _ZL25safe_mod_func_int64_t_s_sll@GOTPCREL(%rip)
	# SetupCalls(2534:3): move result from %rax
	movq %rax, %r14
	movq %r13, %rcx
	orq %r14, %rcx
	# LowerLoad(2536:3).2: (^81) into ^598
	movq -2200(%rbp), %rax
	movl (%rax), %edx
	movslq %edx, %rax
	# LowerIcmp(2538:3): i64 ^597 vs. operand i64 ^599
	cmpq %rax, %rcx
	setg %al
	# LowerBasicConversion(2539:3): ^600 -> ^601
	movb %al, %cl
	# LowerLoad(2540:3).4: _ZL6g_2354 into ^602
	movq _ZL6g_2354, %rax
	# LowerTrunc(2541:3): 32 to 8, move
	movb %al, %dl
	# LowerTrunc(2541:3): 32 to 8, apply mask
	andb $255, %dl
	# SetupCalls(2542:3): move argument i8 signext ^601
	movb %cl, %dil
	movsbq %dil, %rdi
	# SetupCalls(2542:3): move argument i8 signext ^603
	movb %dl, %sil
	movsbq %sil, %rsi
	callq _ZL24safe_add_func_int8_t_s_saa@GOTPCREL(%rip)
	# SetupCalls(2542:3): move result from %rax
	movb %al, %r13b
	movsbq %r13b, %rax
	# LowerLoad(2544:3).4: _ZL5g_338 into ^606
	movq _ZL5g_338, %rcx
	# SetupCalls(2545:3): move argument i64 ^605
	movq %rax, %rdi
	# SetupCalls(2545:3): move argument i64 ^606
	movq %rcx, %rsi
	callq _ZL25safe_mod_func_int64_t_s_sll@GOTPCREL(%rip)
	# SetupCalls(2545:3): move result from %rax
	movq %rax, %r13
	# LowerTrunc(2546:3): 64 to 16, move
	movw %r13w, %ax
	# LowerTrunc(2546:3): 64 to 16, apply mask
	andw $65535, %ax
	# SetupCalls(2547:3): move argument i16 signext 7
	movq $7, %rdi
	movswq %di, %rdi
	# SetupCalls(2547:3): move argument i16 signext ^608
	movw %ax, %si
	movswq %si, %rsi
	callq _ZL25safe_mul_func_int16_t_s_sss@GOTPCREL(%rip)
	# SetupCalls(2547:3): move result from %rax
	movw %ax, %r13w
	movswq %r13w, %rax
	# LowerIcmp(2549:3): i64 ^610 vs. intlike 4022093807
	movabsq $4022093807, %rcx
	cmpq %rcx, %rax
	setne %cl
	# LowerBasicConversion(2550:3): ^611 -> ^612
	movq %rcx, %rax
	# LowerIcmp(2551:3): i64 ^612 vs. intlike 1
	cmpq $1, %rax
	setl %al
	# LowerBasicConversion(2552:3): ^613 -> ^614
	movl %eax, %ecx
	# LowerGetelementptr(2553:3): struct-type: ptr ^15 -> ^615, indices=0,2
	movq -2120(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(2553:3): type of ^615 is ptr*
	# LowerGetelementptr(2554:3): struct-type: ptr ^615 -> ^616, indices=0,0
	movq %rax, %rdx
	# LowerGetelementptr(2554:3): type of ^616 is ptr*
	# LowerLoad(2555:3).2: (^616) into ^617
	movw (%rdx), %ax
	# LowerBasicConversion(2556:3): ^617 -> ^618
	movl %eax, %edx
	# LowerIcmp(2557:3): i32 ^614 vs. operand i32 ^618
	cmpl %edx, %ecx
	sete %al
	# LowerBasicConversion(2558:3): ^619 -> ^620
	movl %eax, %ecx
	# LowerGetelementptr(2559:3): struct-type: ptr ^78 -> ^621, indices=0,2
	movq -2192(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(2559:3): type of ^621 is ptr*
	# LowerGetelementptr(2560:3): struct-type: ptr ^621 -> ^622, indices=0,4
	movq %rax, %rdx
	addq $32, %rdx
	# LowerGetelementptr(2560:3): type of ^622 is ptr*
	# LowerLoad(2561:3).2: (^622) into ^623
	movb (%rdx), %al
	# LowerBasicConversion(2562:3): ^623 -> ^624
	movl %eax, %edx
	# LowerIcmp(2563:3): i32 ^620 vs. operand i32 ^624
	cmpl %edx, %ecx
	setne %al
	# LowerBasicConversion(2564:3): ^625 -> ^626
	movl %eax, %ecx
	# LowerLoad(2565:3).4: _ZL6g_1680 into ^627
	movq _ZL6g_1680, %rax
	# LowerLoad(2566:3).2: (^627) into ^628
	movq (%rax), %rdx
	# LowerLoad(2567:3).2: (^628) into ^629
	movq (%rdx), %rax
	# LowerLoad(2568:3).2: (^629) into ^630
	movq (%rax), %rdx
	# LowerLoad(2569:3).2: (^630) into ^631
	movl (%rdx), %eax
	# LowerIcmp(2570:3): i32 ^626 vs. operand i32 ^631
	cmpl %eax, %ecx
	setne %al
	# LowerBasicConversion(2571:3): ^632 -> ^633
	movq %rax, %rcx
	# LowerIcmp(2572:3): i64 ^633 vs. intlike 5244673685766057056
	movabsq $5244673685766057056, %rax
	cmpq %rax, %rcx
	setl %cl
	# LowerBasicConversion(2573:3): ^634 -> ^635
	movl %ecx, %eax
	# LowerLoad(2574:3).4: _ZL6g_1681 into ^636
	movq _ZL6g_1681, %rcx
	# LowerLoad(2575:3).2: (^636) into ^637
	movq (%rcx), %rdx
	# LowerLoad(2576:3).2: (^637) into ^638
	movq (%rdx), %rcx
	# LowerLoad(2577:3).2: (^638) into ^639
	movl (%rcx), %edx
	# SetupCalls(2578:3): move argument i32 ^635
	movl %eax, %edi
	# SetupCalls(2578:3): move argument i32 ^639
	movl %edx, %esi
	callq _ZL26safe_div_func_uint32_t_u_ujj@GOTPCREL(%rip)
	# SetupCalls(2578:3): move result from %rax
	movl %eax, %r13d
	# LowerBasicConversion(2579:3): ^640 -> ^641
	movq %r13, %rcx
	# LowerLoad(2580:3).2: (^81) into ^642
	movq -2200(%rbp), %rax
	movl (%rax), %edx
	# SetupCalls(2581:3): move argument i64 ^641
	movq %rcx, %rdi
	# SetupCalls(2581:3): move argument i32 ^642
	movl %edx, %esi
	callq _ZL28safe_lshift_func_int64_t_s_sli@GOTPCREL(%rip)
	# SetupCalls(2581:3): move result from %rax
	movq %rax, %r13
	# LowerGetelementptr(2582:3): struct-type: ptr ^15 -> ^644, indices=0,1
	movq -2120(%rbp), %rax
	addq $8, %rax
	# LowerGetelementptr(2582:3): type of ^644 is ptr*
	# LowerGetelementptr(2583:3): struct-type: ptr ^644 -> ^645, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(2583:3): type of ^645 is ptr*
	# LowerLoad(2584:3).2: (^645) into ^646
	movw (%rcx), %ax
	# LowerBasicConversion(2585:3): ^646 -> ^647
	movq %rax, %rcx
	# LowerIcmp(2586:3): i64 ^643 vs. operand i64 ^647
	cmpq %rcx, %r13
	setl %al
	# LowerLoad(2587:3).2: (^53) into ^649
	movq -2136(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2588:3).2: (^649) into ^650
	movl (%rcx), %eax
	movslq %eax, %rcx
	# SetupCalls(2590:3): move argument i64 ^565
	movq %r12, %rdi
	# SetupCalls(2590:3): move argument i64 ^651
	movq %rcx, %rsi
	callq _ZL26safe_div_func_uint64_t_u_umm@GOTPCREL(%rip)
	# SetupCalls(2590:3): move result from %rax
	movq %rax, %r12
	# LowerLoad(2591:3).4: _ZL6g_2324 into ^653
	movq _ZL6g_2324, %rax
	# LowerBasicConversion(2592:3): ^653 -> ^654
	movq %rax, %rcx
	movq %r12, %rax
	xorq %rcx, %rax
	# LowerIcmp(2594:3): i64 ^655 vs. intlike 0
	cmpq $0, %rax
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M3406
	.___ZL6func_1v__M3403:
	# MovePhi: intlike -> ^661 (in new block 1228 whose parent is 1107)
	movb $0, -2144(%rbp)
	jmp .___ZL6func_1v__M3414
	.___ZL6func_1v__M3406:
	# LowerLoad(2598:3).4: _ZL6g_1948 into ^658
	movq _ZL6g_1948, %rax
	# LowerIcmp(2599:3): i32 ^658 vs. intlike 0
	cmpl $0, %eax
	setne %al
	# MovePhi: ^659 -> ^661
	movb %al, -2144(%rbp)
	.___ZL6func_1v__M3414:
	# LowerBasicConversion(2604:3): ^661 -> ^662
	movl -2144(%rbp), %eax
	# LowerIcmp(2605:3): i32 ^561 vs. operand i32 ^662
	cmpl %eax, %ebx
	setge %al
	# LowerBasicConversion(2606:3): ^663 -> ^664
	movq %rax, %rbx
	# LowerIcmp(2607:3): i64 ^664 vs. intlike 0
	cmpq $0, %rbx
	setle %al
	# LowerBasicConversion(2608:3): ^665 -> ^666
	movl %eax, %ebx
	# LowerLoad(2609:3).4: _ZL6g_2357 into ^667
	movq _ZL6g_2357, %rax
	# LowerStore(2610:3).9: mov ^666, (^667)
	movl %ebx, (%rax)
	# LowerLoad(2614:3).4: _ZL6g_1898 into ^669
	movq _ZL6g_1898, %rax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(2616:3).8a: movq var, %temp
	movq _ZL6g_1898@GOTPCREL(%rip), %rax
	# LowerStore(2616:3).8b: movq ^670, (%temp)
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M2866
	.___ZL6func_1v__M3440:
	# LowerLoad(2623:3).4: _ZL6g_1921 into ^673
	movq _ZL6g_1921, %rax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(2625:3).8a: movq var, %temp
	movq _ZL6g_1921@GOTPCREL(%rip), %rax
	# LowerStore(2625:3).8b: movq ^674, (%temp)
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M2830
	.___ZL6func_1v__M3450:
	# LowerLoad(2632:3).4: _ZL6g_1904 into ^677
	movq _ZL6g_1904, %rax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(2634:3).8a: movq var, %temp
	movq _ZL6g_1904@GOTPCREL(%rip), %rax
	# LowerStore(2634:3).8b: movq ^678, (%temp)
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M2819
	.___ZL6func_1v__M3460:
	jmp .___ZL6func_1v__M4343
	.___ZL6func_1v__M3461:
	# LowerStore(2642:3).3: mov $imm, ^83
	movq -2240(%rbp), %rax
	movl $-1902289856, (%rax)
	# SetupCalls(2644:3): move argument ptr align 16 ^84
	movq -2232(%rbp), %rdi
	# SetupCalls(2644:3): move argument ptr align 16 @__const._ZL6func_1v.l_2445
	movq __const._ZL6func_1v.l_2445, %rsi
	# SetupCalls(2644:3): move argument i64 400
	movq $400, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(2646:3).3: mov $imm, ^85
	movq -2224(%rbp), %rax
	movl $757060412, (%rax)
	# LowerStore(2648:3).3: mov $imm, ^86
	movabsq $-6161547311127722695, %rbx
	movq -2472(%rbp), %rax
	movq %rbx, (%rax)
	# SetupCalls(2651:3): move argument ptr align 16 ^88
	movq -2464(%rbp), %rdi
	# SetupCalls(2651:3): move argument ptr align 16 @__const._ZL6func_1v.l_2475
	movq __const._ZL6func_1v.l_2475, %rsi
	# SetupCalls(2651:3): move argument i64 504
	movq $504, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(2654:3).3: mov $imm, ^89
	movq -2448(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M3521:
	# LowerLoad(2658:3).2: (^89) into ^682
	movq -2448(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(2659:3): i32 ^682 vs. intlike 1
	cmpl $1, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL6func_1v__M3527
	jmp .___ZL6func_1v__M3548
	.___ZL6func_1v__M3527:
	# LowerLoad(2663:3).2: (^89) into ^685
	movq -2448(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerGetelementptr(2665:3): struct-type: ptr ^87 -> ^687, indices=0,%686
	movq -2440(%rbp), %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(2665:3): type of ^687 is ptr*
	# LowerStore(2666:3).6: load global
	movq _ZL5g_338@GOTPCREL(%rip), %rbx
	# LowerStore(2666:3).9: mov ^1187, (^687)
	movq %rbx, (%rax)
	# LowerLoad(2670:3).2: (^89) into ^689
	movq -2448(%rbp), %rbx
	movl (%rbx), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(2672:3).9: mov ^690, (^89)
	movq -2448(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M3521
	.___ZL6func_1v__M3548:
	# LowerStore(2676:3).2a: mov $imm, %temp
	movl $0, %eax
	# LowerStore(2676:3).2b: mov %temp, (global)
	movl %eax, _ZL6g_1934@GOTPCREL(%rip)
	.___ZL6func_1v__M3553:
	# LowerLoad(2680:3).4: _ZL6g_1934 into ^693
	movq _ZL6g_1934, %rax
	# LowerIcmp(2681:3): i32 ^693 vs. intlike 6
	cmpl $6, %eax
	setbe %al
	cmpb $0, %al
	jne .___ZL6func_1v__M3559
	jmp .___ZL6func_1v__M3900
	.___ZL6func_1v__M3559:
	# LowerStore(2686:3).3: mov $imm, ^91
	movq -2272(%rbp), %rax
	movw $-1834, (%rax)
	# SetupCalls(2688:3): move argument ptr align 2 ^92
	movq -2280(%rbp), %rdi
	# SetupCalls(2688:3): move argument i32 0
	movq $0, %rsi
	# SetupCalls(2688:3): move argument i64 2
	movq $2, %rdx
	callq memset@PLT@GOTPCREL(%rip)
	# LowerStore(2690:3).3: mov $imm, ^93
	movq -2288(%rbp), %rax
	movl $-1, (%rax)
	# SetupCalls(2692:3): move argument ptr align 16 ^94
	movq -2296(%rbp), %rdi
	# SetupCalls(2692:3): move argument ptr align 16 @__const._ZL6func_1v.l_2462
	movq __const._ZL6func_1v.l_2462, %rsi
	# SetupCalls(2692:3): move argument i64 40
	movq $40, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(2694:3).3: mov $imm, ^95
	movq -2304(%rbp), %rax
	movl $-849278951, (%rax)
	# LowerStore(2696:3).3: mov $imm, ^96
	movq -2312(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(2698:3).2a: mov $imm, %temp
	movl $0, %eax
	# LowerStore(2698:3).2b: mov %temp, (global)
	movl %eax, _ZL5g_693@GOTPCREL(%rip)
	# LowerLoad(2702:3).4: _ZL5g_693 into ^697
	movq _ZL5g_693, %rax
	# LowerIcmp(2703:3): i32 ^697 vs. intlike 6
	cmpl $6, %eax
	setle %al
	cmpb $0, %al
	jne .___ZL6func_1v__M3628
	jmp .___ZL6func_1v__M3654
	.___ZL6func_1v__M3628:
	# SetupCalls(2708:3): move argument ptr align 2 ^1
	movq -2104(%rbp), %rdi
	# SetupCalls(2708:3): move argument ptr align 2 @__const._ZL6func_1v.l_2420
	movq __const._ZL6func_1v.l_2420, %rsi
	# SetupCalls(2708:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	jmp .___ZL6func_1v__M5733
	.___ZL6func_1v__M3654:
	# LowerStore(2718:3).2a: mov $imm, %temp
	movl $1, %eax
	# LowerStore(2718:3).2b: mov %temp, (global)
	movl %eax, _ZL5g_744@GOTPCREL(%rip)
	.___ZL6func_1v__M3659:
	# LowerLoad(2722:3).4: _ZL5g_744 into ^705
	movq _ZL5g_744, %rax
	# LowerIcmp(2723:3): i32 ^705 vs. intlike 6
	cmpl $6, %eax
	setbe %al
	cmpb $0, %al
	jne .___ZL6func_1v__M3665
	jmp .___ZL6func_1v__M3890
	.___ZL6func_1v__M3665:
	# SetupCalls(2728:3): move argument ptr align 16 ^98
	movq -2320(%rbp), %rdi
	# SetupCalls(2728:3): move argument ptr align 16 @__const._ZL6func_1v.l_2431
	movq __const._ZL6func_1v.l_2431, %rsi
	# SetupCalls(2728:3): move argument i64 84
	movq $84, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(2730:3).3: mov $imm, ^99
	movq -2328(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(2733:3).2a: mov $imm, %temp
	movl $0, %eax
	# LowerStore(2733:3).2b: mov %temp, (global)
	movl %eax, _ZL6g_1928@GOTPCREL(%rip)
	.___ZL6func_1v__M3697:
	# LowerLoad(2737:3).4: _ZL6g_1928 into ^709
	movq _ZL6g_1928, %rax
	# LowerIcmp(2738:3): i32 ^709 vs. intlike 6
	cmpl $6, %eax
	setbe %al
	cmpb $0, %al
	jne .___ZL6func_1v__M3703
	jmp .___ZL6func_1v__M3836
	.___ZL6func_1v__M3703:
	# LowerStore(2743:3).6: load global
	movq _ZL6g_2423@GOTPCREL(%rip), %rbx
	# LowerStore(2743:3).9: mov ^1192, (^102)
	movq -2336(%rbp), %rax
	movq %rbx, (%rax)
	# LowerLoad(2745:3).4: _ZL6g_2423 into ^712
	movq _ZL6g_2423, %rax
	# LowerLoad(2746:3).2: (^102) into ^713
	movq -2336(%rbp), %rcx
	movq (%rcx), %rbx
	# LowerStore(2747:3).9: mov ^712, (^713)
	movq %rax, (%rbx)
	# LowerIcmp(2748:3): ptr ^712 vs. intlike 0
	cmpq $0, %rax
	sete %al
	# LowerBasicConversion(2749:3): ^714 -> ^715
	movw %ax, %bx
	# LowerLoad(2750:3).4: _ZL6g_1928 into ^716
	movq _ZL6g_1928, %rax
	# LowerBasicConversion(2751:3): ^716 -> ^717
	movq %rax, %rcx
	movq _ZL6g_1945, %rax
	movq _ZL6g_1945, %rdx
	# LowerGetelementptr(2752:3): struct-type: ptr ^1152 -> ^718, indices=0,%717
	movq %rdx, %rax
	movq %rcx, %rdx
	shlq $3, %rdx
	addq %rdx, %rax
	# LowerGetelementptr(2752:3): type of ^718 is ptr*
	# LowerLoad(2753:3).2: (^718) into ^719
	movl (%rax), %ecx
	# LowerTrunc(2754:3): 32 to 8, move
	movb %cl, %al
	# LowerTrunc(2754:3): 32 to 8, apply mask
	andb $255, %al
	# SetupCalls(2755:3): move argument i8 zeroext ^720
	movb %al, %dil
	andq $255, %rdi
	# SetupCalls(2755:3): move argument i32 1
	movq $1, %rsi
	callq _ZL28safe_lshift_func_uint8_t_u_uhj@GOTPCREL(%rip)
	# SetupCalls(2755:3): move result from %rax
	movb %al, %r12b
	# LowerBasicConversion(2756:3): ^721 -> ^722
	movl %r12d, %eax
	# SetupCalls(2757:3): move argument i16 signext ^715
	movw %bx, %di
	movswq %di, %rdi
	# SetupCalls(2757:3): move argument i32 ^722
	movl %eax, %esi
	callq _ZL28safe_rshift_func_int16_t_s_ssi@GOTPCREL(%rip)
	# SetupCalls(2757:3): move result from %rax
	movw %ax, %bx
	movswl %bx, %eax
	# LowerGetelementptr(2759:3): struct-type: ptr ^98 -> ^725, indices=0,1
	movq -2320(%rbp), %rbx
	addq $8, %rbx
	# LowerGetelementptr(2759:3): type of ^725 is ptr*
	# LowerGetelementptr(2760:3): struct-type: ptr ^725 -> ^726, indices=0,4
	movq %rbx, %rcx
	addq $32, %rcx
	# LowerGetelementptr(2760:3): type of ^726 is ptr*
	# LowerLoad(2761:3).2: (^726) into ^727
	movl (%rcx), %ebx
	movl %ebx, %edx
	orl %eax, %edx
	# LowerStore(2763:3).9: mov ^728, (^726)
	movl %edx, (%rcx)
	# LowerStore(2764:3).3: mov $imm, ^91
	movq -2272(%rbp), %rax
	movw $-1, (%rax)
	# LowerLoad(2765:3).4: _ZL5g_653 into ^729
	movq _ZL5g_653, %rax
	# LowerLoad(2766:3).2: (^729) into ^730
	movq (%rax), %rbx
	# LowerLoad(2767:3).2: (^730) into ^731
	movq (%rbx), %rax
	# LowerLoad(2768:3).4: _ZL5g_653 into ^732
	movq _ZL5g_653, %rbx
	# LowerLoad(2769:3).2: (^732) into ^733
	movq (%rbx), %rcx
	# LowerStore(2770:3).9: mov ^731, (^733)
	movq %rax, (%rcx)
	# LowerLoad(2771:3).2: (^83) into ^734
	movq -2240(%rbp), %rax
	movl (%rax), %ebx
	movl %ebx, %ecx
	addl $-1, %ecx
	# LowerStore(2773:3).9: mov ^735, (^83)
	movq -2240(%rbp), %rax
	movl %ecx, (%rax)
	# LowerLoad(2777:3).4: _ZL6g_1928 into ^737
	movq _ZL6g_1928, %rbx
	movl %ebx, %eax
	addl $1, %eax
	# LowerStore(2779:3).8a: movq var, %temp
	movq _ZL6g_1928@GOTPCREL(%rip), %rbx
	# LowerStore(2779:3).8b: movq ^738, (%temp)
	movl %eax, (%rbx)
	jmp .___ZL6func_1v__M3697
	.___ZL6func_1v__M3836:
	# LowerStore(2783:3).2a: mov $imm, %temp
	movl $-1, %eax
	# LowerStore(2783:3).2b: mov %temp, (global)
	movl %eax, _ZL6g_1939@GOTPCREL(%rip)
	# LowerLoad(2787:3).4: _ZL6g_1939 into ^741
	movq _ZL6g_1939, %rax
	# LowerIcmp(2788:3): i32 ^741 vs. intlike 55
	cmpl $55, %eax
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M3847
	jmp .___ZL6func_1v__M3880
	.___ZL6func_1v__M3847:
	# SetupCalls(2793:3): move argument ptr align 2 ^1
	movq -2104(%rbp), %rdi
	# SetupCalls(2793:3): move argument ptr align 2 @__const._ZL6func_1v.l_2438
	movq __const._ZL6func_1v.l_2438, %rsi
	# SetupCalls(2793:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerLoad(2794:3).2: (^83) into ^744
	movq -2240(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(2795:3): i32 ^744 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M3878
	jmp .___ZL6func_1v__M3879
	.___ZL6func_1v__M3878:
	jmp .___ZL6func_1v__M3880
	.___ZL6func_1v__M3879:
	jmp .___ZL6func_1v__M5733
	.___ZL6func_1v__M3880:
	# LowerLoad(2814:3).4: _ZL5g_744 into ^753
	movq _ZL5g_744, %rax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(2816:3).8a: movq var, %temp
	movq _ZL5g_744@GOTPCREL(%rip), %rax
	# LowerStore(2816:3).8b: movq ^754, (%temp)
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M3659
	.___ZL6func_1v__M3890:
	# LowerLoad(2823:3).4: _ZL6g_1934 into ^757
	movq _ZL6g_1934, %rax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(2825:3).8a: movq var, %temp
	movq _ZL6g_1934@GOTPCREL(%rip), %rax
	# LowerStore(2825:3).8b: movq ^758, (%temp)
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M3553
	.___ZL6func_1v__M3900:
	# LowerLoad(2829:3).2: (^85) into ^760
	movq -2224(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(2830:3): i32 ^760 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M3909
	.___ZL6func_1v__M3906:
	# MovePhi: intlike -> ^832 (in new block 1230 whose parent is 759)
	movb $0, -2152(%rbp)
	jmp .___ZL6func_1v__M4334
	.___ZL6func_1v__M3909:
	# LowerLoad(2834:3).2: (^53) into ^763
	movq -2136(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(2835:3).2: (^763) into ^764
	movl (%rbx), %eax
	# LowerTrunc(2836:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(2836:3): 32 to 16, apply mask
	andw $65535, %bx
	# LowerLoad(2837:3).4: _ZL6g_2423 into ^766
	movq _ZL6g_2423, %rax
	# LowerLoad(2838:3).2: (^766) into ^767
	movq (%rax), %rcx
	# LowerLoad(2839:3).2: (^767) into ^768
	movq (%rcx), %rax
	# LowerLoad(2840:3).2: (^768) into ^769
	movq (%rax), %rcx
	# LowerLoad(2841:3).2: (^53) into ^770
	movq -2136(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2842:3).2: (^770) into ^771
	movl (%rcx), %eax
	# LowerTrunc(2843:3): 32 to 16, move
	movw %ax, %cx
	# LowerTrunc(2843:3): 32 to 16, apply mask
	andw $65535, %cx
	# SetupCalls(2844:3): move argument i16 signext ^772
	movw %cx, %di
	movswq %di, %rdi
	# SetupCalls(2844:3): move argument i32 7
	movq $7, %rsi
	callq _ZL28safe_rshift_func_int16_t_s_ssi@GOTPCREL(%rip)
	# SetupCalls(2844:3): move result from %rax
	movw %ax, %r12w
	movswq %r12w, %r13
	# LowerLoad(2846:3).4: _ZL5g_150 into ^775
	movq _ZL5g_150, %rax
	# LowerLoad(2847:3).4: _ZL5g_150 into ^776
	movq _ZL5g_150, %rcx
	# SetupCalls(2848:3): move argument ptr nonnull dereferenceable(8) align 8 ^776
	movq %rcx, %rdi
	# SetupCalls(2848:3): move argument ptr nonnull dereferenceable(8) align 8 ^775
	movq %rax, %rsi
	callq _ZN2U2aSERKS_@GOTPCREL(%rip)
	# SetupCalls(2848:3): move result from %rax
	movq %rax, %rax
	# LowerLoad(2849:3).2: (^2) into ^778
	movq -2128(%rbp), %rax
	movl (%rax), %ecx
	movslq %ecx, %rax
	movq $23858, %r12
	xorq %rax, %r12
	# LowerLoad(2852:3).4: _ZL6g_2024 into ^781
	movq _ZL6g_2024, %rax
	# LowerIcmp(2853:3): i32 ^781 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M4001
	jmp .___ZL6func_1v__M4004
	.___ZL6func_1v__M4001:
	# MovePhi: intlike -> ^785 (in new block 1229 whose parent is 1109)
	movb $1, %al
	jmp .___ZL6func_1v__M4007
	.___ZL6func_1v__M4004:
	# MovePhi: intlike -> ^785
	movb $1, %al
	.___ZL6func_1v__M4007:
	# LowerLoad(2861:3).2: (^17) into ^786
	movq -2216(%rbp), %rax
	movw (%rax), %cx
	# LowerTrunc(2862:3): 16 to 8, move
	movb %cl, %al
	# LowerTrunc(2862:3): 16 to 8, apply mask
	andb $255, %al
	# SetupCalls(2863:3): move argument i8 zeroext 1
	movq $1, %rdi
	andq $255, %rdi
	# SetupCalls(2863:3): move argument i8 zeroext ^787
	movb %al, %sil
	andq $255, %rsi
	callq _ZL25safe_div_func_uint8_t_u_uhh@GOTPCREL(%rip)
	# SetupCalls(2863:3): move result from %rax
	movb %al, %r14b
	# LowerBasicConversion(2864:3): ^788 -> ^789
	movq %r14, %rax
	# SetupCalls(2865:3): move argument i64 ^780
	movq %r12, %rdi
	# SetupCalls(2865:3): move argument i64 ^789
	movq %rax, %rsi
	callq _ZL26safe_mul_func_uint64_t_u_umm@GOTPCREL(%rip)
	# SetupCalls(2865:3): move result from %rax
	movq %rax, %r12
	# SetupCalls(2866:3): move argument i64 ^774
	movq %r13, %rdi
	# SetupCalls(2866:3): move argument i64 ^790
	movq %r12, %rsi
	callq _ZL25safe_div_func_int64_t_s_sll@GOTPCREL(%rip)
	# SetupCalls(2866:3): move result from %rax
	movq %rax, %r12
	# LowerTrunc(2867:3): 64 to 16, move
	movw %r12w, %ax
	# LowerTrunc(2867:3): 64 to 16, apply mask
	andw $65535, %ax
	# SetupCalls(2868:3): move argument i16 zeroext ^765
	movw %bx, %di
	andq $65535, %rdi
	# SetupCalls(2868:3): move argument i16 zeroext ^792
	movw %ax, %si
	andq $65535, %rsi
	callq _ZL26safe_div_func_uint16_t_u_utt@GOTPCREL(%rip)
	# SetupCalls(2868:3): move result from %rax
	movw %ax, %bx
	# LowerBasicConversion(2869:3): ^793 -> ^794
	movl %ebx, %ecx
	# LowerLoad(2870:3).2: (^2) into ^795
	movq -2128(%rbp), %rax
	movl (%rax), %ebx
	movl %ecx, %eax
	orl %ebx, %eax
	# LowerGetelementptr(2872:3): struct-type: ptr ^15 -> ^797, indices=0,3
	movq -2120(%rbp), %rbx
	addq $24, %rbx
	# LowerGetelementptr(2872:3): type of ^797 is ptr*
	# LowerGetelementptr(2873:3): struct-type: ptr ^797 -> ^798, indices=0,0
	movq %rbx, %rcx
	# LowerGetelementptr(2873:3): type of ^798 is ptr*
	# LowerLoad(2874:3).2: (^798) into ^799
	movw (%rcx), %bx
	# LowerBasicConversion(2875:3): ^799 -> ^800
	movl %ebx, %ecx
	movl %eax, %ebx
	orl %ecx, %ebx
	# LowerGetelementptr(2877:3): struct-type: ptr ^15 -> ^802, indices=0,2
	movq -2120(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(2877:3): type of ^802 is ptr*
	# LowerGetelementptr(2878:3): struct-type: ptr ^802 -> ^803, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(2878:3): type of ^803 is ptr*
	# LowerLoad(2879:3).2: (^803) into ^804
	movw (%rcx), %ax
	# LowerBasicConversion(2880:3): ^804 -> ^805
	movl %eax, %ecx
	# SetupCalls(2881:3): move argument i32 ^801
	movl %ebx, %edi
	# SetupCalls(2881:3): move argument i32 ^805
	movl %ecx, %esi
	callq _ZL29safe_rshift_func_uint32_t_u_ujj@GOTPCREL(%rip)
	# SetupCalls(2881:3): move result from %rax
	movl %eax, %ebx
	# LowerBasicConversion(2882:3): ^806 -> ^807
	movq %rbx, %rcx
	# LowerLoad(2883:3).2: (^53) into ^808
	movq -2136(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(2884:3).2: (^808) into ^809
	movl (%rbx), %eax
	movslq %eax, %rbx
	# SetupCalls(2886:3): move argument i64 ^807
	movq %rcx, %rdi
	# SetupCalls(2886:3): move argument i64 ^810
	movq %rbx, %rsi
	callq _ZL25safe_div_func_int64_t_s_sll@GOTPCREL(%rip)
	# SetupCalls(2886:3): move result from %rax
	movq %rax, %rbx
	# LowerLoad(2887:3).2: (^83) into ^812
	movq -2240(%rbp), %rax
	movl (%rax), %ecx
	# LowerBasicConversion(2888:3): ^812 -> ^813
	movq %rcx, %rax
	# LowerIcmp(2889:3): i64 ^811 vs. operand i64 ^813
	cmpq %rax, %rbx
	setne %al
	# LowerBasicConversion(2890:3): ^814 -> ^815
	movl %eax, %ebx
	# LowerLoad(2891:3).2: (^53) into ^816
	movq -2136(%rbp), %rax
	movq (%rax), %rcx
	# LowerLoad(2892:3).2: (^816) into ^817
	movl (%rcx), %eax
	# LowerIcmp(2893:3): i32 ^815 vs. operand i32 ^817
	cmpl %eax, %ebx
	setge %al
	# LowerBasicConversion(2894:3): ^818 -> ^819
	movb %al, %bl
	# LowerLoad(2895:3).4: _ZL6g_1932 into ^820
	movq _ZL6g_1932, %rax
	# SetupCalls(2896:3): move argument i8 zeroext ^819
	movb %bl, %dil
	andq $255, %rdi
	# SetupCalls(2896:3): move argument i32 ^820
	movl %eax, %esi
	callq _ZL28safe_lshift_func_uint8_t_u_shi@GOTPCREL(%rip)
	# SetupCalls(2896:3): move result from %rax
	movb %al, %bl
	# SetupCalls(2897:3): move argument i8 signext ^821
	movb %bl, %dil
	movsbq %dil, %rdi
	# SetupCalls(2897:3): move argument i8 signext 82
	movq $82, %rsi
	movsbq %sil, %rsi
	callq _ZL24safe_add_func_int8_t_s_saa@GOTPCREL(%rip)
	# SetupCalls(2897:3): move result from %rax
	movb %al, %bl
	movsbq %bl, %rax
	# LowerGetelementptr(2899:3): struct-type: ptr ^84 -> ^824, indices=0,3
	movq -2232(%rbp), %rbx
	addq $24, %rbx
	# LowerGetelementptr(2899:3): type of ^824 is ptr*
	# LowerGetelementptr(2900:3): struct-type: ptr ^824 -> ^825, indices=0,2
	movq %rbx, %rcx
	addq $16, %rcx
	# LowerGetelementptr(2900:3): type of ^825 is ptr*
	# LowerLoad(2901:3).2: (^825) into ^826
	movq (%rcx), %rbx
	# SetupCalls(2902:3): move argument i64 ^823
	movq %rax, %rdi
	# SetupCalls(2902:3): move argument i64 ^826
	movq %rbx, %rsi
	callq _ZL26safe_mul_func_uint64_t_u_umm@GOTPCREL(%rip)
	# SetupCalls(2902:3): move result from %rax
	movq %rax, %rax
	# LowerLoad(2903:3).2: (^85) into ^828
	movq -2224(%rbp), %rax
	movl (%rax), %ebx
	# LowerLoad(2904:3).2: (^53) into ^829
	movq -2136(%rbp), %rax
	movq (%rax), %rcx
	# LowerStore(2905:3).9: mov ^828, (^829)
	movl %ebx, (%rcx)
	# LowerIcmp(2906:3): i32 ^828 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	# MovePhi: ^830 -> ^832
	movb %al, -2152(%rbp)
	.___ZL6func_1v__M4334:
	# LowerBasicConversion(2911:3): ^832 -> ^833
	movl -2152(%rbp), %eax
	# LowerLoad(2912:3).4: _ZL5g_139 into ^834
	movq _ZL5g_139, %rbx
	# LowerLoad(2913:3).2: (^834) into ^835
	movq (%rbx), %rcx
	# LowerStore(2914:3).9: mov ^833, (^835)
	movl %eax, (%rcx)
	.___ZL6func_1v__M4343:
	jmp .___ZL6func_1v__M5705
	.___ZL6func_1v__M4344:
	# LowerStore(2922:3).6: load global
	movq _ZL6g_2504@GOTPCREL(%rip), %rbx
	# LowerStore(2922:3).9: mov ^1197, (^104)
	movq -2880(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2924:3).3: mov $imm, ^105
	movq -2864(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(2926:3).6: load global
	movq _ZL5g_313@GOTPCREL(%rip), %rbx
	# LowerStore(2926:3).9: mov ^1198, (^106)
	movq -2544(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(2928:3).3: mov $imm, ^107
	movq -2976(%rbp), %rax
	movl $197268864, (%rax)
	# LowerStore(2930:3).3: mov $imm, ^108
	movq -2984(%rbp), %rax
	movl $-199073996, (%rax)
	# SetupCalls(2932:3): move argument ptr align 16 ^109
	movq -2496(%rbp), %rdi
	# SetupCalls(2932:3): move argument ptr align 16 @__const._ZL6func_1v.l_2541
	movq __const._ZL6func_1v.l_2541, %rsi
	# SetupCalls(2932:3): move argument i64 224
	movq $224, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(2934:3).9: mov ^27, (^110)
	movq -2488(%rbp), %rax
	# Fixing movq -2416(%rbp), (%rax)
	movq -2416(%rbp), %r15
	movq %r15, (%rax)
	# SetupCalls(2936:3): move argument ptr align 2 ^111
	movq -2728(%rbp), %rdi
	# SetupCalls(2936:3): move argument ptr align 2 @__const._ZL6func_1v.l_2605
	movq __const._ZL6func_1v.l_2605, %rsi
	# SetupCalls(2936:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	movq _ZL5g_149, %rax
	addq $32, %rax
	# LowerLoad(2939:3).2: (^1129) into ^838
	movq (%rax), %rbx
	# SetupCalls(2940:3): move argument i64 ^838
	movq %rbx, %rdi
	callq _ZL31safe_unary_minus_func_int64_t_sl@GOTPCREL(%rip)
	# SetupCalls(2940:3): move result from %rax
	movq %rax, %rbx
	# LowerLoad(2941:3).4: _ZL5g_150 into ^840
	movq _ZL5g_150, %rax
	# LowerLoad(2942:3).4: _ZL6g_2504 into ^841
	movq _ZL6g_2504, %rax
	# LowerLoad(2943:3).2: (^104) into ^842
	movq -2880(%rbp), %rdx
	movq (%rdx), %rcx
	# LowerStore(2944:3).9: mov ^841, (^842)
	movq %rax, (%rcx)
	# LowerIcmp(2945:3): ptr ^841 vs. global _ZL6g_2505
	movq %r15, _ZL6g_2505@GOTPCREL(%rip)
	movq %r15, (%r15)
	cmpq %r15, %rax
	setne %al
	# LowerLoad(2946:3).4: _ZL5g_448 into ^844
	movq _ZL5g_448, %rax
	# LowerLoad(2947:3).2: (^844) into ^845
	movl (%rax), %ecx
	# SetupCalls(2948:3): move argument i32 2093652833
	movq $2093652833, %rdi
	# SetupCalls(2948:3): move argument i32 ^845
	movl %ecx, %esi
	callq _ZL25safe_sub_func_int32_t_s_sii@GOTPCREL(%rip)
	# SetupCalls(2948:3): move result from %rax
	movl %eax, %r12d
	# LowerLoad(2949:3).2: (^2) into ^847
	movq -2128(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(2950:3): i32 ^846 vs. operand i32 ^847
	cmpl %ecx, %r12d
	sete %al
	# LowerBasicConversion(2951:3): ^848 -> ^849
	movw %ax, %cx
	# LowerLoad(2952:3).2: (^106) into ^850
	movq -2544(%rbp), %rdx
	movq (%rdx), %rax
	# LowerStore(2953:3).9: mov ^849, (^850)
	movw %cx, (%rax)
	# LowerLoad(2954:3).2: (^105) into ^851
	movq -2864(%rbp), %rdx
	movl (%rdx), %eax
	# LowerTrunc(2955:3): 32 to 16, move
	movw %ax, %dx
	# LowerTrunc(2955:3): 32 to 16, apply mask
	andw $65535, %dx
	# SetupCalls(2956:3): move argument i16 signext ^849
	movw %cx, %di
	movswq %di, %rdi
	# SetupCalls(2956:3): move argument i16 signext ^852
	movw %dx, %si
	movswq %si, %rsi
	callq _ZL25safe_mod_func_int16_t_s_sss@GOTPCREL(%rip)
	# SetupCalls(2956:3): move result from %rax
	movw %ax, %r12w
	movswl %r12w, %ecx
	movq _ZL6g_1922, %rax
	addq $24, %rax
	# LowerLoad(2958:3).2: (^1130) into ^855
	movl (%rax), %edx
	# LowerIcmp(2959:3): i32 ^854 vs. operand i32 ^855
	cmpl %edx, %ecx
	setbe %al
	# LowerBasicConversion(2960:3): ^856 -> ^857
	movl %eax, %ecx
	# LowerLoad(2961:3).2: (^5) into ^858
	movq -2208(%rbp), %rax
	movl (%rax), %edx
	# LowerIcmp(2962:3): i32 ^857 vs. operand i32 ^858
	cmpl %edx, %ecx
	setle %al
	# LowerBasicConversion(2963:3): ^859 -> ^860
	movl %eax, %ecx
	# LowerLoad(2964:3).2: (^105) into ^861
	movq -2864(%rbp), %rdx
	movl (%rdx), %eax
	# LowerIcmp(2965:3): i32 ^860 vs. operand i32 ^861
	cmpl %eax, %ecx
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M4547
	jmp .___ZL6func_1v__M4550
	.___ZL6func_1v__M4547:
	# MovePhi: intlike -> ^868 (in new block 1231 whose parent is 1113)
	movb $1, -2592(%rbp)
	jmp .___ZL6func_1v__M4560
	.___ZL6func_1v__M4550:
	# LowerLoad(2969:3).4: _ZL5g_337 into ^864
	movq _ZL5g_337, %rax
	# LowerLoad(2970:3).2: (^864) into ^865
	movq (%rax), %rcx
	# LowerIcmp(2971:3): i64 ^865 vs. intlike 0
	cmpq $0, %rcx
	setne %al
	# MovePhi: ^866 -> ^868
	movb %al, -2592(%rbp)
	.___ZL6func_1v__M4560:
	# LowerBasicConversion(2976:3): ^868 -> ^869
	movw -2592(%rbp), %ax
	# SetupCalls(2977:3): move argument i16 signext ^869
	movw %ax, %di
	movswq %di, %rdi
	# SetupCalls(2977:3): move argument i32 14
	movq $14, %rsi
	callq _ZL28safe_rshift_func_int16_t_s_usj@GOTPCREL(%rip)
	# SetupCalls(2977:3): move result from %rax
	movw %ax, %r12w
	movswq %r12w, %rax
	# LowerLoad(2979:3).4: _ZL6g_1930 into ^872
	movq _ZL6g_1930, %rcx
	# SetupCalls(2980:3): move argument i64 ^871
	movq %rax, %rdi
	# SetupCalls(2980:3): move argument i32 ^872
	movl %ecx, %esi
	callq _ZL29safe_lshift_func_uint64_t_u_smi@GOTPCREL(%rip)
	# SetupCalls(2980:3): move result from %rax
	movq %rax, %r12
	movq $1746, %rax
	# LowerIcmp(2981:3): i64 ^1138 vs. operand i64 ^873
	cmpq %r12, %rax
	setb %al
	# LowerBasicConversion(2982:3): ^874 -> ^875
	movl %eax, %ecx
	# LowerLoad(2983:3).2: (^105) into ^876
	movq -2864(%rbp), %rdx
	movl (%rdx), %eax
	# LowerIcmp(2984:3): i32 ^875 vs. operand i32 ^876
	cmpl %eax, %ecx
	sete %al
	# LowerBasicConversion(2985:3): ^877 -> ^878
	movw %ax, %cx
	# SetupCalls(2986:3): move argument i16 signext ^878
	movw %cx, %di
	movswq %di, %rdi
	# SetupCalls(2986:3): move argument i16 signext 4663
	movq $4663, %rsi
	movswq %si, %rsi
	callq _ZL25safe_mod_func_int16_t_s_sss@GOTPCREL(%rip)
	# SetupCalls(2986:3): move result from %rax
	movw %ax, %r12w
	movswq %r12w, %rax
	# LowerIcmp(2988:3): i64 ^880 vs. intlike 2978496419
	movabsq $2978496419, %rcx
	cmpq %rcx, %rax
	setl %al
	# LowerBasicConversion(2989:3): ^881 -> ^882
	movl %eax, %ecx
	# SetupCalls(2990:3): move argument i64 ^839
	movq %rbx, %rdi
	# SetupCalls(2990:3): move argument i32 ^882
	movl %ecx, %esi
	callq _ZL29safe_rshift_func_uint64_t_u_umj@GOTPCREL(%rip)
	# SetupCalls(2990:3): move result from %rax
	movq %rax, %rbx
	# LowerTrunc(2991:3): 64 to 32, move
	movl %ebx, %eax
	# LowerTrunc(2991:3): 64 to 32, apply mask
	movabsq $4294967295, %rbx
	andl %ebx, %eax
	# SetupCalls(2992:3): move argument i64 -8285731994164951014
	movabsq $-8285731994164951014, %rbx
	movq %rbx, %rdi
	# SetupCalls(2992:3): move argument i32 ^884
	movl %eax, %esi
	callq _ZL28safe_lshift_func_int64_t_s_ulj@GOTPCREL(%rip)
	# SetupCalls(2992:3): move result from %rax
	movq %rax, %rbx
	movq %rbx, %rax
	orq $63187, %rax
	# LowerTrunc(2994:3): 64 to 8, move
	movb %al, %bl
	# LowerTrunc(2994:3): 64 to 8, apply mask
	andb $255, %bl
	# LowerLoad(2995:3).4: _ZL6g_2519 into ^888
	movq _ZL6g_2519, %rax
	# LowerTrunc(2996:3): 16 to 8, move
	movb %al, %cl
	# LowerTrunc(2996:3): 16 to 8, apply mask
	andb $255, %cl
	# SetupCalls(2997:3): move argument i8 zeroext ^887
	movb %bl, %dil
	andq $255, %rdi
	# SetupCalls(2997:3): move argument i8 zeroext ^889
	movb %cl, %sil
	andq $255, %rsi
	callq _ZL25safe_add_func_uint8_t_u_uhh@GOTPCREL(%rip)
	# SetupCalls(2997:3): move result from %rax
	movb %al, %bl
	# LowerIcmp(2998:3): i8 ^890 vs. intlike 0
	cmpb $0, %bl
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M4763
	jmp .___ZL6func_1v__M5639
	.___ZL6func_1v__M4763:
	# LowerStore(3003:3).3: mov $imm, ^114
	movq -2680(%rbp), %rax
	movb $1, (%rax)
	# LowerStore(3005:3).3: mov $imm, ^115
	movq -2792(%rbp), %rax
	movl $2118415308, (%rax)
	# LowerStore(3007:3).3: mov $imm, ^116
	movq -2808(%rbp), %rax
	movl $1, (%rax)
	# LowerStore(3009:3).3: mov $imm, ^117
	movq -2832(%rbp), %rax
	movl $1564788400, (%rax)
	# LowerStore(3011:3).3: mov $imm, ^118
	movq -2840(%rbp), %rax
	movl $-72581471, (%rax)
	# SetupCalls(3013:3): move argument ptr align 16 ^119
	movq -2816(%rbp), %rdi
	# SetupCalls(3013:3): move argument ptr align 16 @__const._ZL6func_1v.l_2552
	movq __const._ZL6func_1v.l_2552, %rsi
	# SetupCalls(3013:3): move argument i64 32
	movq $32, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(3015:3).3: mov $imm, ^120
	movq -2760(%rbp), %rax
	movb $0, (%rax)
	# LowerStore(3017:3).3: mov $imm, ^121
	movq -2776(%rbp), %rax
	movl $1200670702, (%rax)
	# SetupCalls(3020:3): move argument ptr align 2 ^123
	movq -2696(%rbp), %rdi
	# SetupCalls(3020:3): move argument ptr align 2 @__const._ZL6func_1v.l_2573
	movq __const._ZL6func_1v.l_2573, %rsi
	# SetupCalls(3020:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(3022:3).6: load global
	movq _ZL5g_837@GOTPCREL(%rip), %rax
	# LowerStore(3022:3).9: mov ^1199, (^124)
	movq -2736(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerGetelementptr(3024:3): struct-type: ptr ^125 -> ^893, indices=0,0
	movq -2744(%rbp), %rax
	# LowerGetelementptr(3024:3): type of ^893 is ptr*
	# LowerGetelementptr(3025:3): struct-type: ptr ^893 -> ^894, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(3025:3): type of ^894 is ptr*
	# LowerStore(3026:3).9: mov ^114, (^894)
	# Fixing movq -2680(%rbp), (%rbx)
	movq -2680(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(3027:3): struct-type: ptr ^894 -> ^895, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3027:3): type of ^895 is ptr*
	# LowerStore(3028:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rbx
	# LowerStore(3028:3).9: mov ^1200, (^895)
	movq %rbx, (%rcx)
	# LowerGetelementptr(3029:3): struct-type: ptr ^895 -> ^896, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3029:3): type of ^896 is ptr*
	# LowerStore(3030:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rcx
	# LowerStore(3030:3).9: mov ^1201, (^896)
	movq %rcx, (%rbx)
	# LowerGetelementptr(3031:3): struct-type: ptr ^896 -> ^897, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3031:3): type of ^897 is ptr*
	# LowerStore(3032:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rbx
	# LowerStore(3032:3).9: mov ^1202, (^897)
	movq %rbx, (%rcx)
	# LowerGetelementptr(3033:3): struct-type: ptr ^897 -> ^898, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3033:3): type of ^898 is ptr*
	# LowerStore(3034:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rcx
	# LowerStore(3034:3).9: mov ^1203, (^898)
	movq %rcx, (%rbx)
	# LowerGetelementptr(3035:3): struct-type: ptr ^893 -> ^899, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3035:3): type of ^899 is ptr*
	# LowerGetelementptr(3036:3): struct-type: ptr ^899 -> ^900, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(3036:3): type of ^900 is ptr*
	# LowerStore(3037:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rcx
	# LowerStore(3037:3).9: mov ^1204, (^900)
	movq %rcx, (%rax)
	# LowerGetelementptr(3038:3): struct-type: ptr ^900 -> ^901, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3038:3): type of ^901 is ptr*
	# LowerStore(3039:3).9: mov ^114, (^901)
	# Fixing movq -2680(%rbp), (%rcx)
	movq -2680(%rbp), %r15
	movq %r15, (%rcx)
	# LowerGetelementptr(3040:3): struct-type: ptr ^901 -> ^902, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(3040:3): type of ^902 is ptr*
	# LowerStore(3041:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rcx
	# LowerStore(3041:3).9: mov ^1205, (^902)
	movq %rcx, (%rax)
	# LowerGetelementptr(3042:3): struct-type: ptr ^902 -> ^903, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3042:3): type of ^903 is ptr*
	# LowerStore(3043:3).6: load global
	movq _ZL5g_259@GOTPCREL(%rip), %rax
	# LowerStore(3043:3).9: mov ^1206, (^903)
	movq %rax, (%rcx)
	# LowerGetelementptr(3044:3): struct-type: ptr ^903 -> ^904, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(3044:3): type of ^904 is ptr*
	# LowerStore(3045:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rcx
	# LowerStore(3045:3).9: mov ^1207, (^904)
	movq %rcx, (%rax)
	# LowerGetelementptr(3046:3): struct-type: ptr ^899 -> ^905, indices=1
	movq %rbx, %r12
	addq $8, %r12
	# LowerGetelementptr(3046:3): type of ^905 is ptr*
	# LowerGetelementptr(3047:3): struct-type: ptr ^905 -> ^906, indices=0,0
	movq %r12, %rax
	# LowerGetelementptr(3047:3): type of ^906 is ptr*
	# SetupCalls(3048:3): move argument ptr align 8 ^905
	movq %r12, %rdi
	# SetupCalls(3048:3): move argument ptr align 8 @constinit
	movq constinit, %rsi
	# SetupCalls(3048:3): move argument i64 40
	movq $40, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerGetelementptr(3049:3): struct-type: ptr ^905 -> ^907, indices=1
	movq %r12, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3049:3): type of ^907 is ptr*
	# LowerGetelementptr(3050:3): struct-type: ptr ^907 -> ^908, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(3050:3): type of ^908 is ptr*
	# SetupCalls(3051:3): move argument ptr align 8 ^907
	movq %rbx, %rdi
	# SetupCalls(3051:3): move argument ptr align 8 @constinit.124
	movq constinit.124, %rsi
	# SetupCalls(3051:3): move argument i64 40
	movq $40, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerGetelementptr(3052:3): struct-type: ptr ^907 -> ^909, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(3052:3): type of ^909 is ptr*
	# LowerGetelementptr(3053:3): struct-type: ptr ^909 -> ^910, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(3053:3): type of ^910 is ptr*
	# LowerStore(3054:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rcx
	# LowerStore(3054:3).9: mov ^1208, (^910)
	movq %rcx, (%rbx)
	# LowerGetelementptr(3055:3): struct-type: ptr ^910 -> ^911, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3055:3): type of ^911 is ptr*
	# LowerStore(3056:3).6: load global
	movq _ZL5g_259@GOTPCREL(%rip), %rbx
	# LowerStore(3056:3).9: mov ^1209, (^911)
	movq %rbx, (%rcx)
	# LowerGetelementptr(3057:3): struct-type: ptr ^911 -> ^912, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3057:3): type of ^912 is ptr*
	# LowerStore(3058:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rcx
	# LowerStore(3058:3).9: mov ^1210, (^912)
	movq %rcx, (%rbx)
	# LowerGetelementptr(3059:3): struct-type: ptr ^912 -> ^913, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(3059:3): type of ^913 is ptr*
	# LowerStore(3060:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rbx
	# LowerStore(3060:3).9: mov ^1211, (^913)
	movq %rbx, (%rcx)
	# LowerGetelementptr(3061:3): struct-type: ptr ^913 -> ^914, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3061:3): type of ^914 is ptr*
	# LowerStore(3062:3).9: mov ^114, (^914)
	# Fixing movq -2680(%rbp), (%rbx)
	movq -2680(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(3063:3): struct-type: ptr ^909 -> ^915, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3063:3): type of ^915 is ptr*
	# LowerGetelementptr(3064:3): struct-type: ptr ^915 -> ^916, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(3064:3): type of ^916 is ptr*
	# LowerStore(3065:3).9: mov ^114, (^916)
	# Fixing movq -2680(%rbp), (%rax)
	movq -2680(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(3066:3): struct-type: ptr ^916 -> ^917, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3066:3): type of ^917 is ptr*
	# LowerStore(3067:3).6: load global
	movq _ZL5g_259@GOTPCREL(%rip), %rax
	# LowerStore(3067:3).9: mov ^1212, (^917)
	movq %rax, (%rbx)
	# LowerGetelementptr(3068:3): struct-type: ptr ^917 -> ^918, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(3068:3): type of ^918 is ptr*
	# LowerStore(3069:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rbx
	# LowerStore(3069:3).9: mov ^1213, (^918)
	movq %rbx, (%rax)
	# LowerGetelementptr(3070:3): struct-type: ptr ^918 -> ^919, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(3070:3): type of ^919 is ptr*
	# LowerStore(3071:3).6: load global
	movq _ZL5g_259@GOTPCREL(%rip), %rax
	# LowerStore(3071:3).9: mov ^1214, (^919)
	movq %rax, (%rbx)
	# LowerGetelementptr(3072:3): struct-type: ptr ^919 -> ^920, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(3072:3): type of ^920 is ptr*
	# LowerStore(3073:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rbx
	# LowerStore(3073:3).9: mov ^1215, (^920)
	movq %rbx, (%rax)
	# LowerStore(3075:3).3: mov $imm, ^126
	movq -2560(%rbp), %rax
	movw $7524, (%rax)
	# LowerStore(3077:3).9: mov ^123, (^127)
	movq -2528(%rbp), %rax
	# Fixing movq -2696(%rbp), (%rax)
	movq -2696(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(3080:3).3: mov $imm, ^128
	movq -2688(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M5066:
	# LowerLoad(3084:3).2: (^128) into ^922
	movq -2688(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(3085:3): i32 ^922 vs. intlike 8
	cmpl $8, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL6func_1v__M5072
	jmp .___ZL6func_1v__M5091
	.___ZL6func_1v__M5072:
	# LowerLoad(3089:3).2: (^128) into ^925
	movq -2688(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerGetelementptr(3091:3): struct-type: ptr ^122 -> ^927, indices=0,%926
	movq -2672(%rbp), %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(3091:3): type of ^927 is ptr*
	# LowerStore(3092:3).3: mov $imm, ^927
	movw $1, (%rax)
	# LowerLoad(3096:3).2: (^128) into ^929
	movq -2688(%rbp), %rbx
	movl (%rbx), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(3098:3).9: mov ^930, (^128)
	movq -2688(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M5066
	.___ZL6func_1v__M5091:
	# LowerStore(3102:3).3: mov $imm, ^4
	movq -2168(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M5094:
	# LowerLoad(3106:3).2: (^4) into ^933
	movq -2168(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(3107:3): i32 ^933 vs. intlike -27
	cmpl $-27, %ebx
	setle %al
	cmpb $0, %al
	jne .___ZL6func_1v__M5100
	jmp .___ZL6func_1v__M5173
	.___ZL6func_1v__M5100:
	# LowerStore(3112:3).3: mov $imm, ^130
	movq -2600(%rbp), %rax
	movl $-6, (%rax)
	# LowerStore(3114:3).3: mov $imm, ^131
	movq -2608(%rbp), %rax
	movl $-1202443627, (%rax)
	# LowerStore(3116:3).3: mov $imm, ^132
	movq -2616(%rbp), %rax
	movl $9, (%rax)
	# LowerStore(3118:3).3: mov $imm, ^133
	movq -2624(%rbp), %rax
	movl $1326141411, (%rax)
	# LowerStore(3120:3).3: mov $imm, ^134
	movq -2632(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(3122:3).3: mov $imm, ^135
	movq -2640(%rbp), %rax
	movl $-1, (%rax)
	# SetupCalls(3125:3): move argument ptr align 16 ^137
	movq -2656(%rbp), %rdi
	# SetupCalls(3125:3): move argument ptr align 16 @__const._ZL6func_1v.l_2564
	movq __const._ZL6func_1v.l_2564, %rsi
	# SetupCalls(3125:3): move argument i64 320
	movq $320, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(3128:3).3: mov $imm, ^138
	movq -2664(%rbp), %rax
	movl $0, (%rax)
	.___ZL6func_1v__M5140:
	# LowerLoad(3132:3).2: (^138) into ^937
	movq -2664(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(3133:3): i32 ^937 vs. intlike 8
	cmpl $8, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL6func_1v__M5146
	jmp .___ZL6func_1v__M5165
	.___ZL6func_1v__M5146:
	# LowerLoad(3137:3).2: (^138) into ^940
	movq -2664(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerGetelementptr(3139:3): struct-type: ptr ^136 -> ^942, indices=0,%941
	movq -2648(%rbp), %rcx
	movq %rbx, %rax
	shlq $3, %rax
	addq %rax, %rcx
	# LowerGetelementptr(3139:3): type of ^942 is ptr*
	# LowerStore(3140:3).3: mov $imm, ^942
	movl $-476256381, (%rcx)
	# LowerLoad(3144:3).2: (^138) into ^944
	movq -2664(%rbp), %rbx
	movl (%rbx), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(3146:3).9: mov ^945, (^138)
	movq -2664(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M5140
	.___ZL6func_1v__M5165:
	# LowerLoad(3153:3).2: (^4) into ^948
	movq -2168(%rbp), %rax
	movl (%rax), %ebx
	movl %ebx, %ecx
	addl $-1, %ecx
	# LowerStore(3155:3).9: mov ^949, (^4)
	movq -2168(%rbp), %rax
	movl %ecx, (%rax)
	jmp .___ZL6func_1v__M5094
	.___ZL6func_1v__M5173:
	# LowerStore(3159:3).2a: mov $imm, %temp
	movw $0, %ax
	# LowerStore(3159:3).2b: mov %temp, (global)
	movw %ax, _ZL5g_837@GOTPCREL(%rip)
	.___ZL6func_1v__M5178:
	# LowerLoad(3163:3).4: _ZL5g_837 into ^952
	movq _ZL5g_837, %rax
	movswl %ax, %ebx
	# LowerIcmp(3165:3): i32 ^953 vs. intlike 1
	cmpl $1, %ebx
	setl %al
	cmpb $0, %al
	jne .___ZL6func_1v__M5185
	jmp .___ZL6func_1v__M5244
	.___ZL6func_1v__M5185:
	# LowerStore(3169:3).2a: mov $imm, %temp
	movl $0, %eax
	# LowerStore(3169:3).2b: mov %temp, (global)
	movl %eax, _ZL6g_1939@GOTPCREL(%rip)
	.___ZL6func_1v__M5190:
	# LowerLoad(3173:3).4: _ZL6g_1939 into ^957
	movq _ZL6g_1939, %rax
	# LowerIcmp(3174:3): i32 ^957 vs. intlike 5
	cmpl $5, %eax
	setb %al
	cmpb $0, %al
	jne .___ZL6func_1v__M5196
	jmp .___ZL6func_1v__M5229
	.___ZL6func_1v__M5196:
	# LowerLoad(3178:3).4: _ZL5g_837 into ^960
	movq _ZL5g_837, %rax
	movswq %ax, %rbx
	movq _ZL6g_2324, %rax
	movq _ZL6g_2324, %rcx
	# LowerGetelementptr(3180:3): struct-type: ptr ^1157 -> ^962, indices=0,%961
	movq %rcx, %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(3180:3): type of ^962 is ptr*
	# LowerLoad(3181:3).4: _ZL6g_1939 into ^963
	movq _ZL6g_1939, %rbx
	# LowerBasicConversion(3182:3): ^963 -> ^964
	movq %rbx, %rcx
	# LowerGetelementptr(3183:3): struct-type: ptr ^962 -> ^965, indices=0,%964
	movq %rax, %rbx
	movq %rcx, %rax
	shlq $3, %rax
	addq %rax, %rbx
	# LowerGetelementptr(3183:3): type of ^965 is ptr*
	# LowerStore(3184:3).3: mov $imm, ^965
	movl $1769521508, (%rbx)
	# LowerLoad(3188:3).4: _ZL6g_1939 into ^967
	movq _ZL6g_1939, %rax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(3190:3).8a: movq var, %temp
	movq _ZL6g_1939@GOTPCREL(%rip), %rax
	# LowerStore(3190:3).8b: movq ^968, (%temp)
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M5190
	.___ZL6func_1v__M5229:
	# LowerLoad(3197:3).4: _ZL5g_837 into ^971
	movq _ZL5g_837, %rax
	movswl %ax, %ebx
	movl %ebx, %eax
	addl $1, %eax
	# LowerTrunc(3200:3): 32 to 16, move
	movw %ax, %bx
	# LowerTrunc(3200:3): 32 to 16, apply mask
	andw $65535, %bx
	# LowerStore(3201:3).8a: movq var, %temp
	movq _ZL5g_837@GOTPCREL(%rip), %rax
	# LowerStore(3201:3).8b: movq ^974, (%temp)
	movw %bx, (%rax)
	jmp .___ZL6func_1v__M5178
	.___ZL6func_1v__M5244:
	# LowerLoad(3205:3).4: _ZL6g_2504 into ^976
	movq _ZL6g_2504, %rax
	# LowerLoad(3206:3).2: (^976) into ^977
	movq (%rax), %rbx
	# LowerLoad(3207:3).2: (^977) into ^978
	movw (%rbx), %ax
	# LowerIcmp(3208:3): i16 ^978 vs. intlike 0
	cmpw $0, %ax
	setne %al
	cmpb $0, %al
	jne .___ZL6func_1v__M5257
	.___ZL6func_1v__M5254:
	# MovePhi: intlike -> ^984 (in new block 1232 whose parent is 975)
	movb $0, -2376(%rbp)
	jmp .___ZL6func_1v__M5265
	.___ZL6func_1v__M5257:
	# LowerLoad(3212:3).4: _ZL6g_1946 into ^981
	movq _ZL6g_1946, %rax
	# LowerIcmp(3213:3): i32 ^981 vs. intlike 0
	cmpl $0, %eax
	setne %al
	# MovePhi: ^982 -> ^984
	movb %al, -2376(%rbp)
	.___ZL6func_1v__M5265:
	# LowerBasicConversion(3218:3): ^984 -> ^985
	movq -2376(%rbp), %rbx
	# LowerGetelementptr(3219:3): struct-type: ptr ^109 -> ^986, indices=0,4
	movq -2496(%rbp), %rax
	addq $32, %rax
	# LowerGetelementptr(3219:3): type of ^986 is ptr*
	# LowerGetelementptr(3220:3): struct-type: ptr ^986 -> ^987, indices=0,5
	movq %rax, %rcx
	addq $40, %rcx
	# LowerGetelementptr(3220:3): type of ^987 is ptr*
	# LowerLoad(3221:3).2: (^987) into ^988
	movl (%rcx), %r12d
	# LowerLoad(3222:3).2: (^26) into ^989
	movq -2400(%rbp), %rax
	movl (%rax), %r13d
	# LowerLoad(3223:3).2: (^27) into ^990
	movq -2416(%rbp), %rax
	movq (%rax), %rcx
	# LowerIcmp(3224:3): i64 ^990 vs. intlike 0
	cmpq $0, %rcx
	setne %al
	movb %al, %cl
	xorb $1, %cl
	# LowerBasicConversion(3226:3): ^992 -> ^993
	movl %ecx, %r14d
	# LowerGetelementptr(3227:3): struct-type: ptr ^28 -> ^994, indices=0,3
	movq -2392(%rbp), %rax
	addq $24, %rax
	# LowerGetelementptr(3227:3): type of ^994 is ptr*
	# LowerLoad(3228:3).2: (^994) into ^995
	movl (%rax), %ecx
	movl %ecx, %edx
	addl $1, %edx
	# LowerStore(3230:3).9: mov ^996, (^994)
	movl %edx, (%rax)
	# LowerLoad(3231:3).4: _ZL5g_259 into ^997
	movq _ZL5g_259, %rax
	# LowerBasicConversion(3232:3): ^997 -> ^998
	movl %eax, %edx
	movl %edx, %eax
	xorl %ecx, %eax
	# LowerTrunc(3234:3): 32 to 8, move
	movb %al, %cl
	# LowerTrunc(3234:3): 32 to 8, apply mask
	andb $255, %cl
	# LowerStore(3235:3).8a: movq var, %temp
	movq _ZL5g_259@GOTPCREL(%rip), %rax
	# LowerStore(3235:3).8b: movq ^1000, (%temp)
	movb %cl, (%rax)
	# LowerBasicConversion(3236:3): ^1000 -> ^1001
	movl %ecx, %eax
	# LowerTrunc(3237:3): 32 to 8, move
	movb %al, %cl
	# LowerTrunc(3237:3): 32 to 8, apply mask
	andb $255, %cl
	# LowerLoad(3238:3).4: _ZL6g_2599 into ^1003
	movq _ZL6g_2599, %rax
	# LowerLoad(3239:3).2: (^110) into ^1004
	movq -2488(%rbp), %rax
	movq (%rax), %rdx
	movq _ZL6g_2186, %rax
	# LowerIcmp(3240:3): @_ZL6g_2186 ^1139 vs. operand ptr ^1004
	cmpq %rdx, %rax
	setne %al
	# LowerBasicConversion(3241:3): ^1005 -> ^1006
	movb %al, %dl
	# SetupCalls(3242:3): move argument i8 zeroext ^1002
	movb %cl, %dil
	andq $255, %rdi
	# SetupCalls(3242:3): move argument i8 zeroext ^1006
	movb %dl, %sil
	andq $255, %rsi
	callq _ZL25safe_add_func_uint8_t_u_uhh@GOTPCREL(%rip)
	# SetupCalls(3242:3): move result from %rax
	movb %al, %r15b
	# LowerBasicConversion(3243:3): ^1007 -> ^1008
	movq %r15, %rax
	movq %rax, %rcx
	orq $0, %rcx
	movq $0, %rax
	xorq %rcx, %rax
	# LowerTrunc(3246:3): 64 to 16, move
	movw %ax, %cx
	# LowerTrunc(3246:3): 64 to 16, apply mask
	andw $65535, %cx
	# LowerLoad(3247:3).2: (^106) into ^1012
	movq -2544(%rbp), %rdx
	movq (%rdx), %rax
	# LowerStore(3248:3).9: mov ^1011, (^1012)
	movw %cx, (%rax)
	# LowerLoad(3249:3).2: (^126) into ^1013
	movq -2560(%rbp), %rdx
	movw (%rdx), %ax
	# SetupCalls(3250:3): move argument i16 signext ^1011
	movw %cx, %di
	movswq %di, %rdi
	# SetupCalls(3250:3): move argument i16 signext ^1013
	movw %ax, %si
	movswq %si, %rsi
	callq _ZL25safe_add_func_int16_t_s_sss@GOTPCREL(%rip)
	# SetupCalls(3250:3): move result from %rax
	movw %ax, %r15w
	movswl %r15w, %ecx
	# LowerStore(3252:3).9: mov ^1015, (^22)
	movq -2368(%rbp), %rax
	movl %ecx, (%rax)
	# LowerIcmp(3253:3): i32 ^993 vs. operand i32 ^1015
	cmpl %ecx, %r14d
	setge %al
	# LowerGetelementptr(3254:3): struct-type: ptr ^15 -> ^1017, indices=0,2
	movq -2120(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(3254:3): type of ^1017 is ptr*
	# LowerGetelementptr(3255:3): struct-type: ptr ^1017 -> ^1018, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(3255:3): type of ^1018 is ptr*
	# LowerLoad(3256:3).2: (^1018) into ^1019
	movw (%rcx), %ax
	# LowerBasicConversion(3257:3): ^1019 -> ^1020
	movl %eax, %ecx
	# LowerLoad(3258:3).4: _ZL5g_453 into ^1021
	movq _ZL5g_453, %rax
	# LowerBasicConversion(3259:3): ^1021 -> ^1022
	movl %eax, %edx
	movl %ecx, %eax
	andl %edx, %eax
	# LowerTrunc(3261:3): 32 to 16, move
	movw %ax, %cx
	# LowerTrunc(3261:3): 32 to 16, apply mask
	andw $65535, %cx
	# SetupCalls(3262:3): move argument i16 zeroext ^1024
	movw %cx, %di
	andq $65535, %rdi
	# SetupCalls(3262:3): move argument i16 zeroext 0
	movq $0, %rsi
	andq $65535, %rsi
	callq _ZL26safe_mul_func_uint16_t_u_utt@GOTPCREL(%rip)
	# SetupCalls(3262:3): move result from %rax
	movw %ax, %r14w
	# LowerBasicConversion(3263:3): ^1025 -> ^1026
	movq %r14, %rax
	# LowerIcmp(3264:3): i64 ^1026 vs. intlike 8678000381446302913
	movabsq $8678000381446302913, %rcx
	cmpq %rcx, %rax
	setge %al
	# LowerBasicConversion(3265:3): ^1027 -> ^1028
	movw %ax, %cx
	# LowerLoad(3266:3).4: _ZL6g_2504 into ^1029
	movq _ZL6g_2504, %rax
	# LowerLoad(3267:3).2: (^1029) into ^1030
	movq (%rax), %rdx
	# LowerLoad(3268:3).2: (^1030) into ^1031
	movw (%rdx), %ax
	# SetupCalls(3269:3): move argument i16 zeroext ^1028
	movw %cx, %di
	andq $65535, %rdi
	# SetupCalls(3269:3): move argument i16 zeroext ^1031
	movw %ax, %si
	andq $65535, %rsi
	callq _ZL26safe_mul_func_uint16_t_u_utt@GOTPCREL(%rip)
	# SetupCalls(3269:3): move result from %rax
	movw %ax, %r14w
	# LowerBasicConversion(3270:3): ^1032 -> ^1033
	movl %r14d, %eax
	# LowerIcmp(3271:3): i32 ^989 vs. operand i32 ^1033
	cmpl %eax, %r13d
	setge %al
	# LowerBasicConversion(3272:3): ^1034 -> ^1035
	movl %eax, %ecx
	# LowerGetelementptr(3273:3): struct-type: ptr ^109 -> ^1036, indices=0,5
	movq -2496(%rbp), %rax
	addq $40, %rax
	# LowerGetelementptr(3273:3): type of ^1036 is ptr*
	# LowerGetelementptr(3274:3): struct-type: ptr ^1036 -> ^1037, indices=0,0
	movq %rax, %rdx
	# LowerGetelementptr(3274:3): type of ^1037 is ptr*
	# LowerLoad(3275:3).2: (^1037) into ^1038
	movl (%rdx), %eax
	movl %ecx, %edx
	orl %eax, %edx
	# SetupCalls(3277:3): move argument i32 ^988
	movl %r12d, %edi
	# SetupCalls(3277:3): move argument i32 ^1039
	movl %edx, %esi
	callq _ZL25safe_sub_func_int32_t_s_sii@GOTPCREL(%rip)
	# SetupCalls(3277:3): move result from %rax
	movl %eax, %r12d
	# LowerLoad(3278:3).2: (^2) into ^1041
	movq -2128(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(3279:3): move argument i32 ^1040
	movl %r12d, %edi
	# SetupCalls(3279:3): move argument i32 ^1041
	movl %ecx, %esi
	callq _ZL25safe_sub_func_int32_t_s_sii@GOTPCREL(%rip)
	# SetupCalls(3279:3): move result from %rax
	movl %eax, %r12d
	# LowerLoad(3280:3).4: _ZL6g_2504 into ^1043
	movq _ZL6g_2504, %rax
	# LowerLoad(3281:3).2: (^1043) into ^1044
	movq (%rax), %rcx
	# LowerLoad(3282:3).2: (^1044) into ^1045
	movw (%rcx), %ax
	# LowerBasicConversion(3283:3): ^1045 -> ^1046
	movl %eax, %ecx
	movl %r12d, %eax
	xorl %ecx, %eax
	# LowerTrunc(3285:3): 32 to 16, move
	movw %ax, %cx
	# LowerTrunc(3285:3): 32 to 16, apply mask
	andw $65535, %cx
	# LowerLoad(3286:3).2: (^127) into ^1049
	movq -2528(%rbp), %rdx
	movq (%rdx), %rax
	# LowerStore(3287:3).9: mov ^1048, (^1049)
	movw %cx, (%rax)
	# LowerBasicConversion(3288:3): ^1048 -> ^1050
	movl %ecx, %eax
	# LowerGetelementptr(3289:3): struct-type: ptr ^109 -> ^1051, indices=0,5
	movq -2496(%rbp), %rcx
	addq $40, %rcx
	# LowerGetelementptr(3289:3): type of ^1051 is ptr*
	# LowerGetelementptr(3290:3): struct-type: ptr ^1051 -> ^1052, indices=0,0
	movq %rcx, %rdx
	# LowerGetelementptr(3290:3): type of ^1052 is ptr*
	# LowerLoad(3291:3).2: (^1052) into ^1053
	movl (%rdx), %ecx
	movl %eax, %edx
	orl %ecx, %edx
	movslq %edx, %rcx
	# LowerLoad(3294:3).2: (^110) into ^1056
	movq -2488(%rbp), %rax
	movq (%rax), %rdx
	# LowerStore(3295:3).9: mov ^1055, (^1056)
	movq %rcx, (%rdx)
	# SetupCalls(3296:3): move argument i64 ^1055
	movq %rcx, %rdi
	# SetupCalls(3296:3): move argument i32 36
	movq $36, %rsi
	callq _ZL29safe_rshift_func_uint64_t_u_umj@GOTPCREL(%rip)
	# SetupCalls(3296:3): move result from %rax
	movq %rax, %r12
	# LowerIcmp(3297:3): i64 ^985 vs. operand i64 ^1057
	cmpq %r12, %rbx
	seta %al
	# LowerBasicConversion(3298:3): ^1058 -> ^1059
	movl %eax, %ebx
	# LowerLoad(3299:3).4: _ZL5g_140 into ^1060
	movq _ZL5g_140, %rax
	# LowerStore(3300:3).9: mov ^1059, (^1060)
	movl %ebx, (%rax)
	jmp .___ZL6func_1v__M5704
	.___ZL6func_1v__M5639:
	# LowerStore(3304:3).2a: mov $imm, %temp
	movl $0, %eax
	# LowerStore(3304:3).2b: mov %temp, (global)
	movl %eax, _ZL6g_1904@GOTPCREL(%rip)
	# LowerLoad(3308:3).4: _ZL6g_1904 into ^1063
	movq _ZL6g_1904, %rax
	# LowerIcmp(3309:3): i32 ^1063 vs. intlike 20
	cmpl $20, %eax
	setbe %al
	cmpb $0, %al
	jne .___ZL6func_1v__M5650
	jmp .___ZL6func_1v__M5678
	.___ZL6func_1v__M5650:
	# LowerLoad(3313:3).4: _ZL5g_452 into ^1066
	movq _ZL5g_452, %rax
	# SetupCalls(3314:3): move argument ptr align 2 ^1
	movq -2104(%rbp), %rdi
	# SetupCalls(3314:3): move argument ptr align 2 ^1066
	movq %rax, %rsi
	# SetupCalls(3314:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	jmp .___ZL6func_1v__M5733
	.___ZL6func_1v__M5678:
	# SetupCalls(3324:3): move argument ptr align 2 ^1
	movq -2104(%rbp), %rdi
	# SetupCalls(3324:3): move argument ptr align 2 ^111
	movq -2728(%rbp), %rsi
	# SetupCalls(3324:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	jmp .___ZL6func_1v__M5733
	.___ZL6func_1v__M5704:
	.___ZL6func_1v__M5705:
	# LowerLoad(3331:3).2: (^13) into ^1073
	movq -2112(%rbp), %rax
	movq (%rax), %rbx
	# SetupCalls(3332:3): move argument ptr align 2 ^1
	movq -2104(%rbp), %rdi
	# SetupCalls(3332:3): move argument ptr align 2 ^1073
	movq %rbx, %rsi
	# SetupCalls(3332:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	.___ZL6func_1v__M5733:
	# LowerGetelementptr(3336:3): struct-type: ptr ^1 -> ^1075, indices=0,0
	movq -2104(%rbp), %rbx
	# LowerGetelementptr(3336:3): type of ^1075 is ptr*
	# LowerLoad(3337:3).2: (^1075) into ^1076
	movw (%rbx), %ax
	movq -4464(%rbp), %r15
	movq -3104(%rbp), %r14
	movq -3096(%rbp), %r13
	movq -3088(%rbp), %r12
	movq -3080(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_rshift_func_int64_t_s_ulj
.p2align 4, 0x90
_ZL28safe_rshift_func_int64_t_s_ulj:
	.___ZL28safe_rshift_func_int64_t_s_ulj__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(64 + 0, 16)
	subq $64, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(6063:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(6064:3): size = 4, type = i32*, var = ^4
	leaq -12(%rbp), %rax
	# LowerStore(6065:3).9: mov %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(6067:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(6069:3).2: (^3) into ^5
	movq (%rcx), %rbx
	# LowerIcmp(6070:3): i64 ^5 vs. intlike 0
	cmpq $0, %rbx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int64_t_s_ulj__M20
	.___ZL28safe_rshift_func_int64_t_s_ulj__M14:
	# LowerLoad(6074:3).2: (^4) into ^8
	movl (%rax), %ebx
	# LowerIcmp(6075:3): i32 ^8 vs. intlike 32
	cmpl $32, %ebx
	setae %bl
	cmpb $0, %bl
	jne .___ZL28safe_rshift_func_int64_t_s_ulj__M20
	jmp .___ZL28safe_rshift_func_int64_t_s_ulj__M25
	.___ZL28safe_rshift_func_int64_t_s_ulj__M20:
	# LowerLoad(6079:3).2: (^3) into ^11
	movq (%rcx), %rax
	# MovePhi: ^11 -> ^18
	movq %rax, %rbx
	jmp .___ZL28safe_rshift_func_int64_t_s_ulj__M38
	.___ZL28safe_rshift_func_int64_t_s_ulj__M25:
	# LowerLoad(6083:3).2: (^3) into ^13
	movq (%rcx), %rdx
	# LowerLoad(6084:3).2: (^4) into ^14
	movl (%rax), %ebx
	# LowerBasicConversion(6085:3): ^14 -> ^15
	movq %rbx, %rax
	# LowerShift(6086:3): operand ^15 changed to %cl
	movb %al, %cl
	movq %rdx, %rax
	sarq %cl, %rax
	# MovePhi: ^16 -> ^18
	movq %rax, %rbx
	.___ZL28safe_rshift_func_int64_t_s_ulj__M38:
	movq %rbx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_add_func_int32_t_s_sii
.p2align 4, 0x90
_ZL25safe_add_func_int32_t_s_sii:
	.___ZL25safe_add_func_int32_t_s_sii__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(120 + 0, 16)
	subq $128, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(4760:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rcx
	# LowerAlloca(4761:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(4762:3).9: mov %edi, (^3)
	movl %edi, (%rcx)
	# LowerStore(4764:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(4766:3).2: (^3) into ^5
	movl (%rcx), %ebx
	# LowerIcmp(4767:3): i32 ^5 vs. intlike 0
	cmpl $0, %ebx
	setg %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M14
	jmp .___ZL25safe_add_func_int32_t_s_sii__M30
	.___ZL25safe_add_func_int32_t_s_sii__M14:
	# LowerLoad(4771:3).2: (^4) into ^8
	movl (%rax), %ebx
	# LowerIcmp(4772:3): i32 ^8 vs. intlike 0
	cmpl $0, %ebx
	setg %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M20
	jmp .___ZL25safe_add_func_int32_t_s_sii__M30
	.___ZL25safe_add_func_int32_t_s_sii__M20:
	# LowerLoad(4776:3).2: (^3) into ^11
	movl (%rcx), %esi
	# LowerLoad(4777:3).2: (^4) into ^12
	movl (%rax), %edx
	movl $2147483647, %ebx
	subl %edx, %ebx
	# LowerIcmp(4779:3): i32 ^11 vs. operand i32 ^13
	cmpl %ebx, %esi
	setg %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M52
	.___ZL25safe_add_func_int32_t_s_sii__M30:
	# LowerLoad(4783:3).2: (^3) into ^16
	movl (%rcx), %ebx
	# LowerIcmp(4784:3): i32 ^16 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M36
	jmp .___ZL25safe_add_func_int32_t_s_sii__M57
	.___ZL25safe_add_func_int32_t_s_sii__M36:
	# LowerLoad(4788:3).2: (^4) into ^19
	movl (%rax), %ebx
	# LowerIcmp(4789:3): i32 ^19 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M42
	jmp .___ZL25safe_add_func_int32_t_s_sii__M57
	.___ZL25safe_add_func_int32_t_s_sii__M42:
	# LowerLoad(4793:3).2: (^3) into ^22
	movl (%rcx), %ebx
	# LowerLoad(4794:3).2: (^4) into ^23
	movl (%rax), %edx
	movl $-2147483648, %esi
	subl %edx, %esi
	# LowerIcmp(4796:3): i32 ^22 vs. operand i32 ^24
	cmpl %esi, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL25safe_add_func_int32_t_s_sii__M52
	jmp .___ZL25safe_add_func_int32_t_s_sii__M57
	.___ZL25safe_add_func_int32_t_s_sii__M52:
	# LowerLoad(4800:3).2: (^3) into ^27
	movl (%rcx), %eax
	# MovePhi: ^27 -> ^33
	movl %eax, %ebx
	jmp .___ZL25safe_add_func_int32_t_s_sii__M66
	.___ZL25safe_add_func_int32_t_s_sii__M57:
	# LowerLoad(4804:3).2: (^3) into ^29
	movl (%rcx), %ebx
	# LowerLoad(4805:3).2: (^4) into ^30
	movl (%rax), %ecx
	movl %ebx, %eax
	addl %ecx, %eax
	# MovePhi: ^31 -> ^33
	movl %eax, %ebx
	.___ZL25safe_add_func_int32_t_s_sii__M66:
	movl %ebx, %eax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL7func_47ij2U4t2U0
.p2align 4, 0x90
_ZL7func_47ij2U4t2U0:
	.___ZL7func_47ij2U4t2U0__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	movq %rbx, -32(%rbp)
	movq %r12, -40(%rbp)
	# LowerAlloca(4816:3): size = 2, type = %union.U4*, var = ^6
	leaq -2(%rbp), %rax
	# LowerAlloca(4817:3): size = 4, type = %union.U0*, var = ^7
	leaq -8(%rbp), %r11
	# LowerAlloca(4818:3): size = 4, type = i32*, var = ^8
	leaq -12(%rbp), %r9
	# LowerAlloca(4819:3): size = 4, type = i32*, var = ^9
	leaq -16(%rbp), %rbx
	# LowerAlloca(4820:3): size = 2, type = i16*, var = ^10
	leaq -18(%rbp), %r10
	# LowerGetelementptr(4821:3): struct-type: ptr ^6 -> ^11, indices=0,0
	movq %rax, %r12
	# LowerGetelementptr(4821:3): type of ^11 is ptr*
	# LowerStore(4822:3).9: mov %dx, (^11)
	movw %dx, (%r12)
	# LowerGetelementptr(4823:3): struct-type: ptr ^7 -> ^12, indices=0,0
	movq %r11, %rax
	# LowerGetelementptr(4823:3): type of ^12 is ptr*
	# LowerStore(4824:3).9: mov %r8d, (^12)
	movl %r8d, (%rax)
	# LowerStore(4825:3).9: mov %edi, (^8)
	movl %edi, (%r9)
	# LowerStore(4827:3).9: mov %esi, (^9)
	movl %esi, (%rbx)
	# LowerStore(4830:3).9: mov %cx, (^10)
	movw %cx, (%r10)
	# LowerLoad(4833:3).4: _ZL5g_140 into ^13
	movq _ZL5g_140, %rbx
	# LowerLoad(4834:3).2: (^13) into ^14
	movl (%rbx), %eax
	movq -40(%rbp), %r12
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL7func_532U1
.p2align 4, 0x90
_ZL7func_532U1:
	.___ZL7func_532U1__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(2136 + 0, 16)
	subq $2144, %rsp
	movq %rbx, -1688(%rbp)
	movq %r12, -1712(%rbp)
	movq %r13, -1720(%rbp)
	movq %r14, -1704(%rbp)
	movq %r15, -1696(%rbp)
	# LowerAlloca(4840:3): size = 4, type = i32*, var = ^2
	# Fixing leaq -4(%rbp), -1520(%rbp)
	leaq -4(%rbp), %r15
	movq %r15, -1520(%rbp)
	# LowerAlloca(4841:3): size = 2, type = %union.U1*, var = ^3
	# Fixing leaq -6(%rbp), -1528(%rbp)
	leaq -6(%rbp), %r15
	movq %r15, -1528(%rbp)
	# LowerAlloca(4842:3): size = 4, type = %union.U0*, var = ^4
	leaq -12(%rbp), %rax
	# LowerAlloca(4843:3): size = 8, type = ptr*, var = ^5
	leaq -24(%rbp), %rbx
	# LowerAlloca(4844:3): size = 72, type = [9 x ptr]*, var = ^6
	leaq -96(%rbp), %rcx
	# LowerAlloca(4845:3): size = 8, type = ptr*, var = ^7
	# Fixing leaq -104(%rbp), -1544(%rbp)
	leaq -104(%rbp), %r15
	movq %r15, -1544(%rbp)
	# LowerAlloca(4846:3): size = 8, type = ptr*, var = ^8
	# Fixing leaq -112(%rbp), -1584(%rbp)
	leaq -112(%rbp), %r15
	movq %r15, -1584(%rbp)
	# LowerAlloca(4847:3): size = 1344, type = [6 x [7 x [4 x ptr]]]*, var = ^9
	# Fixing leaq -1456(%rbp), -1568(%rbp)
	leaq -1456(%rbp), %r15
	movq %r15, -1568(%rbp)
	# LowerAlloca(4848:3): size = 8, type = ptr*, var = ^10
	# Fixing leaq -1464(%rbp), -1560(%rbp)
	leaq -1464(%rbp), %r15
	movq %r15, -1560(%rbp)
	# LowerAlloca(4849:3): size = 4, type = i32*, var = ^11
	leaq -1468(%rbp), %r15
	# LowerAlloca(4850:3): size = 4, type = i32*, var = ^12
	leaq -1472(%rbp), %r14
	# LowerAlloca(4851:3): size = 16, type = [4 x i32]*, var = ^13
	leaq -1488(%rbp), %r12
	# LowerAlloca(4852:3): size = 14, type = [7 x i16]*, var = ^14
	# Fixing leaq -1502(%rbp), -1552(%rbp)
	leaq -1502(%rbp), %r15
	movq %r15, -1552(%rbp)
	# LowerAlloca(4853:3): size = 4, type = i32*, var = ^15
	leaq -1508(%rbp), %rdx
	andq $-4, %rsp
	# LowerAlloca(4854:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4854:3): mov %rsp, ^16
	movq %rsp, %rdx
	andq $-4, %rsp
	# LowerAlloca(4855:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4855:3): mov %rsp, ^17
	movq %rsp, %rdx
	andq $-16, %rsp
	# LowerAlloca(4856:3): %rsp -= to_sub
	subq $80, %rsp
	# LowerAlloca(4856:3): mov %rsp, ^18
	movq %rsp, -1624(%rbp)
	andq $-8, %rsp
	# LowerAlloca(4857:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4857:3): mov %rsp, ^19
	movq %rsp, -1608(%rbp)
	andq $-8, %rsp
	# LowerAlloca(4858:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4858:3): mov %rsp, ^20
	movq %rsp, -1616(%rbp)
	andq $-8, %rsp
	# LowerAlloca(4859:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4859:3): mov %rsp, ^21
	movq %rsp, -1664(%rbp)
	andq $-8, %rsp
	# LowerAlloca(4860:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4860:3): mov %rsp, ^22
	movq %rsp, -1600(%rbp)
	andq $-4, %rsp
	# LowerAlloca(4861:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4861:3): mov %rsp, ^23
	movq %rsp, -1576(%rbp)
	andq $-8, %rsp
	# LowerAlloca(4862:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4862:3): mov %rsp, ^24
	movq %rsp, -1680(%rbp)
	andq $-16, %rsp
	# LowerAlloca(4863:3): %rsp -= to_sub
	subq $360, %rsp
	# LowerAlloca(4863:3): mov %rsp, ^25
	movq %rsp, %r13
	andq $-8, %rsp
	# LowerAlloca(4864:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4864:3): mov %rsp, ^26
	movq %rsp, -1632(%rbp)
	andq $-2, %rsp
	# LowerAlloca(4865:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4865:3): mov %rsp, ^27
	movq %rsp, -1640(%rbp)
	andq $-2, %rsp
	# LowerAlloca(4866:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4866:3): mov %rsp, ^28
	movq %rsp, -1648(%rbp)
	andq $-2, %rsp
	# LowerAlloca(4867:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4867:3): mov %rsp, ^29
	movq %rsp, -1592(%rbp)
	andq $-4, %rsp
	# LowerAlloca(4868:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4868:3): mov %rsp, ^30
	movq %rsp, -1656(%rbp)
	andq $-4, %rsp
	# LowerAlloca(4869:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4869:3): mov %rsp, ^31
	movq %rsp, %rdx
	andq $-4, %rsp
	# LowerAlloca(4870:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4870:3): mov %rsp, ^32
	movq %rsp, %rdx
	andq $-4, %rsp
	# LowerAlloca(4871:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(4871:3): mov %rsp, ^33
	movq %rsp, %rdx
	# LowerGetelementptr(4872:3): struct-type: ptr ^3 -> ^34, indices=0,0
	movq -1528(%rbp), %rdx
	# LowerGetelementptr(4872:3): type of ^34 is ptr*
	# LowerStore(4873:3).9: mov %di, (^34)
	movw %di, (%rdx)
	# LowerStore(4876:3).3: mov $imm, ^4
	movl $0, (%rax)
	# LowerStore(4878:3).6: load global
	movq _ZL5g_366@GOTPCREL(%rip), %rax
	# LowerStore(4878:3).9: mov ^164, (^5)
	movq %rax, (%rbx)
	# SetupCalls(4880:3): move argument ptr align 16 ^6
	movq %rcx, %rdi
	# SetupCalls(4880:3): move argument ptr align 16 @__const._ZL7func_532U1.l_659
	movq __const._ZL7func_532U1.l_659, %rsi
	# SetupCalls(4880:3): move argument i64 72
	movq $72, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	movq _ZL5g_422, %rcx
	addq $40, %rcx
	# LowerStore(4882:3).9: mov ^159, (^7)
	movq -1544(%rbp), %rax
	movq %rcx, (%rax)
	# LowerStore(4884:3).3: mov $imm, ^8
	movq -1584(%rbp), %rax
	movq $0, (%rax)
	# SetupCalls(4886:3): move argument ptr align 16 ^9
	movq -1568(%rbp), %rdi
	# SetupCalls(4886:3): move argument ptr align 16 @__const._ZL7func_532U1.l_672
	movq __const._ZL7func_532U1.l_672, %rsi
	# SetupCalls(4886:3): move argument i64 1344
	movq $1344, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(4888:3).3: mov $imm, ^10
	movq -1560(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(4890:3).3: mov $imm, ^11
	movl $-1416764660, (%r15)
	# LowerStore(4892:3).3: mov $imm, ^12
	movl $-1, (%r14)
	# SetupCalls(4894:3): move argument ptr align 16 ^13
	movq %r12, %rdi
	# SetupCalls(4894:3): move argument ptr align 16 @__const._ZL7func_532U1.l_681
	movq __const._ZL7func_532U1.l_681, %rsi
	# SetupCalls(4894:3): move argument i64 16
	movq $16, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# SetupCalls(4896:3): move argument ptr align 2 ^14
	movq -1552(%rbp), %rdi
	# SetupCalls(4896:3): move argument ptr align 2 @__const._ZL7func_532U1.l_689
	movq __const._ZL7func_532U1.l_689, %rsi
	# SetupCalls(4896:3): move argument i64 14
	movq $14, %rdx
	# SetupCalls(4896:3): move argument i1 false
	movq $0, %rcx
	callq llvm.memcpy.p0.p0.i64@PLT@GOTPCREL(%rip)
	# LowerLoad(4900:3).4: _ZL5g_422 into ^35
	movq _ZL5g_422, %rax
	# LowerIcmp(4901:3): i32 ^35 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .___ZL7func_532U1__M251
	jmp .___ZL7func_532U1__M254
	.___ZL7func_532U1__M251:
	# MovePhi: intlike -> ^54 (in new block 182 whose parent is 153)
	movb $1, -1672(%rbp)
	jmp .___ZL7func_532U1__M344
	.___ZL7func_532U1__M254:
	# LowerLoad(4905:3).2: (^5) into ^38
	movq (%rbx), %rax
	# LowerStore(4906:3).8a: movq var, %temp
	movq _ZL5g_365@GOTPCREL(%rip), %rbx
	# LowerStore(4906:3).8b: movq ^38, (%temp)
	movq %rax, (%rbx)
	movq _ZL5g_366, %rbx
	# LowerIcmp(4907:3): @_ZL5g_366 ^163 vs. operand ptr ^38
	cmpq %rax, %rbx
	sete %al
	# LowerBasicConversion(4908:3): ^39 -> ^40
	movl %eax, %ebx
	# LowerLoad(4909:3).4: _ZL5g_448 into ^41
	movq _ZL5g_448, %rax
	# LowerLoad(4910:3).2: (^41) into ^42
	movl (%rax), %ecx
	# SetupCalls(4911:3): move argument i32 1
	movq $1, %rdi
	# SetupCalls(4911:3): move argument i32 ^42
	movl %ecx, %esi
	callq _ZL26safe_add_func_uint32_t_u_ujj@GOTPCREL(%rip)
	# SetupCalls(4911:3): move result from %rax
	movl %eax, %eax
	# LowerLoad(4912:3).4: _ZL5g_246 into ^44
	movq _ZL5g_246, %rax
	# LowerTrunc(4913:3): 32 to 16, move
	movw %ax, %dx
	# LowerTrunc(4913:3): 32 to 16, apply mask
	andw $65535, %dx
	# LowerLoad(4914:3).2: (^3) into ^46
	movq -1528(%rbp), %rcx
	movb (%rcx), %al
	movsbw %al, %cx
	# SetupCalls(4916:3): move argument i16 signext ^45
	movw %dx, %di
	movswq %di, %rdi
	# SetupCalls(4916:3): move argument i16 signext ^47
	movw %cx, %si
	movswq %si, %rsi
	callq _ZL25safe_add_func_int16_t_s_sss@GOTPCREL(%rip)
	# SetupCalls(4916:3): move result from %rax
	movw %ax, %r12w
	movswl %r12w, %eax
	# LowerIcmp(4918:3): i32 ^40 vs. operand i32 ^49
	cmpl %eax, %ebx
	setne %al
	# LowerBasicConversion(4919:3): ^50 -> ^51
	movq %rax, %rbx
	# LowerIcmp(4920:3): i64 ^51 vs. intlike 1
	cmpq $1, %rbx
	setb %bl
	# MovePhi: ^52 -> ^54
	movb %bl, -1672(%rbp)
	.___ZL7func_532U1__M344:
	# LowerBasicConversion(4925:3): ^54 -> ^55
	movl -1672(%rbp), %ebx
	movl %ebx, %eax
	orl $12039, %eax
	movslq %eax, %rbx
	# LowerStore(4928:3).8a: movq var, %temp
	movq _ZL5g_245@GOTPCREL(%rip), %rax
	# LowerStore(4928:3).8b: movq ^57, (%temp)
	movq %rbx, (%rax)
	# LowerLoad(4929:3).2: (^3) into ^58
	movq -1528(%rbp), %rcx
	movb (%rcx), %al
	movsbq %al, %rcx
	# LowerIcmp(4931:3): i64 ^57 vs. operand i64 ^59
	cmpq %rcx, %rbx
	setg %al
	# LowerBasicConversion(4932:3): ^60 -> ^61
	movl %eax, %ebx
	# LowerLoad(4933:3).2: (^3) into ^62
	movq -1528(%rbp), %rcx
	movb (%rcx), %al
	movsbl %al, %ecx
	# LowerIcmp(4935:3): i32 ^61 vs. operand i32 ^63
	cmpl %ecx, %ebx
	setg %al
	# LowerBasicConversion(4936:3): ^64 -> ^65
	movl %eax, %ebx
	# LowerLoad(4937:3).2: (^7) into ^66
	movq -1544(%rbp), %rcx
	movq (%rcx), %rax
	# LowerStore(4938:3).9: mov ^65, (^66)
	movl %ebx, (%rax)
	cmpb $0, %al
	jne .___ZL7func_532U1__M374
	jmp .___ZL7func_532U1__M380
	.___ZL7func_532U1__M374:
	# LowerLoad(4942:3).2: (^3) into ^68
	movq -1528(%rbp), %rbx
	movb (%rbx), %al
	movsbl %al, %ebx
	# LowerStore(4944:3).9: mov ^69, (^2)
	movq -1520(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL7func_532U1__M862
	.___ZL7func_532U1__M380:
	# SetupCalls(4949:3): move argument ptr align 16 ^18
	movq -1624(%rbp), %rdi
	# SetupCalls(4949:3): move argument ptr align 16 @__const._ZL7func_532U1.l_665
	movq __const._ZL7func_532U1.l_665, %rsi
	# SetupCalls(4949:3): move argument i64 80
	movq $80, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(4951:3).6: load global
	movq _ZL5g_667@GOTPCREL(%rip), %rax
	# LowerStore(4951:3).9: mov ^167, (^19)
	movq -1608(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(4953:3).9: mov ^19, (^20)
	movq -1616(%rbp), %rax
	# Fixing movq -1608(%rbp), (%rax)
	movq -1608(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(4955:3).6: load global
	movq _ZL5g_667@GOTPCREL(%rip), %rax
	# LowerStore(4955:3).9: mov ^168, (^21)
	movq -1664(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(4957:3).9: mov ^21, (^22)
	movq -1600(%rbp), %rax
	# Fixing movq -1664(%rbp), (%rax)
	movq -1664(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(4959:3).3: mov $imm, ^23
	movq -1576(%rbp), %rax
	movl $-9, (%rax)
	movq _ZL5g_149, %rax
	addq $32, %rax
	# LowerStore(4961:3).9: mov ^160, (^24)
	movq -1680(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerGetelementptr(4963:3): struct-type: ptr ^25 -> ^71, indices=0,0
	movq %r13, %rbx
	# LowerGetelementptr(4963:3): type of ^71 is ptr*
	# LowerGetelementptr(4964:3): struct-type: ptr ^71 -> ^72, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(4964:3): type of ^72 is ptr*
	# SetupCalls(4965:3): move argument ptr align 8 ^71
	movq %rbx, %rdi
	# SetupCalls(4965:3): move argument ptr align 8 @constinit.126
	movq constinit.126, %rsi
	# SetupCalls(4965:3): move argument i64 40
	movq $40, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerGetelementptr(4966:3): struct-type: ptr ^71 -> ^73, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(4966:3): type of ^73 is ptr*
	# LowerGetelementptr(4967:3): struct-type: ptr ^73 -> ^74, indices=0,0
	movq %rcx, %rax
	# LowerGetelementptr(4967:3): type of ^74 is ptr*
	# LowerStore(4968:3).6: load global
	movq _ZL5g_422@GOTPCREL(%rip), %rbx
	# LowerStore(4968:3).9: mov ^169, (^74)
	movq %rbx, (%rax)
	# LowerGetelementptr(4969:3): struct-type: ptr ^74 -> ^75, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(4969:3): type of ^75 is ptr*
	# LowerStore(4970:3).3: mov $imm, ^75
	movq $0, (%rbx)
	# LowerGetelementptr(4971:3): struct-type: ptr ^75 -> ^76, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(4971:3): type of ^76 is ptr*
	# LowerStore(4972:3).9: mov ^23, (^76)
	# Fixing movq -1576(%rbp), (%rax)
	movq -1576(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(4973:3): struct-type: ptr ^76 -> ^77, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(4973:3): type of ^77 is ptr*
	# LowerStore(4974:3).6: load global
	movq _ZL3g_2@GOTPCREL(%rip), %rax
	# LowerStore(4974:3).9: mov ^170, (^77)
	movq %rax, (%rbx)
	# LowerGetelementptr(4975:3): struct-type: ptr ^77 -> ^78, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(4975:3): type of ^78 is ptr*
	# LowerStore(4976:3).9: mov ^23, (^78)
	# Fixing movq -1576(%rbp), (%rax)
	movq -1576(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(4977:3): struct-type: ptr ^73 -> ^79, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(4977:3): type of ^79 is ptr*
	# LowerGetelementptr(4978:3): struct-type: ptr ^79 -> ^80, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(4978:3): type of ^80 is ptr*
	# LowerStore(4979:3).9: mov ^23, (^80)
	# Fixing movq -1576(%rbp), (%rbx)
	movq -1576(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(4980:3): struct-type: ptr ^80 -> ^81, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(4980:3): type of ^81 is ptr*
	# LowerStore(4981:3).9: mov ^23, (^81)
	# Fixing movq -1576(%rbp), (%rcx)
	movq -1576(%rbp), %r15
	movq %r15, (%rcx)
	# LowerGetelementptr(4982:3): struct-type: ptr ^81 -> ^82, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(4982:3): type of ^82 is ptr*
	# LowerStore(4983:3).3: mov $imm, ^82
	movq $0, (%rbx)
	# LowerGetelementptr(4984:3): struct-type: ptr ^82 -> ^83, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(4984:3): type of ^83 is ptr*
	# LowerStore(4985:3).6: load global
	movq _ZL3g_2@GOTPCREL(%rip), %rbx
	# LowerStore(4985:3).9: mov ^171, (^83)
	movq %rbx, (%rcx)
	# LowerGetelementptr(4986:3): struct-type: ptr ^83 -> ^84, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(4986:3): type of ^84 is ptr*
	# LowerStore(4987:3).6: load global
	movq _ZL3g_2@GOTPCREL(%rip), %rcx
	# LowerStore(4987:3).9: mov ^172, (^84)
	movq %rcx, (%rbx)
	# LowerGetelementptr(4988:3): struct-type: ptr ^79 -> ^85, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(4988:3): type of ^85 is ptr*
	# LowerGetelementptr(4989:3): struct-type: ptr ^85 -> ^86, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(4989:3): type of ^86 is ptr*
	# LowerStore(4990:3).3: mov $imm, ^86
	movq $0, (%rax)
	# LowerGetelementptr(4991:3): struct-type: ptr ^86 -> ^87, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(4991:3): type of ^87 is ptr*
	# LowerStore(4992:3).6: load global
	movq _ZL5g_422@GOTPCREL(%rip), %rax
	# LowerStore(4992:3).9: mov ^173, (^87)
	movq %rax, (%rcx)
	# LowerGetelementptr(4993:3): struct-type: ptr ^87 -> ^88, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(4993:3): type of ^88 is ptr*
	# LowerStore(4994:3).6: load global
	movq _ZL5g_422@GOTPCREL(%rip), %rcx
	# LowerStore(4994:3).9: mov ^174, (^88)
	movq %rcx, (%rax)
	# LowerGetelementptr(4995:3): struct-type: ptr ^88 -> ^89, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(4995:3): type of ^89 is ptr*
	# LowerStore(4996:3).3: mov $imm, ^89
	movq $0, (%rcx)
	# LowerGetelementptr(4997:3): struct-type: ptr ^89 -> ^90, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(4997:3): type of ^90 is ptr*
	# LowerStore(4998:3).9: mov ^23, (^90)
	# Fixing movq -1576(%rbp), (%rax)
	movq -1576(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(4999:3): struct-type: ptr ^85 -> ^91, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(4999:3): type of ^91 is ptr*
	# LowerGetelementptr(5000:3): struct-type: ptr ^91 -> ^92, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5000:3): type of ^92 is ptr*
	# LowerStore(5001:3).3: mov $imm, ^92
	movq $0, (%rbx)
	# LowerGetelementptr(5002:3): struct-type: ptr ^92 -> ^93, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5002:3): type of ^93 is ptr*
	# LowerStore(5003:3).6: load global
	movq _ZL3g_2@GOTPCREL(%rip), %rbx
	# LowerStore(5003:3).9: mov ^175, (^93)
	movq %rbx, (%rcx)
	# LowerGetelementptr(5004:3): struct-type: ptr ^93 -> ^94, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5004:3): type of ^94 is ptr*
	# LowerStore(5005:3).9: mov ^23, (^94)
	# Fixing movq -1576(%rbp), (%rbx)
	movq -1576(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(5006:3): struct-type: ptr ^94 -> ^95, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5006:3): type of ^95 is ptr*
	# LowerStore(5007:3).9: mov ^23, (^95)
	# Fixing movq -1576(%rbp), (%rcx)
	movq -1576(%rbp), %r15
	movq %r15, (%rcx)
	# LowerGetelementptr(5008:3): struct-type: ptr ^95 -> ^96, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5008:3): type of ^96 is ptr*
	# LowerStore(5009:3).6: load global
	movq _ZL3g_2@GOTPCREL(%rip), %rcx
	# LowerStore(5009:3).9: mov ^176, (^96)
	movq %rcx, (%rbx)
	# LowerGetelementptr(5010:3): struct-type: ptr ^91 -> ^97, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5010:3): type of ^97 is ptr*
	# LowerGetelementptr(5011:3): struct-type: ptr ^97 -> ^98, indices=0,0
	movq %rbx, %rcx
	# LowerGetelementptr(5011:3): type of ^98 is ptr*
	# LowerStore(5012:3).9: mov ^23, (^98)
	# Fixing movq -1576(%rbp), (%rcx)
	movq -1576(%rbp), %r15
	movq %r15, (%rcx)
	# LowerGetelementptr(5013:3): struct-type: ptr ^98 -> ^99, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5013:3): type of ^99 is ptr*
	# LowerStore(5014:3).6: load global
	movq _ZL5g_422@GOTPCREL(%rip), %rcx
	# LowerStore(5014:3).9: mov ^177, (^99)
	movq %rcx, (%rax)
	# LowerGetelementptr(5015:3): struct-type: ptr ^99 -> ^100, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5015:3): type of ^100 is ptr*
	# LowerStore(5016:3).9: mov ^23, (^100)
	# Fixing movq -1576(%rbp), (%rcx)
	movq -1576(%rbp), %r15
	movq %r15, (%rcx)
	# LowerGetelementptr(5017:3): struct-type: ptr ^100 -> ^101, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5017:3): type of ^101 is ptr*
	# LowerStore(5018:3).3: mov $imm, ^101
	movq $0, (%rax)
	# LowerGetelementptr(5019:3): struct-type: ptr ^101 -> ^102, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5019:3): type of ^102 is ptr*
	# LowerStore(5020:3).3: mov $imm, ^102
	movq $0, (%rcx)
	# LowerGetelementptr(5021:3): struct-type: ptr ^97 -> ^103, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5021:3): type of ^103 is ptr*
	# LowerGetelementptr(5022:3): struct-type: ptr ^103 -> ^104, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5022:3): type of ^104 is ptr*
	# LowerStore(5023:3).6: load global
	movq _ZL5g_422@GOTPCREL(%rip), %rcx
	# LowerStore(5023:3).9: mov ^178, (^104)
	movq %rcx, (%rbx)
	# LowerGetelementptr(5024:3): struct-type: ptr ^104 -> ^105, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5024:3): type of ^105 is ptr*
	# LowerStore(5025:3).9: mov ^23, (^105)
	# Fixing movq -1576(%rbp), (%rcx)
	movq -1576(%rbp), %r15
	movq %r15, (%rcx)
	# LowerGetelementptr(5026:3): struct-type: ptr ^105 -> ^106, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5026:3): type of ^106 is ptr*
	# LowerStore(5027:3).6: load global
	movq _ZL5g_422@GOTPCREL(%rip), %rcx
	# LowerStore(5027:3).9: mov ^179, (^106)
	movq %rcx, (%rbx)
	# LowerGetelementptr(5028:3): struct-type: ptr ^106 -> ^107, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5028:3): type of ^107 is ptr*
	# LowerStore(5029:3).9: mov ^23, (^107)
	# Fixing movq -1576(%rbp), (%rcx)
	movq -1576(%rbp), %r15
	movq %r15, (%rcx)
	# LowerGetelementptr(5030:3): struct-type: ptr ^107 -> ^108, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5030:3): type of ^108 is ptr*
	# LowerStore(5031:3).3: mov $imm, ^108
	movq $0, (%rbx)
	# LowerGetelementptr(5032:3): struct-type: ptr ^103 -> ^109, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5032:3): type of ^109 is ptr*
	# LowerGetelementptr(5033:3): struct-type: ptr ^109 -> ^110, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5033:3): type of ^110 is ptr*
	# SetupCalls(5034:3): move argument ptr align 8 ^109
	movq %rbx, %rdi
	# SetupCalls(5034:3): move argument ptr align 8 @constinit.127
	movq constinit.127, %rsi
	# SetupCalls(5034:3): move argument i64 40
	movq $40, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerGetelementptr(5035:3): struct-type: ptr ^109 -> ^111, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5035:3): type of ^111 is ptr*
	# LowerGetelementptr(5036:3): struct-type: ptr ^111 -> ^112, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5036:3): type of ^112 is ptr*
	# LowerStore(5037:3).6: load global
	movq _ZL5g_422@GOTPCREL(%rip), %rax
	# LowerStore(5037:3).9: mov ^180, (^112)
	movq %rax, (%rbx)
	# LowerGetelementptr(5038:3): struct-type: ptr ^112 -> ^113, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5038:3): type of ^113 is ptr*
	# LowerStore(5039:3).3: mov $imm, ^113
	movq $0, (%rcx)
	# LowerGetelementptr(5040:3): struct-type: ptr ^113 -> ^114, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5040:3): type of ^114 is ptr*
	# LowerStore(5041:3).9: mov ^23, (^114)
	# Fixing movq -1576(%rbp), (%rax)
	movq -1576(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5042:3): struct-type: ptr ^114 -> ^115, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5042:3): type of ^115 is ptr*
	# LowerStore(5043:3).6: load global
	movq _ZL3g_2@GOTPCREL(%rip), %rax
	# LowerStore(5043:3).9: mov ^181, (^115)
	movq %rax, (%rbx)
	# LowerGetelementptr(5044:3): struct-type: ptr ^115 -> ^116, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5044:3): type of ^116 is ptr*
	# LowerStore(5045:3).9: mov ^23, (^116)
	# Fixing movq -1576(%rbp), (%rax)
	movq -1576(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5047:3).3: mov $imm, ^26
	movq -1632(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(5049:3).3: mov $imm, ^27
	movq -1640(%rbp), %rax
	movw $-27602, (%rax)
	# LowerStore(5051:3).3: mov $imm, ^28
	movq -1648(%rbp), %rax
	movw $27048, (%rax)
	# LowerStore(5053:3).3: mov $imm, ^29
	movq -1592(%rbp), %rax
	movw $1461, (%rax)
	# LowerStore(5055:3).3: mov $imm, ^30
	movq -1656(%rbp), %rax
	movl $1827560133, (%rax)
	# LowerGetelementptr(5059:3): struct-type: ptr ^18 -> ^117, indices=0,0
	movq -1624(%rbp), %rax
	# LowerGetelementptr(5059:3): type of ^117 is ptr*
	# LowerGetelementptr(5060:3): struct-type: ptr ^117 -> ^118, indices=0,1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5060:3): type of ^118 is ptr*
	# LowerGetelementptr(5061:3): struct-type: ptr ^118 -> ^119, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5061:3): type of ^119 is ptr*
	# LowerLoad(5062:3).2: (^119) into ^120
	movq (%rax), %rbx
	# LowerIcmp(5063:3): i64 ^120 vs. intlike 0
	cmpq $0, %rbx
	setne %al
	cmpb $0, %al
	jne .___ZL7func_532U1__M775
	.___ZL7func_532U1__M772:
	# MovePhi: intlike -> ^139 (in new block 183 whose parent is 157)
	movb $0, -1536(%rbp)
	jmp .___ZL7func_532U1__M831
	.___ZL7func_532U1__M775:
	movq _ZL5g_666, %rbx
	addq $16, %rbx
	# LowerLoad(5067:3).2: (^161) into ^123
	movq (%rbx), %rax
	# LowerStore(5068:3).9: mov ^123, (^8)
	movq -1584(%rbp), %rbx
	movq %rax, (%rbx)
	movq _ZL5g_666, %rbx
	addq $48, %rbx
	# LowerStore(5069:3).9: mov ^123, (^162)
	movq %rax, (%rbx)
	# LowerLoad(5070:3).2: (^19) into ^124
	movq -1608(%rbp), %rcx
	movq (%rcx), %rbx
	# LowerLoad(5071:3).2: (^20) into ^125
	movq -1616(%rbp), %rdx
	movq (%rdx), %rcx
	# LowerStore(5072:3).9: mov ^124, (^125)
	movq %rbx, (%rcx)
	# LowerGetelementptr(5073:3): struct-type: ptr ^9 -> ^126, indices=0,3
	movq -1568(%rbp), %rcx
	addq $24, %rcx
	# LowerGetelementptr(5073:3): type of ^126 is ptr*
	# LowerGetelementptr(5074:3): struct-type: ptr ^126 -> ^127, indices=0,6
	movq %rcx, %rdx
	addq $48, %rdx
	# LowerGetelementptr(5074:3): type of ^127 is ptr*
	# LowerGetelementptr(5075:3): struct-type: ptr ^127 -> ^128, indices=0,0
	movq %rdx, %rcx
	# LowerGetelementptr(5075:3): type of ^128 is ptr*
	# LowerStore(5076:3).9: mov ^124, (^128)
	movq %rbx, (%rcx)
	# LowerLoad(5077:3).2: (^22) into ^129
	movq -1600(%rbp), %rdx
	movq (%rdx), %rcx
	# LowerStore(5078:3).9: mov ^124, (^129)
	movq %rbx, (%rcx)
	# LowerIcmp(5079:3): ptr ^123 vs. operand ptr ^124
	cmpq %rbx, %rax
	sete %al
	# LowerBasicConversion(5080:3): ^130 -> ^131
	movl %eax, %ecx
	# LowerLoad(5081:3).2: (^10) into ^132
	movq -1560(%rbp), %rbx
	movq (%rbx), %rax
	# LowerLoad(5082:3).2: (^10) into ^133
	movq -1560(%rbp), %rdx
	movq (%rdx), %rbx
	# LowerIcmp(5083:3): ptr ^132 vs. operand ptr ^133
	cmpq %rbx, %rax
	sete %al
	# LowerBasicConversion(5084:3): ^134 -> ^135
	movl %eax, %ebx
	movl %ecx, %eax
	andl %ebx, %eax
	# LowerIcmp(5086:3): i32 ^136 vs. intlike 0
	cmpl $0, %eax
	setne %al
	# MovePhi: ^137 -> ^139
	movb %al, -1536(%rbp)
	.___ZL7func_532U1__M831:
	# LowerBasicConversion(5091:3): ^139 -> ^140
	movl -1536(%rbp), %eax
	# LowerLoad(5092:3).2: (^7) into ^141
	movq -1544(%rbp), %rcx
	movq (%rcx), %rbx
	# LowerStore(5093:3).9: mov ^140, (^141)
	movl %eax, (%rbx)
	# LowerStore(5094:3).9: mov ^140, (^23)
	movq -1576(%rbp), %rbx
	movl %eax, (%rbx)
	# LowerLoad(5095:3).2: (^29) into ^142
	movq -1592(%rbp), %rbx
	movw (%rbx), %ax
	movw %ax, %bx
	addw $-1, %bx
	# LowerStore(5097:3).9: mov ^143, (^29)
	movq -1592(%rbp), %rax
	movw %bx, (%rax)
	# LowerGetelementptr(5098:3): struct-type: ptr ^14 -> ^144, indices=0,1
	movq -1552(%rbp), %rax
	addq $8, %rax
	# LowerGetelementptr(5098:3): type of ^144 is ptr*
	# LowerLoad(5099:3).2: (^144) into ^145
	movw (%rax), %bx
	movw %bx, %cx
	addw $1, %cx
	# LowerStore(5101:3).9: mov ^146, (^144)
	movw %cx, (%rax)
	# LowerLoad(5105:3).2: (^3) into ^148
	movq -1528(%rbp), %rax
	movb (%rax), %bl
	movsbl %bl, %ecx
	# LowerStore(5107:3).9: mov ^149, (^2)
	movq -1520(%rbp), %rax
	movl %ecx, (%rax)
	.___ZL7func_532U1__M862:
	# LowerLoad(5111:3).2: (^2) into ^151
	movq -1520(%rbp), %rax
	movl (%rax), %ebx
	movl %ebx, %eax
	movq -1696(%rbp), %r15
	movq -1704(%rbp), %r14
	movq -1720(%rbp), %r13
	movq -1712(%rbp), %r12
	movq -1688(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL7func_552U0
.p2align 4, 0x90
_ZL7func_552U0:
	.___ZL7func_552U0__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(5117:3): size = 2, type = %union.U1*, var = ^2
	leaq -2(%rbp), %rax
	# LowerAlloca(5118:3): size = 4, type = %union.U0*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerGetelementptr(5119:3): struct-type: ptr ^3 -> ^4, indices=0,0
	movq %rcx, %rbx
	# LowerGetelementptr(5119:3): type of ^4 is ptr*
	# LowerStore(5120:3).9: mov %edi, (^4)
	movl %edi, (%rbx)
	# LowerStore(5123:3).3: mov $imm, ^2
	movb $1, (%rax)
	# LowerGetelementptr(5124:3): struct-type: ptr ^2 -> ^5, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5124:3): type of ^5 is ptr*
	# LowerLoad(5125:3).2: (^5) into ^6
	movw (%rbx), %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL7func_57majs2U2
.p2align 4, 0x90
_ZL7func_57majs2U2:
	.___ZL7func_57majs2U2__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(3240 + 0, 16)
	subq $3248, %rsp
	movq %rbx, -2016(%rbp)
	movq %r12, -2648(%rbp)
	movq %r13, -2632(%rbp)
	movq %r14, -2656(%rbp)
	# LowerAlloca(5131:3): size = 4, type = %union.U0*, var = ^6
	# Fixing leaq -4(%rbp), -1504(%rbp)
	leaq -4(%rbp), %r15
	movq %r15, -1504(%rbp)
	# LowerAlloca(5132:3): size = 8, type = %union.U2*, var = ^7
	# Fixing leaq -16(%rbp), -1720(%rbp)
	leaq -16(%rbp), %r15
	movq %r15, -1720(%rbp)
	# LowerAlloca(5133:3): size = 8, type = i64*, var = ^8
	# Fixing leaq -24(%rbp), -1728(%rbp)
	leaq -24(%rbp), %r15
	movq %r15, -1728(%rbp)
	# LowerAlloca(5134:3): size = 1, type = i8*, var = ^9
	# Fixing leaq -25(%rbp), -1736(%rbp)
	leaq -25(%rbp), %r15
	movq %r15, -1736(%rbp)
	# LowerAlloca(5135:3): size = 4, type = i32*, var = ^10
	# Fixing leaq -32(%rbp), -1744(%rbp)
	leaq -32(%rbp), %r15
	movq %r15, -1744(%rbp)
	# LowerAlloca(5136:3): size = 2, type = i16*, var = ^11
	# Fixing leaq -34(%rbp), -1752(%rbp)
	leaq -34(%rbp), %r15
	movq %r15, -1752(%rbp)
	# LowerAlloca(5137:3): size = 4, type = [2 x i16]*, var = ^12
	# Fixing leaq -38(%rbp), -1760(%rbp)
	leaq -38(%rbp), %r15
	movq %r15, -1760(%rbp)
	# LowerAlloca(5138:3): size = 8, type = ptr*, var = ^13
	# Fixing leaq -48(%rbp), -1768(%rbp)
	leaq -48(%rbp), %r15
	movq %r15, -1768(%rbp)
	# LowerAlloca(5139:3): size = 4, type = i32*, var = ^14
	# Fixing leaq -52(%rbp), -1776(%rbp)
	leaq -52(%rbp), %r15
	movq %r15, -1776(%rbp)
	# LowerAlloca(5140:3): size = 864, type = [8 x [9 x [3 x i32]]]*, var = ^15
	# Fixing leaq -928(%rbp), -1512(%rbp)
	leaq -928(%rbp), %r15
	movq %r15, -1512(%rbp)
	# LowerAlloca(5141:3): size = 8, type = ptr*, var = ^16
	# Fixing leaq -936(%rbp), -1992(%rbp)
	leaq -936(%rbp), %r15
	movq %r15, -1992(%rbp)
	# LowerAlloca(5142:3): size = 480, type = [10 x [6 x %union.U2]]*, var = ^17
	# Fixing leaq -1424(%rbp), -1520(%rbp)
	leaq -1424(%rbp), %r15
	movq %r15, -1520(%rbp)
	# LowerAlloca(5143:3): size = 64, type = [8 x ptr]*, var = ^18
	# Fixing leaq -1488(%rbp), -1912(%rbp)
	leaq -1488(%rbp), %r15
	movq %r15, -1912(%rbp)
	# LowerAlloca(5144:3): size = 8, type = ptr*, var = ^19
	# Fixing leaq -1496(%rbp), -1936(%rbp)
	leaq -1496(%rbp), %r15
	movq %r15, -1936(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5145:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5145:3): mov %rsp, ^20
	movq %rsp, -1944(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5146:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5146:3): mov %rsp, ^21
	movq %rsp, -1952(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5147:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5147:3): mov %rsp, ^22
	movq %rsp, -1960(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5148:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5148:3): mov %rsp, ^23
	movq %rsp, -1904(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5149:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5149:3): mov %rsp, ^24
	movq %rsp, -1920(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5150:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5150:3): mov %rsp, ^25
	movq %rsp, -1968(%rbp)
	andq $-4, %rsp
	# LowerAlloca(5151:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5151:3): mov %rsp, ^26
	movq %rsp, -1976(%rbp)
	andq $-2, %rsp
	# LowerAlloca(5152:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5152:3): mov %rsp, ^27
	movq %rsp, -1528(%rbp)
	movq %rsp, %rax
	movq $8, %rax
	movq $0, %rdx
	divq %rsp
	movq %rdx, %rax
	subq %rax, %rsp
	# LowerAlloca(5153:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5153:3): mov %rsp, ^28
	movq %rsp, -1984(%rbp)
	andq $-2, %rsp
	# LowerAlloca(5154:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5154:3): mov %rsp, ^29
	movq %rsp, -1544(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5155:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5155:3): mov %rsp, ^30
	movq %rsp, -1536(%rbp)
	andq $-4, %rsp
	# LowerAlloca(5156:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5156:3): mov %rsp, ^31
	movq %rsp, -1928(%rbp)
	andq $-4, %rsp
	# LowerAlloca(5157:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5157:3): mov %rsp, ^32
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(5158:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5158:3): mov %rsp, ^33
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(5159:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5159:3): mov %rsp, ^34
	movq %rsp, -1784(%rbp)
	andq $-16, %rsp
	# LowerAlloca(5160:3): %rsp -= to_sub
	subq $640, %rsp
	# LowerAlloca(5160:3): mov %rsp, ^35
	movq %rsp, -1792(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5161:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5161:3): mov %rsp, ^36
	movq %rsp, -1800(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5162:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5162:3): mov %rsp, ^37
	movq %rsp, -1808(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5163:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5163:3): mov %rsp, ^38
	movq %rsp, -1816(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5164:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5164:3): mov %rsp, ^39
	movq %rsp, -1824(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5165:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5165:3): mov %rsp, ^40
	movq %rsp, -1832(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5166:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5166:3): mov %rsp, ^41
	movq %rsp, -1840(%rbp)
	andq $-16, %rsp
	# LowerAlloca(5167:3): %rsp -= to_sub
	subq $40, %rsp
	# LowerAlloca(5167:3): mov %rsp, ^42
	movq %rsp, -1848(%rbp)
	movq %rsp, %rax
	movq $8, %rax
	movq $0, %rdx
	divq %rsp
	movq %rdx, %rax
	subq %rax, %rsp
	# LowerAlloca(5168:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5168:3): mov %rsp, ^43
	movq %rsp, -1856(%rbp)
	andq $-4, %rsp
	# LowerAlloca(5169:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5169:3): mov %rsp, ^44
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(5170:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5170:3): mov %rsp, ^45
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(5171:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5171:3): mov %rsp, ^46
	movq %rsp, %rax
	andq $-2, %rsp
	# LowerAlloca(5172:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5172:3): mov %rsp, ^47
	movq %rsp, -1864(%rbp)
	andq $-16, %rsp
	# LowerAlloca(5173:3): %rsp -= to_sub
	subq $40, %rsp
	# LowerAlloca(5173:3): mov %rsp, ^48
	movq %rsp, -1872(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5174:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5174:3): mov %rsp, ^49
	movq %rsp, -1880(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5175:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5175:3): mov %rsp, ^50
	movq %rsp, -1888(%rbp)
	andq $-4, %rsp
	# LowerAlloca(5176:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5176:3): mov %rsp, ^51
	movq %rsp, -1896(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5177:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5177:3): mov %rsp, ^52
	movq %rsp, -1552(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5178:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5178:3): mov %rsp, ^53
	movq %rsp, -1560(%rbp)
	andq $-16, %rsp
	# LowerAlloca(5179:3): %rsp -= to_sub
	subq $48, %rsp
	# LowerAlloca(5179:3): mov %rsp, ^54
	movq %rsp, -1568(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5180:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5180:3): mov %rsp, ^55
	movq %rsp, -1576(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5181:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5181:3): mov %rsp, ^56
	movq %rsp, -1584(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5182:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5182:3): mov %rsp, ^57
	movq %rsp, -1592(%rbp)
	andq $-4, %rsp
	# LowerAlloca(5183:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5183:3): mov %rsp, ^58
	movq %rsp, -1600(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5184:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5184:3): mov %rsp, ^59
	movq %rsp, -1608(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5185:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5185:3): mov %rsp, ^60
	movq %rsp, -1616(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5186:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5186:3): mov %rsp, ^61
	movq %rsp, -1624(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5187:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5187:3): mov %rsp, ^62
	movq %rsp, -1632(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5188:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5188:3): mov %rsp, ^63
	movq %rsp, -1640(%rbp)
	andq $-2, %rsp
	# LowerAlloca(5189:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5189:3): mov %rsp, ^64
	movq %rsp, -1648(%rbp)
	andq $-2, %rsp
	# LowerAlloca(5190:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5190:3): mov %rsp, ^65
	movq %rsp, -1656(%rbp)
	andq $-16, %rsp
	# LowerAlloca(5191:3): %rsp -= to_sub
	subq $24, %rsp
	# LowerAlloca(5191:3): mov %rsp, ^66
	movq %rsp, -1664(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5192:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5192:3): mov %rsp, ^67
	movq %rsp, -1672(%rbp)
	andq $-16, %rsp
	# LowerAlloca(5193:3): %rsp -= to_sub
	subq $80, %rsp
	# LowerAlloca(5193:3): mov %rsp, ^68
	movq %rsp, -1680(%rbp)
	andq $-8, %rsp
	# LowerAlloca(5194:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5194:3): mov %rsp, ^69
	movq %rsp, -1688(%rbp)
	andq $-16, %rsp
	# LowerAlloca(5195:3): %rsp -= to_sub
	subq $288, %rsp
	# LowerAlloca(5195:3): mov %rsp, ^70
	movq %rsp, -1696(%rbp)
	andq $-4, %rsp
	# LowerAlloca(5196:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5196:3): mov %rsp, ^71
	movq %rsp, -1704(%rbp)
	andq $-4, %rsp
	# LowerAlloca(5197:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5197:3): mov %rsp, ^72
	movq %rsp, %rax
	andq $-4, %rsp
	# LowerAlloca(5198:3): %rsp -= to_sub
	subq $8, %rsp
	# LowerAlloca(5198:3): mov %rsp, ^73
	movq %rsp, %rax
	# LowerGetelementptr(5199:3): struct-type: ptr ^7 -> ^74, indices=0,0
	movq -1720(%rbp), %rax
	# LowerGetelementptr(5199:3): type of ^74 is ptr*
	# LowerStore(5200:3).9: mov %r8, (^74)
	movq %r8, (%rax)
	# LowerStore(5201:3).9: mov %rdi, (^8)
	movq -1728(%rbp), %rax
	movq %rdi, (%rax)
	# LowerStore(5203:3).9: mov %sil, (^9)
	movq -1736(%rbp), %rax
	movb %sil, (%rax)
	# LowerStore(5205:3).9: mov %edx, (^10)
	movq -1744(%rbp), %rax
	movl %edx, (%rax)
	# LowerStore(5207:3).9: mov %cx, (^11)
	movq -1752(%rbp), %rax
	movw %cx, (%rax)
	# LowerStore(5212:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rbx
	# LowerStore(5212:3).9: mov ^467, (^13)
	movq -1768(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5214:3).3: mov $imm, ^14
	movq -1776(%rbp), %rax
	movl $118983987, (%rax)
	# SetupCalls(5216:3): move argument ptr align 16 ^15
	movq -1512(%rbp), %rdi
	# SetupCalls(5216:3): move argument ptr align 16 @__const._ZL7func_57majs2U2.l_116
	movq __const._ZL7func_57majs2U2.l_116, %rsi
	# SetupCalls(5216:3): move argument i64 864
	movq $864, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerGetelementptr(5218:3): struct-type: ptr ^15 -> ^75, indices=0,7
	movq -1512(%rbp), %rbx
	addq $56, %rbx
	# LowerGetelementptr(5218:3): type of ^75 is ptr*
	# LowerGetelementptr(5219:3): struct-type: ptr ^75 -> ^76, indices=0,4
	movq %rbx, %rax
	addq $32, %rax
	# LowerGetelementptr(5219:3): type of ^76 is ptr*
	# LowerGetelementptr(5220:3): struct-type: ptr ^76 -> ^77, indices=0,1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5220:3): type of ^77 is ptr*
	# LowerStore(5221:3).9: mov ^77, (^16)
	movq -1992(%rbp), %rax
	movq %rbx, (%rax)
	# LowerGetelementptr(5223:3): struct-type: ptr ^17 -> ^78, indices=0,0
	movq -1520(%rbp), %rax
	# LowerGetelementptr(5223:3): type of ^78 is ptr*
	# LowerGetelementptr(5224:3): struct-type: ptr ^78 -> ^79, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5224:3): type of ^79 is ptr*
	# LowerStore(5225:3).3: mov $imm, ^79
	movq $-1, (%rbx)
	# LowerGetelementptr(5226:3): struct-type: ptr ^79 -> ^80, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5226:3): type of ^80 is ptr*
	# LowerStore(5227:3).3: mov $imm, ^80
	movabsq $8465845472384687599, %rbx
	movq %rbx, (%rcx)
	# LowerGetelementptr(5228:3): struct-type: ptr ^80 -> ^81, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5228:3): type of ^81 is ptr*
	# LowerStore(5229:3).3: mov $imm, ^81
	movabsq $9057255019317769000, %rcx
	movq %rcx, (%rbx)
	# LowerGetelementptr(5230:3): struct-type: ptr ^81 -> ^82, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5230:3): type of ^82 is ptr*
	# LowerStore(5231:3).3: mov $imm, ^82
	movabsq $5257880311641606578, %rbx
	movq %rbx, (%rcx)
	# LowerGetelementptr(5232:3): struct-type: ptr ^82 -> ^83, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5232:3): type of ^83 is ptr*
	# LowerStore(5233:3).3: mov $imm, ^83
	movabsq $5257880311641606578, %rcx
	movq %rcx, (%rbx)
	# LowerGetelementptr(5234:3): struct-type: ptr ^83 -> ^84, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5234:3): type of ^84 is ptr*
	# LowerStore(5235:3).3: mov $imm, ^84
	movabsq $9057255019317769000, %rbx
	movq %rbx, (%rcx)
	# LowerGetelementptr(5236:3): struct-type: ptr ^78 -> ^85, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5236:3): type of ^85 is ptr*
	# LowerGetelementptr(5237:3): struct-type: ptr ^85 -> ^86, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5237:3): type of ^86 is ptr*
	# LowerStore(5238:3).3: mov $imm, ^86
	movq $-1, (%rax)
	# LowerGetelementptr(5239:3): struct-type: ptr ^86 -> ^87, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5239:3): type of ^87 is ptr*
	# LowerStore(5240:3).3: mov $imm, ^87
	movq $-1, (%rcx)
	# LowerGetelementptr(5241:3): struct-type: ptr ^87 -> ^88, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5241:3): type of ^88 is ptr*
	# LowerStore(5242:3).3: mov $imm, ^88
	movq $-1, (%rax)
	# LowerGetelementptr(5243:3): struct-type: ptr ^88 -> ^89, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5243:3): type of ^89 is ptr*
	# LowerStore(5244:3).3: mov $imm, ^89
	movabsq $-8666319007712456100, %rax
	movq %rax, (%rcx)
	# LowerGetelementptr(5245:3): struct-type: ptr ^89 -> ^90, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5245:3): type of ^90 is ptr*
	# LowerStore(5246:3).3: mov $imm, ^90
	movq $-1, (%rax)
	# LowerGetelementptr(5247:3): struct-type: ptr ^90 -> ^91, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5247:3): type of ^91 is ptr*
	# LowerStore(5248:3).3: mov $imm, ^91
	movabsq $5257880311641606578, %rax
	movq %rax, (%rcx)
	# LowerGetelementptr(5249:3): struct-type: ptr ^85 -> ^92, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5249:3): type of ^92 is ptr*
	# LowerGetelementptr(5250:3): struct-type: ptr ^92 -> ^93, indices=0,0
	movq %rcx, %rax
	# LowerGetelementptr(5250:3): type of ^93 is ptr*
	# LowerStore(5251:3).3: mov $imm, ^93
	movq $-1, (%rax)
	# LowerGetelementptr(5252:3): struct-type: ptr ^93 -> ^94, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5252:3): type of ^94 is ptr*
	# LowerStore(5253:3).3: mov $imm, ^94
	movabsq $-5531817056347653028, %rax
	movq %rax, (%rbx)
	# LowerGetelementptr(5254:3): struct-type: ptr ^94 -> ^95, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5254:3): type of ^95 is ptr*
	# LowerStore(5255:3).3: mov $imm, ^95
	movabsq $8465845472384687599, %rbx
	movq %rbx, (%rax)
	# LowerGetelementptr(5256:3): struct-type: ptr ^95 -> ^96, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5256:3): type of ^96 is ptr*
	# LowerStore(5257:3).3: mov $imm, ^96
	movabsq $-8666319007712456100, %rax
	movq %rax, (%rbx)
	# LowerGetelementptr(5258:3): struct-type: ptr ^96 -> ^97, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5258:3): type of ^97 is ptr*
	# LowerStore(5259:3).3: mov $imm, ^97
	movabsq $-5531817056347653028, %rbx
	movq %rbx, (%rax)
	# LowerGetelementptr(5260:3): struct-type: ptr ^97 -> ^98, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5260:3): type of ^98 is ptr*
	# LowerStore(5261:3).3: mov $imm, ^98
	movq $-1, (%rbx)
	# LowerGetelementptr(5262:3): struct-type: ptr ^92 -> ^99, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5262:3): type of ^99 is ptr*
	# LowerGetelementptr(5263:3): struct-type: ptr ^99 -> ^100, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5263:3): type of ^100 is ptr*
	# LowerStore(5264:3).3: mov $imm, ^100
	movq $-1, (%rbx)
	# LowerGetelementptr(5265:3): struct-type: ptr ^100 -> ^101, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5265:3): type of ^101 is ptr*
	# LowerStore(5266:3).3: mov $imm, ^101
	movq $-1, (%rcx)
	# LowerGetelementptr(5267:3): struct-type: ptr ^101 -> ^102, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5267:3): type of ^102 is ptr*
	# LowerStore(5268:3).3: mov $imm, ^102
	movabsq $8465845472384687599, %rcx
	movq %rcx, (%rbx)
	# LowerGetelementptr(5269:3): struct-type: ptr ^102 -> ^103, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5269:3): type of ^103 is ptr*
	# LowerStore(5270:3).3: mov $imm, ^103
	movq $-1, (%rcx)
	# LowerGetelementptr(5271:3): struct-type: ptr ^103 -> ^104, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5271:3): type of ^104 is ptr*
	# LowerStore(5272:3).3: mov $imm, ^104
	movq $-1, (%rbx)
	# LowerGetelementptr(5273:3): struct-type: ptr ^104 -> ^105, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5273:3): type of ^105 is ptr*
	# LowerStore(5274:3).3: mov $imm, ^105
	movabsq $5257880311641606578, %rbx
	movq %rbx, (%rcx)
	# LowerGetelementptr(5275:3): struct-type: ptr ^99 -> ^106, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5275:3): type of ^106 is ptr*
	# LowerGetelementptr(5276:3): struct-type: ptr ^106 -> ^107, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5276:3): type of ^107 is ptr*
	# LowerStore(5277:3).3: mov $imm, ^107
	movabsq $-5217174645934436860, %rcx
	movq %rcx, (%rax)
	# LowerGetelementptr(5278:3): struct-type: ptr ^107 -> ^108, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5278:3): type of ^108 is ptr*
	# LowerStore(5279:3).3: mov $imm, ^108
	movq $-1, (%rcx)
	# LowerGetelementptr(5280:3): struct-type: ptr ^108 -> ^109, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5280:3): type of ^109 is ptr*
	# LowerStore(5281:3).3: mov $imm, ^109
	movq $-1, (%rax)
	# LowerGetelementptr(5282:3): struct-type: ptr ^109 -> ^110, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5282:3): type of ^110 is ptr*
	# LowerStore(5283:3).3: mov $imm, ^110
	movabsq $-5217174645934436860, %rax
	movq %rax, (%rcx)
	# LowerGetelementptr(5284:3): struct-type: ptr ^110 -> ^111, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5284:3): type of ^111 is ptr*
	# LowerStore(5285:3).3: mov $imm, ^111
	movabsq $-5531817056347653028, %rcx
	movq %rcx, (%rax)
	# LowerGetelementptr(5286:3): struct-type: ptr ^111 -> ^112, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5286:3): type of ^112 is ptr*
	# LowerStore(5287:3).3: mov $imm, ^112
	movq $8, (%rcx)
	# LowerGetelementptr(5288:3): struct-type: ptr ^106 -> ^113, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5288:3): type of ^113 is ptr*
	# LowerGetelementptr(5289:3): struct-type: ptr ^113 -> ^114, indices=0,0
	movq %rcx, %rax
	# LowerGetelementptr(5289:3): type of ^114 is ptr*
	# LowerStore(5290:3).3: mov $imm, ^114
	movabsq $-5217174645934436860, %rbx
	movq %rbx, (%rax)
	# LowerGetelementptr(5291:3): struct-type: ptr ^114 -> ^115, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5291:3): type of ^115 is ptr*
	# LowerStore(5292:3).3: mov $imm, ^115
	movabsq $-5531817056347653028, %rax
	movq %rax, (%rbx)
	# LowerGetelementptr(5293:3): struct-type: ptr ^115 -> ^116, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5293:3): type of ^116 is ptr*
	# LowerStore(5294:3).3: mov $imm, ^116
	movq $8, (%rax)
	# LowerGetelementptr(5295:3): struct-type: ptr ^116 -> ^117, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5295:3): type of ^117 is ptr*
	# LowerStore(5296:3).3: mov $imm, ^117
	movq $-1, (%rbx)
	# LowerGetelementptr(5297:3): struct-type: ptr ^117 -> ^118, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5297:3): type of ^118 is ptr*
	# LowerStore(5298:3).3: mov $imm, ^118
	movq $-1, (%rax)
	# LowerGetelementptr(5299:3): struct-type: ptr ^118 -> ^119, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5299:3): type of ^119 is ptr*
	# LowerStore(5300:3).3: mov $imm, ^119
	movq $8, (%rbx)
	# LowerGetelementptr(5301:3): struct-type: ptr ^113 -> ^120, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5301:3): type of ^120 is ptr*
	# LowerGetelementptr(5302:3): struct-type: ptr ^120 -> ^121, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5302:3): type of ^121 is ptr*
	# LowerStore(5303:3).3: mov $imm, ^121
	movq $-1, (%rbx)
	# LowerGetelementptr(5304:3): struct-type: ptr ^121 -> ^122, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5304:3): type of ^122 is ptr*
	# LowerStore(5305:3).3: mov $imm, ^122
	movq $-1, (%rcx)
	# LowerGetelementptr(5306:3): struct-type: ptr ^122 -> ^123, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5306:3): type of ^123 is ptr*
	# LowerStore(5307:3).3: mov $imm, ^123
	movq $-1, (%rbx)
	# LowerGetelementptr(5308:3): struct-type: ptr ^123 -> ^124, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5308:3): type of ^124 is ptr*
	# LowerStore(5309:3).3: mov $imm, ^124
	movabsq $-8666319007712456100, %rbx
	movq %rbx, (%rcx)
	# LowerGetelementptr(5310:3): struct-type: ptr ^124 -> ^125, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5310:3): type of ^125 is ptr*
	# LowerStore(5311:3).3: mov $imm, ^125
	movq $-1, (%rbx)
	# LowerGetelementptr(5312:3): struct-type: ptr ^125 -> ^126, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5312:3): type of ^126 is ptr*
	# LowerStore(5313:3).3: mov $imm, ^126
	movabsq $5257880311641606578, %rbx
	movq %rbx, (%rcx)
	# LowerGetelementptr(5314:3): struct-type: ptr ^120 -> ^127, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5314:3): type of ^127 is ptr*
	# LowerGetelementptr(5315:3): struct-type: ptr ^127 -> ^128, indices=0,0
	movq %rcx, %rax
	# LowerGetelementptr(5315:3): type of ^128 is ptr*
	# LowerStore(5316:3).3: mov $imm, ^128
	movq $-1, (%rax)
	# LowerGetelementptr(5317:3): struct-type: ptr ^128 -> ^129, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5317:3): type of ^129 is ptr*
	# LowerStore(5318:3).3: mov $imm, ^129
	movabsq $-5531817056347653028, %rax
	movq %rax, (%rbx)
	# LowerGetelementptr(5319:3): struct-type: ptr ^129 -> ^130, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5319:3): type of ^130 is ptr*
	# LowerStore(5320:3).3: mov $imm, ^130
	movabsq $8465845472384687599, %rbx
	movq %rbx, (%rax)
	# LowerGetelementptr(5321:3): struct-type: ptr ^130 -> ^131, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5321:3): type of ^131 is ptr*
	# LowerStore(5322:3).3: mov $imm, ^131
	movabsq $-8666319007712456100, %rax
	movq %rax, (%rbx)
	# LowerGetelementptr(5323:3): struct-type: ptr ^131 -> ^132, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5323:3): type of ^132 is ptr*
	# LowerStore(5324:3).3: mov $imm, ^132
	movabsq $-5531817056347653028, %rbx
	movq %rbx, (%rax)
	# LowerGetelementptr(5325:3): struct-type: ptr ^132 -> ^133, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5325:3): type of ^133 is ptr*
	# LowerStore(5326:3).3: mov $imm, ^133
	movq $-1, (%rbx)
	# LowerGetelementptr(5327:3): struct-type: ptr ^127 -> ^134, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5327:3): type of ^134 is ptr*
	# LowerGetelementptr(5328:3): struct-type: ptr ^134 -> ^135, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5328:3): type of ^135 is ptr*
	# LowerStore(5329:3).3: mov $imm, ^135
	movq $-1, (%rbx)
	# LowerGetelementptr(5330:3): struct-type: ptr ^135 -> ^136, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5330:3): type of ^136 is ptr*
	# LowerStore(5331:3).3: mov $imm, ^136
	movq $-1, (%rcx)
	# LowerGetelementptr(5332:3): struct-type: ptr ^136 -> ^137, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5332:3): type of ^137 is ptr*
	# LowerStore(5333:3).3: mov $imm, ^137
	movabsq $8465845472384687599, %rcx
	movq %rcx, (%rbx)
	# LowerGetelementptr(5334:3): struct-type: ptr ^137 -> ^138, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5334:3): type of ^138 is ptr*
	# LowerStore(5335:3).3: mov $imm, ^138
	movq $-1, (%rcx)
	# LowerGetelementptr(5336:3): struct-type: ptr ^138 -> ^139, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5336:3): type of ^139 is ptr*
	# LowerStore(5337:3).3: mov $imm, ^139
	movq $-1, (%rbx)
	# LowerGetelementptr(5338:3): struct-type: ptr ^139 -> ^140, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5338:3): type of ^140 is ptr*
	# LowerStore(5339:3).3: mov $imm, ^140
	movabsq $5257880311641606578, %rbx
	movq %rbx, (%rcx)
	# LowerGetelementptr(5340:3): struct-type: ptr ^134 -> ^141, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5340:3): type of ^141 is ptr*
	# LowerGetelementptr(5341:3): struct-type: ptr ^141 -> ^142, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5341:3): type of ^142 is ptr*
	# LowerStore(5342:3).3: mov $imm, ^142
	movabsq $-5217174645934436860, %rbx
	movq %rbx, (%rax)
	# LowerGetelementptr(5343:3): struct-type: ptr ^142 -> ^143, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5343:3): type of ^143 is ptr*
	# LowerStore(5344:3).3: mov $imm, ^143
	movq $-1, (%rbx)
	# LowerGetelementptr(5345:3): struct-type: ptr ^143 -> ^144, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5345:3): type of ^144 is ptr*
	# LowerStore(5346:3).3: mov $imm, ^144
	movq $-1, (%rax)
	# LowerGetelementptr(5347:3): struct-type: ptr ^144 -> ^145, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5347:3): type of ^145 is ptr*
	# LowerStore(5348:3).3: mov $imm, ^145
	movabsq $-5217174645934436860, %rax
	movq %rax, (%rbx)
	# LowerGetelementptr(5349:3): struct-type: ptr ^145 -> ^146, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5349:3): type of ^146 is ptr*
	# LowerStore(5350:3).3: mov $imm, ^146
	movabsq $-5531817056347653028, %rbx
	movq %rbx, (%rax)
	# LowerGetelementptr(5351:3): struct-type: ptr ^146 -> ^147, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5351:3): type of ^147 is ptr*
	# LowerStore(5352:3).3: mov $imm, ^147
	movq $8, (%rbx)
	# LowerStore(5355:3).6: load global
	movq _ZL4g_66@GOTPCREL(%rip), %rax
	# LowerStore(5355:3).9: mov ^468, (^19)
	movq -1936(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(5357:3).6: load global
	movq _ZL5g_367@GOTPCREL(%rip), %rax
	# LowerStore(5357:3).9: mov ^469, (^20)
	movq -1944(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(5359:3).9: mov ^20, (^21)
	movq -1952(%rbp), %rax
	# Fixing movq -1944(%rbp), (%rax)
	movq -1944(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5361:3).9: mov ^21, (^22)
	movq -1960(%rbp), %rax
	# Fixing movq -1952(%rbp), (%rax)
	movq -1952(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5363:3).6: load global
	movq _ZL5g_313@GOTPCREL(%rip), %rax
	# LowerStore(5363:3).9: mov ^470, (^23)
	movq -1904(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(5366:3).3: mov $imm, ^25
	movq -1968(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(5368:3).3: mov $imm, ^26
	movq -1976(%rbp), %rax
	movl $-1, (%rax)
	# LowerStore(5371:3).3: mov $imm, ^28
	movq -1984(%rbp), %rax
	movb $6, (%rax)
	# SetupCalls(5373:3): move argument ptr align 2 ^29
	movq -1544(%rbp), %rdi
	# SetupCalls(5373:3): move argument ptr align 2 @__const._ZL7func_57majs2U2.l_572
	movq __const._ZL7func_57majs2U2.l_572, %rsi
	# SetupCalls(5373:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(5375:3).6: load global
	movq _ZL4g_66@GOTPCREL(%rip), %rbx
	# LowerStore(5375:3).9: mov ^471, (^30)
	movq -1536(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5379:3).3: mov $imm, ^31
	movq -1928(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M856:
	# LowerLoad(5383:3).2: (^31) into ^149
	movq -1928(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5384:3): i32 ^149 vs. intlike 2
	cmpl $2, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M862
	jmp .___ZL7func_57majs2U2__M881
	.___ZL7func_57majs2U2__M862:
	# LowerLoad(5388:3).2: (^31) into ^152
	movq -1928(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerGetelementptr(5390:3): struct-type: ptr ^12 -> ^154, indices=0,%153
	movq -1760(%rbp), %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(5390:3): type of ^154 is ptr*
	# LowerStore(5391:3).3: mov $imm, ^154
	movw $1, (%rax)
	# LowerLoad(5395:3).2: (^31) into ^156
	movq -1928(%rbp), %rbx
	movl (%rbx), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(5397:3).9: mov ^157, (^31)
	movq -1928(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL7func_57majs2U2__M856
	.___ZL7func_57majs2U2__M881:
	# LowerStore(5401:3).3: mov $imm, ^31
	movq -1928(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M884:
	# LowerLoad(5405:3).2: (^31) into ^160
	movq -1928(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5406:3): i32 ^160 vs. intlike 8
	cmpl $8, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M890
	jmp .___ZL7func_57majs2U2__M909
	.___ZL7func_57majs2U2__M890:
	# LowerLoad(5410:3).2: (^31) into ^163
	movq -1928(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerGetelementptr(5412:3): struct-type: ptr ^18 -> ^165, indices=0,%164
	movq -1912(%rbp), %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(5412:3): type of ^165 is ptr*
	# LowerStore(5413:3).3: mov $imm, ^165
	movq $0, (%rax)
	# LowerLoad(5417:3).2: (^31) into ^167
	movq -1928(%rbp), %rbx
	movl (%rbx), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(5419:3).9: mov ^168, (^31)
	movq -1928(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL7func_57majs2U2__M884
	.___ZL7func_57majs2U2__M909:
	# LowerStore(5423:3).3: mov $imm, ^31
	movq -1928(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M912:
	# LowerLoad(5427:3).2: (^31) into ^171
	movq -1928(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5428:3): i32 ^171 vs. intlike 1
	cmpl $1, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M918
	jmp .___ZL7func_57majs2U2__M937
	.___ZL7func_57majs2U2__M918:
	# LowerLoad(5432:3).2: (^31) into ^174
	movq -1928(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerGetelementptr(5434:3): struct-type: ptr ^24 -> ^176, indices=0,%175
	movq -1920(%rbp), %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(5434:3): type of ^176 is ptr*
	# LowerStore(5435:3).9: mov ^23, (^176)
	# Fixing movq -1904(%rbp), (%rax)
	movq -1904(%rbp), %r15
	movq %r15, (%rax)
	# LowerLoad(5439:3).2: (^31) into ^178
	movq -1928(%rbp), %rax
	movl (%rax), %ebx
	movl %ebx, %eax
	addl $1, %eax
	# LowerStore(5441:3).9: mov ^179, (^31)
	movq -1928(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL7func_57majs2U2__M912
	.___ZL7func_57majs2U2__M937:
	# LowerStore(5445:3).3: mov $imm, ^31
	movq -1928(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M940:
	# LowerLoad(5449:3).2: (^31) into ^182
	movq -1928(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5450:3): i32 ^182 vs. intlike 1
	cmpl $1, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M946
	jmp .___ZL7func_57majs2U2__M965
	.___ZL7func_57majs2U2__M946:
	# LowerLoad(5454:3).2: (^31) into ^185
	movq -1928(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# LowerGetelementptr(5456:3): struct-type: ptr ^27 -> ^187, indices=0,%186
	movq -1528(%rbp), %rax
	movq %rbx, %rcx
	shlq $3, %rcx
	addq %rcx, %rax
	# LowerGetelementptr(5456:3): type of ^187 is ptr*
	# LowerStore(5457:3).3: mov $imm, ^187
	movw $-13122, (%rax)
	# LowerLoad(5461:3).2: (^31) into ^189
	movq -1928(%rbp), %rbx
	movl (%rbx), %eax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(5463:3).9: mov ^190, (^31)
	movq -1928(%rbp), %rax
	movl %ebx, (%rax)
	jmp .___ZL7func_57majs2U2__M940
	.___ZL7func_57majs2U2__M965:
	# LowerStore(5467:3).3: mov $imm, ^7
	movq -1720(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M968:
	# LowerLoad(5471:3).2: (^7) into ^193
	movq -1720(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5472:3): i32 ^193 vs. intlike 1
	cmpl $1, %eax
	setle %al
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M974
	jmp .___ZL7func_57majs2U2__M1512
	.___ZL7func_57majs2U2__M974:
	# LowerStore(5477:3).3: mov $imm, ^34
	movq -1784(%rbp), %rax
	movl $-1, (%rax)
	# SetupCalls(5479:3): move argument ptr align 16 ^35
	movq -1792(%rbp), %rdi
	# SetupCalls(5479:3): move argument ptr align 16 @__const._ZL7func_57majs2U2.l_102
	movq __const._ZL7func_57majs2U2.l_102, %rsi
	# SetupCalls(5479:3): move argument i64 640
	movq $640, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(5481:3).9: mov ^14, (^36)
	movq -1800(%rbp), %rax
	# Fixing movq -1776(%rbp), (%rax)
	movq -1776(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5483:3).9: mov ^14, (^37)
	movq -1808(%rbp), %rax
	# Fixing movq -1776(%rbp), (%rax)
	movq -1776(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5485:3).9: mov ^14, (^38)
	movq -1816(%rbp), %rax
	# Fixing movq -1776(%rbp), (%rax)
	movq -1776(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5487:3).9: mov ^14, (^39)
	movq -1824(%rbp), %rax
	# Fixing movq -1776(%rbp), (%rax)
	movq -1776(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5489:3).3: mov $imm, ^40
	movq -1832(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(5491:3).9: mov ^14, (^41)
	movq -1840(%rbp), %rax
	# Fixing movq -1776(%rbp), (%rax)
	movq -1776(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5493:3): struct-type: ptr ^42 -> ^196, indices=0,0
	movq -1848(%rbp), %rax
	# LowerGetelementptr(5493:3): type of ^196 is ptr*
	# LowerStore(5494:3).9: mov ^14, (^196)
	# Fixing movq -1776(%rbp), (%rax)
	movq -1776(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5495:3): struct-type: ptr ^196 -> ^197, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5495:3): type of ^197 is ptr*
	# LowerStore(5496:3).9: mov ^14, (^197)
	# Fixing movq -1776(%rbp), (%rbx)
	movq -1776(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(5497:3): struct-type: ptr ^197 -> ^198, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5497:3): type of ^198 is ptr*
	# LowerStore(5498:3).9: mov ^14, (^198)
	# Fixing movq -1776(%rbp), (%rax)
	movq -1776(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5499:3): struct-type: ptr ^198 -> ^199, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5499:3): type of ^199 is ptr*
	# LowerStore(5500:3).9: mov ^14, (^199)
	# Fixing movq -1776(%rbp), (%rbx)
	movq -1776(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(5501:3): struct-type: ptr ^199 -> ^200, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5501:3): type of ^200 is ptr*
	# LowerStore(5502:3).9: mov ^14, (^200)
	# Fixing movq -1776(%rbp), (%rax)
	movq -1776(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5504:3).3: mov $imm, ^43
	movq -1856(%rbp), %rax
	movb $0, (%rax)
	# LowerStore(5508:3).2a: mov $imm, %temp
	movl $0, %eax
	# LowerStore(5508:3).2b: mov %temp, (global)
	movl %eax, _ZL4g_66@GOTPCREL(%rip)
	.___ZL7func_57majs2U2__M1049:
	# LowerLoad(5512:3).4: _ZL4g_66 into ^202
	movq _ZL4g_66, %rax
	# LowerIcmp(5513:3): i32 ^202 vs. intlike 1
	cmpl $1, %eax
	setbe %al
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M1055
	jmp .___ZL7func_57majs2U2__M1477
	.___ZL7func_57majs2U2__M1055:
	# SetupCalls(5518:3): move argument ptr align 2 ^47
	movq -1864(%rbp), %rdi
	# SetupCalls(5518:3): move argument ptr align 2 @__const._ZL7func_57majs2U2.l_99
	movq __const._ZL7func_57majs2U2.l_99, %rsi
	# SetupCalls(5518:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# SetupCalls(5520:3): move argument ptr align 16 ^48
	movq -1872(%rbp), %rdi
	# SetupCalls(5520:3): move argument ptr align 16 @__const._ZL7func_57majs2U2.l_104
	movq __const._ZL7func_57majs2U2.l_104, %rsi
	# SetupCalls(5520:3): move argument i64 40
	movq $40, %rdx
	# SetupCalls(5520:3): move argument i1 false
	movq $0, %rcx
	callq llvm.memcpy.p0.p0.i64@PLT@GOTPCREL(%rip)
	# LowerStore(5523:3).9: mov ^14, (^50)
	movq -1888(%rbp), %rax
	# Fixing movq -1776(%rbp), (%rax)
	movq -1776(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5525:3).3: mov $imm, ^51
	movq -1896(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M1112:
	# LowerLoad(5529:3).2: (^51) into ^206
	movq -1896(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(5530:3): i32 ^206 vs. intlike 1
	cmpl $1, %eax
	setl %al
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M1118
	jmp .___ZL7func_57majs2U2__M1139
	.___ZL7func_57majs2U2__M1118:
	# LowerLoad(5534:3).2: (^51) into ^209
	movq -1896(%rbp), %rax
	movl (%rax), %ebx
	movslq %ebx, %rax
	# LowerGetelementptr(5536:3): struct-type: ptr ^49 -> ^211, indices=0,%210
	movq -1880(%rbp), %rbx
	movq %rax, %rcx
	shlq $3, %rcx
	addq %rcx, %rbx
	# LowerGetelementptr(5536:3): type of ^211 is ptr*
	# LowerStore(5537:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rax
	# LowerStore(5537:3).9: mov ^473, (^211)
	movq %rax, (%rbx)
	# LowerLoad(5541:3).2: (^51) into ^213
	movq -1896(%rbp), %rax
	movl (%rax), %ebx
	movl %ebx, %eax
	addl $1, %eax
	# LowerStore(5543:3).9: mov ^214, (^51)
	movq -1896(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .___ZL7func_57majs2U2__M1112
	.___ZL7func_57majs2U2__M1139:
	# LowerLoad(5547:3).4: _ZL4g_66 into ^216
	movq _ZL4g_66, -2000(%rbp)
	# LowerLoad(5548:3).2: (^8) into ^217
	movq -1728(%rbp), %rbx
	# Fixing movq (%rbx), -2008(%rbp)
	movq (%rbx), %r15
	movq %r15, -2008(%rbp)
	# LowerLoad(5549:3).4: _ZL3g_2 into ^218
	movq _ZL3g_2, %r13
	# LowerLoad(5550:3).2: (^13) into ^219
	movq -1768(%rbp), %rax
	movq (%rax), %rbx
	# LowerLoad(5551:3).2: (^34) into ^220
	movq -1784(%rbp), %rax
	movl (%rax), %ecx
	# LowerTrunc(5552:3): 32 to 16, move
	movw %cx, %ax
	# LowerTrunc(5552:3): 32 to 16, apply mask
	andw $65535, %ax
	# LowerLoad(5553:3).2: (^7) into ^222
	movq -1720(%rbp), %rdx
	movl (%rdx), %ecx
	movslq %ecx, %rdx
	# LowerGetelementptr(5555:3): struct-type: ptr ^12 -> ^224, indices=0,%223
	movq -1760(%rbp), %rcx
	movq %rdx, %rsi
	shlq $3, %rsi
	addq %rsi, %rcx
	# LowerGetelementptr(5555:3): type of ^224 is ptr*
	# LowerStore(5556:3).9: mov ^221, (^224)
	movw %ax, (%rcx)
	movswl %ax, %r12d
	# LowerLoad(5558:3).2: (^34) into ^226
	movq -1784(%rbp), %rcx
	movl (%rcx), %eax
	# LowerIcmp(5559:3): i32 ^226 vs. intlike 0
	cmpl $0, %eax
	setne %al
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M1174
	.___ZL7func_57majs2U2__M1171:
	# MovePhi: intlike -> ^263 (in new block 504 whose parent is 215)
	movb $0, -1712(%rbp)
	jmp .___ZL7func_57majs2U2__M1362
	.___ZL7func_57majs2U2__M1174:
	# LowerGetelementptr(5563:3): struct-type: ptr ^35 -> ^229, indices=0,0
	movq -1792(%rbp), %rax
	# LowerGetelementptr(5563:3): type of ^229 is ptr*
	# LowerGetelementptr(5564:3): struct-type: ptr ^229 -> ^230, indices=0,1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5564:3): type of ^230 is ptr*
	# LowerGetelementptr(5565:3): struct-type: ptr ^230 -> ^231, indices=0,2
	movq %rcx, %rax
	addq $16, %rax
	# LowerGetelementptr(5565:3): type of ^231 is ptr*
	# LowerLoad(5566:3).2: (^231) into ^232
	movq (%rax), %rcx
	# LowerLoad(5567:3).2: (^14) into ^233
	movq -1776(%rbp), %rdx
	movl (%rdx), %eax
	movslq %eax, %rdx
	# LowerIcmp(5569:3): i64 ^232 vs. operand i64 ^234
	cmpq %rdx, %rcx
	setb %al
	# LowerBasicConversion(5570:3): ^235 -> ^236
	movl %eax, %ecx
	# LowerLoad(5571:3).2: (^10) into ^237
	movq -1744(%rbp), %rdx
	movl (%rdx), %eax
	# LowerIcmp(5572:3): i32 ^236 vs. operand i32 ^237
	cmpl %eax, %ecx
	setb %al
	# LowerBasicConversion(5573:3): ^238 -> ^239
	movq %rax, %rcx
	# LowerIcmp(5574:3): i64 ^239 vs. intlike 65535
	cmpq $65535, %rcx
	setae %al
	# LowerBasicConversion(5575:3): ^240 -> ^241
	movq %rax, %rcx
	# LowerLoad(5576:3).2: (^11) into ^242
	movq -1752(%rbp), %rdx
	movw (%rdx), %ax
	movswq %ax, %rdx
	# SetupCalls(5578:3): move argument i64 ^241
	movq %rcx, %rdi
	# SetupCalls(5578:3): move argument i64 ^243
	movq %rdx, %rsi
	callq _ZL25safe_sub_func_int64_t_s_sll@GOTPCREL(%rip)
	# SetupCalls(5578:3): move result from %rax
	movq %rax, %r14
	# LowerLoad(5579:3).2: (^9) into ^245
	movq -1736(%rbp), %rax
	movb (%rax), %cl
	movsbq %cl, %rax
	# LowerIcmp(5581:3): i64 ^244 vs. operand i64 ^246
	cmpq %rax, %r14
	setge %al
	# LowerBasicConversion(5582:3): ^247 -> ^248
	movq %rax, %rcx
	# LowerLoad(5583:3).4: _ZL4g_66 into ^249
	movq _ZL4g_66, %rax
	# SetupCalls(5584:3): move argument i64 ^248
	movq %rcx, %rdi
	# SetupCalls(5584:3): move argument i32 ^249
	movl %eax, %esi
	callq _ZL28safe_rshift_func_int64_t_s_ulj@GOTPCREL(%rip)
	# SetupCalls(5584:3): move result from %rax
	movq %rax, %rax
	# LowerGetelementptr(5585:3): struct-type: ptr ^48 -> ^251, indices=0,2
	movq -1872(%rbp), %rax
	addq $16, %rax
	# LowerGetelementptr(5585:3): type of ^251 is ptr*
	# LowerLoad(5586:3).2: (^251) into ^252
	movq (%rax), %rcx
	# LowerIcmp(5587:3): ptr ^252 vs. global _ZL4g_91
	movq %r15, _ZL4g_91@GOTPCREL(%rip)
	movq %r15, (%r15)
	cmpq %r15, %rcx
	setne %al
	# LowerBasicConversion(5588:3): ^253 -> ^254
	movb %al, %cl
	# SetupCalls(5589:3): move argument i8 zeroext ^254
	movb %cl, %dil
	andq $255, %rdi
	# SetupCalls(5589:3): move argument i8 zeroext -1
	movq $-1, %rsi
	andq $255, %rsi
	callq _ZL25safe_mul_func_uint8_t_u_uhh@GOTPCREL(%rip)
	# SetupCalls(5589:3): move result from %rax
	movb %al, %r14b
	# LowerBasicConversion(5590:3): ^255 -> ^256
	movw %r14w, %ax
	# LowerStore(5591:3).8a: movq var, %temp
	movq _ZL5g_106@GOTPCREL(%rip), %rcx
	# LowerStore(5591:3).8b: movq ^256, (%temp)
	movw %ax, (%rcx)
	# LowerBasicConversion(5592:3): ^256 -> ^257
	movl %eax, %ecx
	# LowerStore(5593:3).8a: movq var, %temp
	movq _ZL5g_107@GOTPCREL(%rip), %rax
	# LowerStore(5593:3).8b: movq ^257, (%temp)
	movl %ecx, (%rax)
	# LowerTrunc(5594:3): 32 to 16, move
	movw %cx, %dx
	# LowerTrunc(5594:3): 32 to 16, apply mask
	andw $65535, %dx
	# LowerLoad(5595:3).2: (^7) into ^259
	movq -1720(%rbp), %rax
	movl (%rax), %ecx
	# SetupCalls(5596:3): move argument i16 zeroext ^258
	movw %dx, %di
	andq $65535, %rdi
	# SetupCalls(5596:3): move argument i32 ^259
	movl %ecx, %esi
	callq _ZL29safe_rshift_func_uint16_t_u_sti@GOTPCREL(%rip)
	# SetupCalls(5596:3): move result from %rax
	movw %ax, %r14w
	# LowerIcmp(5597:3): i16 ^260 vs. intlike 0
	cmpw $0, %r14w
	setne %al
	# MovePhi: ^261 -> ^263
	movb %al, -1712(%rbp)
	.___ZL7func_57majs2U2__M1362:
	# LowerBasicConversion(5602:3): ^263 -> ^264
	movl -1712(%rbp), %eax
	# LowerLoad(5603:3).4: _ZL3g_5 into ^265
	movq _ZL3g_5, %rcx
	# LowerIcmp(5604:3): i32 ^264 vs. operand i32 ^265
	cmpl %ecx, %eax
	setle %al
	# LowerBasicConversion(5605:3): ^266 -> ^267
	movl %eax, %ecx
	# LowerIcmp(5606:3): i32 ^225 vs. operand i32 ^267
	cmpl %ecx, %r12d
	sete %al
	# LowerBasicConversion(5607:3): ^268 -> ^269
	movl %eax, %ecx
	# LowerLoad(5608:3).2: (^9) into ^270
	movq -1736(%rbp), %rdx
	movb (%rdx), %al
	movsbl %al, %edx
	# LowerIcmp(5610:3): i32 ^269 vs. operand i32 ^271
	cmpl %edx, %ecx
	setg %al
	# LowerGetelementptr(5611:3): struct-type: ptr ^48 -> ^273, indices=0,1
	movq -1872(%rbp), %rax
	addq $8, %rax
	# LowerGetelementptr(5611:3): type of ^273 is ptr*
	# LowerLoad(5612:3).2: (^273) into ^274
	movq (%rax), %rcx
	# LowerIcmp(5613:3): ptr ^219 vs. operand ptr ^274
	cmpq %rcx, %rbx
	sete %al
	# LowerBasicConversion(5614:3): ^275 -> ^276
	movq %rax, %rbx
	# LowerIcmp(5615:3): i64 ^276 vs. intlike 8
	cmpq $8, %rbx
	sete %al
	# LowerBasicConversion(5616:3): ^277 -> ^278
	movl %eax, %ebx
	# LowerLoad(5617:3).2: (^14) into ^279
	movq -1776(%rbp), %rcx
	movl (%rcx), %eax
	movl %ebx, %ecx
	andl %eax, %ecx
	movl %r13d, %eax
	xorl %ecx, %eax
	# LowerIcmp(5620:3): i64 ^217 vs. intlike 1
	cmpq $1, -2008(%rbp)
	sete %al
	# LowerBasicConversion(5621:3): ^282 -> ^283
	movl %eax, %ebx
	# LowerIcmp(5622:3): i32 ^216 vs. operand i32 ^283
	cmpl %ebx, -2000(%rbp)
	sete %al
	# LowerBasicConversion(5623:3): ^284 -> ^285
	movl %eax, %ebx
	# LowerLoad(5624:3).2: (^9) into ^286
	movq -1736(%rbp), %rcx
	movb (%rcx), %al
	movsbl %al, %ecx
	# LowerIcmp(5626:3): i32 ^285 vs. operand i32 ^287
	cmpl %ecx, %ebx
	setg %al
	# LowerBasicConversion(5627:3): ^288 -> ^289
	movq %rax, %rbx
	# LowerLoad(5628:3).4: _ZL4g_91 into ^290
	movq _ZL4g_91, %rax
	# LowerBasicConversion(5629:3): ^290 -> ^291
	movq %rax, %rcx
	# SetupCalls(5630:3): move argument i64 ^289
	movq %rbx, %rdi
	# SetupCalls(5630:3): move argument i64 ^291
	movq %rcx, %rsi
	callq _ZL25safe_mod_func_int64_t_s_sll@GOTPCREL(%rip)
	# SetupCalls(5630:3): move result from %rax
	movq %rax, %rbx
	# LowerIcmp(5631:3): i64 ^292 vs. intlike 128
	cmpq $128, %rbx
	setne %al
	# LowerBasicConversion(5632:3): ^293 -> ^294
	movq %rax, %rbx
	# LowerIcmp(5633:3): i64 ^294 vs. intlike 0
	cmpq $0, %rbx
	setbe %al
	# LowerBasicConversion(5634:3): ^295 -> ^296
	movl %eax, %ebx
	# LowerLoad(5635:3).2: (^50) into ^297
	movq -1888(%rbp), %rcx
	movq (%rcx), %rax
	# LowerStore(5636:3).9: mov ^296, (^297)
	movl %ebx, (%rax)
	# LowerLoad(5640:3).4: _ZL4g_66 into ^299
	movq _ZL4g_66, %rax
	movl %eax, %ebx
	addl $1, %ebx
	# LowerStore(5642:3).8a: movq var, %temp
	movq _ZL4g_66@GOTPCREL(%rip), %rax
	# LowerStore(5642:3).8b: movq ^300, (%temp)
	movl %ebx, (%rax)
	jmp .___ZL7func_57majs2U2__M1049
	.___ZL7func_57majs2U2__M1477:
	# LowerLoad(5646:3).2: (^43) into ^302
	movq -1856(%rbp), %rbx
	movb (%rbx), %al
	movb %al, %bl
	addb $1, %bl
	# LowerStore(5648:3).9: mov ^303, (^43)
	movq -1856(%rbp), %rax
	movb %bl, (%rax)
	# LowerLoad(5649:3).2: (^9) into ^304
	movq -1736(%rbp), %rbx
	movb (%rbx), %al
	movsbl %al, %ebx
	# LowerLoad(5651:3).4: _ZL5g_124 into ^306
	movq _ZL5g_124, %rcx
	# LowerBasicConversion(5652:3): ^306 -> ^307
	movl %ecx, %eax
	movl %eax, %ecx
	orl %ebx, %ecx
	# LowerTrunc(5654:3): 32 to 16, move
	movw %cx, %ax
	# LowerTrunc(5654:3): 32 to 16, apply mask
	andw $65535, %ax
	# LowerStore(5655:3).8a: movq var, %temp
	movq _ZL5g_124@GOTPCREL(%rip), %rbx
	# LowerStore(5655:3).8b: movq ^309, (%temp)
	movw %ax, (%rbx)
	# LowerLoad(5656:3).2: (^41) into ^310
	movq -1840(%rbp), %rbx
	movq (%rbx), %rax
	# LowerStore(5657:3).3: mov $imm, ^310
	movl $-5, (%rax)
	# LowerLoad(5661:3).2: (^7) into ^312
	movq -1720(%rbp), %rax
	movl (%rax), %ebx
	movl %ebx, %ecx
	addl $1, %ecx
	# LowerStore(5663:3).9: mov ^313, (^7)
	movq -1720(%rbp), %rax
	movl %ecx, (%rax)
	jmp .___ZL7func_57majs2U2__M968
	.___ZL7func_57majs2U2__M1512:
	# LowerStore(5667:3).2a: mov $imm, %temp
	movw $0, %ax
	# LowerStore(5667:3).2b: mov %temp, (global)
	movw %ax, _ZL5g_120@GOTPCREL(%rip)
	.___ZL7func_57majs2U2__M1517:
	# LowerLoad(5671:3).4: _ZL5g_120 into ^316
	movq _ZL5g_120, %rax
	movswl %ax, %ebx
	# LowerIcmp(5673:3): i32 ^317 vs. intlike 5
	cmpl $5, %ebx
	setg %al
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M1524
	jmp .___ZL7func_57majs2U2__M2161
	.___ZL7func_57majs2U2__M1524:
	# LowerStore(5678:3).6: load global
	movq _ZL5g_124@GOTPCREL(%rip), %rbx
	# LowerStore(5678:3).9: mov ^479, (^52)
	movq -1552(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5680:3).3: mov $imm, ^53
	movq -1560(%rbp), %rax
	movq $0, (%rax)
	# LowerStore(5683:3).6: load global
	movq _ZL5g_140@GOTPCREL(%rip), %rbx
	# LowerStore(5683:3).9: mov ^480, (^55)
	movq -1576(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5685:3).9: mov ^55, (^56)
	movq -1584(%rbp), %rax
	# Fixing movq -1576(%rbp), (%rax)
	movq -1576(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5687:3).9: mov ^56, (^57)
	movq -1592(%rbp), %rax
	# Fixing movq -1584(%rbp), (%rax)
	movq -1584(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(5689:3).3: mov $imm, ^58
	movq -1600(%rbp), %rax
	movl $1278886306, (%rax)
	# LowerStore(5691:3).6: load global
	movq _ZL4g_91@GOTPCREL(%rip), %rbx
	# LowerStore(5691:3).9: mov ^481, (^59)
	movq -1608(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5693:3).6: load global
	movq _ZL5g_294@GOTPCREL(%rip), %rbx
	# LowerStore(5693:3).9: mov ^482, (^60)
	movq -1616(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5695:3).6: load global
	movq _ZL5g_132@GOTPCREL(%rip), %rbx
	# LowerStore(5695:3).9: mov ^483, (^61)
	movq -1624(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(5697:3).3: mov $imm, ^62
	movq -1632(%rbp), %rax
	movq $-1, (%rax)
	# LowerStore(5699:3).9: mov ^58, (^63)
	movq -1640(%rbp), %rax
	# Fixing movq -1600(%rbp), (%rax)
	movq -1600(%rbp), %r15
	movq %r15, (%rax)
	# SetupCalls(5701:3): move argument ptr align 2 ^64
	movq -1648(%rbp), %rdi
	# SetupCalls(5701:3): move argument ptr align 2 @__const._ZL7func_57majs2U2.l_545
	movq __const._ZL7func_57majs2U2.l_545, %rsi
	# SetupCalls(5701:3): move argument i64 2
	movq $2, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# SetupCalls(5703:3): move argument ptr align 2 ^65
	movq -1656(%rbp), %rdi
	# SetupCalls(5703:3): move argument ptr align 2 @__const._ZL7func_57majs2U2.l_571
	movq __const._ZL7func_57majs2U2.l_571, %rsi
	# SetupCalls(5703:3): move argument i64 2
	movq $2, %rdx
	# SetupCalls(5703:3): move argument i1 false
	movq $0, %rcx
	callq llvm.memcpy.p0.p0.i64@PLT@GOTPCREL(%rip)
	# LowerGetelementptr(5705:3): struct-type: ptr ^66 -> ^320, indices=0,0
	movq -1664(%rbp), %rax
	# LowerGetelementptr(5705:3): type of ^320 is ptr*
	# LowerGetelementptr(5706:3): struct-type: ptr ^320 -> ^321, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5706:3): type of ^321 is ptr*
	# LowerStore(5707:3).3: mov $imm, ^321
	movb $-80, (%rbx)
	# LowerGetelementptr(5708:3): struct-type: ptr ^320 -> ^322, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5708:3): type of ^322 is ptr*
	# LowerGetelementptr(5709:3): struct-type: ptr ^322 -> ^323, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5709:3): type of ^323 is ptr*
	# LowerStore(5710:3).3: mov $imm, ^323
	movb $-80, (%rax)
	# LowerGetelementptr(5711:3): struct-type: ptr ^322 -> ^324, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5711:3): type of ^324 is ptr*
	# LowerGetelementptr(5712:3): struct-type: ptr ^324 -> ^325, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5712:3): type of ^325 is ptr*
	# LowerStore(5713:3).3: mov $imm, ^325
	movb $-80, (%rbx)
	# LowerGetelementptr(5714:3): struct-type: ptr ^324 -> ^326, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5714:3): type of ^326 is ptr*
	# LowerGetelementptr(5715:3): struct-type: ptr ^326 -> ^327, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5715:3): type of ^327 is ptr*
	# LowerStore(5716:3).3: mov $imm, ^327
	movb $-80, (%rax)
	# LowerGetelementptr(5717:3): struct-type: ptr ^326 -> ^328, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5717:3): type of ^328 is ptr*
	# LowerGetelementptr(5718:3): struct-type: ptr ^328 -> ^329, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5718:3): type of ^329 is ptr*
	# LowerStore(5719:3).3: mov $imm, ^329
	movb $-80, (%rbx)
	# LowerGetelementptr(5720:3): struct-type: ptr ^328 -> ^330, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5720:3): type of ^330 is ptr*
	# LowerGetelementptr(5721:3): struct-type: ptr ^330 -> ^331, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5721:3): type of ^331 is ptr*
	# LowerStore(5722:3).3: mov $imm, ^331
	movb $-80, (%rax)
	# LowerGetelementptr(5723:3): struct-type: ptr ^330 -> ^332, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5723:3): type of ^332 is ptr*
	# LowerGetelementptr(5724:3): struct-type: ptr ^332 -> ^333, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5724:3): type of ^333 is ptr*
	# LowerStore(5725:3).3: mov $imm, ^333
	movb $-80, (%rbx)
	# LowerGetelementptr(5726:3): struct-type: ptr ^332 -> ^334, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5726:3): type of ^334 is ptr*
	# LowerGetelementptr(5727:3): struct-type: ptr ^334 -> ^335, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5727:3): type of ^335 is ptr*
	# LowerStore(5728:3).3: mov $imm, ^335
	movb $-80, (%rax)
	# LowerGetelementptr(5729:3): struct-type: ptr ^334 -> ^336, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5729:3): type of ^336 is ptr*
	# LowerGetelementptr(5730:3): struct-type: ptr ^336 -> ^337, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5730:3): type of ^337 is ptr*
	# LowerStore(5731:3).3: mov $imm, ^337
	movb $-80, (%rbx)
	# LowerStore(5733:3).9: mov ^29, (^67)
	movq -1672(%rbp), %rax
	# Fixing movq -1544(%rbp), (%rax)
	movq -1544(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5735:3): struct-type: ptr ^68 -> ^338, indices=0,0
	movq -1680(%rbp), %rax
	# LowerGetelementptr(5735:3): type of ^338 is ptr*
	# LowerGetelementptr(5736:3): struct-type: ptr ^17 -> ^339, indices=0,9
	movq -1520(%rbp), %rbx
	addq $72, %rbx
	# LowerGetelementptr(5736:3): type of ^339 is ptr*
	# LowerGetelementptr(5737:3): struct-type: ptr ^339 -> ^340, indices=0,1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5737:3): type of ^340 is ptr*
	# LowerStore(5738:3).9: mov ^340, (^338)
	movq %rcx, (%rax)
	# LowerGetelementptr(5739:3): struct-type: ptr ^338 -> ^341, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5739:3): type of ^341 is ptr*
	# LowerGetelementptr(5740:3): struct-type: ptr ^17 -> ^342, indices=0,9
	movq -1520(%rbp), %rax
	addq $72, %rax
	# LowerGetelementptr(5740:3): type of ^342 is ptr*
	# LowerGetelementptr(5741:3): struct-type: ptr ^342 -> ^343, indices=0,1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5741:3): type of ^343 is ptr*
	# LowerStore(5742:3).9: mov ^343, (^341)
	movq %rcx, (%rbx)
	# LowerGetelementptr(5743:3): struct-type: ptr ^341 -> ^344, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5743:3): type of ^344 is ptr*
	# LowerStore(5744:3).3: mov $imm, ^344
	movq $0, (%rax)
	# LowerGetelementptr(5745:3): struct-type: ptr ^344 -> ^345, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5745:3): type of ^345 is ptr*
	# LowerGetelementptr(5746:3): struct-type: ptr ^17 -> ^346, indices=0,9
	movq -1520(%rbp), %rcx
	addq $72, %rcx
	# LowerGetelementptr(5746:3): type of ^346 is ptr*
	# LowerGetelementptr(5747:3): struct-type: ptr ^346 -> ^347, indices=0,1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5747:3): type of ^347 is ptr*
	# LowerStore(5748:3).9: mov ^347, (^345)
	movq %rax, (%rbx)
	# LowerGetelementptr(5749:3): struct-type: ptr ^345 -> ^348, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5749:3): type of ^348 is ptr*
	# LowerGetelementptr(5750:3): struct-type: ptr ^17 -> ^349, indices=0,9
	movq -1520(%rbp), %rbx
	addq $72, %rbx
	# LowerGetelementptr(5750:3): type of ^349 is ptr*
	# LowerGetelementptr(5751:3): struct-type: ptr ^349 -> ^350, indices=0,1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5751:3): type of ^350 is ptr*
	# LowerStore(5752:3).9: mov ^350, (^348)
	movq %rcx, (%rax)
	# LowerGetelementptr(5753:3): struct-type: ptr ^348 -> ^351, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5753:3): type of ^351 is ptr*
	# LowerStore(5754:3).3: mov $imm, ^351
	movq $0, (%rbx)
	# LowerGetelementptr(5755:3): struct-type: ptr ^351 -> ^352, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5755:3): type of ^352 is ptr*
	# LowerGetelementptr(5756:3): struct-type: ptr ^17 -> ^353, indices=0,9
	movq -1520(%rbp), %rbx
	addq $72, %rbx
	# LowerGetelementptr(5756:3): type of ^353 is ptr*
	# LowerGetelementptr(5757:3): struct-type: ptr ^353 -> ^354, indices=0,1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5757:3): type of ^354 is ptr*
	# LowerStore(5758:3).9: mov ^354, (^352)
	movq %rcx, (%rax)
	# LowerGetelementptr(5759:3): struct-type: ptr ^352 -> ^355, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5759:3): type of ^355 is ptr*
	# LowerGetelementptr(5760:3): struct-type: ptr ^17 -> ^356, indices=0,9
	movq -1520(%rbp), %rax
	addq $72, %rax
	# LowerGetelementptr(5760:3): type of ^356 is ptr*
	# LowerGetelementptr(5761:3): struct-type: ptr ^356 -> ^357, indices=0,1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5761:3): type of ^357 is ptr*
	# LowerStore(5762:3).9: mov ^357, (^355)
	movq %rcx, (%rbx)
	# LowerGetelementptr(5763:3): struct-type: ptr ^355 -> ^358, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5763:3): type of ^358 is ptr*
	# LowerStore(5764:3).3: mov $imm, ^358
	movq $0, (%rax)
	# LowerGetelementptr(5765:3): struct-type: ptr ^358 -> ^359, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5765:3): type of ^359 is ptr*
	# LowerGetelementptr(5766:3): struct-type: ptr ^17 -> ^360, indices=0,9
	movq -1520(%rbp), %rax
	addq $72, %rax
	# LowerGetelementptr(5766:3): type of ^360 is ptr*
	# LowerGetelementptr(5767:3): struct-type: ptr ^360 -> ^361, indices=0,1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5767:3): type of ^361 is ptr*
	# LowerStore(5768:3).9: mov ^361, (^359)
	movq %rcx, (%rbx)
	# LowerStore(5770:3).6: load global
	movq _ZL4g_66@GOTPCREL(%rip), %rbx
	# LowerStore(5770:3).9: mov ^484, (^69)
	movq -1688(%rbp), %rax
	movq %rbx, (%rax)
	# LowerGetelementptr(5772:3): struct-type: ptr ^70 -> ^362, indices=0,0
	movq -1696(%rbp), %rbx
	# LowerGetelementptr(5772:3): type of ^362 is ptr*
	# LowerGetelementptr(5773:3): struct-type: ptr ^362 -> ^363, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5773:3): type of ^363 is ptr*
	# LowerGetelementptr(5774:3): struct-type: ptr ^363 -> ^364, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(5774:3): type of ^364 is ptr*
	# LowerStore(5775:3).6: load global
	movq _ZL5g_313@GOTPCREL(%rip), %rax
	# LowerStore(5775:3).9: mov ^485, (^364)
	movq %rax, (%rcx)
	# LowerGetelementptr(5776:3): struct-type: ptr ^364 -> ^365, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5776:3): type of ^365 is ptr*
	# LowerStore(5777:3).9: mov ^65, (^365)
	# Fixing movq -1656(%rbp), (%rax)
	movq -1656(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5778:3): struct-type: ptr ^365 -> ^366, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5778:3): type of ^366 is ptr*
	# LowerStore(5779:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rax
	# LowerStore(5779:3).9: mov ^486, (^366)
	movq %rax, (%rcx)
	# LowerGetelementptr(5780:3): struct-type: ptr ^366 -> ^367, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5780:3): type of ^367 is ptr*
	# LowerStore(5781:3).9: mov ^29, (^367)
	# Fixing movq -1544(%rbp), (%rax)
	movq -1544(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5782:3): struct-type: ptr ^367 -> ^368, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5782:3): type of ^368 is ptr*
	# LowerStore(5783:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rax
	# LowerStore(5783:3).9: mov ^487, (^368)
	movq %rax, (%rcx)
	# LowerGetelementptr(5784:3): struct-type: ptr ^368 -> ^369, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5784:3): type of ^369 is ptr*
	# LowerStore(5785:3).9: mov ^65, (^369)
	# Fixing movq -1656(%rbp), (%rax)
	movq -1656(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5786:3): struct-type: ptr ^362 -> ^370, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5786:3): type of ^370 is ptr*
	# LowerGetelementptr(5787:3): struct-type: ptr ^370 -> ^371, indices=0,0
	movq %rcx, %rax
	# LowerGetelementptr(5787:3): type of ^371 is ptr*
	# LowerGetelementptr(5788:3): struct-type: ptr ^371 -> ^372, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5788:3): type of ^372 is ptr*
	# LowerStore(5789:3).6: load global
	movq _ZL5g_313@GOTPCREL(%rip), %rax
	# LowerStore(5789:3).9: mov ^488, (^372)
	movq %rax, (%rbx)
	# LowerGetelementptr(5790:3): struct-type: ptr ^372 -> ^373, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5790:3): type of ^373 is ptr*
	# LowerStore(5791:3).9: mov ^65, (^373)
	# Fixing movq -1656(%rbp), (%rax)
	movq -1656(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5792:3): struct-type: ptr ^373 -> ^374, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5792:3): type of ^374 is ptr*
	# LowerStore(5793:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rax
	# LowerStore(5793:3).9: mov ^489, (^374)
	movq %rax, (%rbx)
	# LowerGetelementptr(5794:3): struct-type: ptr ^374 -> ^375, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5794:3): type of ^375 is ptr*
	# LowerStore(5795:3).9: mov ^29, (^375)
	# Fixing movq -1544(%rbp), (%rax)
	movq -1544(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5796:3): struct-type: ptr ^375 -> ^376, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5796:3): type of ^376 is ptr*
	# LowerStore(5797:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rax
	# LowerStore(5797:3).9: mov ^490, (^376)
	movq %rax, (%rbx)
	# LowerGetelementptr(5798:3): struct-type: ptr ^376 -> ^377, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5798:3): type of ^377 is ptr*
	# LowerStore(5799:3).9: mov ^65, (^377)
	# Fixing movq -1656(%rbp), (%rax)
	movq -1656(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5800:3): struct-type: ptr ^370 -> ^378, indices=1
	movq %rcx, %rdx
	addq $8, %rdx
	# LowerGetelementptr(5800:3): type of ^378 is ptr*
	# LowerGetelementptr(5801:3): struct-type: ptr ^378 -> ^379, indices=0,0
	movq %rdx, %rax
	# LowerGetelementptr(5801:3): type of ^379 is ptr*
	# LowerGetelementptr(5802:3): struct-type: ptr ^379 -> ^380, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5802:3): type of ^380 is ptr*
	# LowerStore(5803:3).6: load global
	movq _ZL5g_313@GOTPCREL(%rip), %rax
	# LowerStore(5803:3).9: mov ^491, (^380)
	movq %rax, (%rbx)
	# LowerGetelementptr(5804:3): struct-type: ptr ^380 -> ^381, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5804:3): type of ^381 is ptr*
	# LowerStore(5805:3).9: mov ^65, (^381)
	# Fixing movq -1656(%rbp), (%rax)
	movq -1656(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5806:3): struct-type: ptr ^381 -> ^382, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5806:3): type of ^382 is ptr*
	# LowerStore(5807:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rax
	# LowerStore(5807:3).9: mov ^492, (^382)
	movq %rax, (%rbx)
	# LowerGetelementptr(5808:3): struct-type: ptr ^382 -> ^383, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5808:3): type of ^383 is ptr*
	# LowerStore(5809:3).9: mov ^29, (^383)
	# Fixing movq -1544(%rbp), (%rax)
	movq -1544(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5810:3): struct-type: ptr ^383 -> ^384, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5810:3): type of ^384 is ptr*
	# LowerStore(5811:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rax
	# LowerStore(5811:3).9: mov ^493, (^384)
	movq %rax, (%rbx)
	# LowerGetelementptr(5812:3): struct-type: ptr ^384 -> ^385, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5812:3): type of ^385 is ptr*
	# LowerStore(5813:3).9: mov ^65, (^385)
	# Fixing movq -1656(%rbp), (%rax)
	movq -1656(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5814:3): struct-type: ptr ^378 -> ^386, indices=1
	movq %rdx, %rax
	addq $8, %rax
	# LowerGetelementptr(5814:3): type of ^386 is ptr*
	# LowerGetelementptr(5815:3): struct-type: ptr ^386 -> ^387, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5815:3): type of ^387 is ptr*
	# LowerGetelementptr(5816:3): struct-type: ptr ^387 -> ^388, indices=0,0
	movq %rbx, %rcx
	# LowerGetelementptr(5816:3): type of ^388 is ptr*
	# LowerStore(5817:3).6: load global
	movq _ZL5g_313@GOTPCREL(%rip), %rbx
	# LowerStore(5817:3).9: mov ^494, (^388)
	movq %rbx, (%rcx)
	# LowerGetelementptr(5818:3): struct-type: ptr ^388 -> ^389, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5818:3): type of ^389 is ptr*
	# LowerStore(5819:3).9: mov ^65, (^389)
	# Fixing movq -1656(%rbp), (%rbx)
	movq -1656(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(5820:3): struct-type: ptr ^389 -> ^390, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5820:3): type of ^390 is ptr*
	# LowerStore(5821:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rbx
	# LowerStore(5821:3).9: mov ^495, (^390)
	movq %rbx, (%rcx)
	# LowerGetelementptr(5822:3): struct-type: ptr ^390 -> ^391, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5822:3): type of ^391 is ptr*
	# LowerStore(5823:3).9: mov ^29, (^391)
	# Fixing movq -1544(%rbp), (%rbx)
	movq -1544(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(5824:3): struct-type: ptr ^391 -> ^392, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5824:3): type of ^392 is ptr*
	# LowerStore(5825:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rbx
	# LowerStore(5825:3).9: mov ^496, (^392)
	movq %rbx, (%rcx)
	# LowerGetelementptr(5826:3): struct-type: ptr ^392 -> ^393, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5826:3): type of ^393 is ptr*
	# LowerStore(5827:3).9: mov ^65, (^393)
	# Fixing movq -1656(%rbp), (%rbx)
	movq -1656(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(5828:3): struct-type: ptr ^386 -> ^394, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5828:3): type of ^394 is ptr*
	# LowerGetelementptr(5829:3): struct-type: ptr ^394 -> ^395, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5829:3): type of ^395 is ptr*
	# LowerGetelementptr(5830:3): struct-type: ptr ^395 -> ^396, indices=0,0
	movq %rax, %rcx
	# LowerGetelementptr(5830:3): type of ^396 is ptr*
	# LowerStore(5831:3).6: load global
	movq _ZL5g_313@GOTPCREL(%rip), %rax
	# LowerStore(5831:3).9: mov ^497, (^396)
	movq %rax, (%rcx)
	# LowerGetelementptr(5832:3): struct-type: ptr ^396 -> ^397, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5832:3): type of ^397 is ptr*
	# LowerStore(5833:3).9: mov ^65, (^397)
	# Fixing movq -1656(%rbp), (%rax)
	movq -1656(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5834:3): struct-type: ptr ^397 -> ^398, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5834:3): type of ^398 is ptr*
	# LowerStore(5835:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rax
	# LowerStore(5835:3).9: mov ^498, (^398)
	movq %rax, (%rcx)
	# LowerGetelementptr(5836:3): struct-type: ptr ^398 -> ^399, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5836:3): type of ^399 is ptr*
	# LowerStore(5837:3).9: mov ^29, (^399)
	# Fixing movq -1544(%rbp), (%rax)
	movq -1544(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(5838:3): struct-type: ptr ^399 -> ^400, indices=1
	movq %rax, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5838:3): type of ^400 is ptr*
	# LowerGetelementptr(5839:3): struct-type: ptr ^27 -> ^401, indices=0,0
	movq -1528(%rbp), %rax
	# LowerGetelementptr(5839:3): type of ^401 is ptr*
	# LowerStore(5840:3).9: mov ^401, (^400)
	movq %rax, (%rcx)
	# LowerGetelementptr(5841:3): struct-type: ptr ^400 -> ^402, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(5841:3): type of ^402 is ptr*
	# LowerStore(5842:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rcx
	# LowerStore(5842:3).9: mov ^499, (^402)
	movq %rcx, (%rax)
	# LowerGetelementptr(5843:3): struct-type: ptr ^394 -> ^403, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5843:3): type of ^403 is ptr*
	# LowerGetelementptr(5844:3): struct-type: ptr ^403 -> ^404, indices=0,0
	movq %rax, %rbx
	# LowerGetelementptr(5844:3): type of ^404 is ptr*
	# LowerGetelementptr(5845:3): struct-type: ptr ^404 -> ^405, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(5845:3): type of ^405 is ptr*
	# LowerStore(5846:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rbx
	# LowerStore(5846:3).9: mov ^500, (^405)
	movq %rbx, (%rax)
	# LowerGetelementptr(5847:3): struct-type: ptr ^405 -> ^406, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5847:3): type of ^406 is ptr*
	# LowerStore(5848:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rax
	# LowerStore(5848:3).9: mov ^501, (^406)
	movq %rax, (%rbx)
	# LowerGetelementptr(5849:3): struct-type: ptr ^406 -> ^407, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5849:3): type of ^407 is ptr*
	# LowerGetelementptr(5850:3): struct-type: ptr ^27 -> ^408, indices=0,0
	movq -1528(%rbp), %rbx
	# LowerGetelementptr(5850:3): type of ^408 is ptr*
	# LowerStore(5851:3).9: mov ^408, (^407)
	movq %rbx, (%rax)
	# LowerGetelementptr(5852:3): struct-type: ptr ^407 -> ^409, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5852:3): type of ^409 is ptr*
	# LowerStore(5853:3).9: mov ^65, (^409)
	# Fixing movq -1656(%rbp), (%rbx)
	movq -1656(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(5854:3): struct-type: ptr ^409 -> ^410, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(5854:3): type of ^410 is ptr*
	# LowerGetelementptr(5855:3): struct-type: ptr ^27 -> ^411, indices=0,0
	movq -1528(%rbp), %rbx
	# LowerGetelementptr(5855:3): type of ^411 is ptr*
	# LowerStore(5856:3).9: mov ^411, (^410)
	movq %rbx, (%rax)
	# LowerGetelementptr(5857:3): struct-type: ptr ^410 -> ^412, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(5857:3): type of ^412 is ptr*
	# LowerStore(5858:3).6: load global
	movq _ZL5g_106@GOTPCREL(%rip), %rax
	# LowerStore(5858:3).9: mov ^502, (^412)
	movq %rax, (%rbx)
	# LowerStore(5862:3).3: mov $imm, ^71
	movq -1704(%rbp), %rax
	movl $0, (%rax)
	.___ZL7func_57majs2U2__M2114:
	# LowerLoad(5866:3).2: (^71) into ^414
	movq -1704(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(5867:3): i32 ^414 vs. intlike 6
	cmpl $6, %ebx
	setl %al
	cmpb $0, %al
	jne .___ZL7func_57majs2U2__M2120
	jmp .___ZL7func_57majs2U2__M2151
	.___ZL7func_57majs2U2__M2120:
	# LowerGetelementptr(5871:3): struct-type: ptr ^15 -> ^417, indices=0,7
	movq -1512(%rbp), %rax
	addq $56, %rax
	# LowerGetelementptr(5871:3): type of ^417 is ptr*
	# LowerGetelementptr(5872:3): struct-type: ptr ^417 -> ^418, indices=0,4
	movq %rax, %rbx
	addq $32, %rbx
	# LowerGetelementptr(5872:3): type of ^418 is ptr*
	# LowerGetelementptr(5873:3): struct-type: ptr ^418 -> ^419, indices=0,1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(5873:3): type of ^419 is ptr*
	# LowerLoad(5874:3).2: (^71) into ^420
	movq -1704(%rbp), %rax
	movl (%rax), %ebx
	movslq %ebx, %rax
	# LowerGetelementptr(5876:3): struct-type: ptr ^54 -> ^422, indices=0,%421
	movq -1568(%rbp), %rbx
	movq %rax, %rdx
	shlq $3, %rdx
	addq %rdx, %rbx
	# LowerGetelementptr(5876:3): type of ^422 is ptr*
	# LowerStore(5877:3).9: mov ^419, (^422)
	movq %rcx, (%rbx)
	# LowerLoad(5881:3).2: (^71) into ^424
	movq -1704(%rbp), %rax
	movl (%rax), %ebx
	movl %ebx, %ecx
	addl $1, %ecx
	# LowerStore(5883:3).9: mov ^425, (^71)
	movq -1704(%rbp), %rax
	movl %ecx, (%rax)
	jmp .___ZL7func_57majs2U2__M2114
	.___ZL7func_57majs2U2__M2151:
	# LowerLoad(5890:3).4: _ZL5g_120 into ^428
	movq _ZL5g_120, %rax
	movw %ax, %bx
	addw $1, %bx
	# LowerStore(5892:3).8a: movq var, %temp
	movq _ZL5g_120@GOTPCREL(%rip), %rax
	# LowerStore(5892:3).8b: movq ^429, (%temp)
	movw %bx, (%rax)
	jmp .___ZL7func_57majs2U2__M1517
	.___ZL7func_57majs2U2__M2161:
	# LowerLoad(5896:3).4: _ZL5g_139 into ^431
	movq _ZL5g_139, %rax
	# LowerLoad(5897:3).2: (^431) into ^432
	movq (%rax), %rbx
	# LowerLoad(5898:3).4: _ZL5g_139 into ^433
	movq _ZL5g_139, %rax
	# LowerStore(5899:3).9: mov ^432, (^433)
	movq %rbx, (%rax)
	# LowerLoad(5900:3).2: (^30) into ^434
	movq -1536(%rbp), %rax
	movq (%rax), %rbx
	# SetupCalls(5901:3): move argument ptr align 4 ^6
	movq -1504(%rbp), %rdi
	# SetupCalls(5901:3): move argument ptr align 4 ^434
	movq %rbx, %rsi
	# SetupCalls(5901:3): move argument i64 4
	movq $4, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerGetelementptr(5902:3): struct-type: ptr ^6 -> ^435, indices=0,0
	movq -1504(%rbp), %rax
	# LowerGetelementptr(5902:3): type of ^435 is ptr*
	# LowerLoad(5903:3).2: (^435) into ^436
	movl (%rax), %ebx
	movl %ebx, %eax
	movq -2656(%rbp), %r14
	movq -2632(%rbp), %r13
	movq -2648(%rbp), %r12
	movq -2016(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL26safe_mul_func_uint64_t_u_umm
.p2align 4, 0x90
_ZL26safe_mul_func_uint64_t_u_umm:
	.___ZL26safe_mul_func_uint64_t_u_umm__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(3868:3): size = 8, type = i64*, var = ^3
	leaq -8(%rbp), %rcx
	# LowerAlloca(3869:3): size = 8, type = i64*, var = ^4
	leaq -16(%rbp), %rax
	# LowerStore(3870:3).9: mov %rdi, (^3)
	movq %rdi, (%rcx)
	# LowerStore(3872:3).9: mov %rsi, (^4)
	movq %rsi, (%rax)
	# LowerLoad(3874:3).2: (^3) into ^5
	movq (%rcx), %rbx
	# LowerLoad(3875:3).2: (^4) into ^6
	movq (%rax), %rcx
	movq %rbx, %rax
	mulq %rcx
	movq %rax, %rbx
	movq %rbx, %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZN2U0aSERKS_
.p2align 4, 0x90
_ZN2U0aSERKS_:
	.___ZN2U0aSERKS___M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	movq %rbx, -40(%rbp)
	movq %r12, -48(%rbp)
	movq %r13, -32(%rbp)
	# LowerAlloca(5909:3): size = 8, type = ptr*, var = ^3
	leaq -8(%rbp), %r13
	# LowerAlloca(5910:3): size = 8, type = ptr*, var = ^4
	leaq -16(%rbp), %rax
	# LowerAlloca(5911:3): size = 8, type = ptr*, var = ^5
	leaq -24(%rbp), %rbx
	# LowerStore(5912:3).9: mov %rdi, (^4)
	movq %rdi, (%rax)
	# LowerStore(5914:3).9: mov %rsi, (^5)
	movq %rsi, (%rbx)
	# LowerLoad(5916:3).2: (^4) into ^6
	movq (%rax), %r12
	# LowerLoad(5917:3).2: (^5) into ^7
	movq (%rbx), %rax
	# LowerIcmp(5918:3): ptr ^6 vs. operand ptr ^7
	cmpq %rax, %r12
	sete %al
	cmpb $0, %al
	jne .___ZN2U0aSERKS___M18
	jmp .___ZN2U0aSERKS___M21
	.___ZN2U0aSERKS___M18:
	# LowerStore(5922:3).9: mov ^6, (^3)
	movq %r12, (%r13)
	jmp .___ZN2U0aSERKS___M51
	.___ZN2U0aSERKS___M21:
	# LowerLoad(5926:3).2: (^5) into ^11
	movq (%rbx), %rax
	# SetupCalls(5927:3): move argument ptr align 4 ^6
	movq %r12, %rdi
	# SetupCalls(5927:3): move argument ptr align 4 ^11
	movq %rax, %rsi
	# SetupCalls(5927:3): move argument i64 4
	movq $4, %rdx
	callq memcpy@PLT@GOTPCREL(%rip)
	# LowerStore(5928:3).9: mov ^6, (^3)
	movq %r12, (%r13)
	.___ZN2U0aSERKS___M51:
	# LowerLoad(5932:3).2: (^3) into ^13
	movq (%r13), %rax
	movq -32(%rbp), %r13
	movq -48(%rbp), %r12
	movq -40(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL25safe_mod_func_uint8_t_u_uhh
.p2align 4, 0x90
_ZL25safe_mod_func_uint8_t_u_uhh:
	.___ZL25safe_mod_func_uint8_t_u_uhh__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(72 + 0, 16)
	subq $80, %rsp
	movq %rbx, -32(%rbp)
	# LowerAlloca(5938:3): size = 1, type = i8*, var = ^3
	leaq -1(%rbp), %rdx
	# LowerAlloca(5939:3): size = 1, type = i8*, var = ^4
	leaq -2(%rbp), %rax
	# LowerStore(5940:3).9: mov %dil, (^3)
	movb %dil, (%rdx)
	# LowerStore(5942:3).9: mov %sil, (^4)
	movb %sil, (%rax)
	# LowerLoad(5944:3).2: (^4) into ^5
	movb (%rax), %bl
	# LowerBasicConversion(5945:3): ^5 -> ^6
	movl %ebx, %ecx
	# LowerIcmp(5946:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	sete %bl
	cmpb $0, %bl
	jne .___ZL25safe_mod_func_uint8_t_u_uhh__M16
	jmp .___ZL25safe_mod_func_uint8_t_u_uhh__M23
	.___ZL25safe_mod_func_uint8_t_u_uhh__M16:
	# LowerLoad(5950:3).2: (^3) into ^9
	movb (%rdx), %al
	# LowerBasicConversion(5951:3): ^9 -> ^10
	movl %eax, %ebx
	# MovePhi: ^10 -> ^18
	movl %ebx, %r8d
	jmp .___ZL25safe_mod_func_uint8_t_u_uhh__M42
	.___ZL25safe_mod_func_uint8_t_u_uhh__M23:
	# LowerLoad(5955:3).2: (^3) into ^12
	movb (%rdx), %bl
	# LowerBasicConversion(5956:3): ^12 -> ^13
	movl %ebx, %ecx
	# LowerLoad(5957:3).2: (^4) into ^14
	movb (%rax), %bl
	# LowerBasicConversion(5958:3): ^14 -> ^15
	movl %ebx, %esi
	# Clobber %rax
	movq %rax, -16(%rbp)
	# Clobber %rdx
	movq %rdx, -24(%rbp)
	movl $0, %edx
	movl %ecx, %eax
	idivl %esi
	movl %edx, %ebx
	# Unclobber %rdx
	movq -24(%rbp), %rdx
	# Unclobber %rax
	movq -16(%rbp), %rax
	# MovePhi: ^16 -> ^18
	movl %ebx, %r8d
	.___ZL25safe_mod_func_uint8_t_u_uhh__M42:
	# LowerTrunc(5964:3): 32 to 8, move
	movb %r8b, %al
	# LowerTrunc(5964:3): 32 to 8, apply mask
	andb $255, %al
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global _ZL28safe_lshift_func_int16_t_s_ssi
.p2align 4, 0x90
_ZL28safe_lshift_func_int16_t_s_ssi:
	.___ZL28safe_lshift_func_int16_t_s_ssi__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(88 + 0, 16)
	subq $96, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(6014:3): size = 2, type = i16*, var = ^3
	leaq -2(%rbp), %rdx
	# LowerAlloca(6015:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(6016:3).9: mov %di, (^3)
	movw %di, (%rdx)
	# LowerStore(6018:3).9: mov %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(6020:3).2: (^3) into ^5
	movw (%rdx), %bx
	movswl %bx, %ecx
	# LowerIcmp(6022:3): i32 ^6 vs. intlike 0
	cmpl $0, %ecx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_ssi__M40
	.___ZL28safe_lshift_func_int16_t_s_ssi__M15:
	# LowerLoad(6026:3).2: (^4) into ^9
	movl (%rax), %ebx
	# LowerIcmp(6027:3): i32 ^9 vs. intlike 0
	cmpl $0, %ebx
	setl %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_ssi__M40
	.___ZL28safe_lshift_func_int16_t_s_ssi__M21:
	# LowerLoad(6031:3).2: (^4) into ^12
	movl (%rax), %ebx
	# LowerIcmp(6032:3): i32 ^12 vs. intlike 32
	cmpl $32, %ebx
	setge %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_ssi__M40
	.___ZL28safe_lshift_func_int16_t_s_ssi__M27:
	# LowerLoad(6036:3).2: (^3) into ^15
	movw (%rdx), %cx
	movswl %cx, %ebx
	# LowerLoad(6038:3).2: (^4) into ^17
	movl (%rax), %esi
	# LowerShift(6039:3): operand ^17 changed to %cl
	movb %sil, %cl
	movl $32767, %esi
	sarl %cl, %esi
	# LowerIcmp(6040:3): i32 ^16 vs. operand i32 ^18
	cmpl %esi, %ebx
	setg %bl
	cmpb $0, %bl
	jne .___ZL28safe_lshift_func_int16_t_s_ssi__M40
	jmp .___ZL28safe_lshift_func_int16_t_s_ssi__M46
	.___ZL28safe_lshift_func_int16_t_s_ssi__M40:
	# LowerLoad(6044:3).2: (^3) into ^21
	movw (%rdx), %bx
	movswl %bx, %eax
	# MovePhi: ^22 -> ^29
	movl %eax, %r8d
	jmp .___ZL28safe_lshift_func_int16_t_s_ssi__M58
	.___ZL28safe_lshift_func_int16_t_s_ssi__M46:
	# LowerLoad(6049:3).2: (^3) into ^24
	movw (%rdx), %cx
	movswl %cx, %ebx
	# LowerLoad(6051:3).2: (^4) into ^26
	movl (%rax), %edx
	# LowerShift(6052:3): operand ^26 changed to %cl
	movb %dl, %cl
	movl %ebx, %eax
	shll %cl, %eax
	# MovePhi: ^27 -> ^29
	movl %eax, %r8d
	.___ZL28safe_lshift_func_int16_t_s_ssi__M58:
	# LowerTrunc(6057:3): 32 to 16, move
	movw %r8w, %ax
	# LowerTrunc(6057:3): 32 to 16, apply mask
	andw $65535, %ax
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

