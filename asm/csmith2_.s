.section .rodata
.align 8
.str:
.ascii "1\000"

.section .rodata
.align 8
.str.1:
.ascii "g_2[i][j][k]\000"

.section .rodata
.align 8
.str.10:
.ascii "g_126\000"

.section .rodata
.align 8
.str.11:
.ascii "g_127[i]\000"

.section .rodata
.align 8
.str.12:
.ascii "index = [%d]\012\000"

.section .rodata
.align 8
.str.13:
.ascii "g_137[i][j][k]\000"

.section .rodata
.align 8
.str.14:
.ascii "g_157\000"

.section .rodata
.align 8
.str.15:
.ascii "g_159\000"

.section .rodata
.align 8
.str.16:
.ascii "g_205\000"

.section .rodata
.align 8
.str.17:
.ascii "g_209\000"

.section .rodata
.align 8
.str.18:
.ascii "g_222\000"

.section .rodata
.align 8
.str.19:
.ascii "g_225\000"

.section .rodata
.align 8
.str.2:
.ascii "index = [%d][%d][%d]\012\000"

.section .rodata
.align 8
.str.20:
.ascii "g_238\000"

.section .rodata
.align 8
.str.21:
.ascii "g_239[i][j][k]\000"

.section .rodata
.align 8
.str.22:
.ascii "g_240\000"

.section .rodata
.align 8
.str.23:
.ascii "g_283\000"

.section .rodata
.align 8
.str.24:
.ascii "g_313[i]\000"

.section .rodata
.align 8
.str.25:
.ascii "g_385.f0\000"

.section .rodata
.align 8
.str.26:
.ascii "g_468\000"

.section .rodata
.align 8
.str.27:
.ascii "g_469\000"

.section .rodata
.align 8
.str.28:
.ascii "g_470\000"

.section .rodata
.align 8
.str.29:
.ascii "g_477\000"

.section .rodata
.align 8
.str.3:
.ascii "g_16.f0\000"

.section .rodata
.align 8
.str.30:
.ascii "g_527\000"

.section .rodata
.align 8
.str.31:
.ascii "g_541\000"

.section .rodata
.align 8
.str.32:
.ascii "g_575\000"

.section .rodata
.align 8
.str.33:
.ascii "g_577\000"

.section .rodata
.align 8
.str.34:
.ascii "g_617\000"

.section .rodata
.align 8
.str.35:
.ascii "g_666\000"

.section .rodata
.align 8
.str.36:
.ascii "g_667[i][j]\000"

.section .rodata
.align 8
.str.37:
.ascii "index = [%d][%d]\012\000"

.section .rodata
.align 8
.str.38:
.ascii "g_764[i]\000"

.section .rodata
.align 8
.str.39:
.ascii "g_765\000"

.section .rodata
.align 8
.str.4:
.ascii "g_44[i][j][k]\000"

.section .rodata
.align 8
.str.40:
.ascii "g_805[i]\000"

.section .rodata
.align 8
.str.41:
.ascii "g_807\000"

.section .rodata
.align 8
.str.42:
.ascii "g_948\000"

.section .rodata
.align 8
.str.43:
.ascii "g_960\000"

.section .rodata
.align 8
.str.44:
.ascii "g_1154\000"

.section .rodata
.align 8
.str.45:
.ascii "g_1447\000"

.section .rodata
.align 8
.str.46:
.ascii "g_1567\000"

.section .rodata
.align 8
.str.47:
.ascii "g_1628\000"

.section .rodata
.align 8
.str.48:
.ascii "g_1636[i][j]\000"

.section .rodata
.align 8
.str.49:
.ascii "g_1637\000"

.section .rodata
.align 8
.str.5:
.ascii "g_48\000"

.section .rodata
.align 8
.str.50:
.ascii "g_1639[i]\000"

.section .rodata
.align 8
.str.51:
.ascii "g_1702[i]\000"

.section .rodata
.align 8
.str.52:
.ascii "g_1733\000"

.section .rodata
.align 8
.str.53:
.ascii "g_1737\000"

.section .rodata
.align 8
.str.54:
.ascii "g_1758\000"

.section .rodata
.align 8
.str.55:
.ascii "g_1831\000"

.section .rodata
.align 8
.str.56:
.ascii "g_1926\000"

.section .rodata
.align 8
.str.57:
.ascii "g_1937\000"

.section .rodata
.align 8
.str.58:
.ascii "g_2031[i][j][k]\000"

.section .rodata
.align 8
.str.59:
.ascii "g_2146\000"

.section .rodata
.align 8
.str.6:
.ascii "g_84\000"

.section .rodata
.align 8
.str.60:
.ascii "g_2252\000"

.section .rodata
.align 8
.str.61:
.ascii "g_2285\000"

.section .rodata
.align 8
.str.62:
.ascii "g_2577\000"

.section .rodata
.align 8
.str.63:
.ascii "g_2613\000"

.section .rodata
.align 8
.str.64:
.ascii "g_2691[i][j]\000"

.section .rodata
.align 8
.str.65:
.ascii "g_2782\000"

.section .rodata
.align 8
.str.66:
.ascii "g_2937\000"

.section .rodata
.align 8
.str.67:
.ascii "g_2939\000"

.section .rodata
.align 8
.str.68:
.ascii "g_3056[i][j][k]\000"

.section .rodata
.align 8
.str.69:
.ascii "g_3218\000"

.section .rodata
.align 8
.str.7:
.ascii "g_91\000"

.section .rodata
.align 8
.str.70:
.ascii "g_3318\000"

.section .rodata
.align 8
.str.71:
.ascii "g_3326\000"

.section .rodata
.align 8
.str.72:
.ascii "g_3368\000"

.section .rodata
.align 8
.str.73:
.ascii "g_3436\000"

.section .rodata
.align 8
.str.74:
.ascii "g_3498\000"

.section .rodata
.align 8
.str.75:
.ascii "g_3513\000"

.section .rodata
.align 8
.str.76:
.ascii "g_3516\000"

.section .rodata
.align 8
.str.77:
.ascii "g_3529\000"

.section .rodata
.align 8
.str.78:
.ascii "g_3532\000"

.section .rodata
.align 8
.str.79:
.ascii "g_3667\000"

.section .rodata
.align 8
.str.8:
.ascii "g_124\000"

.section .rodata
.align 8
.str.80:
.ascii "g_3718\000"

.section .rodata
.align 8
.str.81:
.ascii "g_3725\000"

.section .rodata
.align 8
.str.82:
.ascii "g_3728\000"

.section .rodata
.align 8
.str.83:
.ascii "g_3729\000"

.section .rodata
.align 8
.str.84:
.ascii "g_3758\000"

.section .rodata
.align 8
.str.85:
.ascii "g_3812\000"

.section .rodata
.align 8
.str.86:
.ascii "g_3917[i][j]\000"

.section .rodata
.align 8
.str.87:
.ascii "g_3958\000"

.section .rodata
.align 8
.str.9:
.ascii "g_125\000"

.section .rodata
.align 8
.str.90:
.ascii "...checksum after hashing %s : %lX\012\000"

.section .rodata
.align 8
.str.91:
.ascii "checksum = %X\012\000"

.section .data
.align 8
__const.func_1.l_3841:
.quad 7314920260613050551

.section .data
.align 8
__const.func_1.l_3954:
.quad -1313740227392601378

.section .data
.align 8
__const.func_1.l_3957:
.word 6
.word 24798
.word 24798
.word 24798
.word -4
.word 6984
.word 6
.word -4
.word 6
.word 32255
.word 24798
.word 6984
.word 32255
.word 32255
.word 24798
.word 6
.word 24798
.word 24798
.word 24798
.word -4
.word 6984

.section .data
.align 8
constinit:
.fill 72, 1, 0

.section .data
.align 8
constinit.88:
.fill 72, 1, 0

.section .data
.align 8
constinit.89:
.fill 72, 1, 0

.section .data
.align 8
crc32_context:
.int -1

.section .data
.align 8
crc32_tab:
.fill 1024, 1, 0

.section .data
.align 8
g_1154:
.word -3

.section .data
.align 8
g_124:
.word -13650

.section .data
.align 8
g_125:
.byte 0

.section .data
.align 8
g_126:
.byte 7

.section .rodata
.align 8
g_127:
.ascii "pp"

.section .data
.align 8
g_137:
.word 25869
.word -30071
.word -1
.word -1
.word 1
.word -27779
.word -7613
.word 2
.word 1
.word -24968
.word -28179
.word 25869
.word -25277
.word -7613
.word 1
.word 0
.word 1
.word -13387
.word 0
.word 25869
.word 1
.word 0
.word -2253
.word 2
.word 0
.word 1
.word -24968
.word -25277
.word 1
.word -25277
.word -24968
.word 1
.word -1
.word -7613
.word 0
.word 2
.word -25277
.word -28179
.word 2
.word -27779
.word 25869
.word 1
.word 1
.word -2253
.word -1
.word 0
.word 2
.word -13387
.word -27779
.word -2253
.word 0
.word -28179
.word 11630
.word -24968
.word -24968
.word 11630
.word 11630
.word -24968
.word -24968
.word 11630
.word -28179
.word 0
.word -2253
.word -27779

.section .data
.align 8
g_1447:
.byte 1

.section .data
.align 8
g_1567:
.byte -1

.section .data
.align 8
g_159:
.quad 5

.section .data
.align 8
g_16:
.fill 8, 1, 0

.section .data
.align 8
g_1628:
.int -417146956

.section .data
.align 8
g_1636:
.int 180123032
.int -2
.int 2
.int -1
.int 1458185853
.int 1
.int -1
.int -1
.int -1
.int -2095384536
.int -773233662
.int -1289161998
.int 180123032
.int -1289161998
.int -773233662
.int -2095384536
.int 527244214
.int 109383803
.int -881995032
.int 2
.int -526737635
.int -26632546
.int 9
.int -4
.int 1
.int -334724952
.int -1713438600
.int 704495194
.int 109383803
.int -334724952
.int -9
.int -884648380
.int -1
.int -116586223
.int 527244214
.int 180123032
.int -1370786516
.int 0
.int -2095384536
.int 0
.int -1194642638
.int -1
.int -2044899789
.int -1
.int -526737635
.int 1
.int -927241133
.int 527244214
.int 1618414547
.int 1920591599
.int 9
.int -2044899789
.int -2044899789
.int 9
.int 539689296
.int 1
.int 0
.int 1
.int 539689296
.int -1
.int -116586223
.int 180123032
.int -1
.int -1289161998
.int -1
.int -1713438600
.int 109383803
.int 0
.int 1618414547
.int 1
.int 1458185853
.int 1
.int 0
.int -884648380
.int -1
.int -927241133
.int -773233662
.int -1
.int -2095384536
.int 1
.int 539689296
.int -1
.int -1
.int 0
.int 539689296
.int -2095384536
.int 9
.int -1
.int 109383803
.int -1194642638

.section .data
.align 8
g_1637:
.word -28415

.section .data
.align 8
g_1639:
.word 1
.word 1
.word 1
.word 1

.section .data
.align 8
g_1702:
.word 9
.word 9
.word 9
.word 9
.word 9

.section .data
.align 8
g_1733:
.quad 8

.section .data
.align 8
g_1737:
.byte 0

.section .data
.align 8
g_1758:
.int 992899423

.section .data
.align 8
g_1831:
.byte -94

.section .data
.align 8
g_1926:
.int -282227949

.section .data
.align 8
g_1937:
.word -7

.section .data
.align 8
g_2:
.int 1599871052
.int 1599871052
.int 1599871052
.int 1599871052
.int 1599871052
.int 1599871052
.int 1599871052
.int 1599871052

.section .data
.align 8
g_2031:
.word 18641
.word 8
.word -60
.word 4
.word 1
.word 3811
.word 1
.word 28283
.word -15981
.word 1
.word 0
.word 4
.word -12835
.word 16191
.word -27604
.word 1
.word -1
.word -10
.word 0
.word 14067
.word -28888
.word -9
.word 1
.word 15467
.word 18641
.word 4
.word 1
.word -10
.word -1
.word 1
.word -27604
.word 4
.word -24473
.word 15467
.word 0
.word 3811
.word -15981
.word -1
.word 0
.word 0
.word -60
.word 15467
.word -60
.word 16191
.word -28888
.word 1
.word 4
.word -1
.word -15981
.word -6
.word -27604
.word -9
.word 0
.word 4
.word -27604
.word -6
.word 28256
.word -1
.word -6
.word 1
.word -28888
.word 14206
.word -60
.word 7
.word -60
.word 0
.word 1
.word -1
.word 28256
.word 3811
.word 0
.word 7
.word -24473
.word 8
.word -27604
.word 1
.word -10
.word -10
.word 0
.word 4
.word 18641
.word 7
.word 1
.word 4
.word -28888
.word 14067
.word 1
.word -10
.word -10
.word 1
.word -27604
.word 14206
.word -12835
.word -9
.word 0
.word 1
.word 28256
.word 28283
.word 0
.word 3811
.word 1
.word -9
.word -60
.word 4
.word 18641
.word 1
.word 4
.word -10
.word 28256
.word -1
.word -27604
.word 15467
.word 10225
.word 15467
.word -27604
.word 14067
.word -15981
.word -18747
.word -6
.word 0
.word 18641
.word 4
.word -60
.word -9
.word 1
.word 1
.word 1
.word 8
.word -15981
.word 0
.word 0
.word -9
.word -12835
.word 14206
.word -27604
.word 0
.word -1
.word -1
.word 0
.word -1
.word -28888
.word 4
.word 1
.word 7
.word 18641
.word -6
.word 1
.word -18747
.word -1
.word 3811
.word -27604
.word 8
.word -24473
.word 7
.word 0
.word -1
.word -10
.word -13128
.word -6
.word 4
.word 1
.word 8
.word 1
.word 3568
.word 1
.word 14067
.word 9
.word 28283
.word -10
.word 9
.word 0
.word 14206
.word -15825
.word 16191
.word 0
.word 9
.word -1
.word 28283
.word -1
.word 14067
.word 1
.word 5
.word 1
.word 4
.word 1
.word 4
.word 4
.word -13128
.word -1
.word -1
.word 21248
.word 4
.word 10225
.word 2
.word 0
.word 14067
.word 28283
.word -1
.word -6
.word -1

.section .data
.align 8
g_205:
.int -229011729

.section .data
.align 8
g_209:
.quad 0

.section .data
.align 8
g_2146:
.int -119428432

.section .data
.align 8
g_222:
.quad -1505296249073589342

.section .data
.align 8
g_225:
.quad 1

.section .data
.align 8
g_2252:
.byte -3

.section .data
.align 8
g_2285:
.int 164511830

.section .data
.align 8
g_238:
.int -6

.section .data
.align 8
g_239:
.int 0
.int 1
.int 372569090
.int 1
.int -1992960871
.int 0
.int 1226500327
.int -692117236
.int 2
.int 1
.int 1
.int 0
.int 9
.int -9
.int 372569090
.int -621786820
.int 9
.int 710914818
.int 0
.int 1226500327
.int 1226500327
.int 0
.int 710914818
.int 9
.int -621786820
.int 372569090
.int -9
.int 9
.int 0
.int 1
.int 1
.int 2
.int -692117236
.int 1226500327
.int 0
.int -1992960871
.int 1
.int 372569090
.int 1
.int 0
.int 710914818
.int -9
.int -9
.int 1226500327
.int -9
.int 1
.int 9
.int 1
.int 7
.int -9
.int -1992960871
.int 1356028917
.int 1
.int -692117236
.int -9
.int -692117236
.int 1
.int 1356028917
.int -1992960871
.int -9
.int 7
.int 1
.int 9
.int 1
.int -9
.int 1226500327
.int -9
.int -9
.int 710914818
.int 0
.int 1
.int 372569090
.int 1
.int -1992960871
.int 0
.int 1226500327
.int -692117236
.int 2
.int 1
.int 1
.int 0
.int 9
.int -9
.int 372569090
.int -621786820
.int 9
.int 710914818
.int 0
.int 1226500327
.int 1226500327
.int 0
.int 710914818
.int 9
.int -621786820
.int 372569090
.int -9
.int 9
.int 0
.int 1
.int 1
.int 2
.int -692117236
.int 1226500327
.int 0
.int -1992960871
.int 1
.int 372569090
.int 1
.int 0
.int 710914818
.int -9
.int -9
.int 1226500327
.int -9
.int 1
.int 9
.int 1
.int 7
.int -9
.int -1992960871
.int 1356028917
.int 1
.int -692117236
.int -9
.int -692117236
.int 1
.int 1356028917
.int -1992960871
.int -9
.int 7
.int 1
.int 1226500327
.int -9
.int -1
.int 1
.int -1
.int -1
.int 2
.int -9
.int 1
.int -692117236
.int 7
.int 1
.int 0
.int 1
.int 710914818
.int 1356028917
.int 1
.int 7
.int 0
.int 1226500327
.int 372569090
.int -692117236
.int -1992960871
.int 1226500327
.int 2
.int -1
.int 1
.int 1
.int -1
.int 2
.int 1226500327
.int -1992960871
.int -692117236
.int 372569090
.int 1226500327
.int 0
.int 7
.int 1
.int 1356028917
.int 710914818
.int 1
.int 0
.int 1
.int 7
.int -692117236
.int 1
.int -9
.int 2
.int -1

.section .data
.align 8
g_240:
.word 1

.section .data
.align 8
g_2577:
.quad 3

.section .data
.align 8
g_2613:
.byte -4

.section .data
.align 8
g_2691:
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561
.word 19561

.section .data
.align 8
g_2782:
.byte -15

.section .data
.align 8
g_283:
.quad 3530011286221499356

.section .data
.align 8
g_3056:
.ascii "\\\011\\"
.ascii "\001\374|"
.ascii "\010\377\001"
.ascii "\255\305\350"
.ascii "\377\377{"
.ascii "\255(\366"
.ascii "\010\001h"
.ascii "\001\003\335"
.ascii "\\\\\006"
.ascii "\326|\216"
.ascii "{\001\263"
.ascii "\335\350\367"
.ascii "\001\0102"
.ascii "\335\216\350"
.ascii "\001\011\367"
.ascii "P\001\001"
.ascii "\004\367\011"
.ascii "(\350\216"
.ascii "\0112\010"
.ascii "\001\255Q"
.ascii "\2332{"
.ascii "\011\350\001"
.ascii "\\\367y"
.ascii "P\001P"
.ascii "\377\011Y"
.ascii "|\216\305"
.ascii "Y\010\006"
.ascii "\216Q\011"
.ascii "Y{\005"
.ascii "|\001\335"
.ascii "\377y\233"
.ascii "PP\367"
.ascii "\\Y\377"
.ascii "\011\305\326"
.ascii "\233\006K"
.ascii "\001\011\326"
.ascii "\011\005\377"
.ascii "(\335\367"
.ascii "\004\233\233"
.ascii "P\367\335"
.ascii "\001\377\005"
.ascii "\335\326\011"
.ascii "YK\006"
.ascii "\001\326\305"
.ascii "\010\377Y"
.ascii "\003\367P"
.ascii "y\233y"
.ascii "\366\335\001"
.ascii "\001\005{"
.ascii "\000\011Q"
.ascii "\005\006\010"
.ascii "\000\305\216"
.ascii "\001Y\011"
.ascii "\366P\001"
.ascii "yy\367"
.ascii "\003\001\350"
.ascii "\010{2"
.ascii "\001Q\255"
.ascii "Y\0102"
.ascii "\335\216\350"
.ascii "\001\011\367"
.ascii "P\001\001"
.ascii "\004\367\011"
.ascii "(\350\216"
.ascii "\0112\010"
.ascii "\001\255Q"
.ascii "\2332{"
.ascii "\011\350\001"
.ascii "\\\367y"
.ascii "P\001P"

.section .data
.align 8
g_313:
.int -3
.int -3
.int -3
.int -3
.int -3
.int -3
.int -3
.int -3

.section .data
.align 8
g_3218:
.word -1

.section .data
.align 8
g_3318:
.int -1241677342

.section .data
.align 8
g_3326:
.word 20403

.section .data
.align 8
g_3368:
.quad 5837211238388700101

.section .data
.align 8
g_3513:
.byte -20

.section .data
.align 8
g_3516:
.word -1

.section .data
.align 8
g_3529:
.byte 0

.section .data
.align 8
g_3532:
.byte -93

.section .data
.align 8
g_3667:
.byte 0

.section .data
.align 8
g_3718:
.int 6

.section .data
.align 8
g_3728:
.word -1

.section .data
.align 8
g_3729:
.word -3684

.section .data
.align 8
g_3758:
.byte -5

.section .data
.align 8
g_3812:
.int 0

.section .data
.align 8
g_385:
.quad -36814632711761407

.section .data
.align 8
g_3917:
.quad 1
.quad 1
.quad 1

.section .data
.align 8
g_3958:
.quad -6

.section .data
.align 8
g_44:
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"
.ascii "\214"
.ascii "\377"

.section .data
.align 8
g_468:
.int -517096832

.section .data
.align 8
g_469:
.quad -4454091520474734408

.section .data
.align 8
g_470:
.int 48476008

.section .data
.align 8
g_477:
.int -354772247

.section .data
.align 8
g_48:
.int 1

.section .data
.align 8
g_527:
.word 16598

.section .data
.align 8
g_541:
.word -11628

.section .data
.align 8
g_575:
.byte 0

.section .data
.align 8
g_577:
.byte 1

.section .data
.align 8
g_617:
.int -6

.section .data
.align 8
g_666:
.byte -15

.section .data
.align 8
g_667:
.word -8
.word -8
.word -15163
.word -8
.word -8
.word -15163
.word -8
.word -8
.word -5
.word -8
.word -5
.word -5
.word -8
.word -5
.word -5
.word -8
.word -8
.word -5
.word -5
.word -8
.word -5
.word -5
.word -8
.word -5
.word -8
.word -8
.word -15163
.word -8
.word -8
.word -15163
.word -8
.word -8

.section .rodata
.align 8
g_764:
.ascii "\001\352c\352\001\001\352c\352\001"

.section .data
.align 8
g_765:
.quad 4937379653580541020

.section .data
.align 8
g_805:
.word -25691
.word -25691
.word -25691
.word -25691

.section .data
.align 8
g_84:
.word -3

.section .data
.align 8
g_91:
.byte -77

.section .data
.align 8
g_948:
.quad -1

.section .data
.align 8
g_960:
.byte -124

.section .text
.global crc32_byte
.p2align 4, 0x90
crc32_byte:
	.__crc32_byte__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(48 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -16(%rbp)
	# LowerAlloca(1858:3): size = 1, type = i8*, var = ^2
	leaq -1(%rbp), %rax
	# LowerStore(1859:3).9: mov i8 %dil, (^2)
	movb %dil, (%rax)
	# LowerLoad(1860:3).4: crc32_context into ^3
	movl crc32_context(%rip), %ebx
	# LowerLshr(1861:3): ^3, 8 into i32 ^4
	shrl $8, %ebx
	# LowerLogic(1863:3): ^4, 16777215 into i32 ^5
	movl %ebx, %ecx
	andl $16777215, %ecx
	# LowerLoad(1863:3).4: crc32_context into ^6
	movl crc32_context(%rip), %edx
	# LowerLoad(1864:3).2: (^2) into i8 ^7
	movb (%rax), %bl
	# LowerBasicConversion(1865:3): i8 ^7 -> i32 ^8
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLogic(1867:3): ^6, ^8 into i32 ^9
	movl %edx, %eax
	xorl %ebx, %eax
	# LowerLogic(1868:3): ^9, 255 into i32 ^10
	movl %eax, %ebx
	andl $255, %ebx
	# LowerBasicConversion(1868:3): i32 ^10 -> i64 ^11
	movq %rbx, %rdx
	leaq crc32_tab(%rip), %rbx
	# tt = Pointer, type = [256 x i32]
	# LowerGetelementptr(1869:3): array/pointer-type, dynamic index -> ^12
	# index ^11 -> temp ^16
	movq %rdx, %rax
	# Multiply temp ^16 by 4 start
	shlq $2, %rax
	# Multiply end
	# temp ^16 -> operand ^12
	movq %rax, %rdx
	# Result ^12 += skip 0
	addq $0, %rdx
	# Result ^12 += base pointer ^15
	addq %rbx, %rdx
	# LowerLoad(1870:3).2: (^12) into i32 ^13
	movl (%rdx), %eax
	# LowerLogic(1872:3): ^5, ^13 into i32 ^14
	movl %ecx, %ebx
	xorl %eax, %ebx
	# LowerStore(1872:3).8a: leaq var, %temp
	leaq crc32_context(%rip), %rax
	# LowerStore(1872:3).8b: movq ^14, (%temp)
	movl %ebx, (%rax)
	movq -16(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global crc32_8bytes
.p2align 4, 0x90
crc32_8bytes:
	.__crc32_8bytes__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(40 + 0, 16)
	subq $48, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -32(%rbp)
	# LowerAlloca(1811:3): size = 8, type = i64*, var = ^2
	leaq -8(%rbp), %rbx
	# LowerStore(1812:3).9: mov i64 %rdi, (^2)
	movq %rdi, (%rbx)
	# LowerLoad(1813:3).2: (^2) into i64 ^3
	movq (%rbx), %rax
	# LowerLshr(1814:3): ^3, 0 into i64 ^4
	shrq $0, %rax
	# LowerLogic(1816:3): ^4, 255 into i64 ^5
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(1816:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(1816:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(1817:3): move argument i8 zeroext ^6
	movzbq %al, %rdi
	andq $255, %rdi
	callq crc32_byte
	# Unclobber %rax
	movq -16(%rbp), %rax
	# LowerLoad(1818:3).2: (^2) into i64 ^7
	movq (%rbx), %rax
	# LowerLshr(1819:3): ^7, 8 into i64 ^8
	shrq $8, %rax
	# LowerLogic(1821:3): ^8, 255 into i64 ^9
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(1821:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(1821:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(1822:3): move argument i8 zeroext ^10
	movzbq %al, %rdi
	andq $255, %rdi
	callq crc32_byte
	# Unclobber %rax
	movq -16(%rbp), %rax
	# LowerLoad(1823:3).2: (^2) into i64 ^11
	movq (%rbx), %rcx
	# LowerLshr(1824:3): ^11, 16 into i64 ^12
	shrq $16, %rcx
	# LowerLogic(1826:3): ^12, 255 into i64 ^13
	movq %rcx, %rax
	andq $255, %rax
	# LowerTrunc(1826:3): 64 to 8, move
	movb %al, %cl
	# LowerTrunc(1826:3): 64 to 8, apply mask
	andq $255, %rcx
	# Clobber %rcx
	movq %rcx, -24(%rbp)
	# SetupCalls(1827:3): move argument i8 zeroext ^14
	movzbq %cl, %rdi
	andq $255, %rdi
	callq crc32_byte
	# Unclobber %rcx
	movq -24(%rbp), %rcx
	# LowerLoad(1828:3).2: (^2) into i64 ^15
	movq (%rbx), %rcx
	# LowerLshr(1829:3): ^15, 24 into i64 ^16
	movq %rcx, %rax
	shrq $24, %rax
	# LowerLogic(1831:3): ^16, 255 into i64 ^17
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(1831:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(1831:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(1832:3): move argument i8 zeroext ^18
	movzbq %al, %rdi
	andq $255, %rdi
	callq crc32_byte
	# Unclobber %rax
	movq -16(%rbp), %rax
	# LowerLoad(1833:3).2: (^2) into i64 ^19
	movq (%rbx), %rax
	# LowerLshr(1834:3): ^19, 32 into i64 ^20
	shrq $32, %rax
	# LowerLogic(1836:3): ^20, 255 into i64 ^21
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(1836:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(1836:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(1837:3): move argument i8 zeroext ^22
	movzbq %al, %rdi
	andq $255, %rdi
	callq crc32_byte
	# Unclobber %rax
	movq -16(%rbp), %rax
	# LowerLoad(1838:3).2: (^2) into i64 ^23
	movq (%rbx), %rcx
	# LowerLshr(1839:3): ^23, 40 into i64 ^24
	shrq $40, %rcx
	# LowerLogic(1841:3): ^24, 255 into i64 ^25
	movq %rcx, %rax
	andq $255, %rax
	# LowerTrunc(1841:3): 64 to 8, move
	movb %al, %cl
	# LowerTrunc(1841:3): 64 to 8, apply mask
	andq $255, %rcx
	# Clobber %rcx
	movq %rcx, -24(%rbp)
	# SetupCalls(1842:3): move argument i8 zeroext ^26
	movzbq %cl, %rdi
	andq $255, %rdi
	callq crc32_byte
	# Unclobber %rcx
	movq -24(%rbp), %rcx
	# LowerLoad(1843:3).2: (^2) into i64 ^27
	movq (%rbx), %rax
	# LowerLshr(1844:3): ^27, 48 into i64 ^28
	shrq $48, %rax
	# LowerLogic(1846:3): ^28, 255 into i64 ^29
	movq %rax, %rcx
	andq $255, %rcx
	# LowerTrunc(1846:3): 64 to 8, move
	movb %cl, %al
	# LowerTrunc(1846:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(1847:3): move argument i8 zeroext ^30
	movzbq %al, %rdi
	andq $255, %rdi
	callq crc32_byte
	# Unclobber %rax
	movq -16(%rbp), %rax
	# LowerLoad(1848:3).2: (^2) into i64 ^31
	movq (%rbx), %rax
	# LowerLshr(1849:3): ^31, 56 into i64 ^32
	shrq $56, %rax
	# LowerLogic(1851:3): ^32, 255 into i64 ^33
	movq %rax, %rbx
	andq $255, %rbx
	# LowerTrunc(1851:3): 64 to 8, move
	movb %bl, %al
	# LowerTrunc(1851:3): 64 to 8, apply mask
	andq $255, %rax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(1852:3): move argument i8 zeroext ^34
	movzbq %al, %rdi
	andq $255, %rdi
	callq crc32_byte
	# Unclobber %rax
	movq -16(%rbp), %rax
	movq -32(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global platform_main_end
.p2align 4, 0x90
platform_main_end:
	.__platform_main_end__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(24 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	# LowerAlloca(1794:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %rbx
	# LowerAlloca(1795:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rax
	# LowerStore(1796:3).9: mov i32 %edi, (^3)
	movl %edi, (%rbx)
	# LowerStore(1797:3).9: mov i32 %esi, (^4)
	movl %esi, (%rax)
	# LowerLoad(1798:3).2: (^3) into i32 ^5
	movl (%rbx), %eax
	# Clobber %rax
	movq %rax, -16(%rbp)
	# SetupCalls(1799:3): move argument ptr @.str.91
	leaq .str.91(%rip), %rdi
	# SetupCalls(1799:3): move argument i32 ^5
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1799:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -16(%rbp), %rax
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global transparent_crc
.p2align 4, 0x90
transparent_crc:
	.__transparent_crc__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(56 + 0, 16)
	subq $64, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -40(%rbp)
	movq %r12, -48(%rbp)
	# LowerAlloca(1766:3): size = 8, type = i64*, var = ^4
	leaq -8(%rbp), %rax
	# LowerAlloca(1767:3): size = 8, type = ptr*, var = ^5
	leaq -16(%rbp), %rbx
	# LowerAlloca(1768:3): size = 4, type = i32*, var = ^6
	leaq -20(%rbp), %r12
	# LowerStore(1769:3).9: mov i64 %rdi, (^4)
	movq %rdi, (%rax)
	# LowerStore(1770:3).9: mov ptr %rsi, (^5)
	movq %rsi, (%rbx)
	# LowerStore(1771:3).9: mov i32 %edx, (^6)
	movl %edx, (%r12)
	# LowerLoad(1772:3).2: (^4) into i64 ^7
	movq (%rax), %rcx
	# Clobber %rcx
	movq %rcx, -32(%rbp)
	# SetupCalls(1773:3): move argument i64 ^7
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	callq crc32_8bytes
	# Unclobber %rcx
	movq -32(%rbp), %rcx
	# LowerLoad(1774:3).2: (^6) into i32 ^8
	movl (%r12), %eax
	# LowerIcmp(1775:3): i32 ^8 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__transparent_crc__M42
	jmp .__transparent_crc__M81
	.__transparent_crc__M42:
	# LowerLoad(1779:3).2: (^5) into ptr ^11
	movq (%rbx), %rcx
	# LowerLoad(1780:3).4: crc32_context into ^12
	movl crc32_context(%rip), %eax
	# LowerBasicConversion(1781:3): i32 ^12 -> i64 ^13
	# LowerLogic(1783:3): ^13, 4294967295 into i64 ^14
	movq %rax, %rbx
	movabsq $4294967295, %rax
	xorq %rax, %rbx
	# Clobber %rcx
	movq %rcx, -32(%rbp)
	# SetupCalls(1783:3): move argument ptr @.str.90
	leaq .str.90(%rip), %rdi
	# SetupCalls(1783:3): move argument ptr ^11
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rsi
	# SetupCalls(1783:3): move argument i64 ^14
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1783:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rcx
	movq -32(%rbp), %rcx
	.__transparent_crc__M81:
	movq -48(%rbp), %r12
	movq -40(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global func_1
.p2align 4, 0x90
func_1:
	.__func_1__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(2008 + 0, 16)
	subq $2016, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -1104(%rbp)
	movq %r12, -1136(%rbp)
	movq %r13, -1096(%rbp)
	movq %r14, -1128(%rbp)
	movq %r15, -1080(%rbp)
	# LowerAlloca(1466:3): size = 8, type = %union.U0*, var = ^1
	# Fixing source-to-dest leaq -8(%rbp), -848(%rbp)
	leaq -8(%rbp), %r15
	movq %r15, -848(%rbp)
	# LowerAlloca(1467:3): size = 36, type = [9 x i32]*, var = ^2
	# Fixing source-to-dest leaq -48(%rbp), -856(%rbp)
	leaq -48(%rbp), %r15
	movq %r15, -856(%rbp)
	# LowerAlloca(1468:3): size = 8, type = ptr*, var = ^3
	leaq -56(%rbp), %r13
	# LowerAlloca(1469:3): size = 1, type = i8*, var = ^4
	leaq -57(%rbp), %rbx
	# LowerAlloca(1470:3): size = 8, type = ptr*, var = ^5
	leaq -72(%rbp), %rsi
	# LowerAlloca(1471:3): size = 32, type = [4 x ptr]*, var = ^6
	leaq -112(%rbp), %rdi
	# LowerAlloca(1472:3): size = 8, type = ptr*, var = ^7
	leaq -120(%rbp), %r8
	# LowerAlloca(1473:3): size = 4, type = [1 x i32]*, var = ^8
	# Fixing source-to-dest leaq -124(%rbp), -1040(%rbp)
	leaq -124(%rbp), %r15
	movq %r15, -1040(%rbp)
	# LowerAlloca(1474:3): size = 8, type = i64*, var = ^9
	leaq -136(%rbp), %r9
	# LowerAlloca(1475:3): size = 8, type = ptr*, var = ^10
	leaq -144(%rbp), %r11
	# LowerAlloca(1476:3): size = 8, type = ptr*, var = ^11
	leaq -152(%rbp), %r15
	# LowerAlloca(1477:3): size = 8, type = ptr*, var = ^12
	leaq -160(%rbp), %r14
	# LowerAlloca(1478:3): size = 4, type = i32*, var = ^13
	leaq -164(%rbp), %rax
	# LowerAlloca(1479:3): size = 4, type = i32*, var = ^14
	leaq -168(%rbp), %rdx
	# LowerAlloca(1480:3): size = 8, type = ptr*, var = ^15
	leaq -176(%rbp), %r10
	# LowerAlloca(1481:3): size = 8, type = i64*, var = ^16
	leaq -184(%rbp), %r12
	# LowerAlloca(1482:3): size = 8, type = ptr*, var = ^17
	# Fixing source-to-dest leaq -192(%rbp), -1072(%rbp)
	pushq %r15
	leaq -192(%rbp), %r15
	movq %r15, -1072(%rbp)
	popq %r15
	# LowerAlloca(1483:3): size = 8, type = ptr*, var = ^18
	# Fixing source-to-dest leaq -200(%rbp), -1056(%rbp)
	pushq %r15
	leaq -200(%rbp), %r15
	movq %r15, -1056(%rbp)
	popq %r15
	# LowerAlloca(1484:3): size = 56, type = [7 x ptr]*, var = ^19
	# Fixing source-to-dest leaq -256(%rbp), -1064(%rbp)
	pushq %r15
	leaq -256(%rbp), %r15
	movq %r15, -1064(%rbp)
	popq %r15
	# LowerAlloca(1485:3): size = 4, type = i32*, var = ^20
	# Fixing source-to-dest leaq -260(%rbp), -1048(%rbp)
	pushq %r15
	leaq -260(%rbp), %r15
	movq %r15, -1048(%rbp)
	popq %r15
	# LowerAlloca(1486:3): size = 2, type = i16*, var = ^21
	# Fixing source-to-dest leaq -262(%rbp), -864(%rbp)
	pushq %r15
	leaq -262(%rbp), %r15
	movq %r15, -864(%rbp)
	popq %r15
	# LowerAlloca(1487:3): size = 2, type = i16*, var = ^22
	# Fixing source-to-dest leaq -264(%rbp), -872(%rbp)
	pushq %r15
	leaq -264(%rbp), %r15
	movq %r15, -872(%rbp)
	popq %r15
	# LowerAlloca(1488:3): size = 8, type = ptr*, var = ^23
	# Fixing source-to-dest leaq -272(%rbp), -880(%rbp)
	pushq %r15
	leaq -272(%rbp), %r15
	movq %r15, -880(%rbp)
	popq %r15
	# LowerAlloca(1489:3): size = 4, type = [1 x i32]*, var = ^24
	# Fixing source-to-dest leaq -276(%rbp), -888(%rbp)
	pushq %r15
	leaq -276(%rbp), %r15
	movq %r15, -888(%rbp)
	popq %r15
	# LowerAlloca(1490:3): size = 8, type = ptr*, var = ^25
	# Fixing source-to-dest leaq -288(%rbp), -896(%rbp)
	pushq %r15
	leaq -288(%rbp), %r15
	movq %r15, -896(%rbp)
	popq %r15
	# LowerAlloca(1491:3): size = 8, type = ptr*, var = ^26
	# Fixing source-to-dest leaq -296(%rbp), -904(%rbp)
	pushq %r15
	leaq -296(%rbp), %r15
	movq %r15, -904(%rbp)
	popq %r15
	# LowerAlloca(1492:3): size = 8, type = ptr*, var = ^27
	# Fixing source-to-dest leaq -304(%rbp), -912(%rbp)
	pushq %r15
	leaq -304(%rbp), %r15
	movq %r15, -912(%rbp)
	popq %r15
	# LowerAlloca(1493:3): size = 8, type = ptr*, var = ^28
	# Fixing source-to-dest leaq -312(%rbp), -920(%rbp)
	pushq %r15
	leaq -312(%rbp), %r15
	movq %r15, -920(%rbp)
	popq %r15
	# LowerAlloca(1494:3): size = 8, type = ptr*, var = ^29
	# Fixing source-to-dest leaq -320(%rbp), -928(%rbp)
	pushq %r15
	leaq -320(%rbp), %r15
	movq %r15, -928(%rbp)
	popq %r15
	# LowerAlloca(1495:3): size = 8, type = ptr*, var = ^30
	# Fixing source-to-dest leaq -328(%rbp), -936(%rbp)
	pushq %r15
	leaq -328(%rbp), %r15
	movq %r15, -936(%rbp)
	popq %r15
	# LowerAlloca(1496:3): size = 360, type = [5 x [9 x ptr]]*, var = ^31
	# Fixing source-to-dest leaq -688(%rbp), -944(%rbp)
	pushq %r15
	leaq -688(%rbp), %r15
	movq %r15, -944(%rbp)
	popq %r15
	# LowerAlloca(1497:3): size = 3, type = [3 x i8]*, var = ^32
	# Fixing source-to-dest leaq -691(%rbp), -952(%rbp)
	pushq %r15
	leaq -691(%rbp), %r15
	movq %r15, -952(%rbp)
	popq %r15
	# LowerAlloca(1498:3): size = 4, type = i32*, var = ^33
	# Fixing source-to-dest leaq -696(%rbp), -960(%rbp)
	pushq %r15
	leaq -696(%rbp), %r15
	movq %r15, -960(%rbp)
	popq %r15
	# LowerAlloca(1499:3): size = 36, type = [9 x i32]*, var = ^34
	# Fixing source-to-dest leaq -736(%rbp), -968(%rbp)
	pushq %r15
	leaq -736(%rbp), %r15
	movq %r15, -968(%rbp)
	popq %r15
	# LowerAlloca(1500:3): size = 8, type = ptr*, var = ^35
	# Fixing source-to-dest leaq -744(%rbp), -976(%rbp)
	pushq %r15
	leaq -744(%rbp), %r15
	movq %r15, -976(%rbp)
	popq %r15
	# LowerAlloca(1501:3): size = 8, type = ptr*, var = ^36
	# Fixing source-to-dest leaq -752(%rbp), -984(%rbp)
	pushq %r15
	leaq -752(%rbp), %r15
	movq %r15, -984(%rbp)
	popq %r15
	# LowerAlloca(1502:3): size = 8, type = ptr*, var = ^37
	# Fixing source-to-dest leaq -760(%rbp), -992(%rbp)
	pushq %r15
	leaq -760(%rbp), %r15
	movq %r15, -992(%rbp)
	popq %r15
	# LowerAlloca(1503:3): size = 8, type = i64*, var = ^38
	# Fixing source-to-dest leaq -768(%rbp), -1000(%rbp)
	pushq %r15
	leaq -768(%rbp), %r15
	movq %r15, -1000(%rbp)
	popq %r15
	# LowerAlloca(1504:3): size = 4, type = i32*, var = ^39
	# Fixing source-to-dest leaq -772(%rbp), -1008(%rbp)
	pushq %r15
	leaq -772(%rbp), %r15
	movq %r15, -1008(%rbp)
	popq %r15
	# LowerAlloca(1505:3): size = 8, type = %union.U0*, var = ^40
	# Fixing source-to-dest leaq -784(%rbp), -1016(%rbp)
	pushq %r15
	leaq -784(%rbp), %r15
	movq %r15, -1016(%rbp)
	popq %r15
	# LowerAlloca(1506:3): size = 42, type = [7 x [3 x i16]]*, var = ^41
	# Fixing source-to-dest leaq -832(%rbp), -1024(%rbp)
	pushq %r15
	leaq -832(%rbp), %r15
	movq %r15, -1024(%rbp)
	popq %r15
	# LowerAlloca(1507:3): size = 4, type = i32*, var = ^42
	# Fixing source-to-dest leaq -836(%rbp), -1032(%rbp)
	pushq %r15
	leaq -836(%rbp), %r15
	movq %r15, -1032(%rbp)
	popq %r15
	# LowerAlloca(1508:3): size = 4, type = i32*, var = ^43
	leaq -840(%rbp), %rcx
	# LowerStore(1509:3).6: load global
	leaq g_48(%rip), %rcx
	# LowerStore(1509:3).9: mov ptr ^207, (^3)
	movq %rcx, (%r13)
	# LowerStore(1510:3).3: mov $imm, (^4)
	movb $6, (%rbx)
	leaq g_764(%rip), %rbx
	# tt = Pointer, type = [10 x i8]
	leaq g_764(%rip), %rcx
	# LowerGetelementptr(1511:3): struct-type: [10 x i8] ^166 -> ^164, indices=0,4
	movq %rcx, %rbx
	addq $4, %rbx
	# LowerGetelementptr(1511:3): type of ^164 is i8*
	# LowerStore(1511:3).9: mov [10 x i8]* ^164, (^5)
	movq %rbx, (%rsi)
	# tt = Pointer, type = [4 x ptr]
	# LowerGetelementptr(1512:3): struct-type: ptr ^6 -> ^44, indices=0,0
	movq %rdi, %rbx
	# LowerGetelementptr(1512:3): type of ^44 is ptr*
	# LowerStore(1513:3).9: mov ptr* ^5, (^44)
	movq %rsi, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1514:3): struct-type: ptr ^44 -> ^45, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(1514:3): type of ^45 is ptr*
	# LowerStore(1515:3).9: mov ptr* ^5, (^45)
	movq %rsi, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1516:3): struct-type: ptr ^45 -> ^46, indices=1
	movq %rcx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1516:3): type of ^46 is ptr*
	# LowerStore(1517:3).9: mov ptr* ^5, (^46)
	movq %rsi, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1518:3): struct-type: ptr ^46 -> ^47, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(1518:3): type of ^47 is ptr*
	# LowerStore(1519:3).9: mov ptr* ^5, (^47)
	movq %rsi, (%rcx)
	# LowerStore(1520:3).9: mov ptr* ^5, (^7)
	movq %rsi, (%r8)
	# LowerStore(1521:3).3: mov $imm, (^9)
	movabsq $-495682376473813218, %rbx
	movq %rbx, (%r9)
	# LowerStore(1522:3).3: mov $imm, (^10)
	movq $0, (%r11)
	# LowerStore(1523:3).9: mov ptr* ^10, (^11)
	movq %r11, (%r15)
	# LowerStore(1524:3).9: mov ptr* ^11, (^12)
	movq %r15, (%r14)
	# LowerStore(1525:3).3: mov $imm, (^13)
	movl $-682156064, (%rax)
	# LowerStore(1526:3).3: mov $imm, (^14)
	movl $-306174005, (%rdx)
	# LowerStore(1527:3).3: mov $imm, (^15)
	movq $0, (%r10)
	# SetupCalls(1528:3): move argument ptr align 8 ^1
	# Fixed movzx with identical source and destination widths
	movq -848(%rbp), %rdi
	# SetupCalls(1528:3): move argument ptr align 8 @__const.func_1.l_3841
	leaq __const.func_1.l_3841(%rip), %rsi
	# SetupCalls(1528:3): move argument i64 8
	movq $8, %rdx
	callq memcpy@PLT
	# LowerStore(1529:3).3: mov $imm, (^16)
	movq $0, (%r12)
	# LowerStore(1530:3).6: load global
	leaq g_3812(%rip), %rax
	# LowerStore(1530:3).9: mov ptr ^208, (^17)
	movq -1072(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(1531:3).3: mov $imm, (^18)
	movq -1056(%rbp), %rax
	movq $0, (%rax)
	# tt = Pointer, type = [7 x ptr]
	# LowerGetelementptr(1532:3): struct-type: ptr ^19 -> ^48, indices=0,0
	movq -1064(%rbp), %rbx
	# LowerGetelementptr(1532:3): type of ^48 is ptr*
	# LowerStore(1533:3).9: mov ptr* ^18, (^48)
	# Fixing source-to-dest movq -1056(%rbp), (%rbx)
	movq -1056(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1534:3): struct-type: ptr ^48 -> ^49, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(1534:3): type of ^49 is ptr*
	# LowerStore(1535:3).9: mov ptr* ^18, (^49)
	# Fixing source-to-dest movq -1056(%rbp), (%rax)
	movq -1056(%rbp), %r15
	movq %r15, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1536:3): struct-type: ptr ^49 -> ^50, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1536:3): type of ^50 is ptr*
	# LowerStore(1537:3).9: mov ptr* ^18, (^50)
	# Fixing source-to-dest movq -1056(%rbp), (%rbx)
	movq -1056(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1538:3): struct-type: ptr ^50 -> ^51, indices=1
	movq %rbx, %rcx
	addq $8, %rcx
	# LowerGetelementptr(1538:3): type of ^51 is ptr*
	# LowerStore(1539:3).9: mov ptr* ^18, (^51)
	# Fixing source-to-dest movq -1056(%rbp), (%rcx)
	movq -1056(%rbp), %r15
	movq %r15, (%rcx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1540:3): struct-type: ptr ^51 -> ^52, indices=1
	movq %rcx, %rax
	addq $8, %rax
	# LowerGetelementptr(1540:3): type of ^52 is ptr*
	# LowerStore(1541:3).9: mov ptr* ^18, (^52)
	# Fixing source-to-dest movq -1056(%rbp), (%rax)
	movq -1056(%rbp), %r15
	movq %r15, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1542:3): struct-type: ptr ^52 -> ^53, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1542:3): type of ^53 is ptr*
	# LowerStore(1543:3).9: mov ptr* ^18, (^53)
	# Fixing source-to-dest movq -1056(%rbp), (%rbx)
	movq -1056(%rbp), %r15
	movq %r15, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1544:3): struct-type: ptr ^53 -> ^54, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(1544:3): type of ^54 is ptr*
	# LowerStore(1545:3).9: mov ptr* ^18, (^54)
	# Fixing source-to-dest movq -1056(%rbp), (%rax)
	movq -1056(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(1546:3).3: mov $imm, (^20)
	movq -1048(%rbp), %rax
	movl $0, (%rax)
	.__func_1__M233:
	# LowerLoad(1550:3).2: (^20) into i32 ^56
	movq -1048(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1551:3): i32 ^56 vs. intlike 9
	cmpl $9, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__func_1__M240
	jmp .__func_1__M267
	.__func_1__M240:
	# LowerLoad(1555:3).2: (^20) into i32 ^59
	movq -1048(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [9 x i32]
	# LowerGetelementptr(1557:3): array/pointer-type, dynamic index -> ^61
	# index ^60 -> temp ^202
	movq %rbx, %rcx
	# Multiply temp ^202 by 4 start
	shlq $2, %rcx
	# Multiply end
	# temp ^202 -> operand ^61
	movq %rcx, %rax
	# Result ^61 += skip 0
	addq $0, %rax
	# Result ^61 += base pointer ^2
	addq -856(%rbp), %rax
	# LowerStore(1558:3).3: mov $imm, (^61)
	movl $2019922526, (%rax)
	# LowerLoad(1562:3).2: (^20) into i32 ^63
	movq -1048(%rbp), %rax
	movl (%rax), %ebx
	# LowerMath(1563:3): ^63, 1 into i32 ^64
	addl $1, %ebx
	# LowerStore(1564:3).9: mov i32 ^64, (^20)
	movq -1048(%rbp), %rax
	movl %ebx, (%rax)
	jmp .__func_1__M233
	.__func_1__M267:
	# LowerStore(1568:3).3: mov $imm, (^20)
	movq -1048(%rbp), %rax
	movl $0, (%rax)
	.__func_1__M270:
	# LowerLoad(1572:3).2: (^20) into i32 ^67
	movq -1048(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1573:3): i32 ^67 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__func_1__M277
	jmp .__func_1__M304
	.__func_1__M277:
	# LowerLoad(1577:3).2: (^20) into i32 ^70
	movq -1048(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1579:3): array/pointer-type, dynamic index -> ^72
	# index ^71 -> temp ^203
	movq %rbx, %rcx
	# Multiply temp ^203 by 4 start
	shlq $2, %rcx
	# Multiply end
	# temp ^203 -> operand ^72
	movq %rcx, %rax
	# Result ^72 += skip 0
	addq $0, %rax
	# Result ^72 += base pointer ^8
	addq -1040(%rbp), %rax
	# LowerStore(1580:3).3: mov $imm, (^72)
	movl $1894834254, (%rax)
	# LowerLoad(1584:3).2: (^20) into i32 ^74
	movq -1048(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(1585:3): ^74, 1 into i32 ^75
	addl $1, %eax
	# LowerStore(1586:3).9: mov i32 ^75, (^20)
	movq -1048(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .__func_1__M270
	.__func_1__M304:
	leaq g_2(%rip), %rax
	# tt = Pointer, type = [8 x i32]
	leaq g_2(%rip), %rbx
	# LowerGetelementptr(1590:3): struct-type: [8 x i32] ^169 -> ^167, indices=0,1
	movq %rbx, %rax
	addq $4, %rax
	# LowerGetelementptr(1590:3): type of ^167 is i32*
	# LowerStore(1590:3).3: mov $imm, (^167)
	movl $0, (%rax)
	.__func_1__M314:
	leaq g_2(%rip), %rax
	# tt = Pointer, type = [8 x i32]
	leaq g_2(%rip), %rax
	# LowerGetelementptr(1594:3): struct-type: [8 x i32] ^172 -> ^170, indices=0,1
	movq %rax, %rbx
	addq $4, %rbx
	# LowerGetelementptr(1594:3): type of ^170 is i32*
	# LowerLoad(1594:3).2: (^170) into i32 ^78
	movl (%rbx), %eax
	# LowerIcmp(1595:3): i32 ^78 vs. intlike 4
	cmpl $4, %eax
	setle %al
	andq $1, %rax
	cmpb $0, %al
	jne .__func_1__M328
	jmp .__func_1__M966
	.__func_1__M328:
	# LowerStore(1599:3).3: mov $imm, (^21)
	movq -864(%rbp), %rax
	movw $-22347, (%rax)
	# LowerStore(1600:3).3: mov $imm, (^22)
	movq -872(%rbp), %rax
	movw $2, (%rax)
	leaq g_2(%rip), %rax
	# tt = Pointer, type = [8 x i32]
	leaq g_2(%rip), %rax
	# LowerGetelementptr(1601:3): struct-type: [8 x i32] ^175 -> ^173, indices=0,3
	movq %rax, %rbx
	addq $12, %rbx
	# LowerGetelementptr(1601:3): type of ^173 is i32*
	# LowerStore(1601:3).9: mov [8 x i32]* ^173, (^23)
	movq -880(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(1602:3).6: load global
	leaq g_48(%rip), %rbx
	# LowerStore(1602:3).9: mov ptr ^209, (^25)
	movq -896(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(1603:3).3: mov $imm, (^26)
	movq -904(%rbp), %rax
	movq $0, (%rax)
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1604:3): struct-type: ptr ^24 -> ^81, indices=0,0
	movq -912(%rbp), %rax
	# Fixing source-to-dest movq -888(%rbp), (%rax)
	movq -888(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(1604:3): type of ^81 is i32*
	# LowerStore(1605:3).9: mov [1 x i32]* ^81, (^27)
	# LowerStore(1606:3).3: mov $imm, (^28)
	movq -920(%rbp), %rax
	movq $0, (%rax)
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1607:3): struct-type: ptr ^24 -> ^82, indices=0,0
	movq -928(%rbp), %rax
	# Fixing source-to-dest movq -888(%rbp), (%rax)
	movq -888(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(1607:3): type of ^82 is i32*
	# LowerStore(1608:3).9: mov [1 x i32]* ^82, (^29)
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1609:3): struct-type: ptr ^24 -> ^83, indices=0,0
	movq -936(%rbp), %rax
	# Fixing source-to-dest movq -888(%rbp), (%rax)
	movq -888(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(1609:3): type of ^83 is i32*
	# LowerStore(1610:3).9: mov [1 x i32]* ^83, (^30)
	# tt = Pointer, type = [5 x [9 x ptr]]
	# LowerGetelementptr(1611:3): struct-type: ptr ^31 -> ^84, indices=0,0
	movq -944(%rbp), %rbx
	# LowerGetelementptr(1611:3): type of ^84 is [9 x ptr]*
	# SetupCalls(1612:3): move argument ptr align 8 ^84
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1612:3): move argument i32 0
	movq $0, %rsi
	# SetupCalls(1612:3): move argument i64 72
	movq $72, %rdx
	callq memset@PLT
	# tt = Pointer, type = [9 x ptr]
	# LowerGetelementptr(1613:3): struct-type: ptr ^84 -> ^85, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(1613:3): type of ^85 is ptr*
	# SetupCalls(1614:3): move argument ptr align 8 ^84
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1614:3): move argument ptr align 8 @constinit
	leaq constinit(%rip), %rsi
	# SetupCalls(1614:3): move argument i64 72
	movq $72, %rdx
	callq memcpy@PLT
	# tt = Pointer, type = [9 x ptr]
	# LowerGetelementptr(1615:3): struct-type: ptr ^84 -> ^86, indices=1
	movq %rbx, %rcx
	addq $72, %rcx
	# LowerGetelementptr(1615:3): type of ^86 is [9 x ptr]*
	# tt = Pointer, type = [9 x ptr]
	# LowerGetelementptr(1616:3): struct-type: ptr ^86 -> ^87, indices=0,0
	movq %rcx, %rax
	# LowerGetelementptr(1616:3): type of ^87 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1617:3): struct-type: ptr ^24 -> ^88, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rax)
	movq -888(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(1617:3): type of ^88 is i32*
	# LowerStore(1618:3).9: mov [1 x i32]* ^88, (^87)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1619:3): struct-type: ptr ^87 -> ^89, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1619:3): type of ^89 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1620:3): struct-type: ptr ^24 -> ^90, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rbx)
	movq -888(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(1620:3): type of ^90 is i32*
	# LowerStore(1621:3).9: mov [1 x i32]* ^90, (^89)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1622:3): struct-type: ptr ^89 -> ^91, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(1622:3): type of ^91 is ptr*
	leaq g_2(%rip), %rbx
	# tt = Pointer, type = [8 x i32]
	leaq g_2(%rip), %rdx
	# LowerGetelementptr(1623:3): struct-type: [8 x i32] ^178 -> ^176, indices=0,2
	movq %rdx, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1623:3): type of ^176 is i32*
	# LowerStore(1623:3).9: mov [8 x i32]* ^176, (^91)
	movq %rbx, (%rax)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1624:3): struct-type: ptr ^91 -> ^92, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1624:3): type of ^92 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1625:3): struct-type: ptr ^24 -> ^93, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rbx)
	movq -888(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(1625:3): type of ^93 is i32*
	# LowerStore(1626:3).9: mov [1 x i32]* ^93, (^92)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1627:3): struct-type: ptr ^92 -> ^94, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(1627:3): type of ^94 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1628:3): struct-type: ptr ^24 -> ^95, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rax)
	movq -888(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(1628:3): type of ^95 is i32*
	# LowerStore(1629:3).9: mov [1 x i32]* ^95, (^94)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1630:3): struct-type: ptr ^94 -> ^96, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1630:3): type of ^96 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1631:3): struct-type: ptr ^24 -> ^97, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rbx)
	movq -888(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(1631:3): type of ^97 is i32*
	# LowerStore(1632:3).9: mov [1 x i32]* ^97, (^96)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1633:3): struct-type: ptr ^96 -> ^98, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(1633:3): type of ^98 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1634:3): struct-type: ptr ^24 -> ^99, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rax)
	movq -888(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(1634:3): type of ^99 is i32*
	# LowerStore(1635:3).9: mov [1 x i32]* ^99, (^98)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1636:3): struct-type: ptr ^98 -> ^100, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1636:3): type of ^100 is ptr*
	leaq g_2(%rip), %rax
	# tt = Pointer, type = [8 x i32]
	leaq g_2(%rip), %rdx
	# LowerGetelementptr(1637:3): struct-type: [8 x i32] ^181 -> ^179, indices=0,2
	movq %rdx, %rax
	addq $8, %rax
	# LowerGetelementptr(1637:3): type of ^179 is i32*
	# LowerStore(1637:3).9: mov [8 x i32]* ^179, (^100)
	movq %rax, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1638:3): struct-type: ptr ^100 -> ^101, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(1638:3): type of ^101 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1639:3): struct-type: ptr ^24 -> ^102, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rax)
	movq -888(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(1639:3): type of ^102 is i32*
	# LowerStore(1640:3).9: mov [1 x i32]* ^102, (^101)
	# tt = Pointer, type = [9 x ptr]
	# LowerGetelementptr(1641:3): struct-type: ptr ^86 -> ^103, indices=1
	movq %rcx, %rbx
	addq $72, %rbx
	# LowerGetelementptr(1641:3): type of ^103 is [9 x ptr]*
	# SetupCalls(1642:3): move argument ptr align 8 ^103
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1642:3): move argument i32 0
	movq $0, %rsi
	# SetupCalls(1642:3): move argument i64 72
	movq $72, %rdx
	callq memset@PLT
	# tt = Pointer, type = [9 x ptr]
	# LowerGetelementptr(1643:3): struct-type: ptr ^103 -> ^104, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(1643:3): type of ^104 is ptr*
	# SetupCalls(1644:3): move argument ptr align 8 ^103
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1644:3): move argument ptr align 8 @constinit.88
	leaq constinit.88(%rip), %rsi
	# SetupCalls(1644:3): move argument i64 72
	movq $72, %rdx
	callq memcpy@PLT
	# tt = Pointer, type = [9 x ptr]
	# LowerGetelementptr(1645:3): struct-type: ptr ^103 -> ^105, indices=1
	movq %rbx, %rcx
	addq $72, %rcx
	# LowerGetelementptr(1645:3): type of ^105 is [9 x ptr]*
	# tt = Pointer, type = [9 x ptr]
	# LowerGetelementptr(1646:3): struct-type: ptr ^105 -> ^106, indices=0,0
	movq %rcx, %rax
	# LowerGetelementptr(1646:3): type of ^106 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1647:3): struct-type: ptr ^24 -> ^107, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rax)
	movq -888(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(1647:3): type of ^107 is i32*
	# LowerStore(1648:3).9: mov [1 x i32]* ^107, (^106)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1649:3): struct-type: ptr ^106 -> ^108, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1649:3): type of ^108 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1650:3): struct-type: ptr ^24 -> ^109, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rbx)
	movq -888(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(1650:3): type of ^109 is i32*
	# LowerStore(1651:3).9: mov [1 x i32]* ^109, (^108)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1652:3): struct-type: ptr ^108 -> ^110, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(1652:3): type of ^110 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1653:3): struct-type: ptr ^24 -> ^111, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rax)
	movq -888(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(1653:3): type of ^111 is i32*
	# LowerStore(1654:3).9: mov [1 x i32]* ^111, (^110)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1655:3): struct-type: ptr ^110 -> ^112, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1655:3): type of ^112 is ptr*
	leaq g_2(%rip), %rax
	# tt = Pointer, type = [8 x i32]
	leaq g_2(%rip), %rdx
	# LowerGetelementptr(1656:3): struct-type: [8 x i32] ^184 -> ^182, indices=0,2
	movq %rdx, %rax
	addq $8, %rax
	# LowerGetelementptr(1656:3): type of ^182 is i32*
	# LowerStore(1656:3).9: mov [8 x i32]* ^182, (^112)
	movq %rax, (%rbx)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1657:3): struct-type: ptr ^112 -> ^113, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(1657:3): type of ^113 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1658:3): struct-type: ptr ^24 -> ^114, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rax)
	movq -888(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(1658:3): type of ^114 is i32*
	# LowerStore(1659:3).9: mov [1 x i32]* ^114, (^113)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1660:3): struct-type: ptr ^113 -> ^115, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1660:3): type of ^115 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1661:3): struct-type: ptr ^24 -> ^116, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rbx)
	movq -888(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(1661:3): type of ^116 is i32*
	# LowerStore(1662:3).9: mov [1 x i32]* ^116, (^115)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1663:3): struct-type: ptr ^115 -> ^117, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(1663:3): type of ^117 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1664:3): struct-type: ptr ^24 -> ^118, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rax)
	movq -888(%rbp), %r15
	movq %r15, (%rax)
	# LowerGetelementptr(1664:3): type of ^118 is i32*
	# LowerStore(1665:3).9: mov [1 x i32]* ^118, (^117)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1666:3): struct-type: ptr ^117 -> ^119, indices=1
	movq %rax, %rbx
	addq $8, %rbx
	# LowerGetelementptr(1666:3): type of ^119 is ptr*
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1667:3): struct-type: ptr ^24 -> ^120, indices=0,0
	# Fixing source-to-dest movq -888(%rbp), (%rbx)
	movq -888(%rbp), %r15
	movq %r15, (%rbx)
	# LowerGetelementptr(1667:3): type of ^120 is i32*
	# LowerStore(1668:3).9: mov [1 x i32]* ^120, (^119)
	# tt = Pointer, type = ptr
	# LowerGetelementptr(1669:3): struct-type: ptr ^119 -> ^121, indices=1
	movq %rbx, %rax
	addq $8, %rax
	# LowerGetelementptr(1669:3): type of ^121 is ptr*
	leaq g_2(%rip), %rbx
	# tt = Pointer, type = [8 x i32]
	leaq g_2(%rip), %rbx
	# LowerGetelementptr(1670:3): struct-type: [8 x i32] ^187 -> ^185, indices=0,2
	movq %rbx, %rdx
	addq $8, %rdx
	# LowerGetelementptr(1670:3): type of ^185 is i32*
	# LowerStore(1670:3).9: mov [8 x i32]* ^185, (^121)
	movq %rdx, (%rax)
	# tt = Pointer, type = [9 x ptr]
	# LowerGetelementptr(1671:3): struct-type: ptr ^105 -> ^122, indices=1
	movq %rcx, %rbx
	addq $72, %rbx
	# LowerGetelementptr(1671:3): type of ^122 is [9 x ptr]*
	# SetupCalls(1672:3): move argument ptr align 8 ^122
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1672:3): move argument i32 0
	movq $0, %rsi
	# SetupCalls(1672:3): move argument i64 72
	movq $72, %rdx
	callq memset@PLT
	# tt = Pointer, type = [9 x ptr]
	# LowerGetelementptr(1673:3): struct-type: ptr ^122 -> ^123, indices=0,0
	movq %rbx, %rax
	# LowerGetelementptr(1673:3): type of ^123 is ptr*
	# SetupCalls(1674:3): move argument ptr align 8 ^122
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1674:3): move argument ptr align 8 @constinit.89
	leaq constinit.89(%rip), %rsi
	# SetupCalls(1674:3): move argument i64 72
	movq $72, %rdx
	callq memcpy@PLT
	# LowerStore(1675:3).3: mov $imm, (^33)
	movq -960(%rbp), %rax
	movl $2, (%rax)
	# tt = Pointer, type = [9 x i32]
	# LowerGetelementptr(1676:3): struct-type: ptr ^2 -> ^124, indices=0,6
	movq -856(%rbp), %rbx
	addq $24, %rbx
	# LowerGetelementptr(1676:3): type of ^124 is i32*
	# LowerStore(1677:3).9: mov [9 x i32]* ^124, (^35)
	movq -976(%rbp), %rax
	movq %rbx, (%rax)
	# LowerStore(1678:3).9: mov ptr* ^35, (^36)
	movq -984(%rbp), %rax
	# Fixing source-to-dest movq -976(%rbp), (%rax)
	movq -976(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(1679:3).9: mov ptr* ^36, (^37)
	movq -992(%rbp), %rax
	# Fixing source-to-dest movq -984(%rbp), (%rax)
	movq -984(%rbp), %r15
	movq %r15, (%rax)
	# LowerStore(1680:3).3: mov $imm, (^38)
	movabsq $-2443352938090701540, %rax
	movq -1000(%rbp), %rbx
	movq %rax, (%rbx)
	# LowerStore(1681:3).3: mov $imm, (^39)
	movq -1008(%rbp), %rax
	movl $-1708225926, (%rax)
	# SetupCalls(1682:3): move argument ptr align 8 ^40
	# Fixed movzx with identical source and destination widths
	movq -1016(%rbp), %rdi
	# SetupCalls(1682:3): move argument ptr align 8 @__const.func_1.l_3954
	leaq __const.func_1.l_3954(%rip), %rsi
	# SetupCalls(1682:3): move argument i64 8
	movq $8, %rdx
	callq memcpy@PLT
	# SetupCalls(1683:3): move argument ptr align 16 ^41
	# Fixed movzx with identical source and destination widths
	movq -1024(%rbp), %rdi
	# SetupCalls(1683:3): move argument ptr align 16 @__const.func_1.l_3957
	leaq __const.func_1.l_3957(%rip), %rsi
	# SetupCalls(1683:3): move argument i64 42
	movq $42, %rdx
	callq memcpy@PLT
	# LowerStore(1684:3).3: mov $imm, (^42)
	movq -1032(%rbp), %rax
	movl $0, (%rax)
	.__func_1__M836:
	# LowerLoad(1688:3).2: (^42) into i32 ^126
	movq -1032(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1689:3): i32 ^126 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__func_1__M843
	jmp .__func_1__M870
	.__func_1__M843:
	# LowerLoad(1693:3).2: (^42) into i32 ^129
	movq -1032(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [1 x i32]
	# LowerGetelementptr(1695:3): array/pointer-type, dynamic index -> ^131
	# index ^130 -> temp ^204
	movq %rbx, %rcx
	# Multiply temp ^204 by 4 start
	shlq $2, %rcx
	# Multiply end
	# temp ^204 -> operand ^131
	movq %rcx, %rax
	# Result ^131 += skip 0
	addq $0, %rax
	# Result ^131 += base pointer ^24
	addq -888(%rbp), %rax
	# LowerStore(1696:3).3: mov $imm, (^131)
	movl $-1996879866, (%rax)
	# LowerLoad(1700:3).2: (^42) into i32 ^133
	movq -1032(%rbp), %rax
	movl (%rax), %ebx
	# LowerMath(1701:3): ^133, 1 into i32 ^134
	addl $1, %ebx
	# LowerStore(1702:3).9: mov i32 ^134, (^42)
	movq -1032(%rbp), %rax
	movl %ebx, (%rax)
	jmp .__func_1__M836
	.__func_1__M870:
	# LowerStore(1706:3).3: mov $imm, (^42)
	movq -1032(%rbp), %rax
	movl $0, (%rax)
	.__func_1__M873:
	# LowerLoad(1710:3).2: (^42) into i32 ^137
	movq -1032(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1711:3): i32 ^137 vs. intlike 3
	cmpl $3, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__func_1__M880
	jmp .__func_1__M906
	.__func_1__M880:
	# LowerLoad(1715:3).2: (^42) into i32 ^140
	movq -1032(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [3 x i8]
	# LowerGetelementptr(1717:3): array/pointer-type, dynamic index -> ^142
	# index ^141 -> temp ^205
	movq %rbx, %rax
	# Multiply temp ^205 by 1 start
	# Multiply end
	# temp ^205 -> operand ^142
	# Result ^142 += skip 0
	addq $0, %rax
	# Result ^142 += base pointer ^32
	addq -952(%rbp), %rax
	# LowerStore(1718:3).3: mov $imm, (^142)
	movb $1, (%rax)
	# LowerLoad(1722:3).2: (^42) into i32 ^144
	movq -1032(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(1723:3): ^144, 1 into i32 ^145
	addl $1, %eax
	# LowerStore(1724:3).9: mov i32 ^145, (^42)
	movq -1032(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .__func_1__M873
	.__func_1__M906:
	# LowerStore(1728:3).3: mov $imm, (^42)
	movq -1032(%rbp), %rax
	movl $0, (%rax)
	.__func_1__M909:
	# LowerLoad(1732:3).2: (^42) into i32 ^148
	movq -1032(%rbp), %rbx
	movl (%rbx), %eax
	# LowerIcmp(1733:3): i32 ^148 vs. intlike 9
	cmpl $9, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__func_1__M916
	jmp .__func_1__M943
	.__func_1__M916:
	# LowerLoad(1737:3).2: (^42) into i32 ^151
	movq -1032(%rbp), %rbx
	movl (%rbx), %eax
	movslq %eax, %rbx
	# tt = Pointer, type = [9 x i32]
	# LowerGetelementptr(1739:3): array/pointer-type, dynamic index -> ^153
	# index ^152 -> temp ^206
	movq %rbx, %rcx
	# Multiply temp ^206 by 4 start
	shlq $2, %rcx
	# Multiply end
	# temp ^206 -> operand ^153
	movq %rcx, %rax
	# Result ^153 += skip 0
	addq $0, %rax
	# Result ^153 += base pointer ^34
	addq -968(%rbp), %rax
	# LowerStore(1740:3).3: mov $imm, (^153)
	movl $-6, (%rax)
	# LowerLoad(1744:3).2: (^42) into i32 ^155
	movq -1032(%rbp), %rbx
	movl (%rbx), %eax
	# LowerMath(1745:3): ^155, 1 into i32 ^156
	addl $1, %eax
	# LowerStore(1746:3).9: mov i32 ^156, (^42)
	movq -1032(%rbp), %rbx
	movl %eax, (%rbx)
	jmp .__func_1__M909
	.__func_1__M943:
	leaq g_2(%rip), %rax
	# tt = Pointer, type = [8 x i32]
	leaq g_2(%rip), %rax
	# LowerGetelementptr(1753:3): struct-type: [8 x i32] ^190 -> ^188, indices=0,1
	movq %rax, %rbx
	addq $4, %rbx
	# LowerGetelementptr(1753:3): type of ^188 is i32*
	# LowerLoad(1753:3).2: (^188) into i32 ^159
	movl (%rbx), %eax
	# LowerMath(1754:3): ^159, 1 into i32 ^160
	addl $1, %eax
	leaq g_2(%rip), %rbx
	# tt = Pointer, type = [8 x i32]
	leaq g_2(%rip), %rcx
	# LowerGetelementptr(1755:3): struct-type: [8 x i32] ^193 -> ^191, indices=0,1
	movq %rcx, %rbx
	addq $4, %rbx
	# LowerGetelementptr(1755:3): type of ^191 is i32*
	# LowerStore(1755:3).9: mov i32 ^160, (^191)
	movl %eax, (%rbx)
	jmp .__func_1__M314
	.__func_1__M966:
	# tt = Pointer, type = %union.U0
	# LowerGetelementptr(1759:3): struct-type: ptr ^1 -> ^162, indices=0,0
	movq -848(%rbp), %rax
	# LowerGetelementptr(1759:3): type of ^162 is i64*
	# LowerLoad(1760:3).2: (^162) into i64 ^163
	movq (%rax), %rbx
	movq %rbx, %rax
	movq -1080(%rbp), %r15
	movq -1128(%rbp), %r14
	movq -1096(%rbp), %r13
	movq -1136(%rbp), %r12
	movq -1104(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global crc32_gentab
.p2align 4, 0x90
crc32_gentab:
	.__crc32_gentab__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(32 + 0, 16)
	subq $32, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -24(%rbp)
	movq %r15, -32(%rbp)
	# LowerAlloca(1394:3): size = 4, type = i32*, var = ^1
	leaq -4(%rbp), %rbx
	# LowerAlloca(1395:3): size = 4, type = i32*, var = ^2
	leaq -8(%rbp), %rax
	# LowerAlloca(1396:3): size = 4, type = i32*, var = ^3
	leaq -12(%rbp), %rdx
	# LowerAlloca(1397:3): size = 4, type = i32*, var = ^4
	leaq -16(%rbp), %rcx
	# LowerStore(1398:3).3: mov $imm, (^2)
	movl $-306674912, (%rax)
	# LowerStore(1399:3).3: mov $imm, (^3)
	movl $0, (%rdx)
	.__crc32_gentab__M13:
	# LowerLoad(1403:3).2: (^3) into i32 ^6
	movl (%rdx), %eax
	# LowerIcmp(1404:3): i32 ^6 vs. intlike 256
	cmpl $256, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__crc32_gentab__M20
	jmp .__crc32_gentab__M102
	.__crc32_gentab__M20:
	# LowerLoad(1408:3).2: (^3) into i32 ^9
	# Fixing source-to-dest movl (%rdx), (%rbx)
	movl (%rdx), %r15d
	movl %r15d, (%rbx)
	# LowerStore(1409:3).9: mov i32 ^9, (^1)
	# LowerStore(1410:3).3: mov $imm, (^4)
	movl $8, (%rcx)
	.__crc32_gentab__M27:
	# LowerLoad(1414:3).2: (^4) into i32 ^11
	movl (%rcx), %eax
	# LowerIcmp(1415:3): i32 ^11 vs. intlike 0
	cmpl $0, %eax
	setg %al
	andq $1, %rax
	cmpb $0, %al
	jne .__crc32_gentab__M34
	jmp .__crc32_gentab__M72
	.__crc32_gentab__M34:
	# LowerLoad(1419:3).2: (^1) into i32 ^14
	movl (%rbx), %eax
	# LowerLogic(1421:3): ^14, 1 into i32 ^15
	andl $1, %eax
	# LowerIcmp(1421:3): i32 ^15 vs. intlike 0
	cmpl $0, %eax
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__crc32_gentab__M44
	jmp .__crc32_gentab__M55
	.__crc32_gentab__M44:
	# LowerLoad(1425:3).2: (^1) into i32 ^18
	movl (%rbx), %esi
	# LowerLshr(1426:3): ^18, 1 into i32 ^19
	shrl $1, %esi
	# LowerLogic(1428:3): ^19, -306674912 into i32 ^20
	movl %esi, %eax
	xorl $-306674912, %eax
	# LowerStore(1428:3).9: mov i32 ^20, (^1)
	movl %eax, (%rbx)
	jmp .__crc32_gentab__M63
	.__crc32_gentab__M55:
	# LowerLoad(1432:3).2: (^1) into i32 ^22
	movl (%rbx), %eax
	# LowerLshr(1433:3): ^22, 1 into i32 ^23
	shrl $1, %eax
	# LowerStore(1434:3).9: mov i32 ^23, (^1)
	movl %eax, (%rbx)
	.__crc32_gentab__M63:
	# LowerLoad(1441:3).2: (^4) into i32 ^26
	movl (%rcx), %eax
	# LowerMath(1442:3): ^26, -1 into i32 ^27
	addl $-1, %eax
	# LowerStore(1443:3).9: mov i32 ^27, (^4)
	movl %eax, (%rcx)
	jmp .__crc32_gentab__M27
	.__crc32_gentab__M72:
	# LowerLoad(1447:3).2: (^1) into i32 ^29
	movl (%rbx), %esi
	# LowerLoad(1448:3).2: (^3) into i32 ^30
	movl (%rdx), %eax
	movslq %eax, %rdi
	leaq crc32_tab(%rip), %r8
	# tt = Pointer, type = [256 x i32]
	# LowerGetelementptr(1450:3): array/pointer-type, dynamic index -> ^32
	# index ^31 -> temp ^38
	movq %rdi, %rax
	# Multiply temp ^38 by 4 start
	shlq $2, %rax
	# Multiply end
	# temp ^38 -> operand ^32
	movq %rax, %rdi
	# Result ^32 += skip 0
	addq $0, %rdi
	# Result ^32 += base pointer ^37
	addq %r8, %rdi
	# LowerStore(1451:3).9: mov i32 ^29, (^32)
	movl %esi, (%rdi)
	# LowerLoad(1455:3).2: (^3) into i32 ^34
	movl (%rdx), %eax
	# LowerMath(1456:3): ^34, 1 into i32 ^35
	addl $1, %eax
	# LowerStore(1457:3).9: mov i32 ^35, (^3)
	movl %eax, (%rdx)
	jmp .__crc32_gentab__M13
	.__crc32_gentab__M102:
	movq -32(%rbp), %r15
	movq -24(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global platform_main_begin
.p2align 4, 0x90
platform_main_begin:
	.__platform_main_begin__M0:
	pushq %rbp
	movq %rsp, %rbp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbp, %rsp
	popq %rbp
	retq

.section .text
.global main
.p2align 4, 0x90
main:
	.__main__M0:
	pushq %rbp
	movq %rsp, %rbp
	# upalign(352 + 0, 16)
	subq $352, %rsp
	# Align stack pointer to 16-byte boundary
	andq $-16, %rsp
	movq %rbx, -104(%rbp)
	movq %r12, -88(%rbp)
	movq %r13, -96(%rbp)
	movq %r14, -120(%rbp)
	movq %r15, -112(%rbp)
	# LowerAlloca(186:3): size = 4, type = i32*, var = ^3
	leaq -4(%rbp), %r8
	# LowerAlloca(187:3): size = 4, type = i32*, var = ^4
	leaq -8(%rbp), %rcx
	# LowerAlloca(188:3): size = 8, type = ptr*, var = ^5
	leaq -16(%rbp), %rdx
	# LowerAlloca(189:3): size = 4, type = i32*, var = ^6
	leaq -20(%rbp), %r12
	# LowerAlloca(190:3): size = 4, type = i32*, var = ^7
	leaq -24(%rbp), %r13
	# LowerAlloca(191:3): size = 4, type = i32*, var = ^8
	leaq -28(%rbp), %rbx
	# LowerAlloca(192:3): size = 4, type = i32*, var = ^9
	# Fixing source-to-dest leaq -32(%rbp), -48(%rbp)
	leaq -32(%rbp), %r15
	movq %r15, -48(%rbp)
	# LowerAlloca(193:3): size = 8, type = %union.U0*, var = ^10
	leaq -40(%rbp), %r14
	# LowerStore(194:3).3: mov $imm, (^3)
	movl $0, (%r8)
	# LowerStore(195:3).9: mov i32 %edi, (^4)
	movl %edi, (%rcx)
	# LowerStore(196:3).9: mov ptr %rsi, (^5)
	movq %rsi, (%rdx)
	# LowerStore(197:3).3: mov $imm, (^9)
	movq -48(%rbp), %rax
	movl $0, (%rax)
	# LowerLoad(198:3).2: (^4) into i32 ^11
	movl (%rcx), %eax
	# LowerIcmp(199:3): i32 ^11 vs. intlike 2
	cmpl $2, %eax
	sete %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M31
	jmp .__main__M73
	.__main__M31:
	# LowerLoad(203:3).2: (^5) into ptr ^14
	movq (%rdx), %rcx
	# tt = Pointer, type = ptr
	# LowerGetelementptr(204:3): struct-type: ptr ^14 -> ^15, indices=1
	addq $8, %rcx
	# LowerGetelementptr(204:3): type of ^15 is ptr*
	# LowerLoad(205:3).2: (^15) into ptr ^16
	movq (%rcx), %rax
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(206:3): move argument ptr ^16
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(206:3): move argument ptr @.str
	leaq .str(%rip), %rsi
	callq strcmp@PLT
	# SetupCalls(206:3): move i32 result from %rax
	movl %eax, %r15d
	# Unclobber %rax
	movq -56(%rbp), %rax
	# LowerIcmp(207:3): i32 ^17 vs. intlike 0
	cmpl $0, %r15d
	sete %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M70
	jmp .__main__M73
	.__main__M70:
	# LowerStore(211:3).3: mov $imm, (^9)
	movq -48(%rbp), %rax
	movl $1, (%rax)
	.__main__M73:
	# Discarded useless call to platform_main_begin
	callq crc32_gentab
	callq func_1
	# SetupCalls(217:3): move i64 result from %rax
	movq %rax, %r15
	# tt = Pointer, type = %union.U0
	# LowerGetelementptr(218:3): struct-type: ptr ^10 -> ^22, indices=0,0
	movq %r14, %rax
	# LowerGetelementptr(218:3): type of ^22 is i64*
	# LowerStore(219:3).9: mov i64 ^21, (^22)
	movq %r15, (%rax)
	# LowerStore(220:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M123:
	# LowerLoad(224:3).2: (^6) into i32 ^24
	movl (%r12), %eax
	# LowerIcmp(225:3): i32 ^24 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M130
	jmp .__main__M300
	.__main__M130:
	# LowerStore(229:3).3: mov $imm, (^7)
	movl $0, (%r13)
	.__main__M133:
	# LowerLoad(233:3).2: (^7) into i32 ^28
	movl (%r13), %eax
	# LowerIcmp(234:3): i32 ^28 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M140
	jmp .__main__M291
	.__main__M140:
	# LowerStore(238:3).3: mov $imm, (^8)
	movl $0, (%rbx)
	.__main__M143:
	# LowerLoad(242:3).2: (^8) into i32 ^32
	movl (%rbx), %eax
	# LowerIcmp(243:3): i32 ^32 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M150
	jmp .__main__M282
	.__main__M150:
	# LowerLoad(247:3).2: (^6) into i32 ^35
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_2(%rip), %rax
	# tt = Pointer, type = [1 x [1 x [8 x i32]]]
	# LowerGetelementptr(249:3): array/pointer-type, dynamic index -> ^37
	# index ^36 -> temp ^725
	movq %rcx, %rsi
	# Multiply temp ^725 by 32 start
	shlq $5, %rsi
	# Multiply end
	# temp ^725 -> operand ^37
	movq %rsi, %rdx
	# Result ^37 += skip 0
	addq $0, %rdx
	# Result ^37 += base pointer ^724
	addq %rax, %rdx
	# LowerLoad(250:3).2: (^7) into i32 ^38
	movl (%r13), %eax
	movslq %eax, %rcx
	# tt = Pointer, type = [1 x [8 x i32]]
	# LowerGetelementptr(252:3): array/pointer-type, dynamic index -> ^40
	# index ^39 -> temp ^726
	movq %rcx, %rax
	# Multiply temp ^726 by 32 start
	shlq $5, %rax
	# Multiply end
	# temp ^726 -> operand ^40
	movq %rax, %rcx
	# Result ^40 += skip 0
	addq $0, %rcx
	# Result ^40 += base pointer ^37
	addq %rdx, %rcx
	# LowerLoad(253:3).2: (^8) into i32 ^41
	movl (%rbx), %edx
	movslq %edx, %rax
	# tt = Pointer, type = [8 x i32]
	# LowerGetelementptr(255:3): array/pointer-type, dynamic index -> ^43
	# index ^42 -> temp ^727
	movq %rax, %rdx
	# Multiply temp ^727 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^727 -> operand ^43
	movq %rdx, %rax
	# Result ^43 += skip 0
	addq $0, %rax
	# Result ^43 += base pointer ^40
	addq %rcx, %rax
	# LowerLoad(256:3).2: (^43) into i32 ^44
	movl (%rax), %ecx
	movslq %ecx, %rdx
	# LowerLoad(258:3).2: (^9) into i32 ^46
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rdx
	movq %rdx, -64(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(259:3): move argument i64 ^45
	# Fixed movzx with identical source and destination widths
	movq %rdx, %rdi
	# SetupCalls(259:3): move argument ptr @.str.1
	leaq .str.1(%rip), %rsi
	# SetupCalls(259:3): move argument i32 ^46
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq transparent_crc
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %rdx
	movq -64(%rbp), %rdx
	# LowerLoad(260:3).2: (^9) into i32 ^47
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(261:3): i32 ^47 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M236
	jmp .__main__M273
	.__main__M236:
	# LowerLoad(265:3).2: (^6) into i32 ^50
	movl (%r12), %ecx
	# LowerLoad(266:3).2: (^7) into i32 ^51
	movl (%r13), %r8d
	# LowerLoad(267:3).2: (^8) into i32 ^52
	movl (%rbx), %eax
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(268:3): move argument ptr @.str.2
	leaq .str.2(%rip), %rdi
	# SetupCalls(268:3): move argument i32 ^50
	# Fixed movzx with 32-bit source operand
	movl %ecx, %esi
	# SetupCalls(268:3): move argument i32 ^51
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	# SetupCalls(268:3): move argument i32 ^52
	# Fixed movzx with 32-bit source operand
	movl %eax, %ecx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(268:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	.__main__M273:
	# LowerLoad(275:3).2: (^8) into i32 ^56
	movl (%rbx), %eax
	# LowerMath(276:3): ^56, 1 into i32 ^57
	addl $1, %eax
	# LowerStore(277:3).9: mov i32 ^57, (^8)
	movl %eax, (%rbx)
	jmp .__main__M143
	.__main__M282:
	# LowerLoad(284:3).2: (^7) into i32 ^60
	movl (%r13), %eax
	# LowerMath(285:3): ^60, 1 into i32 ^61
	addl $1, %eax
	# LowerStore(286:3).9: mov i32 ^61, (^7)
	movl %eax, (%r13)
	jmp .__main__M133
	.__main__M291:
	# LowerLoad(293:3).2: (^6) into i32 ^64
	movl (%r12), %eax
	# LowerMath(294:3): ^64, 1 into i32 ^65
	addl $1, %eax
	# LowerStore(295:3).9: mov i32 ^65, (^6)
	movl %eax, (%r12)
	jmp .__main__M123
	.__main__M300:
	# LowerLoad(299:3).4: g_16 into ^67
	movq g_16(%rip), %rcx
	# LowerLoad(300:3).2: (^9) into i32 ^68
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(301:3): move argument i64 ^67
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(301:3): move argument ptr @.str.3
	leaq .str.3(%rip), %rsi
	# SetupCalls(301:3): move argument i32 ^68
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(302:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M332:
	# LowerLoad(306:3).2: (^6) into i32 ^70
	movl (%r12), %eax
	# LowerIcmp(307:3): i32 ^70 vs. intlike 4
	cmpl $4, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M339
	jmp .__main__M510
	.__main__M339:
	# LowerStore(311:3).3: mov $imm, (^7)
	movl $0, (%r13)
	.__main__M342:
	# LowerLoad(315:3).2: (^7) into i32 ^74
	movl (%r13), %eax
	# LowerIcmp(316:3): i32 ^74 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M349
	jmp .__main__M501
	.__main__M349:
	# LowerStore(320:3).3: mov $imm, (^8)
	movl $0, (%rbx)
	.__main__M352:
	# LowerLoad(324:3).2: (^8) into i32 ^78
	movl (%rbx), %eax
	# LowerIcmp(325:3): i32 ^78 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M359
	jmp .__main__M492
	.__main__M359:
	# LowerLoad(329:3).2: (^6) into i32 ^81
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_44(%rip), %rsi
	# tt = Pointer, type = [4 x [8 x [1 x i8]]]
	# LowerGetelementptr(331:3): array/pointer-type, dynamic index -> ^83
	# index ^82 -> temp ^729
	movq %rcx, %rdx
	# Multiply temp ^729 by 8 start
	shlq $3, %rdx
	# Multiply end
	# temp ^729 -> operand ^83
	movq %rdx, %rax
	# Result ^83 += skip 0
	addq $0, %rax
	# Result ^83 += base pointer ^728
	addq %rsi, %rax
	# LowerLoad(332:3).2: (^7) into i32 ^84
	movl (%r13), %ecx
	movslq %ecx, %rdx
	# tt = Pointer, type = [8 x [1 x i8]]
	# LowerGetelementptr(334:3): array/pointer-type, dynamic index -> ^86
	# index ^85 -> temp ^730
	movq %rdx, %rcx
	# Multiply temp ^730 by 1 start
	# Multiply end
	# temp ^730 -> operand ^86
	# Result ^86 += skip 0
	addq $0, %rcx
	# Result ^86 += base pointer ^83
	addq %rax, %rcx
	# LowerLoad(335:3).2: (^8) into i32 ^87
	movl (%rbx), %eax
	movslq %eax, %rdx
	# tt = Pointer, type = [1 x i8]
	# LowerGetelementptr(337:3): array/pointer-type, dynamic index -> ^89
	# index ^88 -> temp ^731
	movq %rdx, %rax
	# Multiply temp ^731 by 1 start
	# Multiply end
	# temp ^731 -> operand ^89
	# Result ^89 += skip 0
	addq $0, %rax
	# Result ^89 += base pointer ^86
	addq %rcx, %rax
	# LowerLoad(338:3).2: (^89) into i8 ^90
	movb (%rax), %cl
	# LowerBasicConversion(339:3): i8 ^90 -> i64 ^91
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerLoad(340:3).2: (^9) into i32 ^92
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(341:3): move argument i64 ^91
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(341:3): move argument ptr @.str.4
	leaq .str.4(%rip), %rsi
	# SetupCalls(341:3): move argument i32 ^92
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(342:3).2: (^9) into i32 ^93
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(343:3): i32 ^93 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M446
	jmp .__main__M483
	.__main__M446:
	# LowerLoad(347:3).2: (^6) into i32 ^96
	movl (%r12), %eax
	# LowerLoad(348:3).2: (^7) into i32 ^97
	movl (%r13), %ecx
	# LowerLoad(349:3).2: (^8) into i32 ^98
	movl (%rbx), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(350:3): move argument ptr @.str.2
	leaq .str.2(%rip), %rdi
	# SetupCalls(350:3): move argument i32 ^96
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(350:3): move argument i32 ^97
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	# SetupCalls(350:3): move argument i32 ^98
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(350:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	.__main__M483:
	# LowerLoad(357:3).2: (^8) into i32 ^102
	movl (%rbx), %eax
	# LowerMath(358:3): ^102, 1 into i32 ^103
	addl $1, %eax
	# LowerStore(359:3).9: mov i32 ^103, (^8)
	movl %eax, (%rbx)
	jmp .__main__M352
	.__main__M492:
	# LowerLoad(366:3).2: (^7) into i32 ^106
	movl (%r13), %eax
	# LowerMath(367:3): ^106, 1 into i32 ^107
	addl $1, %eax
	# LowerStore(368:3).9: mov i32 ^107, (^7)
	movl %eax, (%r13)
	jmp .__main__M342
	.__main__M501:
	# LowerLoad(375:3).2: (^6) into i32 ^110
	movl (%r12), %eax
	# LowerMath(376:3): ^110, 1 into i32 ^111
	addl $1, %eax
	# LowerStore(377:3).9: mov i32 ^111, (^6)
	movl %eax, (%r12)
	jmp .__main__M332
	.__main__M510:
	# LowerLoad(381:3).4: g_48 into ^113
	movl g_48(%rip), %eax
	movslq %eax, %rcx
	# LowerLoad(383:3).2: (^9) into i32 ^115
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(384:3): move argument i64 ^114
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(384:3): move argument ptr @.str.5
	leaq .str.5(%rip), %rsi
	# SetupCalls(384:3): move argument i32 ^115
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(385:3).4: g_84 into ^116
	movw g_84(%rip), %cx
	# LowerBasicConversion(386:3): i16 ^116 -> i64 ^117
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(387:3).2: (^9) into i32 ^118
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(388:3): move argument i64 ^117
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(388:3): move argument ptr @.str.6
	leaq .str.6(%rip), %rsi
	# SetupCalls(388:3): move argument i32 ^118
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(389:3).4: g_91 into ^119
	movb g_91(%rip), %cl
	# LowerBasicConversion(390:3): i8 ^119 -> i64 ^120
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerLoad(391:3).2: (^9) into i32 ^121
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(392:3): move argument i64 ^120
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(392:3): move argument ptr @.str.7
	leaq .str.7(%rip), %rsi
	# SetupCalls(392:3): move argument i32 ^121
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(393:3).4: g_124 into ^122
	movw g_124(%rip), %ax
	movswq %ax, %rcx
	# LowerLoad(395:3).2: (^9) into i32 ^124
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(396:3): move argument i64 ^123
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(396:3): move argument ptr @.str.8
	leaq .str.8(%rip), %rsi
	# SetupCalls(396:3): move argument i32 ^124
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(397:3).4: g_125 into ^125
	movb g_125(%rip), %al
	movsbq %al, %rcx
	# LowerLoad(399:3).2: (^9) into i32 ^127
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(400:3): move argument i64 ^126
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(400:3): move argument ptr @.str.9
	leaq .str.9(%rip), %rsi
	# SetupCalls(400:3): move argument i32 ^127
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(401:3).4: g_126 into ^128
	movb g_126(%rip), %al
	movsbq %al, %rcx
	# LowerLoad(403:3).2: (^9) into i32 ^130
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(404:3): move argument i64 ^129
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(404:3): move argument ptr @.str.10
	leaq .str.10(%rip), %rsi
	# SetupCalls(404:3): move argument i32 ^130
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(405:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M700:
	# LowerLoad(409:3).2: (^6) into i32 ^132
	movl (%r12), %eax
	# LowerIcmp(410:3): i32 ^132 vs. intlike 2
	cmpl $2, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M707
	jmp .__main__M801
	.__main__M707:
	# LowerLoad(414:3).2: (^6) into i32 ^135
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_127(%rip), %rdx
	# tt = Pointer, type = [2 x i8]
	# LowerGetelementptr(416:3): array/pointer-type, dynamic index -> ^137
	# index ^136 -> temp ^733
	movq %rcx, %rax
	# Multiply temp ^733 by 1 start
	# Multiply end
	# temp ^733 -> operand ^137
	# Result ^137 += skip 0
	addq $0, %rax
	# Result ^137 += base pointer ^732
	addq %rdx, %rax
	# LowerLoad(417:3).2: (^137) into i8 ^138
	movb (%rax), %cl
	# LowerBasicConversion(418:3): i8 ^138 -> i64 ^139
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerLoad(419:3).2: (^9) into i32 ^140
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(420:3): move argument i64 ^139
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(420:3): move argument ptr @.str.11
	leaq .str.11(%rip), %rsi
	# SetupCalls(420:3): move argument i32 ^140
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(421:3).2: (^9) into i32 ^141
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(422:3): i32 ^141 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M763
	jmp .__main__M792
	.__main__M763:
	# LowerLoad(426:3).2: (^6) into i32 ^144
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(427:3): move argument ptr @.str.12
	leaq .str.12(%rip), %rdi
	# SetupCalls(427:3): move argument i32 ^144
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(427:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	.__main__M792:
	# LowerLoad(434:3).2: (^6) into i32 ^148
	movl (%r12), %eax
	# LowerMath(435:3): ^148, 1 into i32 ^149
	addl $1, %eax
	# LowerStore(436:3).9: mov i32 ^149, (^6)
	movl %eax, (%r12)
	jmp .__main__M700
	.__main__M801:
	# LowerStore(440:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M804:
	# LowerLoad(444:3).2: (^6) into i32 ^152
	movl (%r12), %eax
	# LowerIcmp(445:3): i32 ^152 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M811
	jmp .__main__M984
	.__main__M811:
	# LowerStore(449:3).3: mov $imm, (^7)
	movl $0, (%r13)
	.__main__M814:
	# LowerLoad(453:3).2: (^7) into i32 ^156
	movl (%r13), %eax
	# LowerIcmp(454:3): i32 ^156 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M821
	jmp .__main__M975
	.__main__M821:
	# LowerStore(458:3).3: mov $imm, (^8)
	movl $0, (%rbx)
	.__main__M824:
	# LowerLoad(462:3).2: (^8) into i32 ^160
	movl (%rbx), %eax
	# LowerIcmp(463:3): i32 ^160 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M831
	jmp .__main__M966
	.__main__M831:
	# LowerLoad(467:3).2: (^6) into i32 ^163
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_137(%rip), %rsi
	# tt = Pointer, type = [8 x [1 x [8 x i16]]]
	# LowerGetelementptr(469:3): array/pointer-type, dynamic index -> ^165
	# index ^164 -> temp ^735
	movq %rcx, %rdx
	# Multiply temp ^735 by 16 start
	shlq $4, %rdx
	# Multiply end
	# temp ^735 -> operand ^165
	movq %rdx, %rax
	# Result ^165 += skip 0
	addq $0, %rax
	# Result ^165 += base pointer ^734
	addq %rsi, %rax
	# LowerLoad(470:3).2: (^7) into i32 ^166
	movl (%r13), %ecx
	movslq %ecx, %rdx
	# tt = Pointer, type = [1 x [8 x i16]]
	# LowerGetelementptr(472:3): array/pointer-type, dynamic index -> ^168
	# index ^167 -> temp ^736
	movq %rdx, %rsi
	# Multiply temp ^736 by 16 start
	shlq $4, %rsi
	# Multiply end
	# temp ^736 -> operand ^168
	movq %rsi, %rcx
	# Result ^168 += skip 0
	addq $0, %rcx
	# Result ^168 += base pointer ^165
	addq %rax, %rcx
	# LowerLoad(473:3).2: (^8) into i32 ^169
	movl (%rbx), %eax
	movslq %eax, %rdx
	# tt = Pointer, type = [8 x i16]
	# LowerGetelementptr(475:3): array/pointer-type, dynamic index -> ^171
	# index ^170 -> temp ^737
	movq %rdx, %rsi
	# Multiply temp ^737 by 2 start
	shlq $1, %rsi
	# Multiply end
	# temp ^737 -> operand ^171
	movq %rsi, %rax
	# Result ^171 += skip 0
	addq $0, %rax
	# Result ^171 += base pointer ^168
	addq %rcx, %rax
	# LowerLoad(476:3).2: (^171) into i16 ^172
	movw (%rax), %cx
	# LowerBasicConversion(477:3): i16 ^172 -> i64 ^173
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(478:3).2: (^9) into i32 ^174
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(479:3): move argument i64 ^173
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(479:3): move argument ptr @.str.13
	leaq .str.13(%rip), %rsi
	# SetupCalls(479:3): move argument i32 ^174
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(480:3).2: (^9) into i32 ^175
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(481:3): i32 ^175 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M920
	jmp .__main__M957
	.__main__M920:
	# LowerLoad(485:3).2: (^6) into i32 ^178
	movl (%r12), %eax
	# LowerLoad(486:3).2: (^7) into i32 ^179
	movl (%r13), %ecx
	# LowerLoad(487:3).2: (^8) into i32 ^180
	movl (%rbx), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(488:3): move argument ptr @.str.2
	leaq .str.2(%rip), %rdi
	# SetupCalls(488:3): move argument i32 ^178
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(488:3): move argument i32 ^179
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	# SetupCalls(488:3): move argument i32 ^180
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(488:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	.__main__M957:
	# LowerLoad(495:3).2: (^8) into i32 ^184
	movl (%rbx), %eax
	# LowerMath(496:3): ^184, 1 into i32 ^185
	addl $1, %eax
	# LowerStore(497:3).9: mov i32 ^185, (^8)
	movl %eax, (%rbx)
	jmp .__main__M824
	.__main__M966:
	# LowerLoad(504:3).2: (^7) into i32 ^188
	movl (%r13), %eax
	# LowerMath(505:3): ^188, 1 into i32 ^189
	addl $1, %eax
	# LowerStore(506:3).9: mov i32 ^189, (^7)
	movl %eax, (%r13)
	jmp .__main__M814
	.__main__M975:
	# LowerLoad(513:3).2: (^6) into i32 ^192
	movl (%r12), %eax
	# LowerMath(514:3): ^192, 1 into i32 ^193
	addl $1, %eax
	# LowerStore(515:3).9: mov i32 ^193, (^6)
	movl %eax, (%r12)
	jmp .__main__M804
	.__main__M984:
	# LowerLoad(519:3).2: (^9) into i32 ^195
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(520:3): move argument i64 -544471354
	movq $-544471354, %rdi
	# SetupCalls(520:3): move argument ptr @.str.14
	leaq .str.14(%rip), %rsi
	# SetupCalls(520:3): move argument i32 ^195
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(521:3).4: g_159 into ^196
	movq g_159(%rip), %rcx
	# LowerLoad(522:3).2: (^9) into i32 ^197
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(523:3): move argument i64 ^196
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(523:3): move argument ptr @.str.15
	leaq .str.15(%rip), %rsi
	# SetupCalls(523:3): move argument i32 ^197
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(524:3).4: g_205 into ^198
	movl g_205(%rip), %ecx
	# LowerBasicConversion(525:3): i32 ^198 -> i64 ^199
	# LowerLoad(526:3).2: (^9) into i32 ^200
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(527:3): move argument i64 ^199
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(527:3): move argument ptr @.str.16
	leaq .str.16(%rip), %rsi
	# SetupCalls(527:3): move argument i32 ^200
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(528:3).4: g_209 into ^201
	movq g_209(%rip), %rcx
	# LowerLoad(529:3).2: (^9) into i32 ^202
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(530:3): move argument i64 ^201
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(530:3): move argument ptr @.str.17
	leaq .str.17(%rip), %rsi
	# SetupCalls(530:3): move argument i32 ^202
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(531:3).4: g_222 into ^203
	movq g_222(%rip), %rcx
	# LowerLoad(532:3).2: (^9) into i32 ^204
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(533:3): move argument i64 ^203
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(533:3): move argument ptr @.str.18
	leaq .str.18(%rip), %rsi
	# SetupCalls(533:3): move argument i32 ^204
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(534:3).4: g_225 into ^205
	movq g_225(%rip), %rcx
	# LowerLoad(535:3).2: (^9) into i32 ^206
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(536:3): move argument i64 ^205
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(536:3): move argument ptr @.str.19
	leaq .str.19(%rip), %rsi
	# SetupCalls(536:3): move argument i32 ^206
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(537:3).4: g_238 into ^207
	movl g_238(%rip), %ecx
	# LowerBasicConversion(538:3): i32 ^207 -> i64 ^208
	# LowerLoad(539:3).2: (^9) into i32 ^209
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(540:3): move argument i64 ^208
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(540:3): move argument ptr @.str.20
	leaq .str.20(%rip), %rsi
	# SetupCalls(540:3): move argument i32 ^209
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(541:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M1193:
	# LowerLoad(545:3).2: (^6) into i32 ^211
	movl (%r12), %eax
	# LowerIcmp(546:3): i32 ^211 vs. intlike 10
	cmpl $10, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1200
	jmp .__main__M1384
	.__main__M1200:
	# LowerStore(550:3).3: mov $imm, (^7)
	movl $0, (%r13)
	.__main__M1203:
	# LowerLoad(554:3).2: (^7) into i32 ^215
	movl (%r13), %eax
	# LowerIcmp(555:3): i32 ^215 vs. intlike 6
	cmpl $6, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1210
	jmp .__main__M1375
	.__main__M1210:
	# LowerStore(559:3).3: mov $imm, (^8)
	movl $0, (%rbx)
	.__main__M1213:
	# LowerLoad(563:3).2: (^8) into i32 ^219
	movl (%rbx), %eax
	# LowerIcmp(564:3): i32 ^219 vs. intlike 3
	cmpl $3, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1220
	jmp .__main__M1366
	.__main__M1220:
	# LowerLoad(568:3).2: (^6) into i32 ^222
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_239(%rip), %rsi
	# tt = Pointer, type = [10 x [6 x [3 x i32]]]
	# LowerGetelementptr(570:3): array/pointer-type, dynamic index -> ^224
	# index ^223 -> temp ^739
	movq %rcx, %rdx
	# Multiply temp ^739 by 72 start
	# Clobber %rdx
	movq %rdx, -64(%rbp)
	movq %rdx, %rax
	movq $72, %rcx
	mulq %rcx
	# Unclobber %rdx
	movq -64(%rbp), %rdx
	movq %rax, %rdx
	# Multiply end
	# temp ^739 -> operand ^224
	movq %rdx, %rcx
	# Result ^224 += skip 0
	addq $0, %rcx
	# Result ^224 += base pointer ^738
	addq %rsi, %rcx
	# LowerLoad(571:3).2: (^7) into i32 ^225
	movl (%r13), %eax
	movslq %eax, %rdx
	# tt = Pointer, type = [6 x [3 x i32]]
	# LowerGetelementptr(573:3): array/pointer-type, dynamic index -> ^227
	# index ^226 -> temp ^741
	movq %rdx, %rsi
	# Multiply temp ^741 by 12 start
	movq %rsi, %rax
	movq $12, %rsi
	mulq %rsi
	movq %rax, %rsi
	# Multiply end
	# temp ^741 -> operand ^227
	movq %rsi, %rax
	# Result ^227 += skip 0
	addq $0, %rax
	# Result ^227 += base pointer ^224
	addq %rcx, %rax
	# LowerLoad(574:3).2: (^8) into i32 ^228
	movl (%rbx), %ecx
	movslq %ecx, %rdx
	# tt = Pointer, type = [3 x i32]
	# LowerGetelementptr(576:3): array/pointer-type, dynamic index -> ^230
	# index ^229 -> temp ^743
	movq %rdx, %rsi
	# Multiply temp ^743 by 4 start
	shlq $2, %rsi
	# Multiply end
	# temp ^743 -> operand ^230
	movq %rsi, %rcx
	# Result ^230 += skip 0
	addq $0, %rcx
	# Result ^230 += base pointer ^227
	addq %rax, %rcx
	# LowerLoad(577:3).2: (^230) into i32 ^231
	movl (%rcx), %eax
	movslq %eax, %rcx
	# LowerLoad(579:3).2: (^9) into i32 ^233
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(580:3): move argument i64 ^232
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(580:3): move argument ptr @.str.21
	leaq .str.21(%rip), %rsi
	# SetupCalls(580:3): move argument i32 ^233
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(581:3).2: (^9) into i32 ^234
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(582:3): i32 ^234 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1320
	jmp .__main__M1357
	.__main__M1320:
	# LowerLoad(586:3).2: (^6) into i32 ^237
	movl (%r12), %eax
	# LowerLoad(587:3).2: (^7) into i32 ^238
	movl (%r13), %ecx
	# LowerLoad(588:3).2: (^8) into i32 ^239
	movl (%rbx), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(589:3): move argument ptr @.str.2
	leaq .str.2(%rip), %rdi
	# SetupCalls(589:3): move argument i32 ^237
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(589:3): move argument i32 ^238
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	# SetupCalls(589:3): move argument i32 ^239
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(589:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	.__main__M1357:
	# LowerLoad(596:3).2: (^8) into i32 ^243
	movl (%rbx), %eax
	# LowerMath(597:3): ^243, 1 into i32 ^244
	addl $1, %eax
	# LowerStore(598:3).9: mov i32 ^244, (^8)
	movl %eax, (%rbx)
	jmp .__main__M1213
	.__main__M1366:
	# LowerLoad(605:3).2: (^7) into i32 ^247
	movl (%r13), %eax
	# LowerMath(606:3): ^247, 1 into i32 ^248
	addl $1, %eax
	# LowerStore(607:3).9: mov i32 ^248, (^7)
	movl %eax, (%r13)
	jmp .__main__M1203
	.__main__M1375:
	# LowerLoad(614:3).2: (^6) into i32 ^251
	movl (%r12), %eax
	# LowerMath(615:3): ^251, 1 into i32 ^252
	addl $1, %eax
	# LowerStore(616:3).9: mov i32 ^252, (^6)
	movl %eax, (%r12)
	jmp .__main__M1193
	.__main__M1384:
	# LowerLoad(620:3).4: g_240 into ^254
	movw g_240(%rip), %ax
	movswq %ax, %rdx
	# LowerLoad(622:3).2: (^9) into i32 ^256
	movq -48(%rbp), %rcx
	movl (%rcx), %eax
	# Clobber %rdx
	movq %rdx, -64(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(623:3): move argument i64 ^255
	# Fixed movzx with identical source and destination widths
	movq %rdx, %rdi
	# SetupCalls(623:3): move argument ptr @.str.22
	leaq .str.22(%rip), %rsi
	# SetupCalls(623:3): move argument i32 ^256
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq transparent_crc
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %rdx
	movq -64(%rbp), %rdx
	# LowerLoad(624:3).4: g_283 into ^257
	movq g_283(%rip), %rcx
	# LowerLoad(625:3).2: (^9) into i32 ^258
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(626:3): move argument i64 ^257
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(626:3): move argument ptr @.str.23
	leaq .str.23(%rip), %rsi
	# SetupCalls(626:3): move argument i32 ^258
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(627:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M1446:
	# LowerLoad(631:3).2: (^6) into i32 ^260
	movl (%r12), %eax
	# LowerIcmp(632:3): i32 ^260 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1453
	jmp .__main__M1545
	.__main__M1453:
	# LowerLoad(636:3).2: (^6) into i32 ^263
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_313(%rip), %rsi
	# tt = Pointer, type = [8 x i32]
	# LowerGetelementptr(638:3): array/pointer-type, dynamic index -> ^265
	# index ^264 -> temp ^745
	movq %rcx, %rdx
	# Multiply temp ^745 by 4 start
	shlq $2, %rdx
	# Multiply end
	# temp ^745 -> operand ^265
	movq %rdx, %rax
	# Result ^265 += skip 0
	addq $0, %rax
	# Result ^265 += base pointer ^744
	addq %rsi, %rax
	# LowerLoad(639:3).2: (^265) into i32 ^266
	movl (%rax), %ecx
	movslq %ecx, %rdx
	# LowerLoad(641:3).2: (^9) into i32 ^268
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rdx
	movq %rdx, -64(%rbp)
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(642:3): move argument i64 ^267
	# Fixed movzx with identical source and destination widths
	movq %rdx, %rdi
	# SetupCalls(642:3): move argument ptr @.str.24
	leaq .str.24(%rip), %rsi
	# SetupCalls(642:3): move argument i32 ^268
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# Unclobber %rdx
	movq -64(%rbp), %rdx
	# LowerLoad(643:3).2: (^9) into i32 ^269
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(644:3): i32 ^269 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1507
	jmp .__main__M1536
	.__main__M1507:
	# LowerLoad(648:3).2: (^6) into i32 ^272
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(649:3): move argument ptr @.str.12
	leaq .str.12(%rip), %rdi
	# SetupCalls(649:3): move argument i32 ^272
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(649:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	.__main__M1536:
	# LowerLoad(656:3).2: (^6) into i32 ^276
	movl (%r12), %eax
	# LowerMath(657:3): ^276, 1 into i32 ^277
	addl $1, %eax
	# LowerStore(658:3).9: mov i32 ^277, (^6)
	movl %eax, (%r12)
	jmp .__main__M1446
	.__main__M1545:
	# LowerLoad(662:3).4: g_385 into ^279
	movq g_385(%rip), %rcx
	# LowerLoad(663:3).2: (^9) into i32 ^280
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(664:3): move argument i64 ^279
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(664:3): move argument ptr @.str.25
	leaq .str.25(%rip), %rsi
	# SetupCalls(664:3): move argument i32 ^280
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(665:3).4: g_468 into ^281
	movl g_468(%rip), %eax
	movslq %eax, %rcx
	# LowerLoad(667:3).2: (^9) into i32 ^283
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(668:3): move argument i64 ^282
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(668:3): move argument ptr @.str.26
	leaq .str.26(%rip), %rsi
	# SetupCalls(668:3): move argument i32 ^283
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(669:3).4: g_469 into ^284
	movq g_469(%rip), %rcx
	# LowerLoad(670:3).2: (^9) into i32 ^285
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(671:3): move argument i64 ^284
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(671:3): move argument ptr @.str.27
	leaq .str.27(%rip), %rsi
	# SetupCalls(671:3): move argument i32 ^285
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(672:3).4: g_470 into ^286
	movl g_470(%rip), %ecx
	# LowerBasicConversion(673:3): i32 ^286 -> i64 ^287
	# LowerLoad(674:3).2: (^9) into i32 ^288
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(675:3): move argument i64 ^287
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(675:3): move argument ptr @.str.28
	leaq .str.28(%rip), %rsi
	# SetupCalls(675:3): move argument i32 ^288
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(676:3).4: g_477 into ^289
	movl g_477(%rip), %ecx
	# LowerBasicConversion(677:3): i32 ^289 -> i64 ^290
	# LowerLoad(678:3).2: (^9) into i32 ^291
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(679:3): move argument i64 ^290
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(679:3): move argument ptr @.str.29
	leaq .str.29(%rip), %rsi
	# SetupCalls(679:3): move argument i32 ^291
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(680:3).4: g_527 into ^292
	movw g_527(%rip), %ax
	# LowerBasicConversion(681:3): i16 ^292 -> i64 ^293
	movq %rax, %rcx
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(682:3).2: (^9) into i32 ^294
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(683:3): move argument i64 ^293
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(683:3): move argument ptr @.str.30
	leaq .str.30(%rip), %rsi
	# SetupCalls(683:3): move argument i32 ^294
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(684:3).4: g_541 into ^295
	movw g_541(%rip), %ax
	movswq %ax, %rcx
	# LowerLoad(686:3).2: (^9) into i32 ^297
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(687:3): move argument i64 ^296
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(687:3): move argument ptr @.str.31
	leaq .str.31(%rip), %rsi
	# SetupCalls(687:3): move argument i32 ^297
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(688:3).4: g_575 into ^298
	movb g_575(%rip), %al
	movsbq %al, %rcx
	# LowerLoad(690:3).2: (^9) into i32 ^300
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(691:3): move argument i64 ^299
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(691:3): move argument ptr @.str.32
	leaq .str.32(%rip), %rsi
	# SetupCalls(691:3): move argument i32 ^300
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(692:3).4: g_577 into ^301
	movb g_577(%rip), %cl
	# LowerBasicConversion(693:3): i8 ^301 -> i64 ^302
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerLoad(694:3).2: (^9) into i32 ^303
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(695:3): move argument i64 ^302
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(695:3): move argument ptr @.str.33
	leaq .str.33(%rip), %rsi
	# SetupCalls(695:3): move argument i32 ^303
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(696:3).4: g_617 into ^304
	movl g_617(%rip), %ecx
	# LowerBasicConversion(697:3): i32 ^304 -> i64 ^305
	# LowerLoad(698:3).2: (^9) into i32 ^306
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(699:3): move argument i64 ^305
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(699:3): move argument ptr @.str.34
	leaq .str.34(%rip), %rsi
	# SetupCalls(699:3): move argument i32 ^306
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(700:3).4: g_666 into ^307
	movb g_666(%rip), %al
	movsbq %al, %rcx
	# LowerLoad(702:3).2: (^9) into i32 ^309
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(703:3): move argument i64 ^308
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(703:3): move argument ptr @.str.35
	leaq .str.35(%rip), %rsi
	# SetupCalls(703:3): move argument i32 ^309
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(704:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M1887:
	# LowerLoad(708:3).2: (^6) into i32 ^311
	movl (%r12), %eax
	# LowerIcmp(709:3): i32 ^311 vs. intlike 4
	cmpl $4, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1894
	jmp .__main__M2028
	.__main__M1894:
	# LowerStore(713:3).3: mov $imm, (^7)
	movl $0, (%r13)
	.__main__M1897:
	# LowerLoad(717:3).2: (^7) into i32 ^315
	movl (%r13), %eax
	# LowerIcmp(718:3): i32 ^315 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1904
	jmp .__main__M2019
	.__main__M1904:
	# LowerLoad(722:3).2: (^6) into i32 ^318
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_667(%rip), %rdx
	# tt = Pointer, type = [4 x [8 x i16]]
	# LowerGetelementptr(724:3): array/pointer-type, dynamic index -> ^320
	# index ^319 -> temp ^747
	movq %rcx, %rsi
	# Multiply temp ^747 by 16 start
	shlq $4, %rsi
	# Multiply end
	# temp ^747 -> operand ^320
	movq %rsi, %rax
	# Result ^320 += skip 0
	addq $0, %rax
	# Result ^320 += base pointer ^746
	addq %rdx, %rax
	# LowerLoad(725:3).2: (^7) into i32 ^321
	movl (%r13), %ecx
	movslq %ecx, %rdx
	# tt = Pointer, type = [8 x i16]
	# LowerGetelementptr(727:3): array/pointer-type, dynamic index -> ^323
	# index ^322 -> temp ^748
	movq %rdx, %rsi
	# Multiply temp ^748 by 2 start
	shlq $1, %rsi
	# Multiply end
	# temp ^748 -> operand ^323
	movq %rsi, %rcx
	# Result ^323 += skip 0
	addq $0, %rcx
	# Result ^323 += base pointer ^320
	addq %rax, %rcx
	# LowerLoad(728:3).2: (^323) into i16 ^324
	movw (%rcx), %dx
	# LowerBasicConversion(729:3): i16 ^324 -> i64 ^325
	# Truncate value to 16 bits
	andl $65535, %edx
	# LowerLoad(730:3).2: (^9) into i32 ^326
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rdx
	movq %rdx, -64(%rbp)
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(731:3): move argument i64 ^325
	# Fixed movzx with identical source and destination widths
	movq %rdx, %rdi
	# SetupCalls(731:3): move argument ptr @.str.36
	leaq .str.36(%rip), %rsi
	# SetupCalls(731:3): move argument i32 ^326
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# Unclobber %rdx
	movq -64(%rbp), %rdx
	# LowerLoad(732:3).2: (^9) into i32 ^327
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(733:3): i32 ^327 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M1977
	jmp .__main__M2010
	.__main__M1977:
	# LowerLoad(737:3).2: (^6) into i32 ^330
	movl (%r12), %eax
	# LowerLoad(738:3).2: (^7) into i32 ^331
	movl (%r13), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(739:3): move argument ptr @.str.37
	leaq .str.37(%rip), %rdi
	# SetupCalls(739:3): move argument i32 ^330
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(739:3): move argument i32 ^331
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(739:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	.__main__M2010:
	# LowerLoad(746:3).2: (^7) into i32 ^335
	movl (%r13), %eax
	# LowerMath(747:3): ^335, 1 into i32 ^336
	addl $1, %eax
	# LowerStore(748:3).9: mov i32 ^336, (^7)
	movl %eax, (%r13)
	jmp .__main__M1897
	.__main__M2019:
	# LowerLoad(755:3).2: (^6) into i32 ^339
	movl (%r12), %eax
	# LowerMath(756:3): ^339, 1 into i32 ^340
	addl $1, %eax
	# LowerStore(757:3).9: mov i32 ^340, (^6)
	movl %eax, (%r12)
	jmp .__main__M1887
	.__main__M2028:
	# LowerStore(761:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M2031:
	# LowerLoad(765:3).2: (^6) into i32 ^343
	movl (%r12), %eax
	# LowerIcmp(766:3): i32 ^343 vs. intlike 10
	cmpl $10, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2038
	jmp .__main__M2132
	.__main__M2038:
	# LowerLoad(770:3).2: (^6) into i32 ^346
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_764(%rip), %rdx
	# tt = Pointer, type = [10 x i8]
	# LowerGetelementptr(772:3): array/pointer-type, dynamic index -> ^348
	# index ^347 -> temp ^750
	movq %rcx, %rax
	# Multiply temp ^750 by 1 start
	# Multiply end
	# temp ^750 -> operand ^348
	# Result ^348 += skip 0
	addq $0, %rax
	# Result ^348 += base pointer ^749
	addq %rdx, %rax
	# LowerLoad(773:3).2: (^348) into i8 ^349
	movb (%rax), %cl
	# LowerBasicConversion(774:3): i8 ^349 -> i64 ^350
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerLoad(775:3).2: (^9) into i32 ^351
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(776:3): move argument i64 ^350
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(776:3): move argument ptr @.str.38
	leaq .str.38(%rip), %rsi
	# SetupCalls(776:3): move argument i32 ^351
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(777:3).2: (^9) into i32 ^352
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(778:3): i32 ^352 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2094
	jmp .__main__M2123
	.__main__M2094:
	# LowerLoad(782:3).2: (^6) into i32 ^355
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(783:3): move argument ptr @.str.12
	leaq .str.12(%rip), %rdi
	# SetupCalls(783:3): move argument i32 ^355
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(783:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	.__main__M2123:
	# LowerLoad(790:3).2: (^6) into i32 ^359
	movl (%r12), %eax
	# LowerMath(791:3): ^359, 1 into i32 ^360
	addl $1, %eax
	# LowerStore(792:3).9: mov i32 ^360, (^6)
	movl %eax, (%r12)
	jmp .__main__M2031
	.__main__M2132:
	# LowerLoad(796:3).4: g_765 into ^362
	movq g_765(%rip), %rcx
	# LowerLoad(797:3).2: (^9) into i32 ^363
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(798:3): move argument i64 ^362
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(798:3): move argument ptr @.str.39
	leaq .str.39(%rip), %rsi
	# SetupCalls(798:3): move argument i32 ^363
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(799:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M2164:
	# LowerLoad(803:3).2: (^6) into i32 ^365
	movl (%r12), %eax
	# LowerIcmp(804:3): i32 ^365 vs. intlike 4
	cmpl $4, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2171
	jmp .__main__M2266
	.__main__M2171:
	# LowerLoad(808:3).2: (^6) into i32 ^368
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_805(%rip), %rdx
	# tt = Pointer, type = [4 x i16]
	# LowerGetelementptr(810:3): array/pointer-type, dynamic index -> ^370
	# index ^369 -> temp ^752
	movq %rcx, %rsi
	# Multiply temp ^752 by 2 start
	shlq $1, %rsi
	# Multiply end
	# temp ^752 -> operand ^370
	movq %rsi, %rax
	# Result ^370 += skip 0
	addq $0, %rax
	# Result ^370 += base pointer ^751
	addq %rdx, %rax
	# LowerLoad(811:3).2: (^370) into i16 ^371
	movw (%rax), %cx
	# LowerBasicConversion(812:3): i16 ^371 -> i64 ^372
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(813:3).2: (^9) into i32 ^373
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(814:3): move argument i64 ^372
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(814:3): move argument ptr @.str.40
	leaq .str.40(%rip), %rsi
	# SetupCalls(814:3): move argument i32 ^373
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(815:3).2: (^9) into i32 ^374
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(816:3): i32 ^374 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2228
	jmp .__main__M2257
	.__main__M2228:
	# LowerLoad(820:3).2: (^6) into i32 ^377
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(821:3): move argument ptr @.str.12
	leaq .str.12(%rip), %rdi
	# SetupCalls(821:3): move argument i32 ^377
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(821:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	.__main__M2257:
	# LowerLoad(828:3).2: (^6) into i32 ^381
	movl (%r12), %eax
	# LowerMath(829:3): ^381, 1 into i32 ^382
	addl $1, %eax
	# LowerStore(830:3).9: mov i32 ^382, (^6)
	movl %eax, (%r12)
	jmp .__main__M2164
	.__main__M2266:
	# LowerLoad(834:3).2: (^9) into i32 ^384
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(835:3): move argument i64 1
	movq $1, %rdi
	# SetupCalls(835:3): move argument ptr @.str.41
	leaq .str.41(%rip), %rsi
	# SetupCalls(835:3): move argument i32 ^384
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(836:3).4: g_948 into ^385
	movq g_948(%rip), %rcx
	# LowerLoad(837:3).2: (^9) into i32 ^386
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(838:3): move argument i64 ^385
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(838:3): move argument ptr @.str.42
	leaq .str.42(%rip), %rsi
	# SetupCalls(838:3): move argument i32 ^386
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(839:3).4: g_960 into ^387
	movb g_960(%rip), %cl
	# LowerBasicConversion(840:3): i8 ^387 -> i64 ^388
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerLoad(841:3).2: (^9) into i32 ^389
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(842:3): move argument i64 ^388
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(842:3): move argument ptr @.str.43
	leaq .str.43(%rip), %rsi
	# SetupCalls(842:3): move argument i32 ^389
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(843:3).4: g_1154 into ^390
	movw g_1154(%rip), %cx
	# LowerBasicConversion(844:3): i16 ^390 -> i64 ^391
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(845:3).2: (^9) into i32 ^392
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(846:3): move argument i64 ^391
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(846:3): move argument ptr @.str.44
	leaq .str.44(%rip), %rsi
	# SetupCalls(846:3): move argument i32 ^392
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(847:3).4: g_1447 into ^393
	movb g_1447(%rip), %al
	movsbq %al, %rcx
	# LowerLoad(849:3).2: (^9) into i32 ^395
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(850:3): move argument i64 ^394
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(850:3): move argument ptr @.str.45
	leaq .str.45(%rip), %rsi
	# SetupCalls(850:3): move argument i32 ^395
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(851:3).4: g_1567 into ^396
	movb g_1567(%rip), %al
	movsbq %al, %rcx
	# LowerLoad(853:3).2: (^9) into i32 ^398
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(854:3): move argument i64 ^397
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(854:3): move argument ptr @.str.46
	leaq .str.46(%rip), %rsi
	# SetupCalls(854:3): move argument i32 ^398
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(855:3).4: g_1628 into ^399
	movl g_1628(%rip), %eax
	movslq %eax, %rcx
	# LowerLoad(857:3).2: (^9) into i32 ^401
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(858:3): move argument i64 ^400
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(858:3): move argument ptr @.str.47
	leaq .str.47(%rip), %rsi
	# SetupCalls(858:3): move argument i32 ^401
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(859:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M2482:
	# LowerLoad(863:3).2: (^6) into i32 ^403
	movl (%r12), %eax
	# LowerIcmp(864:3): i32 ^403 vs. intlike 10
	cmpl $10, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2489
	jmp .__main__M2627
	.__main__M2489:
	# LowerStore(868:3).3: mov $imm, (^7)
	movl $0, (%r13)
	.__main__M2492:
	# LowerLoad(872:3).2: (^7) into i32 ^407
	movl (%r13), %eax
	# LowerIcmp(873:3): i32 ^407 vs. intlike 9
	cmpl $9, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2499
	jmp .__main__M2618
	.__main__M2499:
	# LowerLoad(877:3).2: (^6) into i32 ^410
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_1636(%rip), %rsi
	# tt = Pointer, type = [10 x [9 x i32]]
	# LowerGetelementptr(879:3): array/pointer-type, dynamic index -> ^412
	# index ^411 -> temp ^754
	movq %rcx, %rdx
	# Multiply temp ^754 by 36 start
	# Clobber %rdx
	movq %rdx, -64(%rbp)
	movq %rdx, %rax
	movq $36, %rcx
	mulq %rcx
	# Unclobber %rdx
	movq -64(%rbp), %rdx
	movq %rax, %rdx
	# Multiply end
	# temp ^754 -> operand ^412
	movq %rdx, %rax
	# Result ^412 += skip 0
	addq $0, %rax
	# Result ^412 += base pointer ^753
	addq %rsi, %rax
	# LowerLoad(880:3).2: (^7) into i32 ^413
	movl (%r13), %ecx
	movslq %ecx, %rdx
	# tt = Pointer, type = [9 x i32]
	# LowerGetelementptr(882:3): array/pointer-type, dynamic index -> ^415
	# index ^414 -> temp ^756
	movq %rdx, %rsi
	# Multiply temp ^756 by 4 start
	shlq $2, %rsi
	# Multiply end
	# temp ^756 -> operand ^415
	movq %rsi, %rcx
	# Result ^415 += skip 0
	addq $0, %rcx
	# Result ^415 += base pointer ^412
	addq %rax, %rcx
	# LowerLoad(883:3).2: (^415) into i32 ^416
	movl (%rcx), %eax
	movslq %eax, %rcx
	# LowerLoad(885:3).2: (^9) into i32 ^418
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(886:3): move argument i64 ^417
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(886:3): move argument ptr @.str.48
	leaq .str.48(%rip), %rsi
	# SetupCalls(886:3): move argument i32 ^418
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(887:3).2: (^9) into i32 ^419
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(888:3): i32 ^419 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2576
	jmp .__main__M2609
	.__main__M2576:
	# LowerLoad(892:3).2: (^6) into i32 ^422
	movl (%r12), %eax
	# LowerLoad(893:3).2: (^7) into i32 ^423
	movl (%r13), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(894:3): move argument ptr @.str.37
	leaq .str.37(%rip), %rdi
	# SetupCalls(894:3): move argument i32 ^422
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(894:3): move argument i32 ^423
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(894:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	.__main__M2609:
	# LowerLoad(901:3).2: (^7) into i32 ^427
	movl (%r13), %eax
	# LowerMath(902:3): ^427, 1 into i32 ^428
	addl $1, %eax
	# LowerStore(903:3).9: mov i32 ^428, (^7)
	movl %eax, (%r13)
	jmp .__main__M2492
	.__main__M2618:
	# LowerLoad(910:3).2: (^6) into i32 ^431
	movl (%r12), %eax
	# LowerMath(911:3): ^431, 1 into i32 ^432
	addl $1, %eax
	# LowerStore(912:3).9: mov i32 ^432, (^6)
	movl %eax, (%r12)
	jmp .__main__M2482
	.__main__M2627:
	# LowerLoad(916:3).4: g_1637 into ^434
	movw g_1637(%rip), %cx
	# LowerBasicConversion(917:3): i16 ^434 -> i64 ^435
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(918:3).2: (^9) into i32 ^436
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(919:3): move argument i64 ^435
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(919:3): move argument ptr @.str.49
	leaq .str.49(%rip), %rsi
	# SetupCalls(919:3): move argument i32 ^436
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(920:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M2663:
	# LowerLoad(924:3).2: (^6) into i32 ^438
	movl (%r12), %eax
	# LowerIcmp(925:3): i32 ^438 vs. intlike 4
	cmpl $4, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2670
	jmp .__main__M2762
	.__main__M2670:
	# LowerLoad(929:3).2: (^6) into i32 ^441
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_1639(%rip), %rdx
	# tt = Pointer, type = [4 x i16]
	# LowerGetelementptr(931:3): array/pointer-type, dynamic index -> ^443
	# index ^442 -> temp ^758
	movq %rcx, %rsi
	# Multiply temp ^758 by 2 start
	shlq $1, %rsi
	# Multiply end
	# temp ^758 -> operand ^443
	movq %rsi, %rax
	# Result ^443 += skip 0
	addq $0, %rax
	# Result ^443 += base pointer ^757
	addq %rdx, %rax
	# LowerLoad(932:3).2: (^443) into i16 ^444
	movw (%rax), %cx
	movswq %cx, %rdx
	# LowerLoad(934:3).2: (^9) into i32 ^446
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rdx
	movq %rdx, -64(%rbp)
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(935:3): move argument i64 ^445
	# Fixed movzx with identical source and destination widths
	movq %rdx, %rdi
	# SetupCalls(935:3): move argument ptr @.str.50
	leaq .str.50(%rip), %rsi
	# SetupCalls(935:3): move argument i32 ^446
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# Unclobber %rdx
	movq -64(%rbp), %rdx
	# LowerLoad(936:3).2: (^9) into i32 ^447
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(937:3): i32 ^447 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2724
	jmp .__main__M2753
	.__main__M2724:
	# LowerLoad(941:3).2: (^6) into i32 ^450
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(942:3): move argument ptr @.str.12
	leaq .str.12(%rip), %rdi
	# SetupCalls(942:3): move argument i32 ^450
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(942:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	.__main__M2753:
	# LowerLoad(949:3).2: (^6) into i32 ^454
	movl (%r12), %eax
	# LowerMath(950:3): ^454, 1 into i32 ^455
	addl $1, %eax
	# LowerStore(951:3).9: mov i32 ^455, (^6)
	movl %eax, (%r12)
	jmp .__main__M2663
	.__main__M2762:
	# LowerStore(955:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M2765:
	# LowerLoad(959:3).2: (^6) into i32 ^458
	movl (%r12), %eax
	# LowerIcmp(960:3): i32 ^458 vs. intlike 5
	cmpl $5, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2772
	jmp .__main__M2867
	.__main__M2772:
	# LowerLoad(964:3).2: (^6) into i32 ^461
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_1702(%rip), %rsi
	# tt = Pointer, type = [5 x i16]
	# LowerGetelementptr(966:3): array/pointer-type, dynamic index -> ^463
	# index ^462 -> temp ^760
	movq %rcx, %rdx
	# Multiply temp ^760 by 2 start
	shlq $1, %rdx
	# Multiply end
	# temp ^760 -> operand ^463
	movq %rdx, %rax
	# Result ^463 += skip 0
	addq $0, %rax
	# Result ^463 += base pointer ^759
	addq %rsi, %rax
	# LowerLoad(967:3).2: (^463) into i16 ^464
	movw (%rax), %cx
	# LowerBasicConversion(968:3): i16 ^464 -> i64 ^465
	# Truncate value to 16 bits
	andl $65535, %ecx
	# LowerLoad(969:3).2: (^9) into i32 ^466
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(970:3): move argument i64 ^465
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(970:3): move argument ptr @.str.51
	leaq .str.51(%rip), %rsi
	# SetupCalls(970:3): move argument i32 ^466
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(971:3).2: (^9) into i32 ^467
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(972:3): i32 ^467 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M2829
	jmp .__main__M2858
	.__main__M2829:
	# LowerLoad(976:3).2: (^6) into i32 ^470
	movl (%r12), %eax
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(977:3): move argument ptr @.str.12
	leaq .str.12(%rip), %rdi
	# SetupCalls(977:3): move argument i32 ^470
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(977:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	.__main__M2858:
	# LowerLoad(984:3).2: (^6) into i32 ^474
	movl (%r12), %eax
	# LowerMath(985:3): ^474, 1 into i32 ^475
	addl $1, %eax
	# LowerStore(986:3).9: mov i32 ^475, (^6)
	movl %eax, (%r12)
	jmp .__main__M2765
	.__main__M2867:
	# LowerLoad(990:3).4: g_1733 into ^477
	movq g_1733(%rip), %rcx
	# LowerLoad(991:3).2: (^9) into i32 ^478
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(992:3): move argument i64 ^477
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(992:3): move argument ptr @.str.52
	leaq .str.52(%rip), %rsi
	# SetupCalls(992:3): move argument i32 ^478
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(993:3).4: g_1737 into ^479
	movb g_1737(%rip), %al
	movsbq %al, %rcx
	# LowerLoad(995:3).2: (^9) into i32 ^481
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(996:3): move argument i64 ^480
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(996:3): move argument ptr @.str.53
	leaq .str.53(%rip), %rsi
	# SetupCalls(996:3): move argument i32 ^481
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(997:3).4: g_1758 into ^482
	movl g_1758(%rip), %ecx
	# LowerBasicConversion(998:3): i32 ^482 -> i64 ^483
	# LowerLoad(999:3).2: (^9) into i32 ^484
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(1000:3): move argument i64 ^483
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1000:3): move argument ptr @.str.54
	leaq .str.54(%rip), %rsi
	# SetupCalls(1000:3): move argument i32 ^484
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1001:3).4: g_1831 into ^485
	movb g_1831(%rip), %cl
	# LowerBasicConversion(1002:3): i8 ^485 -> i64 ^486
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerLoad(1003:3).2: (^9) into i32 ^487
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(1004:3): move argument i64 ^486
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1004:3): move argument ptr @.str.55
	leaq .str.55(%rip), %rsi
	# SetupCalls(1004:3): move argument i32 ^487
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1005:3).4: g_1926 into ^488
	movl g_1926(%rip), %ecx
	# LowerBasicConversion(1006:3): i32 ^488 -> i64 ^489
	# LowerLoad(1007:3).2: (^9) into i32 ^490
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(1008:3): move argument i64 ^489
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1008:3): move argument ptr @.str.56
	leaq .str.56(%rip), %rsi
	# SetupCalls(1008:3): move argument i32 ^490
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1009:3).4: g_1937 into ^491
	movw g_1937(%rip), %ax
	movswq %ax, %rcx
	# LowerLoad(1011:3).2: (^9) into i32 ^493
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(1012:3): move argument i64 ^492
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1012:3): move argument ptr @.str.57
	leaq .str.57(%rip), %rsi
	# SetupCalls(1012:3): move argument i32 ^493
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(1013:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M3055:
	# LowerLoad(1017:3).2: (^6) into i32 ^495
	movl (%r12), %eax
	# LowerIcmp(1018:3): i32 ^495 vs. intlike 5
	cmpl $5, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3062
	jmp .__main__M3246
	.__main__M3062:
	# LowerStore(1022:3).3: mov $imm, (^7)
	movl $0, (%r13)
	.__main__M3065:
	# LowerLoad(1026:3).2: (^7) into i32 ^499
	movl (%r13), %eax
	# LowerIcmp(1027:3): i32 ^499 vs. intlike 8
	cmpl $8, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3072
	jmp .__main__M3237
	.__main__M3072:
	# LowerStore(1031:3).3: mov $imm, (^8)
	movl $0, (%rbx)
	.__main__M3075:
	# LowerLoad(1035:3).2: (^8) into i32 ^503
	movl (%rbx), %eax
	# LowerIcmp(1036:3): i32 ^503 vs. intlike 5
	cmpl $5, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3082
	jmp .__main__M3228
	.__main__M3082:
	# LowerLoad(1040:3).2: (^6) into i32 ^506
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_2031(%rip), %rsi
	# tt = Pointer, type = [5 x [8 x [5 x i16]]]
	# LowerGetelementptr(1042:3): array/pointer-type, dynamic index -> ^508
	# index ^507 -> temp ^762
	movq %rcx, %rdx
	# Multiply temp ^762 by 80 start
	# Clobber %rdx
	movq %rdx, -64(%rbp)
	movq %rdx, %rax
	movq $80, %rcx
	mulq %rcx
	# Unclobber %rdx
	movq -64(%rbp), %rdx
	movq %rax, %rdx
	# Multiply end
	# temp ^762 -> operand ^508
	movq %rdx, %rcx
	# Result ^508 += skip 0
	addq $0, %rcx
	# Result ^508 += base pointer ^761
	addq %rsi, %rcx
	# LowerLoad(1043:3).2: (^7) into i32 ^509
	movl (%r13), %eax
	movslq %eax, %rdx
	# tt = Pointer, type = [8 x [5 x i16]]
	# LowerGetelementptr(1045:3): array/pointer-type, dynamic index -> ^511
	# index ^510 -> temp ^764
	movq %rdx, %rsi
	# Multiply temp ^764 by 10 start
	movq %rsi, %rax
	movq $10, %rsi
	mulq %rsi
	movq %rax, %rsi
	# Multiply end
	# temp ^764 -> operand ^511
	movq %rsi, %rax
	# Result ^511 += skip 0
	addq $0, %rax
	# Result ^511 += base pointer ^508
	addq %rcx, %rax
	# LowerLoad(1046:3).2: (^8) into i32 ^512
	movl (%rbx), %ecx
	movslq %ecx, %rdx
	# tt = Pointer, type = [5 x i16]
	# LowerGetelementptr(1048:3): array/pointer-type, dynamic index -> ^514
	# index ^513 -> temp ^766
	movq %rdx, %rsi
	# Multiply temp ^766 by 2 start
	shlq $1, %rsi
	# Multiply end
	# temp ^766 -> operand ^514
	movq %rsi, %rcx
	# Result ^514 += skip 0
	addq $0, %rcx
	# Result ^514 += base pointer ^511
	addq %rax, %rcx
	# LowerLoad(1049:3).2: (^514) into i16 ^515
	movw (%rcx), %ax
	movswq %ax, %rcx
	# LowerLoad(1051:3).2: (^9) into i32 ^517
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(1052:3): move argument i64 ^516
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1052:3): move argument ptr @.str.58
	leaq .str.58(%rip), %rsi
	# SetupCalls(1052:3): move argument i32 ^517
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1053:3).2: (^9) into i32 ^518
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(1054:3): i32 ^518 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3182
	jmp .__main__M3219
	.__main__M3182:
	# LowerLoad(1058:3).2: (^6) into i32 ^521
	movl (%r12), %eax
	# LowerLoad(1059:3).2: (^7) into i32 ^522
	movl (%r13), %ecx
	# LowerLoad(1060:3).2: (^8) into i32 ^523
	movl (%rbx), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(1061:3): move argument ptr @.str.2
	leaq .str.2(%rip), %rdi
	# SetupCalls(1061:3): move argument i32 ^521
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(1061:3): move argument i32 ^522
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	# SetupCalls(1061:3): move argument i32 ^523
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1061:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	.__main__M3219:
	# LowerLoad(1068:3).2: (^8) into i32 ^527
	movl (%rbx), %eax
	# LowerMath(1069:3): ^527, 1 into i32 ^528
	addl $1, %eax
	# LowerStore(1070:3).9: mov i32 ^528, (^8)
	movl %eax, (%rbx)
	jmp .__main__M3075
	.__main__M3228:
	# LowerLoad(1077:3).2: (^7) into i32 ^531
	movl (%r13), %eax
	# LowerMath(1078:3): ^531, 1 into i32 ^532
	addl $1, %eax
	# LowerStore(1079:3).9: mov i32 ^532, (^7)
	movl %eax, (%r13)
	jmp .__main__M3065
	.__main__M3237:
	# LowerLoad(1086:3).2: (^6) into i32 ^535
	movl (%r12), %eax
	# LowerMath(1087:3): ^535, 1 into i32 ^536
	addl $1, %eax
	# LowerStore(1088:3).9: mov i32 ^536, (^6)
	movl %eax, (%r12)
	jmp .__main__M3055
	.__main__M3246:
	# LowerLoad(1092:3).4: g_2146 into ^538
	movl g_2146(%rip), %eax
	# LowerBasicConversion(1093:3): i32 ^538 -> i64 ^539
	# LowerLoad(1094:3).2: (^9) into i32 ^540
	movq -48(%rbp), %rdx
	movl (%rdx), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(1095:3): move argument i64 ^539
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1095:3): move argument ptr @.str.59
	leaq .str.59(%rip), %rsi
	# SetupCalls(1095:3): move argument i32 ^540
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1096:3).4: g_2252 into ^541
	movb g_2252(%rip), %al
	movsbq %al, %rcx
	# LowerLoad(1098:3).2: (^9) into i32 ^543
	movq -48(%rbp), %rdx
	movl (%rdx), %eax
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(1099:3): move argument i64 ^542
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1099:3): move argument ptr @.str.60
	leaq .str.60(%rip), %rsi
	# SetupCalls(1099:3): move argument i32 ^543
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq transparent_crc
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1100:3).4: g_2285 into ^544
	movl g_2285(%rip), %eax
	# LowerBasicConversion(1101:3): i32 ^544 -> i64 ^545
	# LowerLoad(1102:3).2: (^9) into i32 ^546
	movq -48(%rbp), %rdx
	movl (%rdx), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(1103:3): move argument i64 ^545
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1103:3): move argument ptr @.str.61
	leaq .str.61(%rip), %rsi
	# SetupCalls(1103:3): move argument i32 ^546
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1104:3).4: g_2577 into ^547
	movq g_2577(%rip), %rax
	# LowerLoad(1105:3).2: (^9) into i32 ^548
	movq -48(%rbp), %rdx
	movl (%rdx), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(1106:3): move argument i64 ^547
	# Fixed movzx with identical source and destination widths
	movq %rax, %rdi
	# SetupCalls(1106:3): move argument ptr @.str.62
	leaq .str.62(%rip), %rsi
	# SetupCalls(1106:3): move argument i32 ^548
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1107:3).4: g_2613 into ^549
	movb g_2613(%rip), %al
	movsbq %al, %rcx
	# LowerLoad(1109:3).2: (^9) into i32 ^551
	movq -48(%rbp), %rdx
	movl (%rdx), %eax
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(1110:3): move argument i64 ^550
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1110:3): move argument ptr @.str.63
	leaq .str.63(%rip), %rsi
	# SetupCalls(1110:3): move argument i32 ^551
	# Fixed movzx with 32-bit source operand
	movl %eax, %edx
	callq transparent_crc
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(1111:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M3400:
	# LowerLoad(1115:3).2: (^6) into i32 ^553
	movl (%r12), %eax
	# LowerIcmp(1116:3): i32 ^553 vs. intlike 5
	cmpl $5, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3407
	jmp .__main__M3541
	.__main__M3407:
	# LowerStore(1120:3).3: mov $imm, (^7)
	movl $0, (%r13)
	.__main__M3410:
	# LowerLoad(1124:3).2: (^7) into i32 ^557
	movl (%r13), %eax
	# LowerIcmp(1125:3): i32 ^557 vs. intlike 4
	cmpl $4, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3417
	jmp .__main__M3532
	.__main__M3417:
	# LowerLoad(1129:3).2: (^6) into i32 ^560
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_2691(%rip), %rdx
	# tt = Pointer, type = [5 x [4 x i16]]
	# LowerGetelementptr(1131:3): array/pointer-type, dynamic index -> ^562
	# index ^561 -> temp ^768
	movq %rcx, %rsi
	# Multiply temp ^768 by 8 start
	shlq $3, %rsi
	# Multiply end
	# temp ^768 -> operand ^562
	movq %rsi, %rax
	# Result ^562 += skip 0
	addq $0, %rax
	# Result ^562 += base pointer ^767
	addq %rdx, %rax
	# LowerLoad(1132:3).2: (^7) into i32 ^563
	movl (%r13), %ecx
	movslq %ecx, %rdx
	# tt = Pointer, type = [4 x i16]
	# LowerGetelementptr(1134:3): array/pointer-type, dynamic index -> ^565
	# index ^564 -> temp ^769
	movq %rdx, %rsi
	# Multiply temp ^769 by 2 start
	shlq $1, %rsi
	# Multiply end
	# temp ^769 -> operand ^565
	movq %rsi, %rcx
	# Result ^565 += skip 0
	addq $0, %rcx
	# Result ^565 += base pointer ^562
	addq %rax, %rcx
	# LowerLoad(1135:3).2: (^565) into i16 ^566
	movw (%rcx), %dx
	# LowerBasicConversion(1136:3): i16 ^566 -> i64 ^567
	# Truncate value to 16 bits
	andl $65535, %edx
	# LowerLoad(1137:3).2: (^9) into i32 ^568
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rdx
	movq %rdx, -64(%rbp)
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1138:3): move argument i64 ^567
	# Fixed movzx with identical source and destination widths
	movq %rdx, %rdi
	# SetupCalls(1138:3): move argument ptr @.str.64
	leaq .str.64(%rip), %rsi
	# SetupCalls(1138:3): move argument i32 ^568
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# Unclobber %rdx
	movq -64(%rbp), %rdx
	# LowerLoad(1139:3).2: (^9) into i32 ^569
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(1140:3): i32 ^569 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3490
	jmp .__main__M3523
	.__main__M3490:
	# LowerLoad(1144:3).2: (^6) into i32 ^572
	movl (%r12), %eax
	# LowerLoad(1145:3).2: (^7) into i32 ^573
	movl (%r13), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(1146:3): move argument ptr @.str.37
	leaq .str.37(%rip), %rdi
	# SetupCalls(1146:3): move argument i32 ^572
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(1146:3): move argument i32 ^573
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1146:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	.__main__M3523:
	# LowerLoad(1153:3).2: (^7) into i32 ^577
	movl (%r13), %eax
	# LowerMath(1154:3): ^577, 1 into i32 ^578
	addl $1, %eax
	# LowerStore(1155:3).9: mov i32 ^578, (^7)
	movl %eax, (%r13)
	jmp .__main__M3410
	.__main__M3532:
	# LowerLoad(1162:3).2: (^6) into i32 ^581
	movl (%r12), %eax
	# LowerMath(1163:3): ^581, 1 into i32 ^582
	addl $1, %eax
	# LowerStore(1164:3).9: mov i32 ^582, (^6)
	movl %eax, (%r12)
	jmp .__main__M3400
	.__main__M3541:
	# LowerLoad(1168:3).4: g_2782 into ^584
	movb g_2782(%rip), %cl
	# LowerBasicConversion(1169:3): i8 ^584 -> i64 ^585
	# Truncate value to 8 bits
	andl $255, %ecx
	# LowerLoad(1170:3).2: (^9) into i32 ^586
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(1171:3): move argument i64 ^585
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1171:3): move argument ptr @.str.65
	leaq .str.65(%rip), %rsi
	# SetupCalls(1171:3): move argument i32 ^586
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1172:3).2: (^9) into i32 ^587
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1173:3): move argument i64 -10
	movq $-10, %rdi
	# SetupCalls(1173:3): move argument ptr @.str.66
	leaq .str.66(%rip), %rsi
	# SetupCalls(1173:3): move argument i32 ^587
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1174:3).2: (^9) into i32 ^588
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1175:3): move argument i64 2
	movq $2, %rdi
	# SetupCalls(1175:3): move argument ptr @.str.67
	leaq .str.67(%rip), %rsi
	# SetupCalls(1175:3): move argument i32 ^588
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(1176:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M3631:
	# LowerLoad(1180:3).2: (^6) into i32 ^590
	movl (%r12), %eax
	# LowerIcmp(1181:3): i32 ^590 vs. intlike 7
	cmpl $7, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3638
	jmp .__main__M3821
	.__main__M3638:
	# LowerStore(1185:3).3: mov $imm, (^7)
	movl $0, (%r13)
	.__main__M3641:
	# LowerLoad(1189:3).2: (^7) into i32 ^594
	movl (%r13), %eax
	# LowerIcmp(1190:3): i32 ^594 vs. intlike 10
	cmpl $10, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3648
	jmp .__main__M3812
	.__main__M3648:
	# LowerStore(1194:3).3: mov $imm, (^8)
	movl $0, (%rbx)
	.__main__M3651:
	# LowerLoad(1198:3).2: (^8) into i32 ^598
	movl (%rbx), %eax
	# LowerIcmp(1199:3): i32 ^598 vs. intlike 3
	cmpl $3, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3658
	jmp .__main__M3803
	.__main__M3658:
	# LowerLoad(1203:3).2: (^6) into i32 ^601
	movl (%r12), %eax
	movslq %eax, %rcx
	leaq g_3056(%rip), %rsi
	# tt = Pointer, type = [7 x [10 x [3 x i8]]]
	# LowerGetelementptr(1205:3): array/pointer-type, dynamic index -> ^603
	# index ^602 -> temp ^771
	movq %rcx, %rdx
	# Multiply temp ^771 by 30 start
	# Clobber %rdx
	movq %rdx, -64(%rbp)
	movq %rdx, %rax
	movq $30, %rcx
	mulq %rcx
	# Unclobber %rdx
	movq -64(%rbp), %rdx
	movq %rax, %rdx
	# Multiply end
	# temp ^771 -> operand ^603
	movq %rdx, %rcx
	# Result ^603 += skip 0
	addq $0, %rcx
	# Result ^603 += base pointer ^770
	addq %rsi, %rcx
	# LowerLoad(1206:3).2: (^7) into i32 ^604
	movl (%r13), %eax
	movslq %eax, %rdx
	# tt = Pointer, type = [10 x [3 x i8]]
	# LowerGetelementptr(1208:3): array/pointer-type, dynamic index -> ^606
	# index ^605 -> temp ^773
	movq %rdx, %rsi
	# Multiply temp ^773 by 3 start
	movq %rsi, %rax
	movq $3, %rsi
	mulq %rsi
	movq %rax, %rsi
	# Multiply end
	# temp ^773 -> operand ^606
	movq %rsi, %rax
	# Result ^606 += skip 0
	addq $0, %rax
	# Result ^606 += base pointer ^603
	addq %rcx, %rax
	# LowerLoad(1209:3).2: (^8) into i32 ^607
	movl (%rbx), %ecx
	movslq %ecx, %rdx
	# tt = Pointer, type = [3 x i8]
	# LowerGetelementptr(1211:3): array/pointer-type, dynamic index -> ^609
	# index ^608 -> temp ^775
	movq %rdx, %rcx
	# Multiply temp ^775 by 1 start
	# Multiply end
	# temp ^775 -> operand ^609
	# Result ^609 += skip 0
	addq $0, %rcx
	# Result ^609 += base pointer ^606
	addq %rax, %rcx
	# LowerLoad(1212:3).2: (^609) into i8 ^610
	movb (%rcx), %al
	movsbq %al, %rcx
	# LowerLoad(1214:3).2: (^9) into i32 ^612
	movq -48(%rbp), %rax
	movl (%rax), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# SetupCalls(1215:3): move argument i64 ^611
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1215:3): move argument ptr @.str.68
	leaq .str.68(%rip), %rsi
	# SetupCalls(1215:3): move argument i32 ^612
	# Fixed movzx with 32-bit source operand
	movl %r8d, %edx
	callq transparent_crc
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1216:3).2: (^9) into i32 ^613
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# LowerIcmp(1217:3): i32 ^613 vs. intlike 0
	cmpl $0, %ecx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M3757
	jmp .__main__M3794
	.__main__M3757:
	# LowerLoad(1221:3).2: (^6) into i32 ^616
	movl (%r12), %eax
	# LowerLoad(1222:3).2: (^7) into i32 ^617
	movl (%r13), %ecx
	# LowerLoad(1223:3).2: (^8) into i32 ^618
	movl (%rbx), %r8d
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# Clobber %r8
	movq %r8, -80(%rbp)
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(1224:3): move argument ptr @.str.2
	leaq .str.2(%rip), %rdi
	# SetupCalls(1224:3): move argument i32 ^616
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(1224:3): move argument i32 ^617
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	# SetupCalls(1224:3): move argument i32 ^618
	# Fixed movzx with 32-bit source operand
	movl %r8d, %ecx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1224:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	# Unclobber %r8
	movq -80(%rbp), %r8
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	.__main__M3794:
	# LowerLoad(1231:3).2: (^8) into i32 ^622
	movl (%rbx), %eax
	# LowerMath(1232:3): ^622, 1 into i32 ^623
	addl $1, %eax
	# LowerStore(1233:3).9: mov i32 ^623, (^8)
	movl %eax, (%rbx)
	jmp .__main__M3651
	.__main__M3803:
	# LowerLoad(1240:3).2: (^7) into i32 ^626
	movl (%r13), %eax
	# LowerMath(1241:3): ^626, 1 into i32 ^627
	addl $1, %eax
	# LowerStore(1242:3).9: mov i32 ^627, (^7)
	movl %eax, (%r13)
	jmp .__main__M3641
	.__main__M3812:
	# LowerLoad(1249:3).2: (^6) into i32 ^630
	movl (%r12), %eax
	# LowerMath(1250:3): ^630, 1 into i32 ^631
	addl $1, %eax
	# LowerStore(1251:3).9: mov i32 ^631, (^6)
	movl %eax, (%r12)
	jmp .__main__M3631
	.__main__M3821:
	# LowerLoad(1255:3).4: g_3218 into ^633
	movw g_3218(%rip), %ax
	movswq %ax, %rbx
	# LowerLoad(1257:3).2: (^9) into i32 ^635
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1258:3): move argument i64 ^634
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1258:3): move argument ptr @.str.69
	leaq .str.69(%rip), %rsi
	# SetupCalls(1258:3): move argument i32 ^635
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1259:3).4: g_3318 into ^636
	movl g_3318(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(1261:3).2: (^9) into i32 ^638
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1262:3): move argument i64 ^637
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1262:3): move argument ptr @.str.70
	leaq .str.70(%rip), %rsi
	# SetupCalls(1262:3): move argument i32 ^638
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1263:3).4: g_3326 into ^639
	movw g_3326(%rip), %bx
	# LowerBasicConversion(1264:3): i16 ^639 -> i64 ^640
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(1265:3).2: (^9) into i32 ^641
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1266:3): move argument i64 ^640
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1266:3): move argument ptr @.str.71
	leaq .str.71(%rip), %rsi
	# SetupCalls(1266:3): move argument i32 ^641
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1267:3).4: g_3368 into ^642
	movq g_3368(%rip), %rbx
	# LowerLoad(1268:3).2: (^9) into i32 ^643
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1269:3): move argument i64 ^642
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1269:3): move argument ptr @.str.72
	leaq .str.72(%rip), %rsi
	# SetupCalls(1269:3): move argument i32 ^643
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1270:3).2: (^9) into i32 ^644
	movq -48(%rbp), %rax
	movl (%rax), %ebx
	# SetupCalls(1271:3): move argument i64 -1
	movq $-1, %rdi
	# SetupCalls(1271:3): move argument ptr @.str.73
	leaq .str.73(%rip), %rsi
	# SetupCalls(1271:3): move argument i32 ^644
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq transparent_crc
	# LowerLoad(1272:3).2: (^9) into i32 ^645
	movq -48(%rbp), %rax
	movl (%rax), %ebx
	# SetupCalls(1273:3): move argument i64 -10
	movq $-10, %rdi
	# SetupCalls(1273:3): move argument ptr @.str.74
	leaq .str.74(%rip), %rsi
	# SetupCalls(1273:3): move argument i32 ^645
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq transparent_crc
	# LowerLoad(1274:3).4: g_3513 into ^646
	movb g_3513(%rip), %al
	# LowerBasicConversion(1275:3): i8 ^646 -> i64 ^647
	movq %rax, %rbx
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(1276:3).2: (^9) into i32 ^648
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1277:3): move argument i64 ^647
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1277:3): move argument ptr @.str.75
	leaq .str.75(%rip), %rsi
	# SetupCalls(1277:3): move argument i32 ^648
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1278:3).4: g_3516 into ^649
	movw g_3516(%rip), %bx
	# LowerBasicConversion(1279:3): i16 ^649 -> i64 ^650
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(1280:3).2: (^9) into i32 ^651
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1281:3): move argument i64 ^650
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1281:3): move argument ptr @.str.76
	leaq .str.76(%rip), %rsi
	# SetupCalls(1281:3): move argument i32 ^651
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1282:3).4: g_3529 into ^652
	movb g_3529(%rip), %al
	movsbq %al, %rbx
	# LowerLoad(1284:3).2: (^9) into i32 ^654
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1285:3): move argument i64 ^653
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1285:3): move argument ptr @.str.77
	leaq .str.77(%rip), %rsi
	# SetupCalls(1285:3): move argument i32 ^654
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1286:3).4: g_3532 into ^655
	movb g_3532(%rip), %bl
	# LowerBasicConversion(1287:3): i8 ^655 -> i64 ^656
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(1288:3).2: (^9) into i32 ^657
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1289:3): move argument i64 ^656
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1289:3): move argument ptr @.str.78
	leaq .str.78(%rip), %rsi
	# SetupCalls(1289:3): move argument i32 ^657
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1290:3).4: g_3667 into ^658
	movb g_3667(%rip), %bl
	# LowerBasicConversion(1291:3): i8 ^658 -> i64 ^659
	# Truncate value to 8 bits
	andl $255, %ebx
	# LowerLoad(1292:3).2: (^9) into i32 ^660
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1293:3): move argument i64 ^659
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1293:3): move argument ptr @.str.79
	leaq .str.79(%rip), %rsi
	# SetupCalls(1293:3): move argument i32 ^660
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1294:3).4: g_3718 into ^661
	movl g_3718(%rip), %ebx
	# LowerBasicConversion(1295:3): i32 ^661 -> i64 ^662
	# LowerLoad(1296:3).2: (^9) into i32 ^663
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1297:3): move argument i64 ^662
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1297:3): move argument ptr @.str.80
	leaq .str.80(%rip), %rsi
	# SetupCalls(1297:3): move argument i32 ^663
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1298:3).2: (^9) into i32 ^664
	movq -48(%rbp), %rax
	movl (%rax), %ebx
	# SetupCalls(1299:3): move argument i64 3793563439
	movabsq $3793563439, %rax
	movq %rax, %rdi
	# SetupCalls(1299:3): move argument ptr @.str.81
	leaq .str.81(%rip), %rsi
	# SetupCalls(1299:3): move argument i32 ^664
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq transparent_crc
	# LowerLoad(1300:3).4: g_3728 into ^665
	movw g_3728(%rip), %ax
	movswq %ax, %rbx
	# LowerLoad(1302:3).2: (^9) into i32 ^667
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1303:3): move argument i64 ^666
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1303:3): move argument ptr @.str.82
	leaq .str.82(%rip), %rsi
	# SetupCalls(1303:3): move argument i32 ^667
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1304:3).4: g_3729 into ^668
	movw g_3729(%rip), %bx
	# LowerBasicConversion(1305:3): i16 ^668 -> i64 ^669
	# Truncate value to 16 bits
	andl $65535, %ebx
	# LowerLoad(1306:3).2: (^9) into i32 ^670
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1307:3): move argument i64 ^669
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1307:3): move argument ptr @.str.83
	leaq .str.83(%rip), %rsi
	# SetupCalls(1307:3): move argument i32 ^670
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1308:3).4: g_3758 into ^671
	movb g_3758(%rip), %al
	movsbq %al, %rbx
	# LowerLoad(1310:3).2: (^9) into i32 ^673
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1311:3): move argument i64 ^672
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1311:3): move argument ptr @.str.84
	leaq .str.84(%rip), %rsi
	# SetupCalls(1311:3): move argument i32 ^673
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1312:3).4: g_3812 into ^674
	movl g_3812(%rip), %eax
	movslq %eax, %rbx
	# LowerLoad(1314:3).2: (^9) into i32 ^676
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1315:3): move argument i64 ^675
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1315:3): move argument ptr @.str.85
	leaq .str.85(%rip), %rsi
	# SetupCalls(1315:3): move argument i32 ^676
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerStore(1316:3).3: mov $imm, (^6)
	movl $0, (%r12)
	.__main__M4347:
	# LowerLoad(1320:3).2: (^6) into i32 ^678
	movl (%r12), %eax
	# LowerIcmp(1321:3): i32 ^678 vs. intlike 1
	cmpl $1, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M4354
	jmp .__main__M4491
	.__main__M4354:
	# LowerStore(1325:3).3: mov $imm, (^7)
	movl $0, (%r13)
	.__main__M4357:
	# LowerLoad(1329:3).2: (^7) into i32 ^682
	movl (%r13), %eax
	# LowerIcmp(1330:3): i32 ^682 vs. intlike 3
	cmpl $3, %eax
	setl %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M4364
	jmp .__main__M4482
	.__main__M4364:
	# LowerLoad(1334:3).2: (^6) into i32 ^685
	movl (%r12), %eax
	movslq %eax, %rbx
	leaq g_3917(%rip), %rcx
	# tt = Pointer, type = [1 x [3 x i64]]
	# LowerGetelementptr(1336:3): array/pointer-type, dynamic index -> ^687
	# index ^686 -> temp ^777
	movq %rbx, %rdx
	# Multiply temp ^777 by 24 start
	# Clobber %rdx
	movq %rdx, -64(%rbp)
	movq %rdx, %rax
	movq $24, %rbx
	mulq %rbx
	# Unclobber %rdx
	movq -64(%rbp), %rdx
	movq %rax, %rdx
	# Multiply end
	# temp ^777 -> operand ^687
	movq %rdx, %rax
	# Result ^687 += skip 0
	addq $0, %rax
	# Result ^687 += base pointer ^776
	addq %rcx, %rax
	# LowerLoad(1337:3).2: (^7) into i32 ^688
	movl (%r13), %ebx
	movslq %ebx, %rcx
	# tt = Pointer, type = [3 x i64]
	# LowerGetelementptr(1339:3): array/pointer-type, dynamic index -> ^690
	# index ^689 -> temp ^779
	movq %rcx, %rdx
	# Multiply temp ^779 by 8 start
	shlq $3, %rdx
	# Multiply end
	# temp ^779 -> operand ^690
	movq %rdx, %rbx
	# Result ^690 += skip 0
	addq $0, %rbx
	# Result ^690 += base pointer ^687
	addq %rax, %rbx
	# LowerLoad(1340:3).2: (^690) into i64 ^691
	movq (%rbx), %rcx
	# LowerLoad(1341:3).2: (^9) into i32 ^692
	movq -48(%rbp), %rax
	movl (%rax), %ebx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1342:3): move argument i64 ^691
	# Fixed movzx with identical source and destination widths
	movq %rcx, %rdi
	# SetupCalls(1342:3): move argument ptr @.str.86
	leaq .str.86(%rip), %rsi
	# SetupCalls(1342:3): move argument i32 ^692
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1343:3).2: (^9) into i32 ^693
	movq -48(%rbp), %rax
	movl (%rax), %ebx
	# LowerIcmp(1344:3): i32 ^693 vs. intlike 0
	cmpl $0, %ebx
	setne %al
	andq $1, %rax
	cmpb $0, %al
	jne .__main__M4440
	jmp .__main__M4473
	.__main__M4440:
	# LowerLoad(1348:3).2: (^6) into i32 ^696
	movl (%r12), %eax
	# LowerLoad(1349:3).2: (^7) into i32 ^697
	movl (%r13), %ebx
	# Clobber %rax
	movq %rax, -56(%rbp)
	# SetupCalls(1350:3): move argument ptr @.str.37
	leaq .str.37(%rip), %rdi
	# SetupCalls(1350:3): move argument i32 ^696
	# Fixed movzx with 32-bit source operand
	movl %eax, %esi
	# SetupCalls(1350:3): move argument i32 ^697
	# Fixed movzx with 32-bit source operand
	movl %ebx, %edx
	movq $0, %rax
	callq printf@PLT
	# SetupCalls(1350:3): move i32 result from %rax
	movl %eax, %eax
	# Unclobber %rax
	movq -56(%rbp), %rax
	.__main__M4473:
	# LowerLoad(1357:3).2: (^7) into i32 ^701
	movl (%r13), %eax
	# LowerMath(1358:3): ^701, 1 into i32 ^702
	addl $1, %eax
	# LowerStore(1359:3).9: mov i32 ^702, (^7)
	movl %eax, (%r13)
	jmp .__main__M4357
	.__main__M4482:
	# LowerLoad(1366:3).2: (^6) into i32 ^705
	movl (%r12), %eax
	# LowerMath(1367:3): ^705, 1 into i32 ^706
	addl $1, %eax
	# LowerStore(1368:3).9: mov i32 ^706, (^6)
	movl %eax, (%r12)
	jmp .__main__M4347
	.__main__M4491:
	# LowerLoad(1372:3).4: g_3958 into ^708
	movq g_3958(%rip), %rbx
	# LowerLoad(1373:3).2: (^9) into i32 ^709
	movq -48(%rbp), %rax
	movl (%rax), %ecx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1374:3): move argument i64 ^708
	# Fixed movzx with identical source and destination widths
	movq %rbx, %rdi
	# SetupCalls(1374:3): move argument ptr @.str.87
	leaq .str.87(%rip), %rsi
	# SetupCalls(1374:3): move argument i32 ^709
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edx
	callq transparent_crc
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	# LowerLoad(1375:3).4: crc32_context into ^710
	movl crc32_context(%rip), %eax
	# LowerBasicConversion(1376:3): i32 ^710 -> i64 ^711
	# LowerLogic(1378:3): ^711, 4294967295 into i64 ^712
	movq %rax, %rbx
	movabsq $4294967295, %rax
	xorq %rax, %rbx
	# LowerTrunc(1378:3): 64 to 32, move and clear upper bits
	movl %ebx, %ecx
	# LowerLoad(1379:3).2: (^9) into i32 ^714
	movq -48(%rbp), %rax
	movl (%rax), %ebx
	# Clobber %rcx
	movq %rcx, -72(%rbp)
	# SetupCalls(1380:3): move argument i32 ^713
	# Fixed movzx with 32-bit source operand
	movl %ecx, %edi
	# SetupCalls(1380:3): move argument i32 ^714
	# Fixed movzx with 32-bit source operand
	movl %ebx, %esi
	callq platform_main_end
	# Unclobber %rcx
	movq -72(%rbp), %rcx
	movq $0, %rax
	movq -112(%rbp), %r15
	movq -120(%rbp), %r14
	movq -96(%rbp), %r13
	movq -88(%rbp), %r12
	movq -104(%rbp), %rbx
	movq %rbp, %rsp
	popq %rbp
	retq

